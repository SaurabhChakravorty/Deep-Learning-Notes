{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eSHhdguTHm0N"
   },
   "source": [
    "# Challenge: Get the best results on the [fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset!\n",
    "\n",
    "> \"Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\"\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/doc/img/fashion-mnist-sprite.png\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## TASK - Challenge: Get the best results on the fashionMNIST dataset!\n",
    "\n",
    "The challenge of this task is to get the best results on the fashionMNIST dataset by tuning hyperparameters of the model and observing convergence behavior.\n",
    "\n",
    "\"Best\" - for simplicity - means the highest accuracy on the validation set.\n",
    "\n",
    "\"Rules\":\n",
    "\n",
    "    You can change any hyperparameters,\n",
    "    including the number of layers,\n",
    "    width of the layers,\n",
    "    activation functions,\n",
    "    regularizers (and their parameters),\n",
    "    optimizer (and it's parameters), but\n",
    "    you should not change the model architecture, use only fully connected layers! (Even if you know any others... :-P\n",
    "\n",
    "Added constraint: The model with the \"best performance\" has to be saved, so it should not be just a printout happening once during training!\n",
    "\n",
    "And: You may NOT manipulate the validation set! :-P\n",
    "\n",
    "Happy coding! :-)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TIX2ehpiHm0S"
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 825
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "dcJxMEUUHu3M",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "81881ab4-17a4-47e0-969b-a6f3b6c55bc6"
   },
   "outputs": [],
   "source": [
    "! wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
    "! wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
    "! wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
    "! wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "BmhEB9dAHm0V",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gzip\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`.\n",
    "    \"\"\"\n",
    "    labels_path = os.path.join(path,'%s-labels-idx1-ubyte.gz' % kind)\n",
    "    images_path = os.path.join(path,'%s-images-idx3-ubyte.gz' % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "jFmPQL0xM_4p",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "cb3fa898-8839-458d-e967-6e67a1c3581d"
   },
   "outputs": [],
   "source": [
    "train_images, train_labels = load_mnist('.')\n",
    "# because of some limitations of Keras's softmax implementation, it's \n",
    "# advisable to normalise the images by dividing the intensities by the\n",
    "# maximal 255 value\n",
    "train_images = train_images / 255.\n",
    "\n",
    "valid_test_images, valid_test_labels = load_mnist('.', 't10k')\n",
    "\n",
    "valid_test_images = valid_test_images / 255. # the same normalization for valid and test\n",
    "\n",
    "valid_images = valid_test_images[:5000]\n",
    "valid_labels = valid_test_labels[:5000]\n",
    "test_images = valid_test_images[5000:]\n",
    "test_labels = valid_test_labels[5000:]\n",
    "\n",
    "print(train_images.shape, valid_images.shape, test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Aumcj_hUfBg4"
   },
   "source": [
    "Let's have a look at the first few training images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "o105FqR_fBg7",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "74f5ce4a-3f99-4734-b220-0aca434a70dd"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from math import ceil\n",
    "\n",
    "def show_images(images):\n",
    "    \"\"\"Show images in a grid\n",
    "    \"\"\"\n",
    "    n_rows = ceil(len(images) / 10)\n",
    "    fig, ax = plt.subplots(n_rows, 10, figsize=(15, 1.5 * n_rows),\n",
    "                           subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                           gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "    for i, _ in enumerate(images):\n",
    "        # below we scale back the intensities to display the images correctly\n",
    "        ax[i // 10, i % 10].imshow(255 * images[i].reshape(28, 28), cmap='Greys')\n",
    "\n",
    "show_images(train_images[:30])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GclmFak2s54y"
   },
   "source": [
    "# Model\n",
    "\n",
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "YicGfZ4ffBhK",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adadelta, Adam\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.backend import clear_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G3s8ZdftfBhd"
   },
   "source": [
    "We set the random seeds to get (as far as possible) reproducible results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "VFdlHKVDfBhi",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Fix seeds for (hopefully) reproducible results\n",
    "from numpy.random import seed\n",
    "seed(14)\n",
    "tf.random.set_seed(19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0L5qn2lXfBhp"
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "VpD2jPj6s3-g",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Task parameters\n",
    "\n",
    "input_size = 784\n",
    "n_classes = 10\n",
    "\n",
    "# Hyperparameters\n",
    "#################\n",
    "\n",
    "# dropout??? or no dropout???\n",
    "# dropout_rate = ???\n",
    "\n",
    "# regularization\n",
    "\n",
    "#lambda_ = 0.0000 ???\n",
    "# regularizer = l1(lambda_) or???\n",
    "# regularizer = None \n",
    "\n",
    "# weight initialization\n",
    "initializer = #???\n",
    "##########\n",
    "# Warning! \n",
    "##########\n",
    "# Possible bug in Keras Initalizers!\n",
    "# When stuck, use RandomUniform or RandomNormal!\n",
    "\n",
    "# Model parameters\n",
    "#################\n",
    "\n",
    "# hidden_layers\n",
    "hidden_layer_size = #???\n",
    "n_hidden_layers = #???\n",
    "hidden_layer_sizes = n_hidden_layers * [hidden_layer_size]\n",
    "\n",
    "# activation function\n",
    "activation_fun =  #???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QxyeFqibHm05"
   },
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "2Sc9NCoJfBh0",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "7e940ebd-1b09-4848-ee85-7fe89ff9e670"
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph() # It's good practice to clean and reset everything\n",
    "clear_session            # even using Keras\n",
    "\n",
    "\n",
    "# Model\n",
    "#######\n",
    "\n",
    "#Define input with input_size (achtung, vector! :-)\n",
    "....\n",
    "\n",
    "# Hidden layers\n",
    "\n",
    "cur_last_layer = x\n",
    "\n",
    "# Construct a for loop going over the values of hidden_layer_sizes\n",
    "# using cur_last_layer as pointer\n",
    "# build up the network layer by layer\n",
    "# use the parameters units, activation, kernel_regularizer, kernel_initializer, bias_initializer\n",
    "# Add a dopout layer after each one WHEN PARAMETER SET!\n",
    "# Remember, dropout is a separate layer, use dropout_rate as parameter\n",
    "\n",
    "....\n",
    "\n",
    "\n",
    "\n",
    "# Softmax \n",
    "#Define the predictions!\n",
    "#Use Softmax!\n",
    "predictions = ....\n",
    "\n",
    "# Full model\n",
    "# Instantiate with input and output\n",
    "model = ...\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z4vQf0hkfBiA"
   },
   "source": [
    "## Loss, optimization and compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "rWwxSa0ZfBiC",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Loss \n",
    "\n",
    "loss = sparse_categorical_crossentropy # we use this cross entropy variant as the input is not \n",
    "                                       # one-hot encoded\n",
    "\n",
    "# Optimizer\n",
    "\n",
    "optimizer = #??? some SGD variant \n",
    " \n",
    "# Compilation\n",
    "#############\n",
    "#Compile with optimizer and loss, use accuracy as metric\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "plYKl2O-fBiV"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 770
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "3J86Uf8cfBiX",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "db467dbe-c1d3-4ce1-ba69-0f29e0fb1276"
   },
   "outputs": [],
   "source": [
    "history = model.fit(x=train_images, y=train_labels,\n",
    "                    validation_data=(valid_images, valid_labels),\n",
    "                    epochs=20,\n",
    "                    batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "nhzdXlRJfBix",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "e2d6cd06-16df-409a-a0bf-de628b581508"
   },
   "outputs": [],
   "source": [
    "def display_history(history):\n",
    "    \"\"\"Summarize history for accuracy and loss.\n",
    "    \"\"\"\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'valid'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "#If you need...\n",
    "display_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Get over this - minimally!!!!!\n",
    "assert max(history.history['accuracy'])>0.72\n",
    "assert max(history.history['val_accuracy'])>0.73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s8r1zj1fiJw1"
   },
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "2NgYnGN5iOXL",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Day7-Task.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
