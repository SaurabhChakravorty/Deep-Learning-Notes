{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "s3_bucket = sagemaker.Session().default_bucket()  # replace with an existing bucket if needed\n",
    "s3_prefix = 'Deep_AR'    # prefix used for all data stored within the bucket\n",
    "role = sagemaker.get_execution_role()             # IAM role to use by SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n"
     ]
    }
   ],
   "source": [
    "image_name = sagemaker.amazon.amazon_estimator.get_image_uri(boto3.Session().region_name, \"forecasting-deepar\",'latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_data_path = \"s3://{}/{}/data\".format(s3_bucket, s3_prefix)\n",
    "s3_output_path = \"s3://{}/{}/output\".format(s3_bucket, s3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path = 'data/'\n",
    "if new_path not in sys.path:\n",
    "  sys.path.append(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_df = pd.read_pickle(new_path + 'hourly_resampled_contracts_ohlc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contractID</th>\n",
       "      <th>qty</th>\n",
       "      <th>pxopen</th>\n",
       "      <th>pxhigh</th>\n",
       "      <th>pxlow</th>\n",
       "      <th>pxclose</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-01 11:00:00</th>\n",
       "      <td>11629792</td>\n",
       "      <td>7.3</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-01 11:00:00</th>\n",
       "      <td>11629866</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-01 12:00:00</th>\n",
       "      <td>11629866</td>\n",
       "      <td>1755.3</td>\n",
       "      <td>1.71</td>\n",
       "      <td>18.00</td>\n",
       "      <td>-5.57</td>\n",
       "      <td>-5.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-01 11:00:00</th>\n",
       "      <td>11629920</td>\n",
       "      <td>20.7</td>\n",
       "      <td>18.50</td>\n",
       "      <td>18.50</td>\n",
       "      <td>18.50</td>\n",
       "      <td>18.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-01 12:00:00</th>\n",
       "      <td>11629920</td>\n",
       "      <td>1005.3</td>\n",
       "      <td>18.11</td>\n",
       "      <td>19.00</td>\n",
       "      <td>16.21</td>\n",
       "      <td>17.20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    contractID     qty  pxopen  pxhigh  pxlow  pxclose  labels\n",
       "Datetime                                                                      \n",
       "2020-03-01 11:00:00   11629792     7.3   -0.99   -0.99  -1.00    -1.00       0\n",
       "2020-03-01 11:00:00   11629866    28.0    1.30    1.71   1.30     1.41       1\n",
       "2020-03-01 12:00:00   11629866  1755.3    1.71   18.00  -5.57    -5.57       1\n",
       "2020-03-01 11:00:00   11629920    20.7   18.50   18.50  18.50    18.50       2\n",
       "2020-03-01 12:00:00   11629920  1005.3   18.11   19.00  16.21    17.20       2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flatten multilablbel cols\n",
    "resampled_df.columns = [''.join(col).strip() for col in resampled_df.columns.values]\n",
    "resampled_df.rename({'contractIdcontractId': 'contractID', 'qtyqty': 'qty'}, axis=1, inplace=True)\n",
    "resampled_df = resampled_df.sort_values(by ='contractID')\n",
    "d = resampled_df['contractID'].unique().tolist()\n",
    "d = dict((d[i],i) for i in range(len(d)))\n",
    "resampled_df['labels'] = resampled_df['contractID'].map(d).astype(int)\n",
    "resampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contractID</th>\n",
       "      <th>qty</th>\n",
       "      <th>pxopen</th>\n",
       "      <th>pxhigh</th>\n",
       "      <th>pxlow</th>\n",
       "      <th>pxclose</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-01 11:00:00</th>\n",
       "      <td>11629792</td>\n",
       "      <td>7.3</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-01 11:00:00</th>\n",
       "      <td>11629866</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-01 12:00:00</th>\n",
       "      <td>11629866</td>\n",
       "      <td>1755.3</td>\n",
       "      <td>1.71</td>\n",
       "      <td>18.00</td>\n",
       "      <td>-5.57</td>\n",
       "      <td>-5.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-01 11:00:00</th>\n",
       "      <td>11629920</td>\n",
       "      <td>20.7</td>\n",
       "      <td>18.50</td>\n",
       "      <td>18.50</td>\n",
       "      <td>18.50</td>\n",
       "      <td>18.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-01 12:00:00</th>\n",
       "      <td>11629920</td>\n",
       "      <td>1005.3</td>\n",
       "      <td>18.11</td>\n",
       "      <td>19.00</td>\n",
       "      <td>16.21</td>\n",
       "      <td>17.20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    contractID     qty  pxopen  pxhigh  pxlow  pxclose  labels\n",
       "Datetime                                                                      \n",
       "2020-03-01 11:00:00   11629792     7.3   -0.99   -0.99  -1.00    -1.00       0\n",
       "2020-03-01 11:00:00   11629866    28.0    1.30    1.71   1.30     1.41       1\n",
       "2020-03-01 12:00:00   11629866  1755.3    1.71   18.00  -5.57    -5.57       1\n",
       "2020-03-01 11:00:00   11629920    20.7   18.50   18.50  18.50    18.50       2\n",
       "2020-03-01 12:00:00   11629920  1005.3   18.11   19.00  16.21    17.20       2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flatten multilablbel cols\n",
    "resampled_df.columns = [''.join(col).strip() for col in resampled_df.columns.values]\n",
    "resampled_df.rename({'contractIdcontractId': 'contractID', 'qtyqty': 'qty'}, axis=1, inplace=True)\n",
    "resampled_df = resampled_df.sort_values(by ='contractID')\n",
    "d = resampled_df['contractID'].unique().tolist()\n",
    "d = dict((d[i],i) for i in range(len(d)))\n",
    "resampled_df['labels'] = resampled_df['contractID'].map(d).astype(int)\n",
    "resampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = resampled_df['labels'].values\n",
    "y = resampled_df[['pxopen','pxhigh','pxlow','pxclose']].values\n",
    "X_train,X_valid,y_train,y_valid = train_test_split(X,y,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43340\n"
     ]
    }
   ],
   "source": [
    "training_data = [\n",
    "    {\n",
    "        \"start\": str(resampled_df.index[i]),\n",
    "         \"target\": list(y_train[i])\n",
    "       ,\"cat\":  int(X_train[i])\n",
    "    }\n",
    "    for i in range(len(X_train))\n",
    "]\n",
    "\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14447\n"
     ]
    }
   ],
   "source": [
    "test_data = [\n",
    "    {\n",
    "        \"start\": str(resampled_df.index[len(X_train)+i]),\n",
    "        \"target\": list(y_valid[i])\n",
    "        ,\"cat\": int(X_valid[i])\n",
    "    }\n",
    "    for i in range(len(X_valid))\n",
    "]\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dicts_to_file(path, data):\n",
    "    with open(path, 'wb') as fp:\n",
    "        for d in data:\n",
    "            fp.write(json.dumps(d).encode(\"utf-8\"))\n",
    "            fp.write(\"\\n\".encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 259 ms, sys: 3.73 ms, total: 263 ms\n",
      "Wall time: 491 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "write_dicts_to_file(\"train.json\", training_data)\n",
    "write_dicts_to_file(\"test.json\", test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "def copy_to_s3(local_file, s3_path, override=False):\n",
    "    assert s3_path.startswith('s3://')\n",
    "    split = s3_path.split('/')\n",
    "    bucket = split[2]\n",
    "    path = '/'.join(split[3:])\n",
    "    buk = s3.Bucket(bucket)\n",
    "    \n",
    "    if len(list(buk.objects.filter(Prefix=path))) > 0:\n",
    "        if not override:\n",
    "            print('File s3://{}/{} already exists.\\nSet override to upload anyway.\\n'.format(s3_bucket, s3_path))\n",
    "            return\n",
    "        else:\n",
    "            print('Overwriting existing file')\n",
    "    with open(local_file, 'rb') as data:\n",
    "        print('Uploading file to {}'.format(s3_path))\n",
    "        buk.put_object(Key=path, Body=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File s3://sagemaker-us-east-2-313635455612/s3://sagemaker-us-east-2-313635455612/Deep_AR/data/train/train.json already exists.\n",
      "Set override to upload anyway.\n",
      "\n",
      "File s3://sagemaker-us-east-2-313635455612/s3://sagemaker-us-east-2-313635455612/Deep_AR/data/test/test.json already exists.\n",
      "Set override to upload anyway.\n",
      "\n",
      "CPU times: user 17.8 ms, sys: 7.64 ms, total: 25.4 ms\n",
      "Wall time: 99.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "copy_to_s3(\"train.json\", s3_data_path + \"/train/train.json\")\n",
    "copy_to_s3(\"test.json\", s3_data_path + \"/test/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-02 12:30:24 Starting - Starting the training job...\n",
      "2020-11-02 12:30:26 Starting - Launching requested ML instances......\n",
      "2020-11-02 12:31:29 Starting - Preparing the instances for training......\n",
      "2020-11-02 12:32:48 Downloading - Downloading input data\n",
      "2020-11-02 12:32:48 Training - Downloading the training image..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:05 INFO 140088046479168] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:05 INFO 140088046479168] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'5E-4', u'prediction_length': u'1', u'epochs': u'20', u'time_freq': u'1H', u'context_length': u'1', u'mini_batch_size': u'64', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:05 INFO 140088046479168] Final configuration: {u'dropout_rate': u'0.10', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'5E-4', u'num_layers': u'2', u'epochs': u'20', u'embedding_dimension': u'10', u'num_cells': u'40', u'_num_kv_servers': u'auto', u'mini_batch_size': u'64', u'likelihood': u'student-t', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'1', u'time_freq': u'1H', u'context_length': u'1', u'_kvstore': u'auto', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:05 INFO 140088046479168] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:05 INFO 140088046479168] Using early stopping with patience 40\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:05 INFO 140088046479168] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:05 INFO 140088046479168] [num_dynamic_feat=auto] `dynamic_feat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\n",
      "2020-11-02 12:33:02 Training - Training image download completed. Training in progress.\u001b[34m[11/02/2020 12:33:10 INFO 140088046479168] Training set statistics:\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:10 INFO 140088046479168] Real time series\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:10 INFO 140088046479168] number of time series: 43340\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:10 INFO 140088046479168] number of observations: 173360\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:10 INFO 140088046479168] mean target length: 4\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:10 INFO 140088046479168] min/mean/max target: -219.990005493/25.5113462264/275.0\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:10 INFO 140088046479168] mean abs(target): 26.8874566339\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:10 INFO 140088046479168] contains missing values: no\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:11 INFO 140088046479168] Test set statistics:\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:11 INFO 140088046479168] Real time series\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:11 INFO 140088046479168] number of time series: 14447\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:11 INFO 140088046479168] number of observations: 57788\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:11 INFO 140088046479168] mean target length: 4\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:11 INFO 140088046479168] min/mean/max target: -199.0/25.3705203635/272.200012207\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:11 INFO 140088046479168] mean abs(target): 26.9173345725\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:11 INFO 140088046479168] contains missing values: no\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] nvidia-smi took: 0.0251698493958 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 11.18922233581543, \"sum\": 11.18922233581543, \"min\": 11.18922233581543}}, \"EndTime\": 1604320392.02033, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320392.008252}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 44.075965881347656, \"sum\": 44.075965881347656, \"min\": 44.075965881347656}}, \"EndTime\": 1604320392.052451, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320392.020403}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] Epoch[0] Batch[0] avg_epoch_loss=3.931417\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=3.93141746521\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] Epoch[0] Batch[5] avg_epoch_loss=3.945289\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=3.94528853893\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] Epoch[0] Batch [5]#011Speed: 14652.11 samples/sec#011loss=3.945289\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] Epoch[0] Batch[10] avg_epoch_loss=3.898722\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=3.84284281731\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] Epoch[0] Batch [10]#011Speed: 14038.19 samples/sec#011loss=3.842843\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] Epoch[0] Batch[15] avg_epoch_loss=3.878889\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=15 train loss <loss>=3.83525428772\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] Epoch[0] Batch [15]#011Speed: 1465.01 samples/sec#011loss=3.835254\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] Epoch[0] Batch[20] avg_epoch_loss=3.802147\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=20 train loss <loss>=3.55657582283\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] Epoch[0] Batch [20]#011Speed: 14248.17 samples/sec#011loss=3.556576\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] Epoch[0] Batch[25] avg_epoch_loss=3.766711\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=25 train loss <loss>=3.61787791252\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] Epoch[0] Batch [25]#011Speed: 14680.32 samples/sec#011loss=3.617878\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] Epoch[0] Batch[30] avg_epoch_loss=3.712336\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=30 train loss <loss>=3.42958660126\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] Epoch[0] Batch [30]#011Speed: 1613.51 samples/sec#011loss=3.429587\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] Epoch[0] Batch[35] avg_epoch_loss=3.673089\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=35 train loss <loss>=3.42975420952\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:12 INFO 140088046479168] Epoch[0] Batch [35]#011Speed: 14174.44 samples/sec#011loss=3.429754\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] Epoch[0] Batch[40] avg_epoch_loss=3.654199\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=40 train loss <loss>=3.51819014549\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] Epoch[0] Batch [40]#011Speed: 1656.70 samples/sec#011loss=3.518190\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] Epoch[0] Batch[45] avg_epoch_loss=3.632209\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=45 train loss <loss>=3.45189380646\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] Epoch[0] Batch [45]#011Speed: 13289.02 samples/sec#011loss=3.451894\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] Epoch[0] Batch[50] avg_epoch_loss=3.620012\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=50 train loss <loss>=3.50780405998\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] Epoch[0] Batch [50]#011Speed: 13996.47 samples/sec#011loss=3.507804\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] Epoch[0] Batch[55] avg_epoch_loss=3.598343\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=55 train loss <loss>=3.37731451988\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] Epoch[0] Batch [55]#011Speed: 1691.46 samples/sec#011loss=3.377315\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] Epoch[0] Batch[60] avg_epoch_loss=3.579912\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=60 train loss <loss>=3.37348995209\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] Epoch[0] Batch [60]#011Speed: 14287.60 samples/sec#011loss=3.373490\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] Epoch[0] Batch[65] avg_epoch_loss=3.556932\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=65 train loss <loss>=3.27657661438\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] Epoch[0] Batch [65]#011Speed: 1709.82 samples/sec#011loss=3.276577\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] Epoch[0] Batch[70] avg_epoch_loss=3.544948\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=70 train loss <loss>=3.38675541878\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] Epoch[0] Batch [70]#011Speed: 14291.56 samples/sec#011loss=3.386755\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] Epoch[0] Batch[75] avg_epoch_loss=3.527787\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=75 train loss <loss>=3.28409729004\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] Epoch[0] Batch [75]#011Speed: 14183.72 samples/sec#011loss=3.284097\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] Epoch[0] Batch[80] avg_epoch_loss=3.513070\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=80 train loss <loss>=3.28936953545\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] Epoch[0] Batch [80]#011Speed: 1471.08 samples/sec#011loss=3.289370\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] Epoch[0] Batch[85] avg_epoch_loss=3.510009\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=85 train loss <loss>=3.4604262352\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] Epoch[0] Batch [85]#011Speed: 13769.88 samples/sec#011loss=3.460426\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] Epoch[0] Batch[90] avg_epoch_loss=3.496465\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=90 train loss <loss>=3.26350793839\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:13 INFO 140088046479168] Epoch[0] Batch [90]#011Speed: 14430.62 samples/sec#011loss=3.263508\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] Epoch[0] Batch[95] avg_epoch_loss=3.487599\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=95 train loss <loss>=3.32623386383\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] Epoch[0] Batch [95]#011Speed: 1357.54 samples/sec#011loss=3.326234\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] Epoch[0] Batch[100] avg_epoch_loss=3.474840\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=100 train loss <loss>=3.22987685204\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] Epoch[0] Batch [100]#011Speed: 12365.28 samples/sec#011loss=3.229877\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] Epoch[0] Batch[105] avg_epoch_loss=3.457903\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=105 train loss <loss>=3.11577625275\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] Epoch[0] Batch [105]#011Speed: 1243.94 samples/sec#011loss=3.115776\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] Epoch[0] Batch[110] avg_epoch_loss=3.438131\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=110 train loss <loss>=3.01896066666\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] Epoch[0] Batch [110]#011Speed: 13007.61 samples/sec#011loss=3.018961\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] Epoch[0] Batch[115] avg_epoch_loss=3.421564\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=115 train loss <loss>=3.05376272202\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] Epoch[0] Batch [115]#011Speed: 12817.92 samples/sec#011loss=3.053763\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] Epoch[0] Batch[120] avg_epoch_loss=3.407053\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=120 train loss <loss>=3.0704003334\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] Epoch[0] Batch [120]#011Speed: 1130.24 samples/sec#011loss=3.070400\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] Epoch[0] Batch[125] avg_epoch_loss=3.396233\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=125 train loss <loss>=3.13440475464\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] Epoch[0] Batch [125]#011Speed: 13612.35 samples/sec#011loss=3.134405\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] Epoch[0] Batch[130] avg_epoch_loss=3.378132\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=130 train loss <loss>=2.92196779251\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] Epoch[0] Batch [130]#011Speed: 1618.86 samples/sec#011loss=2.921968\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] Epoch[0] Batch[135] avg_epoch_loss=3.359798\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=135 train loss <loss>=2.87946033478\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] Epoch[0] Batch [135]#011Speed: 12807.28 samples/sec#011loss=2.879460\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] Epoch[0] Batch[140] avg_epoch_loss=3.344396\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=140 train loss <loss>=2.92544894218\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:14 INFO 140088046479168] Epoch[0] Batch [140]#011Speed: 13170.35 samples/sec#011loss=2.925449\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] Epoch[0] Batch[145] avg_epoch_loss=3.330989\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=145 train loss <loss>=2.95291528702\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] Epoch[0] Batch [145]#011Speed: 1669.74 samples/sec#011loss=2.952915\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] Epoch[0] Batch[150] avg_epoch_loss=3.322594\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=150 train loss <loss>=3.07745652199\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] Epoch[0] Batch [150]#011Speed: 14169.20 samples/sec#011loss=3.077457\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] Epoch[0] Batch[155] avg_epoch_loss=3.308109\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=155 train loss <loss>=2.87067494392\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] Epoch[0] Batch [155]#011Speed: 13081.52 samples/sec#011loss=2.870675\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] Epoch[0] Batch[160] avg_epoch_loss=3.299920\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=160 train loss <loss>=3.04442105293\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] Epoch[0] Batch [160]#011Speed: 1663.80 samples/sec#011loss=3.044421\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] Epoch[0] Batch[165] avg_epoch_loss=3.284689\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=165 train loss <loss>=2.79424481392\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] Epoch[0] Batch [165]#011Speed: 13349.42 samples/sec#011loss=2.794245\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] Epoch[0] Batch[170] avg_epoch_loss=3.269858\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=170 train loss <loss>=2.77748632431\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] Epoch[0] Batch [170]#011Speed: 1587.97 samples/sec#011loss=2.777486\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] Epoch[0] Batch[175] avg_epoch_loss=3.257746\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=175 train loss <loss>=2.84350142479\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] Epoch[0] Batch [175]#011Speed: 13263.15 samples/sec#011loss=2.843501\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] Epoch[0] Batch[180] avg_epoch_loss=3.245863\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=180 train loss <loss>=2.82760205269\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] Epoch[0] Batch [180]#011Speed: 14474.50 samples/sec#011loss=2.827602\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] Epoch[0] Batch[185] avg_epoch_loss=3.232796\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=185 train loss <loss>=2.75975575447\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] Epoch[0] Batch [185]#011Speed: 1680.44 samples/sec#011loss=2.759756\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] Epoch[0] Batch[190] avg_epoch_loss=3.217190\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=190 train loss <loss>=2.63665361404\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:15 INFO 140088046479168] Epoch[0] Batch [190]#011Speed: 14393.63 samples/sec#011loss=2.636654\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] Epoch[0] Batch[195] avg_epoch_loss=3.202165\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=195 train loss <loss>=2.62820568085\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] Epoch[0] Batch [195]#011Speed: 1814.15 samples/sec#011loss=2.628206\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] Epoch[0] Batch[200] avg_epoch_loss=3.191760\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=200 train loss <loss>=2.78386678696\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] Epoch[0] Batch [200]#011Speed: 13307.20 samples/sec#011loss=2.783867\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] Epoch[0] Batch[205] avg_epoch_loss=3.186897\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=205 train loss <loss>=2.99142570496\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] Epoch[0] Batch [205]#011Speed: 14044.36 samples/sec#011loss=2.991426\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] Epoch[0] Batch[210] avg_epoch_loss=3.181023\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=210 train loss <loss>=2.93900566101\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] Epoch[0] Batch [210]#011Speed: 1542.93 samples/sec#011loss=2.939006\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] Epoch[0] Batch[215] avg_epoch_loss=3.169817\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=215 train loss <loss>=2.6969414711\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] Epoch[0] Batch [215]#011Speed: 12962.26 samples/sec#011loss=2.696941\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] Epoch[0] Batch[220] avg_epoch_loss=3.160492\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=220 train loss <loss>=2.75764613152\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] Epoch[0] Batch [220]#011Speed: 1608.16 samples/sec#011loss=2.757646\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] Epoch[0] Batch[225] avg_epoch_loss=3.152690\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=225 train loss <loss>=2.80784711838\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] Epoch[0] Batch [225]#011Speed: 13484.48 samples/sec#011loss=2.807847\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] Epoch[0] Batch[230] avg_epoch_loss=3.142376\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=230 train loss <loss>=2.67618136406\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] Epoch[0] Batch [230]#011Speed: 13355.00 samples/sec#011loss=2.676181\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] Epoch[0] Batch[235] avg_epoch_loss=3.129819\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=235 train loss <loss>=2.54968867302\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] Epoch[0] Batch [235]#011Speed: 1663.51 samples/sec#011loss=2.549689\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] Epoch[0] Batch[240] avg_epoch_loss=3.120896\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=240 train loss <loss>=2.6997127533\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] Epoch[0] Batch [240]#011Speed: 13663.48 samples/sec#011loss=2.699713\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] Epoch[0] Batch[245] avg_epoch_loss=3.111088\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=245 train loss <loss>=2.63834834099\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:16 INFO 140088046479168] Epoch[0] Batch [245]#011Speed: 1561.92 samples/sec#011loss=2.638348\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] Epoch[0] Batch[250] avg_epoch_loss=3.101380\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=250 train loss <loss>=2.62372951508\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] Epoch[0] Batch [250]#011Speed: 14273.02 samples/sec#011loss=2.623730\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] Epoch[0] Batch[255] avg_epoch_loss=3.092354\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=255 train loss <loss>=2.63926310539\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] Epoch[0] Batch [255]#011Speed: 13407.69 samples/sec#011loss=2.639263\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] Epoch[0] Batch[260] avg_epoch_loss=3.081799\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=260 train loss <loss>=2.54136080742\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] Epoch[0] Batch [260]#011Speed: 1543.72 samples/sec#011loss=2.541361\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] Epoch[0] Batch[265] avg_epoch_loss=3.069312\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=265 train loss <loss>=2.41750841141\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] Epoch[0] Batch [265]#011Speed: 13149.71 samples/sec#011loss=2.417508\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] Epoch[0] Batch[270] avg_epoch_loss=3.055238\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=270 train loss <loss>=2.30649032593\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] Epoch[0] Batch [270]#011Speed: 1816.11 samples/sec#011loss=2.306490\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] Epoch[0] Batch[275] avg_epoch_loss=3.040868\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=275 train loss <loss>=2.26201705933\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] Epoch[0] Batch [275]#011Speed: 14285.62 samples/sec#011loss=2.262017\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] Epoch[0] Batch[280] avg_epoch_loss=3.028204\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=280 train loss <loss>=2.32918591499\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] Epoch[0] Batch [280]#011Speed: 13347.29 samples/sec#011loss=2.329186\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] Epoch[0] Batch[285] avg_epoch_loss=3.014982\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=285 train loss <loss>=2.27188820839\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] Epoch[0] Batch [285]#011Speed: 1660.80 samples/sec#011loss=2.271888\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] Epoch[0] Batch[290] avg_epoch_loss=2.999649\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=290 train loss <loss>=2.12258059978\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] Epoch[0] Batch [290]#011Speed: 13934.85 samples/sec#011loss=2.122581\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] Epoch[0] Batch[295] avg_epoch_loss=2.988215\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=295 train loss <loss>=2.32275898457\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] Epoch[0] Batch [295]#011Speed: 1654.47 samples/sec#011loss=2.322759\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] Epoch[0] Batch[300] avg_epoch_loss=2.973315\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=300 train loss <loss>=2.09122362137\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] Epoch[0] Batch [300]#011Speed: 14205.04 samples/sec#011loss=2.091224\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] Epoch[0] Batch[305] avg_epoch_loss=2.958197\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=305 train loss <loss>=2.0481112957\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:17 INFO 140088046479168] Epoch[0] Batch [305]#011Speed: 14214.67 samples/sec#011loss=2.048111\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] Epoch[0] Batch[310] avg_epoch_loss=2.943156\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=310 train loss <loss>=2.02266230583\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] Epoch[0] Batch [310]#011Speed: 1745.57 samples/sec#011loss=2.022662\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] Epoch[0] Batch[315] avg_epoch_loss=2.928824\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=315 train loss <loss>=2.03733496666\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] Epoch[0] Batch [315]#011Speed: 12806.18 samples/sec#011loss=2.037335\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] Epoch[0] Batch[320] avg_epoch_loss=2.913696\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=320 train loss <loss>=1.95765619278\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] Epoch[0] Batch [320]#011Speed: 1558.49 samples/sec#011loss=1.957656\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] Epoch[0] Batch[325] avg_epoch_loss=2.897207\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=325 train loss <loss>=1.83858127594\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] Epoch[0] Batch [325]#011Speed: 14133.09 samples/sec#011loss=1.838581\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] Epoch[0] Batch[330] avg_epoch_loss=2.883230\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=330 train loss <loss>=1.97196371555\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] Epoch[0] Batch [330]#011Speed: 13584.65 samples/sec#011loss=1.971964\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] Epoch[0] Batch[335] avg_epoch_loss=2.871404\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=335 train loss <loss>=2.08846194744\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] Epoch[0] Batch [335]#011Speed: 1676.40 samples/sec#011loss=2.088462\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] Epoch[0] Batch[340] avg_epoch_loss=2.859925\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=340 train loss <loss>=2.08854148388\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] Epoch[0] Batch [340]#011Speed: 14535.48 samples/sec#011loss=2.088541\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] Epoch[0] Batch[345] avg_epoch_loss=2.847311\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=345 train loss <loss>=1.98708541393\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] Epoch[0] Batch [345]#011Speed: 1683.19 samples/sec#011loss=1.987085\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] Epoch[0] Batch[350] avg_epoch_loss=2.833495\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=350 train loss <loss>=1.87737548351\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] Epoch[0] Batch [350]#011Speed: 13237.38 samples/sec#011loss=1.877375\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] Epoch[0] Batch[355] avg_epoch_loss=2.819553\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=355 train loss <loss>=1.84084451199\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:18 INFO 140088046479168] Epoch[0] Batch [355]#011Speed: 13171.38 samples/sec#011loss=1.840845\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] Epoch[0] Batch[360] avg_epoch_loss=2.807764\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=360 train loss <loss>=1.96842944622\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] Epoch[0] Batch [360]#011Speed: 1788.93 samples/sec#011loss=1.968429\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] Epoch[0] Batch[365] avg_epoch_loss=2.796334\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=365 train loss <loss>=1.97108309269\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] Epoch[0] Batch [365]#011Speed: 13495.73 samples/sec#011loss=1.971083\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] Epoch[0] Batch[370] avg_epoch_loss=2.783666\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=370 train loss <loss>=1.85633058548\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] Epoch[0] Batch [370]#011Speed: 1680.32 samples/sec#011loss=1.856331\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] Epoch[0] Batch[375] avg_epoch_loss=2.769673\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=375 train loss <loss>=1.73140041828\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] Epoch[0] Batch [375]#011Speed: 14270.28 samples/sec#011loss=1.731400\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] Epoch[0] Batch[380] avg_epoch_loss=2.758141\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=380 train loss <loss>=1.89093439579\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] Epoch[0] Batch [380]#011Speed: 14205.79 samples/sec#011loss=1.890934\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] Epoch[0] Batch[385] avg_epoch_loss=2.745821\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=385 train loss <loss>=1.80700657368\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] Epoch[0] Batch [385]#011Speed: 1598.04 samples/sec#011loss=1.807007\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] Epoch[0] Batch[390] avg_epoch_loss=2.734728\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=390 train loss <loss>=1.87840368748\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] Epoch[0] Batch [390]#011Speed: 14295.97 samples/sec#011loss=1.878404\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] Epoch[0] Batch[395] avg_epoch_loss=2.722934\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=395 train loss <loss>=1.8006387949\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] Epoch[0] Batch [395]#011Speed: 14217.08 samples/sec#011loss=1.800639\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] Epoch[0] Batch[400] avg_epoch_loss=2.710924\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=400 train loss <loss>=1.75975530148\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] Epoch[0] Batch [400]#011Speed: 1686.71 samples/sec#011loss=1.759755\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] Epoch[0] Batch[405] avg_epoch_loss=2.698882\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=405 train loss <loss>=1.7330578804\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] Epoch[0] Batch [405]#011Speed: 13989.61 samples/sec#011loss=1.733058\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] Epoch[0] Batch[410] avg_epoch_loss=2.686062\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=410 train loss <loss>=1.64512691498\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] Epoch[0] Batch [410]#011Speed: 1626.15 samples/sec#011loss=1.645127\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] Epoch[0] Batch[415] avg_epoch_loss=2.674433\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=415 train loss <loss>=1.71847367287\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] Epoch[0] Batch [415]#011Speed: 14203.39 samples/sec#011loss=1.718474\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] Epoch[0] Batch[420] avg_epoch_loss=2.663656\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=420 train loss <loss>=1.76701416969\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:19 INFO 140088046479168] Epoch[0] Batch [420]#011Speed: 13939.05 samples/sec#011loss=1.767014\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] Epoch[0] Batch[425] avg_epoch_loss=2.651544\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=425 train loss <loss>=1.63172426224\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] Epoch[0] Batch [425]#011Speed: 1717.33 samples/sec#011loss=1.631724\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] Epoch[0] Batch[430] avg_epoch_loss=2.641095\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=430 train loss <loss>=1.75083730221\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] Epoch[0] Batch [430]#011Speed: 13836.74 samples/sec#011loss=1.750837\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] Epoch[0] Batch[435] avg_epoch_loss=2.630834\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=435 train loss <loss>=1.74631185532\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] Epoch[0] Batch [435]#011Speed: 1600.14 samples/sec#011loss=1.746312\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] Epoch[0] Batch[440] avg_epoch_loss=2.621626\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=440 train loss <loss>=1.81871328354\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] Epoch[0] Batch [440]#011Speed: 14439.78 samples/sec#011loss=1.818713\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] Epoch[0] Batch[445] avg_epoch_loss=2.611852\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=445 train loss <loss>=1.74976050854\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] Epoch[0] Batch [445]#011Speed: 12854.01 samples/sec#011loss=1.749761\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] Epoch[0] Batch[450] avg_epoch_loss=2.601460\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=450 train loss <loss>=1.67454135418\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] Epoch[0] Batch [450]#011Speed: 1614.00 samples/sec#011loss=1.674541\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] Epoch[0] Batch[455] avg_epoch_loss=2.590754\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=455 train loss <loss>=1.62502558231\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] Epoch[0] Batch [455]#011Speed: 14331.08 samples/sec#011loss=1.625026\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] Epoch[0] Batch[460] avg_epoch_loss=2.580818\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=460 train loss <loss>=1.67468616962\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] Epoch[0] Batch [460]#011Speed: 1646.72 samples/sec#011loss=1.674686\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] Epoch[0] Batch[465] avg_epoch_loss=2.571410\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=465 train loss <loss>=1.70399775505\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] Epoch[0] Batch [465]#011Speed: 14301.00 samples/sec#011loss=1.703998\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] Epoch[0] Batch[470] avg_epoch_loss=2.562483\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=470 train loss <loss>=1.73048028946\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:20 INFO 140088046479168] Epoch[0] Batch [470]#011Speed: 14369.13 samples/sec#011loss=1.730480\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] Epoch[0] Batch[475] avg_epoch_loss=2.553843\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=475 train loss <loss>=1.73996815681\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] Epoch[0] Batch [475]#011Speed: 1816.52 samples/sec#011loss=1.739968\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] Epoch[0] Batch[480] avg_epoch_loss=2.543837\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=480 train loss <loss>=1.59122376442\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] Epoch[0] Batch [480]#011Speed: 12996.53 samples/sec#011loss=1.591224\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] Epoch[0] Batch[485] avg_epoch_loss=2.534094\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=485 train loss <loss>=1.59689180851\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] Epoch[0] Batch [485]#011Speed: 1593.48 samples/sec#011loss=1.596892\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] Epoch[0] Batch[490] avg_epoch_loss=2.525249\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=490 train loss <loss>=1.66551823616\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] Epoch[0] Batch [490]#011Speed: 11248.55 samples/sec#011loss=1.665518\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] Epoch[0] Batch[495] avg_epoch_loss=2.515610\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=495 train loss <loss>=1.56901180744\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] Epoch[0] Batch [495]#011Speed: 12906.42 samples/sec#011loss=1.569012\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] Epoch[0] Batch[500] avg_epoch_loss=2.505838\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=500 train loss <loss>=1.53647165298\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] Epoch[0] Batch [500]#011Speed: 1618.75 samples/sec#011loss=1.536472\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] Epoch[0] Batch[505] avg_epoch_loss=2.495089\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=505 train loss <loss>=1.41805553436\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] Epoch[0] Batch [505]#011Speed: 14333.07 samples/sec#011loss=1.418056\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] Epoch[0] Batch[510] avg_epoch_loss=2.485577\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=510 train loss <loss>=1.52292668819\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] Epoch[0] Batch [510]#011Speed: 14299.78 samples/sec#011loss=1.522927\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] Epoch[0] Batch[515] avg_epoch_loss=2.477786\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=515 train loss <loss>=1.6815451622\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] Epoch[0] Batch [515]#011Speed: 1750.99 samples/sec#011loss=1.681545\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] Epoch[0] Batch[520] avg_epoch_loss=2.471145\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=520 train loss <loss>=1.78582396507\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] Epoch[0] Batch [520]#011Speed: 14274.23 samples/sec#011loss=1.785824\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] Epoch[0] Batch[525] avg_epoch_loss=2.461618\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=525 train loss <loss>=1.46885895729\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:21 INFO 140088046479168] Epoch[0] Batch [525]#011Speed: 1788.58 samples/sec#011loss=1.468859\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] Epoch[0] Batch[530] avg_epoch_loss=2.453957\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=530 train loss <loss>=1.64807960987\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] Epoch[0] Batch [530]#011Speed: 14087.55 samples/sec#011loss=1.648080\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] Epoch[0] Batch[535] avg_epoch_loss=2.446764\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=535 train loss <loss>=1.68285727501\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] Epoch[0] Batch [535]#011Speed: 14250.13 samples/sec#011loss=1.682857\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] Epoch[0] Batch[540] avg_epoch_loss=2.438265\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=540 train loss <loss>=1.52714908123\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] Epoch[0] Batch [540]#011Speed: 1749.30 samples/sec#011loss=1.527149\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] Epoch[0] Batch[545] avg_epoch_loss=2.429937\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=545 train loss <loss>=1.52885098457\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] Epoch[0] Batch [545]#011Speed: 14173.69 samples/sec#011loss=1.528851\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] Epoch[0] Batch[550] avg_epoch_loss=2.423467\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=550 train loss <loss>=1.71691365242\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] Epoch[0] Batch [550]#011Speed: 1365.67 samples/sec#011loss=1.716914\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] Epoch[0] Batch[555] avg_epoch_loss=2.414568\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=555 train loss <loss>=1.43394846916\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] Epoch[0] Batch [555]#011Speed: 14292.62 samples/sec#011loss=1.433948\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] Epoch[0] Batch[560] avg_epoch_loss=2.408750\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=560 train loss <loss>=1.76179218292\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] Epoch[0] Batch [560]#011Speed: 13610.69 samples/sec#011loss=1.761792\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] Epoch[0] Batch[565] avg_epoch_loss=2.401460\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=565 train loss <loss>=1.58350422382\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] Epoch[0] Batch [565]#011Speed: 1666.81 samples/sec#011loss=1.583504\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] Epoch[0] Batch[570] avg_epoch_loss=2.394954\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=570 train loss <loss>=1.65847396851\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] Epoch[0] Batch [570]#011Speed: 13272.46 samples/sec#011loss=1.658474\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] Epoch[0] Batch[575] avg_epoch_loss=2.387543\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=575 train loss <loss>=1.54113647938\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] Epoch[0] Batch [575]#011Speed: 1793.33 samples/sec#011loss=1.541136\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] Epoch[0] Batch[580] avg_epoch_loss=2.381363\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=580 train loss <loss>=1.66953659058\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] Epoch[0] Batch [580]#011Speed: 13156.79 samples/sec#011loss=1.669537\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] Epoch[0] Batch[585] avg_epoch_loss=2.375133\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=585 train loss <loss>=1.65112595558\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:22 INFO 140088046479168] Epoch[0] Batch [585]#011Speed: 13296.65 samples/sec#011loss=1.651126\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] Epoch[0] Batch[590] avg_epoch_loss=2.367290\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=590 train loss <loss>=1.44815645218\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] Epoch[0] Batch [590]#011Speed: 1778.23 samples/sec#011loss=1.448156\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] Epoch[0] Batch[595] avg_epoch_loss=2.361009\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=595 train loss <loss>=1.6185997963\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] Epoch[0] Batch [595]#011Speed: 12820.98 samples/sec#011loss=1.618600\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] Epoch[0] Batch[600] avg_epoch_loss=2.355144\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=600 train loss <loss>=1.65603132248\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] Epoch[0] Batch [600]#011Speed: 1448.81 samples/sec#011loss=1.656031\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] Epoch[0] Batch[605] avg_epoch_loss=2.350214\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=605 train loss <loss>=1.75757024288\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] Epoch[0] Batch [605]#011Speed: 14316.40 samples/sec#011loss=1.757570\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] Epoch[0] Batch[610] avg_epoch_loss=2.343377\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=610 train loss <loss>=1.51473975182\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] Epoch[0] Batch [610]#011Speed: 13785.43 samples/sec#011loss=1.514740\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] Epoch[0] Batch[615] avg_epoch_loss=2.335444\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=615 train loss <loss>=1.36602876186\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] Epoch[0] Batch [615]#011Speed: 1719.61 samples/sec#011loss=1.366029\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] Epoch[0] Batch[620] avg_epoch_loss=2.329512\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=620 train loss <loss>=1.59869222641\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] Epoch[0] Batch [620]#011Speed: 14585.24 samples/sec#011loss=1.598692\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] Epoch[0] Batch[625] avg_epoch_loss=2.321865\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=625 train loss <loss>=1.37205688953\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] Epoch[0] Batch [625]#011Speed: 14579.85 samples/sec#011loss=1.372057\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] Epoch[0] Batch[630] avg_epoch_loss=2.316300\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=630 train loss <loss>=1.61959671974\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] Epoch[0] Batch [630]#011Speed: 1601.60 samples/sec#011loss=1.619597\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] Epoch[0] Batch[635] avg_epoch_loss=2.310113\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=635 train loss <loss>=1.52939238548\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:23 INFO 140088046479168] Epoch[0] Batch [635]#011Speed: 13201.83 samples/sec#011loss=1.529392\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] Epoch[0] Batch[640] avg_epoch_loss=2.305494\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=640 train loss <loss>=1.71791932583\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] Epoch[0] Batch [640]#011Speed: 1860.18 samples/sec#011loss=1.717919\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] Epoch[0] Batch[645] avg_epoch_loss=2.299055\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=645 train loss <loss>=1.47360150814\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] Epoch[0] Batch [645]#011Speed: 13116.94 samples/sec#011loss=1.473602\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] Epoch[0] Batch[650] avg_epoch_loss=2.293643\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=650 train loss <loss>=1.59442765713\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] Epoch[0] Batch [650]#011Speed: 13259.21 samples/sec#011loss=1.594428\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] Epoch[0] Batch[655] avg_epoch_loss=2.288072\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=655 train loss <loss>=1.56265118122\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] Epoch[0] Batch [655]#011Speed: 1757.84 samples/sec#011loss=1.562651\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] Epoch[0] Batch[660] avg_epoch_loss=2.281765\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=660 train loss <loss>=1.45435500145\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] Epoch[0] Batch [660]#011Speed: 14469.20 samples/sec#011loss=1.454355\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] Epoch[0] Batch[665] avg_epoch_loss=2.276923\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=665 train loss <loss>=1.63679702282\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] Epoch[0] Batch [665]#011Speed: 1388.99 samples/sec#011loss=1.636797\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] Epoch[0] Batch[670] avg_epoch_loss=2.272424\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=670 train loss <loss>=1.67317488194\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] Epoch[0] Batch [670]#011Speed: 14360.67 samples/sec#011loss=1.673175\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] Epoch[0] Batch[675] avg_epoch_loss=2.266903\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=675 train loss <loss>=1.52588355541\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] Epoch[0] Batch [675]#011Speed: 14333.68 samples/sec#011loss=1.525884\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] Epoch[0] Batch[680] avg_epoch_loss=2.264016\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=680 train loss <loss>=1.87377839088\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] Epoch[0] Batch [680]#011Speed: 1606.95 samples/sec#011loss=1.873778\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] Epoch[0] Batch[685] avg_epoch_loss=2.260176\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=685 train loss <loss>=1.73713989258\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] Epoch[0] Batch [685]#011Speed: 14285.02 samples/sec#011loss=1.737140\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] Epoch[0] Batch[690] avg_epoch_loss=2.255332\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=690 train loss <loss>=1.59072043896\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:24 INFO 140088046479168] Epoch[0] Batch [690]#011Speed: 1758.11 samples/sec#011loss=1.590720\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] Epoch[0] Batch[695] avg_epoch_loss=2.249599\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=695 train loss <loss>=1.45734696388\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] Epoch[0] Batch [695]#011Speed: 12712.54 samples/sec#011loss=1.457347\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] Epoch[0] Batch[700] avg_epoch_loss=2.244609\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=700 train loss <loss>=1.54991881847\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] Epoch[0] Batch [700]#011Speed: 14262.10 samples/sec#011loss=1.549919\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] Epoch[0] Batch[705] avg_epoch_loss=2.238034\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=705 train loss <loss>=1.31630682945\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] Epoch[0] Batch [705]#011Speed: 1477.81 samples/sec#011loss=1.316307\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] Epoch[0] Batch[710] avg_epoch_loss=2.233638\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=710 train loss <loss>=1.61283774376\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] Epoch[0] Batch [710]#011Speed: 14369.13 samples/sec#011loss=1.612838\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] Epoch[0] Batch[715] avg_epoch_loss=2.228459\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=715 train loss <loss>=1.49206888676\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] Epoch[0] Batch [715]#011Speed: 14281.22 samples/sec#011loss=1.492069\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] Epoch[0] Batch[720] avg_epoch_loss=2.223244\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=720 train loss <loss>=1.47646007538\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] Epoch[0] Batch [720]#011Speed: 1766.56 samples/sec#011loss=1.476460\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] Epoch[0] Batch[725] avg_epoch_loss=2.218719\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=725 train loss <loss>=1.56615622044\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] Epoch[0] Batch [725]#011Speed: 13234.11 samples/sec#011loss=1.566156\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] Epoch[0] Batch[730] avg_epoch_loss=2.214719\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=730 train loss <loss>=1.63398869038\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] Epoch[0] Batch [730]#011Speed: 1817.88 samples/sec#011loss=1.633989\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] Epoch[0] Batch[735] avg_epoch_loss=2.211329\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=735 train loss <loss>=1.71567494869\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] Epoch[0] Batch [735]#011Speed: 13245.61 samples/sec#011loss=1.715675\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] Epoch[0] Batch[740] avg_epoch_loss=2.207971\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=740 train loss <loss>=1.71363883018\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] Epoch[0] Batch [740]#011Speed: 1793.52 samples/sec#011loss=1.713639\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] Epoch[0] Batch[745] avg_epoch_loss=2.204468\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=745 train loss <loss>=1.68528552055\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] Epoch[0] Batch [745]#011Speed: 13978.10 samples/sec#011loss=1.685286\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] Epoch[0] Batch[750] avg_epoch_loss=2.201460\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=750 train loss <loss>=1.75275537968\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:25 INFO 140088046479168] Epoch[0] Batch [750]#011Speed: 14557.40 samples/sec#011loss=1.752755\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] Epoch[0] Batch[755] avg_epoch_loss=2.197813\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=755 train loss <loss>=1.65004396439\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] Epoch[0] Batch [755]#011Speed: 1687.45 samples/sec#011loss=1.650044\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] Epoch[0] Batch[760] avg_epoch_loss=2.194009\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=760 train loss <loss>=1.61883056164\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] Epoch[0] Batch [760]#011Speed: 14262.10 samples/sec#011loss=1.618831\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] Epoch[0] Batch[765] avg_epoch_loss=2.188663\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=765 train loss <loss>=1.37496266365\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] Epoch[0] Batch [765]#011Speed: 13588.09 samples/sec#011loss=1.374963\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] Epoch[0] Batch[770] avg_epoch_loss=2.183828\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=770 train loss <loss>=1.443187356\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] Epoch[0] Batch [770]#011Speed: 1733.20 samples/sec#011loss=1.443187\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] Epoch[0] Batch[775] avg_epoch_loss=2.179086\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=775 train loss <loss>=1.44780943394\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] Epoch[0] Batch [775]#011Speed: 13029.96 samples/sec#011loss=1.447809\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] Epoch[0] Batch[780] avg_epoch_loss=2.173909\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=780 train loss <loss>=1.37050065994\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] Epoch[0] Batch [780]#011Speed: 1656.50 samples/sec#011loss=1.370501\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] Epoch[0] Batch[785] avg_epoch_loss=2.169271\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=785 train loss <loss>=1.44482724667\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] Epoch[0] Batch [785]#011Speed: 13362.84 samples/sec#011loss=1.444827\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] Epoch[0] Batch[790] avg_epoch_loss=2.164662\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=790 train loss <loss>=1.44003138542\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] Epoch[0] Batch [790]#011Speed: 14698.48 samples/sec#011loss=1.440031\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] Epoch[0] Batch[795] avg_epoch_loss=2.160467\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=795 train loss <loss>=1.49691674709\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] Epoch[0] Batch [795]#011Speed: 1507.73 samples/sec#011loss=1.496917\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] Epoch[0] Batch[800] avg_epoch_loss=2.156952\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=800 train loss <loss>=1.59731547832\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:26 INFO 140088046479168] Epoch[0] Batch [800]#011Speed: 14288.82 samples/sec#011loss=1.597315\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] Epoch[0] Batch[805] avg_epoch_loss=2.155601\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=805 train loss <loss>=1.93915565014\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] Epoch[0] Batch [805]#011Speed: 1707.86 samples/sec#011loss=1.939156\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] Epoch[0] Batch[810] avg_epoch_loss=2.152488\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=810 train loss <loss>=1.65060665607\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] Epoch[0] Batch [810]#011Speed: 14450.82 samples/sec#011loss=1.650607\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] Epoch[0] Batch[815] avg_epoch_loss=2.150068\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=815 train loss <loss>=1.75758645535\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] Epoch[0] Batch [815]#011Speed: 14210.15 samples/sec#011loss=1.757586\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] Epoch[0] Batch[820] avg_epoch_loss=2.146145\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=820 train loss <loss>=1.50596868992\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] Epoch[0] Batch [820]#011Speed: 1790.66 samples/sec#011loss=1.505969\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] Epoch[0] Batch[825] avg_epoch_loss=2.142261\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=825 train loss <loss>=1.50441656113\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] Epoch[0] Batch [825]#011Speed: 12744.89 samples/sec#011loss=1.504417\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] Epoch[0] Batch[830] avg_epoch_loss=2.138070\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=830 train loss <loss>=1.44581358433\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] Epoch[0] Batch [830]#011Speed: 1593.94 samples/sec#011loss=1.445814\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] Epoch[0] Batch[835] avg_epoch_loss=2.134096\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=835 train loss <loss>=1.47361810207\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] Epoch[0] Batch [835]#011Speed: 14139.34 samples/sec#011loss=1.473618\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] Epoch[0] Batch[840] avg_epoch_loss=2.129449\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=840 train loss <loss>=1.35242128372\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] Epoch[0] Batch [840]#011Speed: 13149.19 samples/sec#011loss=1.352421\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] Epoch[0] Batch[845] avg_epoch_loss=2.126241\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=845 train loss <loss>=1.58665618896\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] Epoch[0] Batch [845]#011Speed: 1588.34 samples/sec#011loss=1.586656\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] Epoch[0] Batch[850] avg_epoch_loss=2.121930\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=850 train loss <loss>=1.39254715443\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] Epoch[0] Batch [850]#011Speed: 14393.01 samples/sec#011loss=1.392547\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] Epoch[0] Batch[855] avg_epoch_loss=2.119092\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=855 train loss <loss>=1.6360471487\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] Epoch[0] Batch [855]#011Speed: 1669.55 samples/sec#011loss=1.636047\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] Epoch[0] Batch[860] avg_epoch_loss=2.114490\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=860 train loss <loss>=1.32668658495\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:27 INFO 140088046479168] Epoch[0] Batch [860]#011Speed: 13809.69 samples/sec#011loss=1.326687\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] Epoch[0] Batch[865] avg_epoch_loss=2.111764\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=865 train loss <loss>=1.64220535755\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] Epoch[0] Batch [865]#011Speed: 12798.97 samples/sec#011loss=1.642205\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] Epoch[0] Batch[870] avg_epoch_loss=2.107427\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=870 train loss <loss>=1.35626869202\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] Epoch[0] Batch [870]#011Speed: 1628.42 samples/sec#011loss=1.356269\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] Epoch[0] Batch[875] avg_epoch_loss=2.103826\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=875 train loss <loss>=1.4766315937\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] Epoch[0] Batch [875]#011Speed: 14319.00 samples/sec#011loss=1.476632\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] Epoch[0] Batch[880] avg_epoch_loss=2.099785\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=880 train loss <loss>=1.39177196026\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] Epoch[0] Batch [880]#011Speed: 13221.60 samples/sec#011loss=1.391772\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] Epoch[0] Batch[885] avg_epoch_loss=2.097253\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=885 train loss <loss>=1.65115430355\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] Epoch[0] Batch [885]#011Speed: 1604.57 samples/sec#011loss=1.651154\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] Epoch[0] Batch[890] avg_epoch_loss=2.094671\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=890 train loss <loss>=1.63701133728\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] Epoch[0] Batch [890]#011Speed: 14435.89 samples/sec#011loss=1.637011\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] Epoch[0] Batch[895] avg_epoch_loss=2.090832\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=895 train loss <loss>=1.40685763359\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] Epoch[0] Batch [895]#011Speed: 2025.73 samples/sec#011loss=1.406858\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] Epoch[0] Batch[900] avg_epoch_loss=2.086846\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, batch=900 train loss <loss>=1.3725209713\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] Epoch[0] Batch [900]#011Speed: 13957.31 samples/sec#011loss=1.372521\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] processed a total of 57828 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 20, \"sum\": 20.0, \"min\": 20}, \"update.time\": {\"count\": 1, \"max\": 16609.455823898315, \"sum\": 16609.455823898315, \"min\": 16609.455823898315}}, \"EndTime\": 1604320408.662083, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320392.052526}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] #throughput_metric: host=algo-1, train throughput=3481.60413624 records/second\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=0, train loss <loss>=2.08408191517\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] Saved checkpoint to \"/opt/ml/model/state_2c5f12a3-8ad2-4d13-afde-a039e296e5bc-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.478973388671875, \"sum\": 10.478973388671875, \"min\": 10.478973388671875}}, \"EndTime\": 1604320408.673214, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320408.662171}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] Epoch[1] Batch[0] avg_epoch_loss=1.622326\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=1.62232553959\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] Epoch[1] Batch[5] avg_epoch_loss=1.473543\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=1.47354269028\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] Epoch[1] Batch [5]#011Speed: 14236.83 samples/sec#011loss=1.473543\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] Epoch[1] Batch[10] avg_epoch_loss=1.553210\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=1.6488104105\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:28 INFO 140088046479168] Epoch[1] Batch [10]#011Speed: 14375.59 samples/sec#011loss=1.648810\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] Epoch[1] Batch[15] avg_epoch_loss=1.568995\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=15 train loss <loss>=1.60372097492\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] Epoch[1] Batch [15]#011Speed: 1771.68 samples/sec#011loss=1.603721\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] Epoch[1] Batch[20] avg_epoch_loss=1.561551\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=20 train loss <loss>=1.53773145676\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] Epoch[1] Batch [20]#011Speed: 13187.69 samples/sec#011loss=1.537731\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] Epoch[1] Batch[25] avg_epoch_loss=1.531984\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=25 train loss <loss>=1.40780432224\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] Epoch[1] Batch [25]#011Speed: 13297.84 samples/sec#011loss=1.407804\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] Epoch[1] Batch[30] avg_epoch_loss=1.526476\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=30 train loss <loss>=1.49783353806\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] Epoch[1] Batch [30]#011Speed: 1735.88 samples/sec#011loss=1.497834\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] Epoch[1] Batch[35] avg_epoch_loss=1.517527\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=35 train loss <loss>=1.46204264164\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] Epoch[1] Batch [35]#011Speed: 7053.44 samples/sec#011loss=1.462043\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] Epoch[1] Batch[40] avg_epoch_loss=1.509398\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=40 train loss <loss>=1.45086903572\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] Epoch[1] Batch [40]#011Speed: 1538.20 samples/sec#011loss=1.450869\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] Epoch[1] Batch[45] avg_epoch_loss=1.512728\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=45 train loss <loss>=1.54003045559\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] Epoch[1] Batch [45]#011Speed: 13251.10 samples/sec#011loss=1.540030\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] Epoch[1] Batch[50] avg_epoch_loss=1.497437\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=50 train loss <loss>=1.35676021576\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] Epoch[1] Batch [50]#011Speed: 13439.24 samples/sec#011loss=1.356760\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] Epoch[1] Batch[55] avg_epoch_loss=1.476545\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=55 train loss <loss>=1.26345396042\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] Epoch[1] Batch [55]#011Speed: 1667.36 samples/sec#011loss=1.263454\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] Epoch[1] Batch[60] avg_epoch_loss=1.460027\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=60 train loss <loss>=1.27502403259\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] Epoch[1] Batch [60]#011Speed: 14416.36 samples/sec#011loss=1.275024\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] Epoch[1] Batch[65] avg_epoch_loss=1.445019\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=65 train loss <loss>=1.26191205978\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:29 INFO 140088046479168] Epoch[1] Batch [65]#011Speed: 14636.61 samples/sec#011loss=1.261912\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] Epoch[1] Batch[70] avg_epoch_loss=1.441985\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=70 train loss <loss>=1.40194859505\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] Epoch[1] Batch [70]#011Speed: 1617.31 samples/sec#011loss=1.401949\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] Epoch[1] Batch[75] avg_epoch_loss=1.442096\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=75 train loss <loss>=1.44367384911\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] Epoch[1] Batch [75]#011Speed: 14762.18 samples/sec#011loss=1.443674\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] Epoch[1] Batch[80] avg_epoch_loss=1.451086\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=80 train loss <loss>=1.58772444725\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] Epoch[1] Batch [80]#011Speed: 1747.07 samples/sec#011loss=1.587724\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] Epoch[1] Batch[85] avg_epoch_loss=1.452966\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=85 train loss <loss>=1.48342447281\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] Epoch[1] Batch [85]#011Speed: 13801.45 samples/sec#011loss=1.483424\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] Epoch[1] Batch[90] avg_epoch_loss=1.449746\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=90 train loss <loss>=1.39435750246\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] Epoch[1] Batch [90]#011Speed: 14657.39 samples/sec#011loss=1.394358\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] Epoch[1] Batch[95] avg_epoch_loss=1.474370\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=95 train loss <loss>=1.92252860069\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] Epoch[1] Batch [95]#011Speed: 1816.86 samples/sec#011loss=1.922529\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] Epoch[1] Batch[100] avg_epoch_loss=1.491127\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=100 train loss <loss>=1.81285820007\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] Epoch[1] Batch [100]#011Speed: 12549.58 samples/sec#011loss=1.812858\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] Epoch[1] Batch[105] avg_epoch_loss=1.511734\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=105 train loss <loss>=1.92799613476\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] Epoch[1] Batch [105]#011Speed: 1800.00 samples/sec#011loss=1.927996\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] Epoch[1] Batch[110] avg_epoch_loss=1.515941\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=110 train loss <loss>=1.60512568951\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] Epoch[1] Batch [110]#011Speed: 14623.85 samples/sec#011loss=1.605126\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] Epoch[1] Batch[115] avg_epoch_loss=1.510746\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=115 train loss <loss>=1.39543652534\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] Epoch[1] Batch [115]#011Speed: 14503.91 samples/sec#011loss=1.395437\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] Epoch[1] Batch[120] avg_epoch_loss=1.509305\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=120 train loss <loss>=1.47586359978\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] Epoch[1] Batch [120]#011Speed: 1752.16 samples/sec#011loss=1.475864\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] Epoch[1] Batch[125] avg_epoch_loss=1.500654\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=125 train loss <loss>=1.29130394459\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:30 INFO 140088046479168] Epoch[1] Batch [125]#011Speed: 14292.77 samples/sec#011loss=1.291304\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] Epoch[1] Batch[130] avg_epoch_loss=1.496307\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=130 train loss <loss>=1.38676731586\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] Epoch[1] Batch [130]#011Speed: 1736.87 samples/sec#011loss=1.386767\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] Epoch[1] Batch[135] avg_epoch_loss=1.492008\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=135 train loss <loss>=1.37935535908\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] Epoch[1] Batch [135]#011Speed: 12858.07 samples/sec#011loss=1.379355\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] Epoch[1] Batch[140] avg_epoch_loss=1.489151\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=140 train loss <loss>=1.41144888401\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] Epoch[1] Batch [140]#011Speed: 14423.48 samples/sec#011loss=1.411449\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] Epoch[1] Batch[145] avg_epoch_loss=1.482533\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=145 train loss <loss>=1.2959174633\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] Epoch[1] Batch [145]#011Speed: 1489.37 samples/sec#011loss=1.295917\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] Epoch[1] Batch[150] avg_epoch_loss=1.483597\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=150 train loss <loss>=1.51465086937\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] Epoch[1] Batch [150]#011Speed: 14364.52 samples/sec#011loss=1.514651\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] Epoch[1] Batch[155] avg_epoch_loss=1.483485\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=155 train loss <loss>=1.48010349274\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] Epoch[1] Batch [155]#011Speed: 1722.88 samples/sec#011loss=1.480103\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] Epoch[1] Batch[160] avg_epoch_loss=1.480093\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=160 train loss <loss>=1.37428097725\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] Epoch[1] Batch [160]#011Speed: 14286.99 samples/sec#011loss=1.374281\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] Epoch[1] Batch[165] avg_epoch_loss=1.480152\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=165 train loss <loss>=1.4820268631\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] Epoch[1] Batch [165]#011Speed: 12749.01 samples/sec#011loss=1.482027\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] Epoch[1] Batch[170] avg_epoch_loss=1.486839\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=170 train loss <loss>=1.70884711742\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] Epoch[1] Batch [170]#011Speed: 1731.96 samples/sec#011loss=1.708847\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] Epoch[1] Batch[175] avg_epoch_loss=1.493335\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=175 train loss <loss>=1.71549592018\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:31 INFO 140088046479168] Epoch[1] Batch [175]#011Speed: 14222.80 samples/sec#011loss=1.715496\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] Epoch[1] Batch[180] avg_epoch_loss=1.503421\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=180 train loss <loss>=1.85844745636\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] Epoch[1] Batch [180]#011Speed: 1818.61 samples/sec#011loss=1.858447\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] Epoch[1] Batch[185] avg_epoch_loss=1.510826\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=185 train loss <loss>=1.77890102863\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] Epoch[1] Batch [185]#011Speed: 13247.70 samples/sec#011loss=1.778901\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] Epoch[1] Batch[190] avg_epoch_loss=1.511422\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=190 train loss <loss>=1.53357748985\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] Epoch[1] Batch [190]#011Speed: 13076.68 samples/sec#011loss=1.533577\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] Epoch[1] Batch[195] avg_epoch_loss=1.512364\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=195 train loss <loss>=1.54835510254\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] Epoch[1] Batch [195]#011Speed: 1770.21 samples/sec#011loss=1.548355\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] Epoch[1] Batch[200] avg_epoch_loss=1.515440\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=200 train loss <loss>=1.63603873253\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] Epoch[1] Batch [200]#011Speed: 14649.39 samples/sec#011loss=1.636039\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] Epoch[1] Batch[205] avg_epoch_loss=1.512621\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=205 train loss <loss>=1.39928126335\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] Epoch[1] Batch [205]#011Speed: 1673.27 samples/sec#011loss=1.399281\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] Epoch[1] Batch[210] avg_epoch_loss=1.507205\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=210 train loss <loss>=1.28406224251\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] Epoch[1] Batch [210]#011Speed: 14407.85 samples/sec#011loss=1.284062\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] Epoch[1] Batch[215] avg_epoch_loss=1.502856\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=215 train loss <loss>=1.31933338642\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] Epoch[1] Batch [215]#011Speed: 13766.91 samples/sec#011loss=1.319333\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] Epoch[1] Batch[220] avg_epoch_loss=1.497882\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=220 train loss <loss>=1.28300914764\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] Epoch[1] Batch [220]#011Speed: 1592.05 samples/sec#011loss=1.283009\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] Epoch[1] Batch[225] avg_epoch_loss=1.498681\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=225 train loss <loss>=1.53401646614\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] Epoch[1] Batch [225]#011Speed: 9808.08 samples/sec#011loss=1.534016\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] Epoch[1] Batch[230] avg_epoch_loss=1.498280\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=230 train loss <loss>=1.48013432026\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] Epoch[1] Batch [230]#011Speed: 1390.42 samples/sec#011loss=1.480134\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] Epoch[1] Batch[235] avg_epoch_loss=1.494556\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=235 train loss <loss>=1.32252473831\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:32 INFO 140088046479168] Epoch[1] Batch [235]#011Speed: 13976.21 samples/sec#011loss=1.322525\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] Epoch[1] Batch[240] avg_epoch_loss=1.490946\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=240 train loss <loss>=1.32053613663\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] Epoch[1] Batch [240]#011Speed: 14347.16 samples/sec#011loss=1.320536\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] Epoch[1] Batch[245] avg_epoch_loss=1.485199\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=245 train loss <loss>=1.20816895962\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] Epoch[1] Batch [245]#011Speed: 1782.22 samples/sec#011loss=1.208169\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] Epoch[1] Batch[250] avg_epoch_loss=1.482003\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=250 train loss <loss>=1.32480349541\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] Epoch[1] Batch [250]#011Speed: 14389.77 samples/sec#011loss=1.324803\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] Epoch[1] Batch[255] avg_epoch_loss=1.478952\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=255 train loss <loss>=1.32576024532\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] Epoch[1] Batch [255]#011Speed: 1733.17 samples/sec#011loss=1.325760\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] Epoch[1] Batch[260] avg_epoch_loss=1.473429\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=260 train loss <loss>=1.1906568408\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] Epoch[1] Batch [260]#011Speed: 14297.19 samples/sec#011loss=1.190657\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] Epoch[1] Batch[265] avg_epoch_loss=1.471107\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=265 train loss <loss>=1.34989488125\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] Epoch[1] Batch [265]#011Speed: 13201.44 samples/sec#011loss=1.349895\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] Epoch[1] Batch[270] avg_epoch_loss=1.467372\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=270 train loss <loss>=1.26868053675\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] Epoch[1] Batch [270]#011Speed: 1682.85 samples/sec#011loss=1.268681\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] Epoch[1] Batch[275] avg_epoch_loss=1.462321\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=275 train loss <loss>=1.18857936859\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] Epoch[1] Batch [275]#011Speed: 13326.75 samples/sec#011loss=1.188579\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] Epoch[1] Batch[280] avg_epoch_loss=1.455459\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=280 train loss <loss>=1.07664599419\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] Epoch[1] Batch [280]#011Speed: 13203.52 samples/sec#011loss=1.076646\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] Epoch[1] Batch[285] avg_epoch_loss=1.448829\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=285 train loss <loss>=1.07623044252\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] Epoch[1] Batch [285]#011Speed: 1632.83 samples/sec#011loss=1.076230\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] Epoch[1] Batch[290] avg_epoch_loss=1.445031\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=290 train loss <loss>=1.22776678801\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:33 INFO 140088046479168] Epoch[1] Batch [290]#011Speed: 14250.13 samples/sec#011loss=1.227767\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] Epoch[1] Batch[295] avg_epoch_loss=1.448416\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=295 train loss <loss>=1.64546954632\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] Epoch[1] Batch [295]#011Speed: 1789.15 samples/sec#011loss=1.645470\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] Epoch[1] Batch[300] avg_epoch_loss=1.449616\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=300 train loss <loss>=1.52065618038\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] Epoch[1] Batch [300]#011Speed: 14067.76 samples/sec#011loss=1.520656\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] Epoch[1] Batch[305] avg_epoch_loss=1.456797\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=305 train loss <loss>=1.88907237053\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] Epoch[1] Batch [305]#011Speed: 14400.12 samples/sec#011loss=1.889072\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] Epoch[1] Batch[310] avg_epoch_loss=1.470639\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=310 train loss <loss>=2.31778907776\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] Epoch[1] Batch [310]#011Speed: 1561.62 samples/sec#011loss=2.317789\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] Epoch[1] Batch[315] avg_epoch_loss=1.475346\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=315 train loss <loss>=1.76810178757\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] Epoch[1] Batch [315]#011Speed: 14222.20 samples/sec#011loss=1.768102\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] Epoch[1] Batch[320] avg_epoch_loss=1.474741\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=320 train loss <loss>=1.43648028374\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] Epoch[1] Batch [320]#011Speed: 1697.59 samples/sec#011loss=1.436480\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] Epoch[1] Batch[325] avg_epoch_loss=1.472128\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=325 train loss <loss>=1.30439321995\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] Epoch[1] Batch [325]#011Speed: 14245.75 samples/sec#011loss=1.304393\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] Epoch[1] Batch[330] avg_epoch_loss=1.469982\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=330 train loss <loss>=1.33003985882\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] Epoch[1] Batch [330]#011Speed: 13381.76 samples/sec#011loss=1.330040\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] Epoch[1] Batch[335] avg_epoch_loss=1.469236\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=335 train loss <loss>=1.41989841461\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] Epoch[1] Batch [335]#011Speed: 1729.08 samples/sec#011loss=1.419898\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] Epoch[1] Batch[340] avg_epoch_loss=1.468909\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=340 train loss <loss>=1.44689564705\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] Epoch[1] Batch [340]#011Speed: 14093.76 samples/sec#011loss=1.446896\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] Epoch[1] Batch[345] avg_epoch_loss=1.473682\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=345 train loss <loss>=1.79920420647\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] Epoch[1] Batch [345]#011Speed: 14109.47 samples/sec#011loss=1.799204\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] Epoch[1] Batch[350] avg_epoch_loss=1.480487\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=350 train loss <loss>=1.95143573284\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:34 INFO 140088046479168] Epoch[1] Batch [350]#011Speed: 1783.77 samples/sec#011loss=1.951436\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] Epoch[1] Batch[355] avg_epoch_loss=1.488739\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=355 train loss <loss>=2.06796460152\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] Epoch[1] Batch [355]#011Speed: 15010.65 samples/sec#011loss=2.067965\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] Epoch[1] Batch[360] avg_epoch_loss=1.491538\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=360 train loss <loss>=1.69088125229\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] Epoch[1] Batch [360]#011Speed: 1683.02 samples/sec#011loss=1.690881\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] Epoch[1] Batch[365] avg_epoch_loss=1.491110\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=365 train loss <loss>=1.46019706726\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] Epoch[1] Batch [365]#011Speed: 13835.45 samples/sec#011loss=1.460197\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] Epoch[1] Batch[370] avg_epoch_loss=1.490948\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=370 train loss <loss>=1.4790828228\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] Epoch[1] Batch [370]#011Speed: 13398.06 samples/sec#011loss=1.479083\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] Epoch[1] Batch[375] avg_epoch_loss=1.490695\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=375 train loss <loss>=1.47194638252\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] Epoch[1] Batch [375]#011Speed: 1825.16 samples/sec#011loss=1.471946\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] Epoch[1] Batch[380] avg_epoch_loss=1.489416\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=380 train loss <loss>=1.39321182966\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] Epoch[1] Batch [380]#011Speed: 12626.79 samples/sec#011loss=1.393212\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] Epoch[1] Batch[385] avg_epoch_loss=1.486779\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=385 train loss <loss>=1.28584418297\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] Epoch[1] Batch [385]#011Speed: 1607.18 samples/sec#011loss=1.285844\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] Epoch[1] Batch[390] avg_epoch_loss=1.487896\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=390 train loss <loss>=1.57412929535\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] Epoch[1] Batch [390]#011Speed: 14283.19 samples/sec#011loss=1.574129\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] Epoch[1] Batch[395] avg_epoch_loss=1.488151\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=395 train loss <loss>=1.50808134079\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] Epoch[1] Batch [395]#011Speed: 14261.49 samples/sec#011loss=1.508081\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] Epoch[1] Batch[400] avg_epoch_loss=1.488541\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=400 train loss <loss>=1.5194160223\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] Epoch[1] Batch [400]#011Speed: 1799.69 samples/sec#011loss=1.519416\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] Epoch[1] Batch[405] avg_epoch_loss=1.485784\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=405 train loss <loss>=1.26470720768\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:35 INFO 140088046479168] Epoch[1] Batch [405]#011Speed: 14340.73 samples/sec#011loss=1.264707\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] Epoch[1] Batch[410] avg_epoch_loss=1.481567\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=410 train loss <loss>=1.1391458869\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] Epoch[1] Batch [410]#011Speed: 1799.74 samples/sec#011loss=1.139146\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] Epoch[1] Batch[415] avg_epoch_loss=1.480630\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=415 train loss <loss>=1.40361757278\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] Epoch[1] Batch [415]#011Speed: 14295.97 samples/sec#011loss=1.403618\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] Epoch[1] Batch[420] avg_epoch_loss=1.478872\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=420 train loss <loss>=1.33256826401\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] Epoch[1] Batch [420]#011Speed: 14051.71 samples/sec#011loss=1.332568\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] Epoch[1] Batch[425] avg_epoch_loss=1.477764\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=425 train loss <loss>=1.38449351788\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] Epoch[1] Batch [425]#011Speed: 1477.45 samples/sec#011loss=1.384494\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] Epoch[1] Batch[430] avg_epoch_loss=1.479141\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=430 train loss <loss>=1.59647324085\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] Epoch[1] Batch [430]#011Speed: 13606.55 samples/sec#011loss=1.596473\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] Epoch[1] Batch[435] avg_epoch_loss=1.479031\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=435 train loss <loss>=1.46951090097\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] Epoch[1] Batch [435]#011Speed: 1741.54 samples/sec#011loss=1.469511\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] Epoch[1] Batch[440] avg_epoch_loss=1.477639\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=440 train loss <loss>=1.35631055832\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] Epoch[1] Batch [440]#011Speed: 12404.48 samples/sec#011loss=1.356311\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] Epoch[1] Batch[445] avg_epoch_loss=1.480200\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=445 train loss <loss>=1.70601770878\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] Epoch[1] Batch [445]#011Speed: 12861.28 samples/sec#011loss=1.706018\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] Epoch[1] Batch[450] avg_epoch_loss=1.480197\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=450 train loss <loss>=1.47994496822\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] Epoch[1] Batch [450]#011Speed: 1771.30 samples/sec#011loss=1.479945\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] Epoch[1] Batch[455] avg_epoch_loss=1.478290\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=455 train loss <loss>=1.30630528927\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] Epoch[1] Batch [455]#011Speed: 14146.05 samples/sec#011loss=1.306305\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] Epoch[1] Batch[460] avg_epoch_loss=1.476967\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=460 train loss <loss>=1.35631508827\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:36 INFO 140088046479168] Epoch[1] Batch [460]#011Speed: 1771.52 samples/sec#011loss=1.356315\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] Epoch[1] Batch[465] avg_epoch_loss=1.475731\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=465 train loss <loss>=1.36172852516\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] Epoch[1] Batch [465]#011Speed: 14425.50 samples/sec#011loss=1.361729\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] Epoch[1] Batch[470] avg_epoch_loss=1.476957\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=470 train loss <loss>=1.59122359753\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] Epoch[1] Batch [470]#011Speed: 14540.84 samples/sec#011loss=1.591224\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] Epoch[1] Batch[475] avg_epoch_loss=1.475740\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=475 train loss <loss>=1.36109683514\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] Epoch[1] Batch [475]#011Speed: 1704.30 samples/sec#011loss=1.361097\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] Epoch[1] Batch[480] avg_epoch_loss=1.475996\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=480 train loss <loss>=1.50039083958\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] Epoch[1] Batch [480]#011Speed: 14450.19 samples/sec#011loss=1.500391\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] Epoch[1] Batch[485] avg_epoch_loss=1.474117\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=485 train loss <loss>=1.29330534935\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] Epoch[1] Batch [485]#011Speed: 14209.55 samples/sec#011loss=1.293305\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] Epoch[1] Batch[490] avg_epoch_loss=1.473983\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=490 train loss <loss>=1.46102790833\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] Epoch[1] Batch [490]#011Speed: 1770.94 samples/sec#011loss=1.461028\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] Epoch[1] Batch[495] avg_epoch_loss=1.472914\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=495 train loss <loss>=1.36787760258\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] Epoch[1] Batch [495]#011Speed: 14096.28 samples/sec#011loss=1.367878\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] Epoch[1] Batch[500] avg_epoch_loss=1.472777\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=500 train loss <loss>=1.459232831\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] Epoch[1] Batch [500]#011Speed: 1842.43 samples/sec#011loss=1.459233\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] Epoch[1] Batch[505] avg_epoch_loss=1.469330\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=505 train loss <loss>=1.12392338514\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] Epoch[1] Batch [505]#011Speed: 13276.26 samples/sec#011loss=1.123923\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] Epoch[1] Batch[510] avg_epoch_loss=1.467487\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=510 train loss <loss>=1.28092751503\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] Epoch[1] Batch [510]#011Speed: 1633.25 samples/sec#011loss=1.280928\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] Epoch[1] Batch[515] avg_epoch_loss=1.466624\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=515 train loss <loss>=1.37849390507\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] Epoch[1] Batch [515]#011Speed: 13228.63 samples/sec#011loss=1.378494\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] Epoch[1] Batch[520] avg_epoch_loss=1.463697\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=520 train loss <loss>=1.16163825989\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:37 INFO 140088046479168] Epoch[1] Batch [520]#011Speed: 13225.25 samples/sec#011loss=1.161638\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] Epoch[1] Batch[525] avg_epoch_loss=1.464613\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=525 train loss <loss>=1.55998573303\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] Epoch[1] Batch [525]#011Speed: 1890.35 samples/sec#011loss=1.559986\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] Epoch[1] Batch[530] avg_epoch_loss=1.463221\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=530 train loss <loss>=1.31685900688\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] Epoch[1] Batch [530]#011Speed: 13588.23 samples/sec#011loss=1.316859\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] Epoch[1] Batch[535] avg_epoch_loss=1.463447\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=535 train loss <loss>=1.48739938736\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] Epoch[1] Batch [535]#011Speed: 1737.91 samples/sec#011loss=1.487399\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] Epoch[1] Batch[540] avg_epoch_loss=1.464047\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=540 train loss <loss>=1.5283400774\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] Epoch[1] Batch [540]#011Speed: 13232.94 samples/sec#011loss=1.528340\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] Epoch[1] Batch[545] avg_epoch_loss=1.465609\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=545 train loss <loss>=1.63464298248\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] Epoch[1] Batch [545]#011Speed: 13892.45 samples/sec#011loss=1.634643\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] Epoch[1] Batch[550] avg_epoch_loss=1.465316\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=550 train loss <loss>=1.43334400654\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] Epoch[1] Batch [550]#011Speed: 1842.11 samples/sec#011loss=1.433344\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] Epoch[1] Batch[555] avg_epoch_loss=1.463959\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=555 train loss <loss>=1.31445360184\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] Epoch[1] Batch [555]#011Speed: 13509.59 samples/sec#011loss=1.314454\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] Epoch[1] Batch[560] avg_epoch_loss=1.463220\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=560 train loss <loss>=1.38104635477\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] Epoch[1] Batch [560]#011Speed: 1780.52 samples/sec#011loss=1.381046\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] Epoch[1] Batch[565] avg_epoch_loss=1.465878\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=565 train loss <loss>=1.76402254105\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] Epoch[1] Batch [565]#011Speed: 14133.69 samples/sec#011loss=1.764023\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] Epoch[1] Batch[570] avg_epoch_loss=1.465162\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=570 train loss <loss>=1.38416962624\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] Epoch[1] Batch [570]#011Speed: 14400.12 samples/sec#011loss=1.384170\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] Epoch[1] Batch[575] avg_epoch_loss=1.465768\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=575 train loss <loss>=1.53493010998\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] Epoch[1] Batch [575]#011Speed: 1724.18 samples/sec#011loss=1.534930\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] Epoch[1] Batch[580] avg_epoch_loss=1.466921\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=580 train loss <loss>=1.59972654581\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:38 INFO 140088046479168] Epoch[1] Batch [580]#011Speed: 14234.26 samples/sec#011loss=1.599727\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] Epoch[1] Batch[585] avg_epoch_loss=1.468061\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=585 train loss <loss>=1.60057735443\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] Epoch[1] Batch [585]#011Speed: 1742.99 samples/sec#011loss=1.600577\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] Epoch[1] Batch[590] avg_epoch_loss=1.467400\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=590 train loss <loss>=1.38989553452\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] Epoch[1] Batch [590]#011Speed: 14587.93 samples/sec#011loss=1.389896\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] Epoch[1] Batch[595] avg_epoch_loss=1.467667\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=595 train loss <loss>=1.49927890301\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] Epoch[1] Batch [595]#011Speed: 14465.92 samples/sec#011loss=1.499279\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] Epoch[1] Batch[600] avg_epoch_loss=1.468164\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=600 train loss <loss>=1.52736885548\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] Epoch[1] Batch [600]#011Speed: 1722.42 samples/sec#011loss=1.527369\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] Epoch[1] Batch[605] avg_epoch_loss=1.466255\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=605 train loss <loss>=1.23675373793\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] Epoch[1] Batch [605]#011Speed: 12347.08 samples/sec#011loss=1.236754\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] Epoch[1] Batch[610] avg_epoch_loss=1.465855\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=610 train loss <loss>=1.41742086411\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] Epoch[1] Batch [610]#011Speed: 12109.25 samples/sec#011loss=1.417421\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] Epoch[1] Batch[615] avg_epoch_loss=1.465545\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=615 train loss <loss>=1.42769552469\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] Epoch[1] Batch [615]#011Speed: 1323.73 samples/sec#011loss=1.427696\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] Epoch[1] Batch[620] avg_epoch_loss=1.462907\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=620 train loss <loss>=1.13792563677\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] Epoch[1] Batch [620]#011Speed: 13515.71 samples/sec#011loss=1.137926\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] Epoch[1] Batch[625] avg_epoch_loss=1.462557\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=625 train loss <loss>=1.4189907074\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] Epoch[1] Batch [625]#011Speed: 1697.13 samples/sec#011loss=1.418991\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] Epoch[1] Batch[630] avg_epoch_loss=1.461751\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=630 train loss <loss>=1.36084775925\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] Epoch[1] Batch [630]#011Speed: 13340.00 samples/sec#011loss=1.360848\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] Epoch[1] Batch[635] avg_epoch_loss=1.459999\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=635 train loss <loss>=1.23896801472\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:39 INFO 140088046479168] Epoch[1] Batch [635]#011Speed: 13886.56 samples/sec#011loss=1.238968\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] Epoch[1] Batch[640] avg_epoch_loss=1.458461\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=640 train loss <loss>=1.26274974346\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] Epoch[1] Batch [640]#011Speed: 1588.14 samples/sec#011loss=1.262750\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] Epoch[1] Batch[645] avg_epoch_loss=1.458554\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=645 train loss <loss>=1.47048521042\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] Epoch[1] Batch [645]#011Speed: 14127.29 samples/sec#011loss=1.470485\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] Epoch[1] Batch[650] avg_epoch_loss=1.457309\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=650 train loss <loss>=1.2965526104\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] Epoch[1] Batch [650]#011Speed: 1848.83 samples/sec#011loss=1.296553\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] Epoch[1] Batch[655] avg_epoch_loss=1.455897\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=655 train loss <loss>=1.27203171253\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] Epoch[1] Batch [655]#011Speed: 13861.74 samples/sec#011loss=1.272032\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] Epoch[1] Batch[660] avg_epoch_loss=1.455985\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=660 train loss <loss>=1.46748769283\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] Epoch[1] Batch [660]#011Speed: 12912.63 samples/sec#011loss=1.467488\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] Epoch[1] Batch[665] avg_epoch_loss=1.455950\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=665 train loss <loss>=1.45137739182\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] Epoch[1] Batch [665]#011Speed: 1694.93 samples/sec#011loss=1.451377\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] Epoch[1] Batch[670] avg_epoch_loss=1.455596\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=670 train loss <loss>=1.40838122368\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] Epoch[1] Batch [670]#011Speed: 14209.55 samples/sec#011loss=1.408381\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] Epoch[1] Batch[675] avg_epoch_loss=1.455849\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=675 train loss <loss>=1.48988745213\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] Epoch[1] Batch [675]#011Speed: 1711.92 samples/sec#011loss=1.489887\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] Epoch[1] Batch[680] avg_epoch_loss=1.454065\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=680 train loss <loss>=1.21286041737\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] Epoch[1] Batch [680]#011Speed: 13586.99 samples/sec#011loss=1.212860\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] Epoch[1] Batch[685] avg_epoch_loss=1.453985\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=685 train loss <loss>=1.44308973551\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:40 INFO 140088046479168] Epoch[1] Batch [685]#011Speed: 14076.47 samples/sec#011loss=1.443090\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] Epoch[1] Batch[690] avg_epoch_loss=1.456587\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=690 train loss <loss>=1.81353049278\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] Epoch[1] Batch [690]#011Speed: 1760.34 samples/sec#011loss=1.813530\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] Epoch[1] Batch[695] avg_epoch_loss=1.461040\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=695 train loss <loss>=2.07649695873\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] Epoch[1] Batch [695]#011Speed: 13946.44 samples/sec#011loss=2.076497\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] Epoch[1] Batch[700] avg_epoch_loss=1.464855\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=700 train loss <loss>=1.99579839706\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] Epoch[1] Batch [700]#011Speed: 1666.18 samples/sec#011loss=1.995798\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] Epoch[1] Batch[705] avg_epoch_loss=1.468660\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=705 train loss <loss>=2.00219051838\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] Epoch[1] Batch [705]#011Speed: 13930.66 samples/sec#011loss=2.002191\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] Epoch[1] Batch[710] avg_epoch_loss=1.470756\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=710 train loss <loss>=1.76663854122\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] Epoch[1] Batch [710]#011Speed: 13426.20 samples/sec#011loss=1.766639\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] Epoch[1] Batch[715] avg_epoch_loss=1.472500\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=715 train loss <loss>=1.72058532238\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] Epoch[1] Batch [715]#011Speed: 1840.17 samples/sec#011loss=1.720585\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] Epoch[1] Batch[720] avg_epoch_loss=1.473597\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=720 train loss <loss>=1.63070499897\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] Epoch[1] Batch [720]#011Speed: 13257.64 samples/sec#011loss=1.630705\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] Epoch[1] Batch[725] avg_epoch_loss=1.475196\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=725 train loss <loss>=1.70575714111\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] Epoch[1] Batch [725]#011Speed: 1685.99 samples/sec#011loss=1.705757\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] Epoch[1] Batch[730] avg_epoch_loss=1.477563\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=730 train loss <loss>=1.82126095295\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] Epoch[1] Batch [730]#011Speed: 13378.96 samples/sec#011loss=1.821261\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] Epoch[1] Batch[735] avg_epoch_loss=1.479399\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=735 train loss <loss>=1.74770870209\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] Epoch[1] Batch [735]#011Speed: 13276.92 samples/sec#011loss=1.747709\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] Epoch[1] Batch[740] avg_epoch_loss=1.478635\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=740 train loss <loss>=1.36627955437\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] Epoch[1] Batch [740]#011Speed: 1867.28 samples/sec#011loss=1.366280\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] Epoch[1] Batch[745] avg_epoch_loss=1.478793\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=745 train loss <loss>=1.50211379528\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:41 INFO 140088046479168] Epoch[1] Batch [745]#011Speed: 13272.59 samples/sec#011loss=1.502114\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] Epoch[1] Batch[750] avg_epoch_loss=1.479862\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=750 train loss <loss>=1.63944044113\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] Epoch[1] Batch [750]#011Speed: 1818.83 samples/sec#011loss=1.639440\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] Epoch[1] Batch[755] avg_epoch_loss=1.480271\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=755 train loss <loss>=1.54164834023\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] Epoch[1] Batch [755]#011Speed: 13162.73 samples/sec#011loss=1.541648\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] Epoch[1] Batch[760] avg_epoch_loss=1.479148\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=760 train loss <loss>=1.3094291687\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] Epoch[1] Batch [760]#011Speed: 13018.71 samples/sec#011loss=1.309429\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] Epoch[1] Batch[765] avg_epoch_loss=1.478663\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=765 train loss <loss>=1.40472760201\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] Epoch[1] Batch [765]#011Speed: 1651.95 samples/sec#011loss=1.404728\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] Epoch[1] Batch[770] avg_epoch_loss=1.477588\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=770 train loss <loss>=1.31295268536\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] Epoch[1] Batch [770]#011Speed: 13639.18 samples/sec#011loss=1.312953\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] Epoch[1] Batch[775] avg_epoch_loss=1.477152\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=775 train loss <loss>=1.40998623371\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] Epoch[1] Batch [775]#011Speed: 14208.95 samples/sec#011loss=1.409986\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] Epoch[1] Batch[780] avg_epoch_loss=1.477388\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=780 train loss <loss>=1.51390044689\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] Epoch[1] Batch [780]#011Speed: 1814.99 samples/sec#011loss=1.513900\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] Epoch[1] Batch[785] avg_epoch_loss=1.476562\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=785 train loss <loss>=1.34753835201\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] Epoch[1] Batch [785]#011Speed: 12743.92 samples/sec#011loss=1.347538\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] Epoch[1] Batch[790] avg_epoch_loss=1.476475\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=790 train loss <loss>=1.46290450096\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] Epoch[1] Batch [790]#011Speed: 1592.40 samples/sec#011loss=1.462905\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] Epoch[1] Batch[795] avg_epoch_loss=1.477128\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=795 train loss <loss>=1.58038380146\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] Epoch[1] Batch [795]#011Speed: 13239.47 samples/sec#011loss=1.580384\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] Epoch[1] Batch[800] avg_epoch_loss=1.476855\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=800 train loss <loss>=1.43339791298\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:42 INFO 140088046479168] Epoch[1] Batch [800]#011Speed: 10696.94 samples/sec#011loss=1.433398\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] Epoch[1] Batch[805] avg_epoch_loss=1.475845\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=805 train loss <loss>=1.31401107311\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] Epoch[1] Batch [805]#011Speed: 1726.76 samples/sec#011loss=1.314011\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] Epoch[1] Batch[810] avg_epoch_loss=1.474873\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=810 train loss <loss>=1.31827396154\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] Epoch[1] Batch [810]#011Speed: 14358.83 samples/sec#011loss=1.318274\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] Epoch[1] Batch[815] avg_epoch_loss=1.473909\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=815 train loss <loss>=1.31753413677\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] Epoch[1] Batch [815]#011Speed: 1782.32 samples/sec#011loss=1.317534\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] Epoch[1] Batch[820] avg_epoch_loss=1.472951\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=820 train loss <loss>=1.3165135622\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] Epoch[1] Batch [820]#011Speed: 13274.16 samples/sec#011loss=1.316514\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] Epoch[1] Batch[825] avg_epoch_loss=1.471793\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=825 train loss <loss>=1.28177560568\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] Epoch[1] Batch [825]#011Speed: 13265.37 samples/sec#011loss=1.281776\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] Epoch[1] Batch[830] avg_epoch_loss=1.471187\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=830 train loss <loss>=1.37105276585\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] Epoch[1] Batch [830]#011Speed: 1743.43 samples/sec#011loss=1.371053\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] Epoch[1] Batch[835] avg_epoch_loss=1.469820\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=835 train loss <loss>=1.2425018549\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] Epoch[1] Batch [835]#011Speed: 13263.67 samples/sec#011loss=1.242502\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] Epoch[1] Batch[840] avg_epoch_loss=1.469855\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=840 train loss <loss>=1.47576224804\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] Epoch[1] Batch [840]#011Speed: 13212.23 samples/sec#011loss=1.475762\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] Epoch[1] Batch[845] avg_epoch_loss=1.469430\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=845 train loss <loss>=1.39792728424\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] Epoch[1] Batch [845]#011Speed: 1804.84 samples/sec#011loss=1.397927\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] Epoch[1] Batch[850] avg_epoch_loss=1.468629\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=850 train loss <loss>=1.33320059776\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] Epoch[1] Batch [850]#011Speed: 12646.78 samples/sec#011loss=1.333201\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] Epoch[1] Batch[855] avg_epoch_loss=1.467758\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=855 train loss <loss>=1.3193972826\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] Epoch[1] Batch [855]#011Speed: 1520.62 samples/sec#011loss=1.319397\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] Epoch[1] Batch[860] avg_epoch_loss=1.466792\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=860 train loss <loss>=1.30147792101\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] Epoch[1] Batch [860]#011Speed: 14227.78 samples/sec#011loss=1.301478\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] Epoch[1] Batch[865] avg_epoch_loss=1.466771\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=865 train loss <loss>=1.46309146881\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:43 INFO 140088046479168] Epoch[1] Batch [865]#011Speed: 14370.36 samples/sec#011loss=1.463091\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] Epoch[1] Batch[870] avg_epoch_loss=1.465205\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=870 train loss <loss>=1.19403467178\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] Epoch[1] Batch [870]#011Speed: 1859.65 samples/sec#011loss=1.194035\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] Epoch[1] Batch[875] avg_epoch_loss=1.466094\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=875 train loss <loss>=1.62086954117\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] Epoch[1] Batch [875]#011Speed: 13632.12 samples/sec#011loss=1.620870\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] Epoch[1] Batch[880] avg_epoch_loss=1.466879\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=880 train loss <loss>=1.60441067219\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] Epoch[1] Batch [880]#011Speed: 1811.53 samples/sec#011loss=1.604411\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] Epoch[1] Batch[885] avg_epoch_loss=1.466302\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=885 train loss <loss>=1.36479312181\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] Epoch[1] Batch [885]#011Speed: 14788.85 samples/sec#011loss=1.364793\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] Epoch[1] Batch[890] avg_epoch_loss=1.465878\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=890 train loss <loss>=1.39068481922\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] Epoch[1] Batch [890]#011Speed: 14289.43 samples/sec#011loss=1.390685\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] Epoch[1] Batch[895] avg_epoch_loss=1.463875\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, batch=895 train loss <loss>=1.10691939592\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] Epoch[1] Batch [895]#011Speed: 2471.52 samples/sec#011loss=1.106919\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] processed a total of 57552 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15838.659048080444, \"sum\": 15838.659048080444, \"min\": 15838.659048080444}}, \"EndTime\": 1604320424.511995, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320408.673274}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] #throughput_metric: host=algo-1, train throughput=3633.61315717 records/second\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=1, train loss <loss>=1.46327616705\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] Saved checkpoint to \"/opt/ml/model/state_2587fc4f-92a5-4c37-913f-27eff89dfb30-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 5.190849304199219, \"sum\": 5.190849304199219, \"min\": 5.190849304199219}}, \"EndTime\": 1604320424.517815, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320424.512078}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] Epoch[2] Batch[0] avg_epoch_loss=1.440644\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=1.44064354897\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] Epoch[2] Batch[5] avg_epoch_loss=1.570434\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=1.57043363651\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] Epoch[2] Batch [5]#011Speed: 11576.18 samples/sec#011loss=1.570434\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] Epoch[2] Batch[10] avg_epoch_loss=1.473734\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=1.35769374371\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] Epoch[2] Batch [10]#011Speed: 14149.93 samples/sec#011loss=1.357694\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] Epoch[2] Batch[15] avg_epoch_loss=1.416519\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=15 train loss <loss>=1.29064793587\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] Epoch[2] Batch [15]#011Speed: 1544.15 samples/sec#011loss=1.290648\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] Epoch[2] Batch[20] avg_epoch_loss=1.371500\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=20 train loss <loss>=1.22743723392\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:44 INFO 140088046479168] Epoch[2] Batch [20]#011Speed: 14248.92 samples/sec#011loss=1.227437\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] Epoch[2] Batch[25] avg_epoch_loss=1.377430\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=25 train loss <loss>=1.40233795643\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] Epoch[2] Batch [25]#011Speed: 1880.10 samples/sec#011loss=1.402338\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] Epoch[2] Batch[30] avg_epoch_loss=1.377346\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=30 train loss <loss>=1.3769077301\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] Epoch[2] Batch [30]#011Speed: 14506.57 samples/sec#011loss=1.376908\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] Epoch[2] Batch[35] avg_epoch_loss=1.379962\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=35 train loss <loss>=1.39618332386\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] Epoch[2] Batch [35]#011Speed: 14219.03 samples/sec#011loss=1.396183\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] Epoch[2] Batch[40] avg_epoch_loss=1.371979\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=40 train loss <loss>=1.31450340748\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] Epoch[2] Batch [40]#011Speed: 1794.70 samples/sec#011loss=1.314503\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] Epoch[2] Batch[45] avg_epoch_loss=1.362579\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=45 train loss <loss>=1.28549103737\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] Epoch[2] Batch [45]#011Speed: 14243.03 samples/sec#011loss=1.285491\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] Epoch[2] Batch[50] avg_epoch_loss=1.343728\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=50 train loss <loss>=1.17030518055\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] Epoch[2] Batch [50]#011Speed: 1839.60 samples/sec#011loss=1.170305\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] Epoch[2] Batch[55] avg_epoch_loss=1.347360\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=55 train loss <loss>=1.38440914154\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] Epoch[2] Batch [55]#011Speed: 14649.39 samples/sec#011loss=1.384409\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] Epoch[2] Batch[60] avg_epoch_loss=1.350682\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=60 train loss <loss>=1.38788659573\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] Epoch[2] Batch [60]#011Speed: 14043.62 samples/sec#011loss=1.387887\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] Epoch[2] Batch[65] avg_epoch_loss=1.343330\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=65 train loss <loss>=1.25362626314\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] Epoch[2] Batch [65]#011Speed: 1357.08 samples/sec#011loss=1.253626\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] Epoch[2] Batch[70] avg_epoch_loss=1.343992\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=70 train loss <loss>=1.35274261236\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:45 INFO 140088046479168] Epoch[2] Batch [70]#011Speed: 14297.80 samples/sec#011loss=1.352743\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] Epoch[2] Batch[75] avg_epoch_loss=1.354236\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=75 train loss <loss>=1.49969575405\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] Epoch[2] Batch [75]#011Speed: 1738.45 samples/sec#011loss=1.499696\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] Epoch[2] Batch[80] avg_epoch_loss=1.358853\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=80 train loss <loss>=1.42902674675\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] Epoch[2] Batch [80]#011Speed: 14163.07 samples/sec#011loss=1.429027\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] Epoch[2] Batch[85] avg_epoch_loss=1.358061\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=85 train loss <loss>=1.34524214268\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] Epoch[2] Batch [85]#011Speed: 13321.20 samples/sec#011loss=1.345242\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] Epoch[2] Batch[90] avg_epoch_loss=1.358745\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=90 train loss <loss>=1.37050442696\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] Epoch[2] Batch [90]#011Speed: 1675.65 samples/sec#011loss=1.370504\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] Epoch[2] Batch[95] avg_epoch_loss=1.361498\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=95 train loss <loss>=1.41159756184\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] Epoch[2] Batch [95]#011Speed: 14258.91 samples/sec#011loss=1.411598\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] Epoch[2] Batch[100] avg_epoch_loss=1.351384\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=100 train loss <loss>=1.1571950078\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] Epoch[2] Batch [100]#011Speed: 1838.11 samples/sec#011loss=1.157195\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] Epoch[2] Batch[105] avg_epoch_loss=1.356154\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=105 train loss <loss>=1.45251064301\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] Epoch[2] Batch [105]#011Speed: 13507.82 samples/sec#011loss=1.452511\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] Epoch[2] Batch[110] avg_epoch_loss=1.350990\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=110 train loss <loss>=1.24150631428\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] Epoch[2] Batch [110]#011Speed: 13230.33 samples/sec#011loss=1.241506\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] Epoch[2] Batch[115] avg_epoch_loss=1.362996\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=115 train loss <loss>=1.62953174114\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] Epoch[2] Batch [115]#011Speed: 1890.63 samples/sec#011loss=1.629532\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] Epoch[2] Batch[120] avg_epoch_loss=1.359331\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=120 train loss <loss>=1.27431877851\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] Epoch[2] Batch [120]#011Speed: 13466.89 samples/sec#011loss=1.274319\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] Epoch[2] Batch[125] avg_epoch_loss=1.351858\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=125 train loss <loss>=1.17100484371\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] Epoch[2] Batch [125]#011Speed: 1645.21 samples/sec#011loss=1.171005\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] Epoch[2] Batch[130] avg_epoch_loss=1.354407\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=130 train loss <loss>=1.41863315105\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] Epoch[2] Batch [130]#011Speed: 14434.65 samples/sec#011loss=1.418633\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] Epoch[2] Batch[135] avg_epoch_loss=1.345381\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=135 train loss <loss>=1.10889325142\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:46 INFO 140088046479168] Epoch[2] Batch [135]#011Speed: 14211.51 samples/sec#011loss=1.108893\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] Epoch[2] Batch[140] avg_epoch_loss=1.340883\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=140 train loss <loss>=1.21855578423\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] Epoch[2] Batch [140]#011Speed: 1781.74 samples/sec#011loss=1.218556\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] Epoch[2] Batch[145] avg_epoch_loss=1.330690\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=145 train loss <loss>=1.04324542284\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] Epoch[2] Batch [145]#011Speed: 14383.30 samples/sec#011loss=1.043245\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] Epoch[2] Batch[150] avg_epoch_loss=1.321402\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=150 train loss <loss>=1.05017821789\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] Epoch[2] Batch [150]#011Speed: 1717.22 samples/sec#011loss=1.050178\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] Epoch[2] Batch[155] avg_epoch_loss=1.320996\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=155 train loss <loss>=1.30873451233\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] Epoch[2] Batch [155]#011Speed: 13309.44 samples/sec#011loss=1.308735\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] Epoch[2] Batch[160] avg_epoch_loss=1.334361\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=160 train loss <loss>=1.75135917664\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] Epoch[2] Batch [160]#011Speed: 13216.00 samples/sec#011loss=1.751359\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] Epoch[2] Batch[165] avg_epoch_loss=1.341412\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=165 train loss <loss>=1.56844898462\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] Epoch[2] Batch [165]#011Speed: 1758.30 samples/sec#011loss=1.568449\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] Epoch[2] Batch[170] avg_epoch_loss=1.356045\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=170 train loss <loss>=1.84186472893\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] Epoch[2] Batch [170]#011Speed: 13409.30 samples/sec#011loss=1.841865\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] Epoch[2] Batch[175] avg_epoch_loss=1.353401\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=175 train loss <loss>=1.26296877861\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] Epoch[2] Batch [175]#011Speed: 1624.78 samples/sec#011loss=1.262969\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] Epoch[2] Batch[180] avg_epoch_loss=1.351979\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=180 train loss <loss>=1.30194665194\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] Epoch[2] Batch [180]#011Speed: 13252.80 samples/sec#011loss=1.301947\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] Epoch[2] Batch[185] avg_epoch_loss=1.348791\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=185 train loss <loss>=1.23336250782\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:47 INFO 140088046479168] Epoch[2] Batch [185]#011Speed: 10692.00 samples/sec#011loss=1.233363\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] Epoch[2] Batch[190] avg_epoch_loss=1.351087\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=190 train loss <loss>=1.43651561737\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] Epoch[2] Batch [190]#011Speed: 1481.78 samples/sec#011loss=1.436516\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] Epoch[2] Batch[195] avg_epoch_loss=1.352132\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=195 train loss <loss>=1.39203364849\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] Epoch[2] Batch [195]#011Speed: 13208.98 samples/sec#011loss=1.392034\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] Epoch[2] Batch[200] avg_epoch_loss=1.352163\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=200 train loss <loss>=1.35338745117\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] Epoch[2] Batch [200]#011Speed: 13155.12 samples/sec#011loss=1.353387\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] Epoch[2] Batch[205] avg_epoch_loss=1.348401\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=205 train loss <loss>=1.19717950821\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] Epoch[2] Batch [205]#011Speed: 1871.33 samples/sec#011loss=1.197180\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] Epoch[2] Batch[210] avg_epoch_loss=1.351871\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=210 train loss <loss>=1.4948274374\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] Epoch[2] Batch [210]#011Speed: 13642.65 samples/sec#011loss=1.494827\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] Epoch[2] Batch[215] avg_epoch_loss=1.353614\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=215 train loss <loss>=1.42717627287\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] Epoch[2] Batch [215]#011Speed: 1764.76 samples/sec#011loss=1.427176\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] Epoch[2] Batch[220] avg_epoch_loss=1.350810\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=220 train loss <loss>=1.2296430707\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] Epoch[2] Batch [220]#011Speed: 14266.49 samples/sec#011loss=1.229643\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] Epoch[2] Batch[225] avg_epoch_loss=1.352778\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=225 train loss <loss>=1.43980584145\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] Epoch[2] Batch [225]#011Speed: 14121.79 samples/sec#011loss=1.439806\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] Epoch[2] Batch[230] avg_epoch_loss=1.359040\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=230 train loss <loss>=1.64203879833\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] Epoch[2] Batch [230]#011Speed: 1702.46 samples/sec#011loss=1.642039\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] Epoch[2] Batch[235] avg_epoch_loss=1.358830\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=235 train loss <loss>=1.34914480448\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] Epoch[2] Batch [235]#011Speed: 13685.77 samples/sec#011loss=1.349145\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] Epoch[2] Batch[240] avg_epoch_loss=1.361164\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=240 train loss <loss>=1.47132248878\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] Epoch[2] Batch [240]#011Speed: 1540.44 samples/sec#011loss=1.471322\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] Epoch[2] Batch[245] avg_epoch_loss=1.365322\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=245 train loss <loss>=1.56576395035\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] Epoch[2] Batch [245]#011Speed: 14231.70 samples/sec#011loss=1.565764\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] Epoch[2] Batch[250] avg_epoch_loss=1.364806\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=250 train loss <loss>=1.33939526081\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:48 INFO 140088046479168] Epoch[2] Batch [250]#011Speed: 14262.25 samples/sec#011loss=1.339395\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] Epoch[2] Batch[255] avg_epoch_loss=1.363204\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=255 train loss <loss>=1.28280214071\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] Epoch[2] Batch [255]#011Speed: 1772.32 samples/sec#011loss=1.282802\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] Epoch[2] Batch[260] avg_epoch_loss=1.359112\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=260 train loss <loss>=1.14960923195\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] Epoch[2] Batch [260]#011Speed: 13500.34 samples/sec#011loss=1.149609\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] Epoch[2] Batch[265] avg_epoch_loss=1.360084\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=265 train loss <loss>=1.41082811356\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] Epoch[2] Batch [265]#011Speed: 1729.60 samples/sec#011loss=1.410828\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] Epoch[2] Batch[270] avg_epoch_loss=1.361832\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=270 train loss <loss>=1.45480235815\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] Epoch[2] Batch [270]#011Speed: 14413.73 samples/sec#011loss=1.454802\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] Epoch[2] Batch[275] avg_epoch_loss=1.362677\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=275 train loss <loss>=1.40848536491\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] Epoch[2] Batch [275]#011Speed: 13996.47 samples/sec#011loss=1.408485\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] Epoch[2] Batch[280] avg_epoch_loss=1.364802\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=280 train loss <loss>=1.48209016323\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] Epoch[2] Batch [280]#011Speed: 1737.09 samples/sec#011loss=1.482090\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] Epoch[2] Batch[285] avg_epoch_loss=1.359118\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=285 train loss <loss>=1.03970243931\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] Epoch[2] Batch [285]#011Speed: 14565.29 samples/sec#011loss=1.039702\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] Epoch[2] Batch[290] avg_epoch_loss=1.357968\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=290 train loss <loss>=1.2921435833\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] Epoch[2] Batch [290]#011Speed: 14558.66 samples/sec#011loss=1.292144\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] Epoch[2] Batch[295] avg_epoch_loss=1.356962\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=295 train loss <loss>=1.29844748974\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] Epoch[2] Batch [295]#011Speed: 1742.23 samples/sec#011loss=1.298447\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] Epoch[2] Batch[300] avg_epoch_loss=1.356124\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=300 train loss <loss>=1.30652480125\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:49 INFO 140088046479168] Epoch[2] Batch [300]#011Speed: 14367.75 samples/sec#011loss=1.306525\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] Epoch[2] Batch[305] avg_epoch_loss=1.355021\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=305 train loss <loss>=1.2886002779\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] Epoch[2] Batch [305]#011Speed: 1730.53 samples/sec#011loss=1.288600\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] Epoch[2] Batch[310] avg_epoch_loss=1.352363\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=310 train loss <loss>=1.18968894482\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] Epoch[2] Batch [310]#011Speed: 14212.11 samples/sec#011loss=1.189689\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] Epoch[2] Batch[315] avg_epoch_loss=1.349165\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=315 train loss <loss>=1.15027185678\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] Epoch[2] Batch [315]#011Speed: 14101.32 samples/sec#011loss=1.150272\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] Epoch[2] Batch[320] avg_epoch_loss=1.348622\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=320 train loss <loss>=1.31425950527\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] Epoch[2] Batch [320]#011Speed: 1651.01 samples/sec#011loss=1.314260\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] Epoch[2] Batch[325] avg_epoch_loss=1.345308\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=325 train loss <loss>=1.13256889582\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] Epoch[2] Batch [325]#011Speed: 14246.96 samples/sec#011loss=1.132569\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] Epoch[2] Batch[330] avg_epoch_loss=1.349850\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=330 train loss <loss>=1.64600980282\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] Epoch[2] Batch [330]#011Speed: 1816.82 samples/sec#011loss=1.646010\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] Epoch[2] Batch[335] avg_epoch_loss=1.347903\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=335 train loss <loss>=1.21896932125\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] Epoch[2] Batch [335]#011Speed: 14198.28 samples/sec#011loss=1.218969\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] Epoch[2] Batch[340] avg_epoch_loss=1.346322\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=340 train loss <loss>=1.24011788368\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] Epoch[2] Batch [340]#011Speed: 13366.17 samples/sec#011loss=1.240118\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] Epoch[2] Batch[345] avg_epoch_loss=1.343957\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=345 train loss <loss>=1.18264042139\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] Epoch[2] Batch [345]#011Speed: 1677.95 samples/sec#011loss=1.182640\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] Epoch[2] Batch[350] avg_epoch_loss=1.342309\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=350 train loss <loss>=1.22827274799\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] Epoch[2] Batch [350]#011Speed: 14489.35 samples/sec#011loss=1.228273\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] Epoch[2] Batch[355] avg_epoch_loss=1.344211\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=355 train loss <loss>=1.47771736383\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] Epoch[2] Batch [355]#011Speed: 1531.74 samples/sec#011loss=1.477717\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] Epoch[2] Batch[360] avg_epoch_loss=1.352264\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=360 train loss <loss>=1.92565925121\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:50 INFO 140088046479168] Epoch[2] Batch [360]#011Speed: 13297.84 samples/sec#011loss=1.925659\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] Epoch[2] Batch[365] avg_epoch_loss=1.360514\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=365 train loss <loss>=1.95612981319\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] Epoch[2] Batch [365]#011Speed: 13995.15 samples/sec#011loss=1.956130\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] Epoch[2] Batch[370] avg_epoch_loss=1.364981\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=370 train loss <loss>=1.69198999405\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] Epoch[2] Batch [370]#011Speed: 1905.85 samples/sec#011loss=1.691990\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] Epoch[2] Batch[375] avg_epoch_loss=1.364968\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=375 train loss <loss>=1.36399960518\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] Epoch[2] Batch [375]#011Speed: 14330.47 samples/sec#011loss=1.364000\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] Epoch[2] Batch[380] avg_epoch_loss=1.366666\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=380 train loss <loss>=1.49438717365\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] Epoch[2] Batch [380]#011Speed: 1859.26 samples/sec#011loss=1.494387\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] Epoch[2] Batch[385] avg_epoch_loss=1.369824\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=385 train loss <loss>=1.61044535637\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] Epoch[2] Batch [385]#011Speed: 14307.40 samples/sec#011loss=1.610445\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] Epoch[2] Batch[390] avg_epoch_loss=1.371287\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=390 train loss <loss>=1.4842287302\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] Epoch[2] Batch [390]#011Speed: 14345.94 samples/sec#011loss=1.484229\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] Epoch[2] Batch[395] avg_epoch_loss=1.372129\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=395 train loss <loss>=1.43794395924\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] Epoch[2] Batch [395]#011Speed: 1816.15 samples/sec#011loss=1.437944\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] Epoch[2] Batch[400] avg_epoch_loss=1.373099\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=400 train loss <loss>=1.4499904871\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] Epoch[2] Batch [400]#011Speed: 14016.64 samples/sec#011loss=1.449990\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] Epoch[2] Batch[405] avg_epoch_loss=1.373961\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=405 train loss <loss>=1.44303240776\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] Epoch[2] Batch [405]#011Speed: 1633.79 samples/sec#011loss=1.443032\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] Epoch[2] Batch[410] avg_epoch_loss=1.373299\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=410 train loss <loss>=1.31956026554\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] Epoch[2] Batch [410]#011Speed: 13422.85 samples/sec#011loss=1.319560\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] Epoch[2] Batch[415] avg_epoch_loss=1.374434\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=415 train loss <loss>=1.46775679588\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:51 INFO 140088046479168] Epoch[2] Batch [415]#011Speed: 13371.23 samples/sec#011loss=1.467757\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] Epoch[2] Batch[420] avg_epoch_loss=1.374729\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=420 train loss <loss>=1.39923593998\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] Epoch[2] Batch [420]#011Speed: 1806.60 samples/sec#011loss=1.399236\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] Epoch[2] Batch[425] avg_epoch_loss=1.376207\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=425 train loss <loss>=1.50066907406\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] Epoch[2] Batch [425]#011Speed: 13271.41 samples/sec#011loss=1.500669\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] Epoch[2] Batch[430] avg_epoch_loss=1.376381\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=430 train loss <loss>=1.39122847319\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] Epoch[2] Batch [430]#011Speed: 1724.45 samples/sec#011loss=1.391228\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] Epoch[2] Batch[435] avg_epoch_loss=1.377080\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=435 train loss <loss>=1.43734350204\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] Epoch[2] Batch [435]#011Speed: 14174.88 samples/sec#011loss=1.437344\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] Epoch[2] Batch[440] avg_epoch_loss=1.377907\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=440 train loss <loss>=1.44998459816\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] Epoch[2] Batch [440]#011Speed: 14202.63 samples/sec#011loss=1.449985\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] Epoch[2] Batch[445] avg_epoch_loss=1.375976\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=445 train loss <loss>=1.20569865704\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] Epoch[2] Batch [445]#011Speed: 1798.38 samples/sec#011loss=1.205699\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] Epoch[2] Batch[450] avg_epoch_loss=1.375675\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=450 train loss <loss>=1.34882166386\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] Epoch[2] Batch [450]#011Speed: 13365.64 samples/sec#011loss=1.348822\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] Epoch[2] Batch[455] avg_epoch_loss=1.374480\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=455 train loss <loss>=1.2666408062\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] Epoch[2] Batch [455]#011Speed: 1748.90 samples/sec#011loss=1.266641\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] Epoch[2] Batch[460] avg_epoch_loss=1.372459\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=460 train loss <loss>=1.1881565094\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] Epoch[2] Batch [460]#011Speed: 14381.45 samples/sec#011loss=1.188157\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] Epoch[2] Batch[465] avg_epoch_loss=1.372267\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=465 train loss <loss>=1.35461678505\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] Epoch[2] Batch [465]#011Speed: 14372.98 samples/sec#011loss=1.354617\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] Epoch[2] Batch[470] avg_epoch_loss=1.369248\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=470 train loss <loss>=1.08780013323\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] Epoch[2] Batch [470]#011Speed: 1634.59 samples/sec#011loss=1.087800\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] Epoch[2] Batch[475] avg_epoch_loss=1.367397\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=475 train loss <loss>=1.19306923151\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:52 INFO 140088046479168] Epoch[2] Batch [475]#011Speed: 12840.61 samples/sec#011loss=1.193069\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] Epoch[2] Batch[480] avg_epoch_loss=1.366446\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=480 train loss <loss>=1.27592253685\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] Epoch[2] Batch [480]#011Speed: 1759.44 samples/sec#011loss=1.275923\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] Epoch[2] Batch[485] avg_epoch_loss=1.365663\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=485 train loss <loss>=1.29033296108\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] Epoch[2] Batch [485]#011Speed: 14077.06 samples/sec#011loss=1.290333\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] Epoch[2] Batch[490] avg_epoch_loss=1.366628\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=490 train loss <loss>=1.46037282944\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] Epoch[2] Batch [490]#011Speed: 14389.16 samples/sec#011loss=1.460373\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] Epoch[2] Batch[495] avg_epoch_loss=1.369850\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=495 train loss <loss>=1.68628098965\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] Epoch[2] Batch [495]#011Speed: 1595.63 samples/sec#011loss=1.686281\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] Epoch[2] Batch[500] avg_epoch_loss=1.375280\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=500 train loss <loss>=1.91398738623\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] Epoch[2] Batch [500]#011Speed: 12582.64 samples/sec#011loss=1.913987\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] Epoch[2] Batch[505] avg_epoch_loss=1.379911\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=505 train loss <loss>=1.84387223721\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] Epoch[2] Batch [505]#011Speed: 13309.97 samples/sec#011loss=1.843872\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] Epoch[2] Batch[510] avg_epoch_loss=1.386337\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=510 train loss <loss>=2.03670213223\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] Epoch[2] Batch [510]#011Speed: 1734.11 samples/sec#011loss=2.036702\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] Epoch[2] Batch[515] avg_epoch_loss=1.390283\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=515 train loss <loss>=1.79354169369\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] Epoch[2] Batch [515]#011Speed: 13255.42 samples/sec#011loss=1.793542\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] Epoch[2] Batch[520] avg_epoch_loss=1.395565\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=520 train loss <loss>=1.94062964916\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] Epoch[2] Batch [520]#011Speed: 1597.29 samples/sec#011loss=1.940630\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] Epoch[2] Batch[525] avg_epoch_loss=1.398947\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=525 train loss <loss>=1.75143342018\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] Epoch[2] Batch [525]#011Speed: 13399.13 samples/sec#011loss=1.751433\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] Epoch[2] Batch[530] avg_epoch_loss=1.400829\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=530 train loss <loss>=1.59878816605\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:53 INFO 140088046479168] Epoch[2] Batch [530]#011Speed: 13235.16 samples/sec#011loss=1.598788\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] Epoch[2] Batch[535] avg_epoch_loss=1.403812\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=535 train loss <loss>=1.72059628963\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] Epoch[2] Batch [535]#011Speed: 1833.95 samples/sec#011loss=1.720596\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] Epoch[2] Batch[540] avg_epoch_loss=1.405911\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=540 train loss <loss>=1.63091959953\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] Epoch[2] Batch [540]#011Speed: 14384.07 samples/sec#011loss=1.630920\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] Epoch[2] Batch[545] avg_epoch_loss=1.406791\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=545 train loss <loss>=1.50203249454\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] Epoch[2] Batch [545]#011Speed: 1773.00 samples/sec#011loss=1.502032\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] Epoch[2] Batch[550] avg_epoch_loss=1.408169\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=550 train loss <loss>=1.55857129097\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] Epoch[2] Batch [550]#011Speed: 14038.19 samples/sec#011loss=1.558571\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] Epoch[2] Batch[555] avg_epoch_loss=1.409423\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=555 train loss <loss>=1.54765188694\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] Epoch[2] Batch [555]#011Speed: 12807.16 samples/sec#011loss=1.547652\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] Epoch[2] Batch[560] avg_epoch_loss=1.409908\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=560 train loss <loss>=1.46384675503\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] Epoch[2] Batch [560]#011Speed: 1717.03 samples/sec#011loss=1.463847\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] Epoch[2] Batch[565] avg_epoch_loss=1.409284\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=565 train loss <loss>=1.33928637505\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] Epoch[2] Batch [565]#011Speed: 13292.31 samples/sec#011loss=1.339286\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] Epoch[2] Batch[570] avg_epoch_loss=1.410866\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=570 train loss <loss>=1.58991057873\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] Epoch[2] Batch [570]#011Speed: 1667.05 samples/sec#011loss=1.589911\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] Epoch[2] Batch[575] avg_epoch_loss=1.411387\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=575 train loss <loss>=1.4708616972\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] Epoch[2] Batch [575]#011Speed: 14335.67 samples/sec#011loss=1.470862\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] Epoch[2] Batch[580] avg_epoch_loss=1.413366\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=580 train loss <loss>=1.64138281345\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] Epoch[2] Batch [580]#011Speed: 14429.38 samples/sec#011loss=1.641383\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] Epoch[2] Batch[585] avg_epoch_loss=1.413452\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=585 train loss <loss>=1.42340395451\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] Epoch[2] Batch [585]#011Speed: 1678.35 samples/sec#011loss=1.423404\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] Epoch[2] Batch[590] avg_epoch_loss=1.413079\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=590 train loss <loss>=1.36935818195\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] Epoch[2] Batch [590]#011Speed: 14448.17 samples/sec#011loss=1.369358\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] Epoch[2] Batch[595] avg_epoch_loss=1.412040\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=595 train loss <loss>=1.28932054043\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:54 INFO 140088046479168] Epoch[2] Batch [595]#011Speed: 14276.66 samples/sec#011loss=1.289321\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] Epoch[2] Batch[600] avg_epoch_loss=1.410352\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=600 train loss <loss>=1.20908126831\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] Epoch[2] Batch [600]#011Speed: 1740.54 samples/sec#011loss=1.209081\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] Epoch[2] Batch[605] avg_epoch_loss=1.409651\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=605 train loss <loss>=1.32545216084\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] Epoch[2] Batch [605]#011Speed: 14320.22 samples/sec#011loss=1.325452\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] Epoch[2] Batch[610] avg_epoch_loss=1.408294\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=610 train loss <loss>=1.24374061823\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] Epoch[2] Batch [610]#011Speed: 1789.67 samples/sec#011loss=1.243741\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] Epoch[2] Batch[615] avg_epoch_loss=1.406177\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=615 train loss <loss>=1.14758030176\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] Epoch[2] Batch [615]#011Speed: 13249.40 samples/sec#011loss=1.147580\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] Epoch[2] Batch[620] avg_epoch_loss=1.405220\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=620 train loss <loss>=1.28727176189\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] Epoch[2] Batch [620]#011Speed: 13263.15 samples/sec#011loss=1.287272\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] Epoch[2] Batch[625] avg_epoch_loss=1.403875\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=625 train loss <loss>=1.23680353165\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] Epoch[2] Batch [625]#011Speed: 1780.70 samples/sec#011loss=1.236804\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] Epoch[2] Batch[630] avg_epoch_loss=1.403394\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=630 train loss <loss>=1.34320251942\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] Epoch[2] Batch [630]#011Speed: 13414.39 samples/sec#011loss=1.343203\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] Epoch[2] Batch[635] avg_epoch_loss=1.400917\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=635 train loss <loss>=1.08830652237\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] Epoch[2] Batch [635]#011Speed: 1648.49 samples/sec#011loss=1.088307\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] Epoch[2] Batch[640] avg_epoch_loss=1.400645\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=640 train loss <loss>=1.36603646278\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] Epoch[2] Batch [640]#011Speed: 14238.04 samples/sec#011loss=1.366036\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] Epoch[2] Batch[645] avg_epoch_loss=1.399520\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=645 train loss <loss>=1.25524686575\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:55 INFO 140088046479168] Epoch[2] Batch [645]#011Speed: 12171.51 samples/sec#011loss=1.255247\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] Epoch[2] Batch[650] avg_epoch_loss=1.397022\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=650 train loss <loss>=1.07433922291\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] Epoch[2] Batch [650]#011Speed: 1766.81 samples/sec#011loss=1.074339\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] Epoch[2] Batch[655] avg_epoch_loss=1.394752\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=655 train loss <loss>=1.09924499989\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] Epoch[2] Batch [655]#011Speed: 13323.97 samples/sec#011loss=1.099245\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] Epoch[2] Batch[660] avg_epoch_loss=1.392664\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=660 train loss <loss>=1.11867280006\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] Epoch[2] Batch [660]#011Speed: 13301.79 samples/sec#011loss=1.118673\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] Epoch[2] Batch[665] avg_epoch_loss=1.391578\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=665 train loss <loss>=1.2480702877\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] Epoch[2] Batch [665]#011Speed: 1713.00 samples/sec#011loss=1.248070\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] Epoch[2] Batch[670] avg_epoch_loss=1.393526\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=670 train loss <loss>=1.65297367573\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] Epoch[2] Batch [670]#011Speed: 14353.61 samples/sec#011loss=1.652974\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] Epoch[2] Batch[675] avg_epoch_loss=1.397517\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=675 train loss <loss>=1.9330801487\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] Epoch[2] Batch [675]#011Speed: 1741.95 samples/sec#011loss=1.933080\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] Epoch[2] Batch[680] avg_epoch_loss=1.402769\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=680 train loss <loss>=2.11289937496\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] Epoch[2] Batch [680]#011Speed: 13574.35 samples/sec#011loss=2.112899\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] Epoch[2] Batch[685] avg_epoch_loss=1.407413\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=685 train loss <loss>=2.0398608923\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] Epoch[2] Batch [685]#011Speed: 13232.42 samples/sec#011loss=2.039861\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] Epoch[2] Batch[690] avg_epoch_loss=1.408755\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=690 train loss <loss>=1.59292793274\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] Epoch[2] Batch [690]#011Speed: 1806.12 samples/sec#011loss=1.592928\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] Epoch[2] Batch[695] avg_epoch_loss=1.409437\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=695 train loss <loss>=1.50357174873\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] Epoch[2] Batch [695]#011Speed: 13458.38 samples/sec#011loss=1.503572\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] Epoch[2] Batch[700] avg_epoch_loss=1.412484\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=700 train loss <loss>=1.83672165871\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] Epoch[2] Batch [700]#011Speed: 1730.16 samples/sec#011loss=1.836722\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] Epoch[2] Batch[705] avg_epoch_loss=1.413766\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=705 train loss <loss>=1.5935005784\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] Epoch[2] Batch [705]#011Speed: 13286.91 samples/sec#011loss=1.593501\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] Epoch[2] Batch[710] avg_epoch_loss=1.413055\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=710 train loss <loss>=1.31263744831\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:56 INFO 140088046479168] Epoch[2] Batch [710]#011Speed: 14318.24 samples/sec#011loss=1.312637\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] Epoch[2] Batch[715] avg_epoch_loss=1.412370\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=715 train loss <loss>=1.31489032507\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] Epoch[2] Batch [715]#011Speed: 1751.74 samples/sec#011loss=1.314890\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] Epoch[2] Batch[720] avg_epoch_loss=1.411107\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=720 train loss <loss>=1.23036687374\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] Epoch[2] Batch [720]#011Speed: 14182.52 samples/sec#011loss=1.230367\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] Epoch[2] Batch[725] avg_epoch_loss=1.411010\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=725 train loss <loss>=1.39700644016\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] Epoch[2] Batch [725]#011Speed: 1815.68 samples/sec#011loss=1.397006\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] Epoch[2] Batch[730] avg_epoch_loss=1.408755\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=730 train loss <loss>=1.08133541346\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] Epoch[2] Batch [730]#011Speed: 14082.08 samples/sec#011loss=1.081335\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] Epoch[2] Batch[735] avg_epoch_loss=1.407739\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=735 train loss <loss>=1.25919057131\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] Epoch[2] Batch [735]#011Speed: 13328.34 samples/sec#011loss=1.259191\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] Epoch[2] Batch[740] avg_epoch_loss=1.407156\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=740 train loss <loss>=1.32132146358\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] Epoch[2] Batch [740]#011Speed: 1848.41 samples/sec#011loss=1.321321\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] Epoch[2] Batch[745] avg_epoch_loss=1.406382\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=745 train loss <loss>=1.29163395166\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] Epoch[2] Batch [745]#011Speed: 14394.87 samples/sec#011loss=1.291634\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] Epoch[2] Batch[750] avg_epoch_loss=1.406066\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=750 train loss <loss>=1.35896379948\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] Epoch[2] Batch [750]#011Speed: 1895.58 samples/sec#011loss=1.358964\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] Epoch[2] Batch[755] avg_epoch_loss=1.404337\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=755 train loss <loss>=1.14459860325\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] Epoch[2] Batch [755]#011Speed: 13306.80 samples/sec#011loss=1.144599\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] Epoch[2] Batch[760] avg_epoch_loss=1.403097\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=760 train loss <loss>=1.21562529802\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:57 INFO 140088046479168] Epoch[2] Batch [760]#011Speed: 1576.77 samples/sec#011loss=1.215625\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] Epoch[2] Batch[765] avg_epoch_loss=1.403047\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=765 train loss <loss>=1.39544918537\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] Epoch[2] Batch [765]#011Speed: 13312.87 samples/sec#011loss=1.395449\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] Epoch[2] Batch[770] avg_epoch_loss=1.402951\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=770 train loss <loss>=1.38828496933\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] Epoch[2] Batch [770]#011Speed: 13369.10 samples/sec#011loss=1.388285\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] Epoch[2] Batch[775] avg_epoch_loss=1.402271\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=775 train loss <loss>=1.29730145931\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] Epoch[2] Batch [775]#011Speed: 1756.19 samples/sec#011loss=1.297301\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] Epoch[2] Batch[780] avg_epoch_loss=1.401497\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=780 train loss <loss>=1.28149544001\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] Epoch[2] Batch [780]#011Speed: 13325.03 samples/sec#011loss=1.281495\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] Epoch[2] Batch[785] avg_epoch_loss=1.400991\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=785 train loss <loss>=1.32192140818\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] Epoch[2] Batch [785]#011Speed: 14188.82 samples/sec#011loss=1.321921\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] Epoch[2] Batch[790] avg_epoch_loss=1.400944\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=790 train loss <loss>=1.39358539581\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] Epoch[2] Batch [790]#011Speed: 1724.82 samples/sec#011loss=1.393585\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] Epoch[2] Batch[795] avg_epoch_loss=1.401324\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=795 train loss <loss>=1.46135559082\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] Epoch[2] Batch [795]#011Speed: 13260.92 samples/sec#011loss=1.461356\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] Epoch[2] Batch[800] avg_epoch_loss=1.401522\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=800 train loss <loss>=1.43306114674\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] Epoch[2] Batch [800]#011Speed: 1802.80 samples/sec#011loss=1.433061\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] Epoch[2] Batch[805] avg_epoch_loss=1.401990\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=805 train loss <loss>=1.47704269886\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] Epoch[2] Batch [805]#011Speed: 12710.49 samples/sec#011loss=1.477043\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] Epoch[2] Batch[810] avg_epoch_loss=1.401088\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=810 train loss <loss>=1.25560145378\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] Epoch[2] Batch [810]#011Speed: 12862.26 samples/sec#011loss=1.255601\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] Epoch[2] Batch[815] avg_epoch_loss=1.400145\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=815 train loss <loss>=1.24728190899\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] Epoch[2] Batch [815]#011Speed: 1595.67 samples/sec#011loss=1.247282\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] Epoch[2] Batch[820] avg_epoch_loss=1.400588\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=820 train loss <loss>=1.472894454\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:58 INFO 140088046479168] Epoch[2] Batch [820]#011Speed: 13795.49 samples/sec#011loss=1.472894\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] Epoch[2] Batch[825] avg_epoch_loss=1.400212\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=825 train loss <loss>=1.33839576244\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] Epoch[2] Batch [825]#011Speed: 1703.80 samples/sec#011loss=1.338396\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] Epoch[2] Batch[830] avg_epoch_loss=1.398801\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=830 train loss <loss>=1.16570049524\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] Epoch[2] Batch [830]#011Speed: 14034.96 samples/sec#011loss=1.165700\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] Epoch[2] Batch[835] avg_epoch_loss=1.397365\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=835 train loss <loss>=1.15865893364\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] Epoch[2] Batch [835]#011Speed: 12990.61 samples/sec#011loss=1.158659\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] Epoch[2] Batch[840] avg_epoch_loss=1.396569\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=840 train loss <loss>=1.26357221603\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] Epoch[2] Batch [840]#011Speed: 1748.73 samples/sec#011loss=1.263572\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] Epoch[2] Batch[845] avg_epoch_loss=1.399307\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=845 train loss <loss>=1.85971016884\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] Epoch[2] Batch [845]#011Speed: 14206.39 samples/sec#011loss=1.859710\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] Epoch[2] Batch[850] avg_epoch_loss=1.403338\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=850 train loss <loss>=2.08542094231\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] Epoch[2] Batch [850]#011Speed: 1758.78 samples/sec#011loss=2.085421\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] Epoch[2] Batch[855] avg_epoch_loss=1.406779\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=855 train loss <loss>=1.99256076813\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] Epoch[2] Batch [855]#011Speed: 13333.37 samples/sec#011loss=1.992561\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] Epoch[2] Batch[860] avg_epoch_loss=1.410550\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=860 train loss <loss>=2.05599882603\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] Epoch[2] Batch [860]#011Speed: 13366.70 samples/sec#011loss=2.055999\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] Epoch[2] Batch[865] avg_epoch_loss=1.412895\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=865 train loss <loss>=1.81675236225\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] Epoch[2] Batch [865]#011Speed: 1667.65 samples/sec#011loss=1.816752\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] Epoch[2] Batch[870] avg_epoch_loss=1.415330\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=870 train loss <loss>=1.83711555004\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] Epoch[2] Batch [870]#011Speed: 14407.23 samples/sec#011loss=1.837116\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] Epoch[2] Batch[875] avg_epoch_loss=1.416418\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=875 train loss <loss>=1.60590672493\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:33:59 INFO 140088046479168] Epoch[2] Batch [875]#011Speed: 13812.81 samples/sec#011loss=1.605907\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] Epoch[2] Batch[880] avg_epoch_loss=1.417155\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=880 train loss <loss>=1.54625072479\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] Epoch[2] Batch [880]#011Speed: 1643.44 samples/sec#011loss=1.546251\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] Epoch[2] Batch[885] avg_epoch_loss=1.416594\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=885 train loss <loss>=1.31769411564\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] Epoch[2] Batch [885]#011Speed: 14267.25 samples/sec#011loss=1.317694\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] Epoch[2] Batch[890] avg_epoch_loss=1.416212\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=890 train loss <loss>=1.34852488041\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] Epoch[2] Batch [890]#011Speed: 1763.88 samples/sec#011loss=1.348525\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] Epoch[2] Batch[895] avg_epoch_loss=1.416110\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=895 train loss <loss>=1.39806578159\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] Epoch[2] Batch [895]#011Speed: 14519.76 samples/sec#011loss=1.398066\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] Epoch[2] Batch[900] avg_epoch_loss=1.416478\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, batch=900 train loss <loss>=1.48245613575\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] Epoch[2] Batch [900]#011Speed: 14253.92 samples/sec#011loss=1.482456\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] processed a total of 57852 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15801.485061645508, \"sum\": 15801.485061645508, \"min\": 15801.485061645508}}, \"EndTime\": 1604320440.319399, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320424.517855}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] #throughput_metric: host=algo-1, train throughput=3661.14824293 records/second\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=2, train loss <loss>=1.41573583869\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] Saved checkpoint to \"/opt/ml/model/state_1dd810aa-2b35-49b6-8148-00c0133b3ed1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 4.841089248657227, \"sum\": 4.841089248657227, \"min\": 4.841089248657227}}, \"EndTime\": 1604320440.324665, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320440.319474}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] Epoch[3] Batch[0] avg_epoch_loss=2.179111\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=2.17911100388\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] Epoch[3] Batch[5] avg_epoch_loss=1.659220\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=1.65921986103\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] Epoch[3] Batch [5]#011Speed: 14306.79 samples/sec#011loss=1.659220\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] Epoch[3] Batch[10] avg_epoch_loss=1.553071\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=1.42569179535\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] Epoch[3] Batch [10]#011Speed: 13870.34 samples/sec#011loss=1.425692\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] Epoch[3] Batch[15] avg_epoch_loss=1.439473\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=15 train loss <loss>=1.18955885172\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] Epoch[3] Batch [15]#011Speed: 1623.44 samples/sec#011loss=1.189559\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] Epoch[3] Batch[20] avg_epoch_loss=1.393409\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=20 train loss <loss>=1.2460036993\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] Epoch[3] Batch [20]#011Speed: 13187.17 samples/sec#011loss=1.246004\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] Epoch[3] Batch[25] avg_epoch_loss=1.347094\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=25 train loss <loss>=1.15257099867\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] Epoch[3] Batch [25]#011Speed: 13925.89 samples/sec#011loss=1.152571\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] Epoch[3] Batch[30] avg_epoch_loss=1.348351\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=30 train loss <loss>=1.35488942862\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] Epoch[3] Batch [30]#011Speed: 1697.32 samples/sec#011loss=1.354889\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] Epoch[3] Batch[35] avg_epoch_loss=1.330591\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=35 train loss <loss>=1.22047688961\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:00 INFO 140088046479168] Epoch[3] Batch [35]#011Speed: 14128.03 samples/sec#011loss=1.220477\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] Epoch[3] Batch[40] avg_epoch_loss=1.320021\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=40 train loss <loss>=1.243917799\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] Epoch[3] Batch [40]#011Speed: 1801.93 samples/sec#011loss=1.243918\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] Epoch[3] Batch[45] avg_epoch_loss=1.320494\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=45 train loss <loss>=1.32437368631\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] Epoch[3] Batch [45]#011Speed: 14349.16 samples/sec#011loss=1.324374\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] Epoch[3] Batch[50] avg_epoch_loss=1.308355\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=50 train loss <loss>=1.19667106867\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] Epoch[3] Batch [50]#011Speed: 13948.18 samples/sec#011loss=1.196671\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] Epoch[3] Batch[55] avg_epoch_loss=1.307670\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=55 train loss <loss>=1.30068840981\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] Epoch[3] Batch [55]#011Speed: 1523.23 samples/sec#011loss=1.300688\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] Epoch[3] Batch[60] avg_epoch_loss=1.287857\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=60 train loss <loss>=1.06595132351\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] Epoch[3] Batch [60]#011Speed: 11745.67 samples/sec#011loss=1.065951\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] Epoch[3] Batch[65] avg_epoch_loss=1.276878\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=65 train loss <loss>=1.14293242693\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] Epoch[3] Batch [65]#011Speed: 1590.30 samples/sec#011loss=1.142932\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] Epoch[3] Batch[70] avg_epoch_loss=1.260424\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=70 train loss <loss>=1.04322921038\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] Epoch[3] Batch [70]#011Speed: 14359.44 samples/sec#011loss=1.043229\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] Epoch[3] Batch[75] avg_epoch_loss=1.262942\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=75 train loss <loss>=1.29870157242\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] Epoch[3] Batch [75]#011Speed: 13725.66 samples/sec#011loss=1.298702\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] Epoch[3] Batch[80] avg_epoch_loss=1.266523\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=80 train loss <loss>=1.32095251083\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] Epoch[3] Batch [80]#011Speed: 1775.16 samples/sec#011loss=1.320953\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] Epoch[3] Batch[85] avg_epoch_loss=1.266591\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=85 train loss <loss>=1.26769096851\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] Epoch[3] Batch [85]#011Speed: 14208.35 samples/sec#011loss=1.267691\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] Epoch[3] Batch[90] avg_epoch_loss=1.269222\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=90 train loss <loss>=1.31446712017\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:01 INFO 140088046479168] Epoch[3] Batch [90]#011Speed: 14296.58 samples/sec#011loss=1.314467\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] Epoch[3] Batch[95] avg_epoch_loss=1.267706\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=95 train loss <loss>=1.24013075829\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] Epoch[3] Batch [95]#011Speed: 1709.78 samples/sec#011loss=1.240131\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] Epoch[3] Batch[100] avg_epoch_loss=1.267806\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=100 train loss <loss>=1.26972126961\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] Epoch[3] Batch [100]#011Speed: 14096.87 samples/sec#011loss=1.269721\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] Epoch[3] Batch[105] avg_epoch_loss=1.267264\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=105 train loss <loss>=1.25631625652\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] Epoch[3] Batch [105]#011Speed: 1748.14 samples/sec#011loss=1.256316\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] Epoch[3] Batch[110] avg_epoch_loss=1.269402\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=110 train loss <loss>=1.31473553181\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] Epoch[3] Batch [110]#011Speed: 13361.65 samples/sec#011loss=1.314736\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] Epoch[3] Batch[115] avg_epoch_loss=1.265638\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=115 train loss <loss>=1.18206884861\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] Epoch[3] Batch [115]#011Speed: 13261.97 samples/sec#011loss=1.182069\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] Epoch[3] Batch[120] avg_epoch_loss=1.268275\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=120 train loss <loss>=1.32944853306\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] Epoch[3] Batch [120]#011Speed: 1767.57 samples/sec#011loss=1.329449\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] Epoch[3] Batch[125] avg_epoch_loss=1.278996\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=125 train loss <loss>=1.53843896389\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] Epoch[3] Batch [125]#011Speed: 14054.21 samples/sec#011loss=1.538439\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] Epoch[3] Batch[130] avg_epoch_loss=1.280150\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=130 train loss <loss>=1.30924603939\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] Epoch[3] Batch [130]#011Speed: 1732.57 samples/sec#011loss=1.309246\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] Epoch[3] Batch[135] avg_epoch_loss=1.283551\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=135 train loss <loss>=1.37265210152\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] Epoch[3] Batch [135]#011Speed: 13937.89 samples/sec#011loss=1.372652\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] Epoch[3] Batch[140] avg_epoch_loss=1.293066\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=140 train loss <loss>=1.55186560154\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] Epoch[3] Batch [140]#011Speed: 14132.50 samples/sec#011loss=1.551866\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] Epoch[3] Batch[145] avg_epoch_loss=1.299460\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=145 train loss <loss>=1.47976903915\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:02 INFO 140088046479168] Epoch[3] Batch [145]#011Speed: 1672.53 samples/sec#011loss=1.479769\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] Epoch[3] Batch[150] avg_epoch_loss=1.294832\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=150 train loss <loss>=1.15971134901\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] Epoch[3] Batch [150]#011Speed: 13857.02 samples/sec#011loss=1.159711\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] Epoch[3] Batch[155] avg_epoch_loss=1.295067\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=155 train loss <loss>=1.30216734409\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] Epoch[3] Batch [155]#011Speed: 12932.91 samples/sec#011loss=1.302167\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] Epoch[3] Batch[160] avg_epoch_loss=1.295234\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=160 train loss <loss>=1.30042674541\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] Epoch[3] Batch [160]#011Speed: 1371.89 samples/sec#011loss=1.300427\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] Epoch[3] Batch[165] avg_epoch_loss=1.298155\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=165 train loss <loss>=1.39220454693\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] Epoch[3] Batch [165]#011Speed: 14198.28 samples/sec#011loss=1.392205\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] Epoch[3] Batch[170] avg_epoch_loss=1.298318\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=170 train loss <loss>=1.30375790596\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] Epoch[3] Batch [170]#011Speed: 1685.11 samples/sec#011loss=1.303758\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] Epoch[3] Batch[175] avg_epoch_loss=1.296986\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=175 train loss <loss>=1.2514313817\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] Epoch[3] Batch [175]#011Speed: 14313.20 samples/sec#011loss=1.251431\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] Epoch[3] Batch[180] avg_epoch_loss=1.295773\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=180 train loss <loss>=1.25306248665\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] Epoch[3] Batch [180]#011Speed: 14144.26 samples/sec#011loss=1.253062\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] Epoch[3] Batch[185] avg_epoch_loss=1.295294\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=185 train loss <loss>=1.27793757915\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] Epoch[3] Batch [185]#011Speed: 1751.90 samples/sec#011loss=1.277938\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] Epoch[3] Batch[190] avg_epoch_loss=1.287927\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=190 train loss <loss>=1.01388738155\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] Epoch[3] Batch [190]#011Speed: 14046.12 samples/sec#011loss=1.013887\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] Epoch[3] Batch[195] avg_epoch_loss=1.286216\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=195 train loss <loss>=1.22083642483\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] Epoch[3] Batch [195]#011Speed: 1833.19 samples/sec#011loss=1.220836\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] Epoch[3] Batch[200] avg_epoch_loss=1.286790\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=200 train loss <loss>=1.30932233334\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] Epoch[3] Batch [200]#011Speed: 13770.02 samples/sec#011loss=1.309322\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] Epoch[3] Batch[205] avg_epoch_loss=1.286067\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=205 train loss <loss>=1.25699660778\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:03 INFO 140088046479168] Epoch[3] Batch [205]#011Speed: 14214.06 samples/sec#011loss=1.256997\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] Epoch[3] Batch[210] avg_epoch_loss=1.284355\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=210 train loss <loss>=1.21381111145\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] Epoch[3] Batch [210]#011Speed: 1761.00 samples/sec#011loss=1.213811\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] Epoch[3] Batch[215] avg_epoch_loss=1.278692\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=215 train loss <loss>=1.0397249341\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] Epoch[3] Batch [215]#011Speed: 13227.98 samples/sec#011loss=1.039725\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] Epoch[3] Batch[220] avg_epoch_loss=1.277380\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=220 train loss <loss>=1.22067658901\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] Epoch[3] Batch [220]#011Speed: 1897.32 samples/sec#011loss=1.220677\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] Epoch[3] Batch[225] avg_epoch_loss=1.271595\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=225 train loss <loss>=1.01592797041\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] Epoch[3] Batch [225]#011Speed: 12698.47 samples/sec#011loss=1.015928\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] Epoch[3] Batch[230] avg_epoch_loss=1.268820\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=230 train loss <loss>=1.14338703156\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] Epoch[3] Batch [230]#011Speed: 13184.45 samples/sec#011loss=1.143387\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] Epoch[3] Batch[235] avg_epoch_loss=1.266822\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=235 train loss <loss>=1.1745018363\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] Epoch[3] Batch [235]#011Speed: 1701.31 samples/sec#011loss=1.174502\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] Epoch[3] Batch[240] avg_epoch_loss=1.271077\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=240 train loss <loss>=1.47192466259\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] Epoch[3] Batch [240]#011Speed: 13985.97 samples/sec#011loss=1.471925\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] Epoch[3] Batch[245] avg_epoch_loss=1.278544\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=245 train loss <loss>=1.63844951391\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] Epoch[3] Batch [245]#011Speed: 1747.42 samples/sec#011loss=1.638450\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] Epoch[3] Batch[250] avg_epoch_loss=1.285944\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=250 train loss <loss>=1.65000338554\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] Epoch[3] Batch [250]#011Speed: 14166.21 samples/sec#011loss=1.650003\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] Epoch[3] Batch[255] avg_epoch_loss=1.302593\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=255 train loss <loss>=2.13839411736\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:04 INFO 140088046479168] Epoch[3] Batch [255]#011Speed: 13352.21 samples/sec#011loss=2.138394\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] Epoch[3] Batch[260] avg_epoch_loss=1.317931\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=260 train loss <loss>=2.10325000286\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] Epoch[3] Batch [260]#011Speed: 1620.20 samples/sec#011loss=2.103250\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] Epoch[3] Batch[265] avg_epoch_loss=1.320999\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=265 train loss <loss>=1.48110830784\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] Epoch[3] Batch [265]#011Speed: 14371.13 samples/sec#011loss=1.481108\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] Epoch[3] Batch[270] avg_epoch_loss=1.319363\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=270 train loss <loss>=1.23235710859\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] Epoch[3] Batch [270]#011Speed: 1758.86 samples/sec#011loss=1.232357\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] Epoch[3] Batch[275] avg_epoch_loss=1.313584\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=275 train loss <loss>=1.0003459692\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] Epoch[3] Batch [275]#011Speed: 13285.73 samples/sec#011loss=1.000346\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] Epoch[3] Batch[280] avg_epoch_loss=1.308290\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=280 train loss <loss>=1.01604380608\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] Epoch[3] Batch [280]#011Speed: 13254.89 samples/sec#011loss=1.016044\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] Epoch[3] Batch[285] avg_epoch_loss=1.306567\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=285 train loss <loss>=1.20977003574\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] Epoch[3] Batch [285]#011Speed: 1726.57 samples/sec#011loss=1.209770\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] Epoch[3] Batch[290] avg_epoch_loss=1.300468\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=290 train loss <loss>=0.95161908865\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] Epoch[3] Batch [290]#011Speed: 13903.39 samples/sec#011loss=0.951619\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] Epoch[3] Batch[295] avg_epoch_loss=1.296987\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=295 train loss <loss>=1.09439504147\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] Epoch[3] Batch [295]#011Speed: 14193.32 samples/sec#011loss=1.094395\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] Epoch[3] Batch[300] avg_epoch_loss=1.294126\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=300 train loss <loss>=1.12474765778\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] Epoch[3] Batch [300]#011Speed: 1895.92 samples/sec#011loss=1.124748\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] Epoch[3] Batch[305] avg_epoch_loss=1.290390\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=305 train loss <loss>=1.0654648304\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] Epoch[3] Batch [305]#011Speed: 13016.57 samples/sec#011loss=1.065465\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] Epoch[3] Batch[310] avg_epoch_loss=1.286257\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=310 train loss <loss>=1.03330686092\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] Epoch[3] Batch [310]#011Speed: 1733.49 samples/sec#011loss=1.033307\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] Epoch[3] Batch[315] avg_epoch_loss=1.281697\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=315 train loss <loss>=0.998088896275\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] Epoch[3] Batch [315]#011Speed: 14341.34 samples/sec#011loss=0.998089\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] Epoch[3] Batch[320] avg_epoch_loss=1.278851\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=320 train loss <loss>=1.09894964695\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:05 INFO 140088046479168] Epoch[3] Batch [320]#011Speed: 14169.35 samples/sec#011loss=1.098950\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] Epoch[3] Batch[325] avg_epoch_loss=1.276675\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=325 train loss <loss>=1.13696885109\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] Epoch[3] Batch [325]#011Speed: 1705.78 samples/sec#011loss=1.136969\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] Epoch[3] Batch[330] avg_epoch_loss=1.273498\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=330 train loss <loss>=1.06638990641\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] Epoch[3] Batch [330]#011Speed: 13228.11 samples/sec#011loss=1.066390\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] Epoch[3] Batch[335] avg_epoch_loss=1.271236\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=335 train loss <loss>=1.12148606777\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] Epoch[3] Batch [335]#011Speed: 1604.55 samples/sec#011loss=1.121486\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] Epoch[3] Batch[340] avg_epoch_loss=1.267878\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=340 train loss <loss>=1.04222458601\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] Epoch[3] Batch [340]#011Speed: 13511.35 samples/sec#011loss=1.042225\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] Epoch[3] Batch[345] avg_epoch_loss=1.266623\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=345 train loss <loss>=1.18103721142\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] Epoch[3] Batch [345]#011Speed: 13244.56 samples/sec#011loss=1.181037\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] Epoch[3] Batch[350] avg_epoch_loss=1.266397\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=350 train loss <loss>=1.25077772141\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] Epoch[3] Batch [350]#011Speed: 1760.61 samples/sec#011loss=1.250778\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] Epoch[3] Batch[355] avg_epoch_loss=1.268425\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=355 train loss <loss>=1.41073265076\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] Epoch[3] Batch [355]#011Speed: 13281.78 samples/sec#011loss=1.410733\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] Epoch[3] Batch[360] avg_epoch_loss=1.267736\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=360 train loss <loss>=1.21873953342\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] Epoch[3] Batch [360]#011Speed: 1777.27 samples/sec#011loss=1.218740\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] Epoch[3] Batch[365] avg_epoch_loss=1.274452\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=365 train loss <loss>=1.75929381847\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] Epoch[3] Batch [365]#011Speed: 13366.70 samples/sec#011loss=1.759294\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] Epoch[3] Batch[370] avg_epoch_loss=1.288134\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=370 train loss <loss>=2.2897002697\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] Epoch[3] Batch [370]#011Speed: 14389.77 samples/sec#011loss=2.289700\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] Epoch[3] Batch[375] avg_epoch_loss=1.298303\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=375 train loss <loss>=2.05280909538\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:06 INFO 140088046479168] Epoch[3] Batch [375]#011Speed: 1862.80 samples/sec#011loss=2.052809\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] Epoch[3] Batch[380] avg_epoch_loss=1.304545\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=380 train loss <loss>=1.77393705845\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] Epoch[3] Batch [380]#011Speed: 14272.41 samples/sec#011loss=1.773937\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] Epoch[3] Batch[385] avg_epoch_loss=1.308231\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=385 train loss <loss>=1.58910272121\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] Epoch[3] Batch [385]#011Speed: 1478.31 samples/sec#011loss=1.589103\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] Epoch[3] Batch[390] avg_epoch_loss=1.314513\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=390 train loss <loss>=1.79948887825\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] Epoch[3] Batch [390]#011Speed: 14334.29 samples/sec#011loss=1.799489\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] Epoch[3] Batch[395] avg_epoch_loss=1.322392\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=395 train loss <loss>=1.93852667809\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] Epoch[3] Batch [395]#011Speed: 14057.30 samples/sec#011loss=1.938527\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] Epoch[3] Batch[400] avg_epoch_loss=1.325515\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=400 train loss <loss>=1.572859478\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] Epoch[3] Batch [400]#011Speed: 1540.98 samples/sec#011loss=1.572859\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] Epoch[3] Batch[405] avg_epoch_loss=1.324874\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=405 train loss <loss>=1.27345206738\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] Epoch[3] Batch [405]#011Speed: 14413.88 samples/sec#011loss=1.273452\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] Epoch[3] Batch[410] avg_epoch_loss=1.324863\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=410 train loss <loss>=1.32401683331\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] Epoch[3] Batch [410]#011Speed: 14062.31 samples/sec#011loss=1.324017\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] Epoch[3] Batch[415] avg_epoch_loss=1.321168\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=415 train loss <loss>=1.01742429733\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] Epoch[3] Batch [415]#011Speed: 1785.69 samples/sec#011loss=1.017424\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] Epoch[3] Batch[420] avg_epoch_loss=1.321370\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=420 train loss <loss>=1.33812992573\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] Epoch[3] Batch [420]#011Speed: 14349.77 samples/sec#011loss=1.338130\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] Epoch[3] Batch[425] avg_epoch_loss=1.317398\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=425 train loss <loss>=0.983027923107\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] Epoch[3] Batch [425]#011Speed: 1906.13 samples/sec#011loss=0.983028\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] Epoch[3] Batch[430] avg_epoch_loss=1.317067\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=430 train loss <loss>=1.28880617619\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] Epoch[3] Batch [430]#011Speed: 14451.44 samples/sec#011loss=1.288806\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] Epoch[3] Batch[435] avg_epoch_loss=1.316969\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=435 train loss <loss>=1.30850923061\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:07 INFO 140088046479168] Epoch[3] Batch [435]#011Speed: 14303.59 samples/sec#011loss=1.308509\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] Epoch[3] Batch[440] avg_epoch_loss=1.318923\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=440 train loss <loss>=1.48938784599\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] Epoch[3] Batch [440]#011Speed: 1656.07 samples/sec#011loss=1.489388\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] Epoch[3] Batch[445] avg_epoch_loss=1.319328\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=445 train loss <loss>=1.35500947237\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] Epoch[3] Batch [445]#011Speed: 13834.88 samples/sec#011loss=1.355009\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] Epoch[3] Batch[450] avg_epoch_loss=1.318533\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=450 train loss <loss>=1.24758411646\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] Epoch[3] Batch [450]#011Speed: 1766.37 samples/sec#011loss=1.247584\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] Epoch[3] Batch[455] avg_epoch_loss=1.318703\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=455 train loss <loss>=1.33405566216\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] Epoch[3] Batch [455]#011Speed: 14269.07 samples/sec#011loss=1.334056\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] Epoch[3] Batch[460] avg_epoch_loss=1.320165\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=460 train loss <loss>=1.45355010033\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] Epoch[3] Batch [460]#011Speed: 1862.17 samples/sec#011loss=1.453550\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] Epoch[3] Batch[465] avg_epoch_loss=1.318404\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=465 train loss <loss>=1.15598784685\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] Epoch[3] Batch [465]#011Speed: 14389.77 samples/sec#011loss=1.155988\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] Epoch[3] Batch[470] avg_epoch_loss=1.315412\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=470 train loss <loss>=1.03655586243\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] Epoch[3] Batch [470]#011Speed: 13573.11 samples/sec#011loss=1.036556\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] Epoch[3] Batch[475] avg_epoch_loss=1.314356\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=475 train loss <loss>=1.21488320827\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] Epoch[3] Batch [475]#011Speed: 1667.92 samples/sec#011loss=1.214883\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] Epoch[3] Batch[480] avg_epoch_loss=1.313380\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=480 train loss <loss>=1.22047305107\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] Epoch[3] Batch [480]#011Speed: 14232.91 samples/sec#011loss=1.220473\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] Epoch[3] Batch[485] avg_epoch_loss=1.313755\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=485 train loss <loss>=1.3498434782\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:08 INFO 140088046479168] Epoch[3] Batch [485]#011Speed: 1809.94 samples/sec#011loss=1.349843\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] Epoch[3] Batch[490] avg_epoch_loss=1.314434\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=490 train loss <loss>=1.38045656681\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] Epoch[3] Batch [490]#011Speed: 13404.35 samples/sec#011loss=1.380457\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] Epoch[3] Batch[495] avg_epoch_loss=1.314181\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=495 train loss <loss>=1.28930109739\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] Epoch[3] Batch [495]#011Speed: 14277.42 samples/sec#011loss=1.289301\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] Epoch[3] Batch[500] avg_epoch_loss=1.313303\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=500 train loss <loss>=1.2261926651\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] Epoch[3] Batch [500]#011Speed: 1750.54 samples/sec#011loss=1.226193\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] Epoch[3] Batch[505] avg_epoch_loss=1.313699\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=505 train loss <loss>=1.35336557627\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] Epoch[3] Batch [505]#011Speed: 12777.04 samples/sec#011loss=1.353366\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] Epoch[3] Batch[510] avg_epoch_loss=1.314895\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=510 train loss <loss>=1.43593509197\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] Epoch[3] Batch [510]#011Speed: 1825.72 samples/sec#011loss=1.435935\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] Epoch[3] Batch[515] avg_epoch_loss=1.312796\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=515 train loss <loss>=1.09834398031\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] Epoch[3] Batch [515]#011Speed: 14356.83 samples/sec#011loss=1.098344\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] Epoch[3] Batch[520] avg_epoch_loss=1.311127\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=520 train loss <loss>=1.13884211779\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] Epoch[3] Batch [520]#011Speed: 14253.16 samples/sec#011loss=1.138842\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] Epoch[3] Batch[525] avg_epoch_loss=1.311729\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=525 train loss <loss>=1.37448906898\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] Epoch[3] Batch [525]#011Speed: 1733.65 samples/sec#011loss=1.374489\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] Epoch[3] Batch[530] avg_epoch_loss=1.309263\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=530 train loss <loss>=1.04984095097\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] Epoch[3] Batch [530]#011Speed: 13379.49 samples/sec#011loss=1.049841\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] Epoch[3] Batch[535] avg_epoch_loss=1.311475\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=535 train loss <loss>=1.54636659622\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] Epoch[3] Batch [535]#011Speed: 1722.51 samples/sec#011loss=1.546367\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] Epoch[3] Batch[540] avg_epoch_loss=1.312298\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=540 train loss <loss>=1.40051857233\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] Epoch[3] Batch [540]#011Speed: 13906.27 samples/sec#011loss=1.400519\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] Epoch[3] Batch[545] avg_epoch_loss=1.315161\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=545 train loss <loss>=1.62490077019\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:09 INFO 140088046479168] Epoch[3] Batch [545]#011Speed: 14316.40 samples/sec#011loss=1.624901\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] Epoch[3] Batch[550] avg_epoch_loss=1.315247\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=550 train loss <loss>=1.32471351624\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] Epoch[3] Batch [550]#011Speed: 1607.03 samples/sec#011loss=1.324714\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] Epoch[3] Batch[555] avg_epoch_loss=1.314182\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=555 train loss <loss>=1.19677922726\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] Epoch[3] Batch [555]#011Speed: 14166.21 samples/sec#011loss=1.196779\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] Epoch[3] Batch[560] avg_epoch_loss=1.314051\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=560 train loss <loss>=1.29947965145\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] Epoch[3] Batch [560]#011Speed: 14175.63 samples/sec#011loss=1.299480\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] Epoch[3] Batch[565] avg_epoch_loss=1.313319\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=565 train loss <loss>=1.23125154972\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] Epoch[3] Batch [565]#011Speed: 1780.46 samples/sec#011loss=1.231252\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] Epoch[3] Batch[570] avg_epoch_loss=1.311995\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=570 train loss <loss>=1.16203858852\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] Epoch[3] Batch [570]#011Speed: 13176.30 samples/sec#011loss=1.162039\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] Epoch[3] Batch[575] avg_epoch_loss=1.310727\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=575 train loss <loss>=1.16593501568\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] Epoch[3] Batch [575]#011Speed: 1610.45 samples/sec#011loss=1.165935\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] Epoch[3] Batch[580] avg_epoch_loss=1.310335\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=580 train loss <loss>=1.26521849632\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] Epoch[3] Batch [580]#011Speed: 13321.59 samples/sec#011loss=1.265218\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] Epoch[3] Batch[585] avg_epoch_loss=1.310132\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=585 train loss <loss>=1.28646166325\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] Epoch[3] Batch [585]#011Speed: 12820.49 samples/sec#011loss=1.286462\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] Epoch[3] Batch[590] avg_epoch_loss=1.309372\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=590 train loss <loss>=1.22034721375\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] Epoch[3] Batch [590]#011Speed: 1578.64 samples/sec#011loss=1.220347\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] Epoch[3] Batch[595] avg_epoch_loss=1.309373\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=595 train loss <loss>=1.30951843262\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] Epoch[3] Batch [595]#011Speed: 14511.12 samples/sec#011loss=1.309518\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] Epoch[3] Batch[600] avg_epoch_loss=1.309105\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=600 train loss <loss>=1.2771130085\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:10 INFO 140088046479168] Epoch[3] Batch [600]#011Speed: 1726.11 samples/sec#011loss=1.277113\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] Epoch[3] Batch[605] avg_epoch_loss=1.309315\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=605 train loss <loss>=1.33463490009\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] Epoch[3] Batch [605]#011Speed: 14278.03 samples/sec#011loss=1.334635\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] Epoch[3] Batch[610] avg_epoch_loss=1.308354\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=610 train loss <loss>=1.19188055992\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] Epoch[3] Batch [610]#011Speed: 13848.01 samples/sec#011loss=1.191881\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] Epoch[3] Batch[615] avg_epoch_loss=1.307076\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=615 train loss <loss>=1.15088591576\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] Epoch[3] Batch [615]#011Speed: 1439.48 samples/sec#011loss=1.150886\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] Epoch[3] Batch[620] avg_epoch_loss=1.307355\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=620 train loss <loss>=1.34170212746\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] Epoch[3] Batch [620]#011Speed: 14300.39 samples/sec#011loss=1.341702\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] Epoch[3] Batch[625] avg_epoch_loss=1.305211\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=625 train loss <loss>=1.03892126083\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] Epoch[3] Batch [625]#011Speed: 13235.81 samples/sec#011loss=1.038921\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] Epoch[3] Batch[630] avg_epoch_loss=1.305444\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=630 train loss <loss>=1.33461945057\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] Epoch[3] Batch [630]#011Speed: 1711.21 samples/sec#011loss=1.334619\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] Epoch[3] Batch[635] avg_epoch_loss=1.302020\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=635 train loss <loss>=0.869856703281\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] Epoch[3] Batch [635]#011Speed: 13311.16 samples/sec#011loss=0.869857\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] Epoch[3] Batch[640] avg_epoch_loss=1.300354\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=640 train loss <loss>=1.08845889568\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] Epoch[3] Batch [640]#011Speed: 1709.73 samples/sec#011loss=1.088459\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] Epoch[3] Batch[645] avg_epoch_loss=1.298766\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=645 train loss <loss>=1.09518146515\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] Epoch[3] Batch [645]#011Speed: 13355.53 samples/sec#011loss=1.095181\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] Epoch[3] Batch[650] avg_epoch_loss=1.298922\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=650 train loss <loss>=1.31914269924\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] Epoch[3] Batch [650]#011Speed: 13615.38 samples/sec#011loss=1.319143\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] Epoch[3] Batch[655] avg_epoch_loss=1.298124\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=655 train loss <loss>=1.19414705038\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] Epoch[3] Batch [655]#011Speed: 1827.87 samples/sec#011loss=1.194147\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] Epoch[3] Batch[660] avg_epoch_loss=1.298221\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=660 train loss <loss>=1.31102089882\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:11 INFO 140088046479168] Epoch[3] Batch [660]#011Speed: 14271.04 samples/sec#011loss=1.311021\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] Epoch[3] Batch[665] avg_epoch_loss=1.301455\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=665 train loss <loss>=1.728992939\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] Epoch[3] Batch [665]#011Speed: 1702.77 samples/sec#011loss=1.728993\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] Epoch[3] Batch[670] avg_epoch_loss=1.302118\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=670 train loss <loss>=1.39039206505\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] Epoch[3] Batch [670]#011Speed: 14239.85 samples/sec#011loss=1.390392\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] Epoch[3] Batch[675] avg_epoch_loss=1.306187\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=675 train loss <loss>=1.85223309994\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] Epoch[3] Batch [675]#011Speed: 14294.60 samples/sec#011loss=1.852233\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] Epoch[3] Batch[680] avg_epoch_loss=1.311579\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=680 train loss <loss>=2.04056792259\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] Epoch[3] Batch [680]#011Speed: 1867.92 samples/sec#011loss=2.040568\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] Epoch[3] Batch[685] avg_epoch_loss=1.318138\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=685 train loss <loss>=2.21150579453\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] Epoch[3] Batch [685]#011Speed: 13299.02 samples/sec#011loss=2.211506\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] Epoch[3] Batch[690] avg_epoch_loss=1.325000\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=690 train loss <loss>=2.2664285183\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] Epoch[3] Batch [690]#011Speed: 1713.22 samples/sec#011loss=2.266429\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] Epoch[3] Batch[695] avg_epoch_loss=1.330009\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=695 train loss <loss>=2.02224657536\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] Epoch[3] Batch [695]#011Speed: 14278.18 samples/sec#011loss=2.022247\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] Epoch[3] Batch[700] avg_epoch_loss=1.331685\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=700 train loss <loss>=1.56505510807\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] Epoch[3] Batch [700]#011Speed: 14380.21 samples/sec#011loss=1.565055\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] Epoch[3] Batch[705] avg_epoch_loss=1.332909\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=705 train loss <loss>=1.5044870615\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] Epoch[3] Batch [705]#011Speed: 1845.93 samples/sec#011loss=1.504487\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] Epoch[3] Batch[710] avg_epoch_loss=1.334912\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=710 train loss <loss>=1.6177036047\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] Epoch[3] Batch [710]#011Speed: 14242.57 samples/sec#011loss=1.617704\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] Epoch[3] Batch[715] avg_epoch_loss=1.335259\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=715 train loss <loss>=1.38467981815\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:12 INFO 140088046479168] Epoch[3] Batch [715]#011Speed: 1805.06 samples/sec#011loss=1.384680\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] Epoch[3] Batch[720] avg_epoch_loss=1.335433\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=720 train loss <loss>=1.36032443047\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] Epoch[3] Batch [720]#011Speed: 12811.19 samples/sec#011loss=1.360324\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] Epoch[3] Batch[725] avg_epoch_loss=1.336669\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=725 train loss <loss>=1.514828825\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] Epoch[3] Batch [725]#011Speed: 12743.44 samples/sec#011loss=1.514829\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] Epoch[3] Batch[730] avg_epoch_loss=1.336843\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=730 train loss <loss>=1.36212917566\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] Epoch[3] Batch [730]#011Speed: 1553.93 samples/sec#011loss=1.362129\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] Epoch[3] Batch[735] avg_epoch_loss=1.335319\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=735 train loss <loss>=1.11254706383\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] Epoch[3] Batch [735]#011Speed: 14246.20 samples/sec#011loss=1.112547\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] Epoch[3] Batch[740] avg_epoch_loss=1.335031\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=740 train loss <loss>=1.29267897606\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] Epoch[3] Batch [740]#011Speed: 1811.32 samples/sec#011loss=1.292679\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] Epoch[3] Batch[745] avg_epoch_loss=1.333358\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=745 train loss <loss>=1.08536169529\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] Epoch[3] Batch [745]#011Speed: 14449.57 samples/sec#011loss=1.085362\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] Epoch[3] Batch[750] avg_epoch_loss=1.332836\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=750 train loss <loss>=1.25493876934\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] Epoch[3] Batch [750]#011Speed: 13465.13 samples/sec#011loss=1.254939\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] Epoch[3] Batch[755] avg_epoch_loss=1.332215\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=755 train loss <loss>=1.23889958858\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] Epoch[3] Batch [755]#011Speed: 1688.25 samples/sec#011loss=1.238900\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] Epoch[3] Batch[760] avg_epoch_loss=1.332392\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=760 train loss <loss>=1.35926070213\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] Epoch[3] Batch [760]#011Speed: 13328.87 samples/sec#011loss=1.359261\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] Epoch[3] Batch[765] avg_epoch_loss=1.332484\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=765 train loss <loss>=1.34636433125\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] Epoch[3] Batch [765]#011Speed: 1834.55 samples/sec#011loss=1.346364\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] Epoch[3] Batch[770] avg_epoch_loss=1.332516\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=770 train loss <loss>=1.33746376038\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] Epoch[3] Batch [770]#011Speed: 13782.46 samples/sec#011loss=1.337464\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] Epoch[3] Batch[775] avg_epoch_loss=1.332321\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=775 train loss <loss>=1.30221614838\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:13 INFO 140088046479168] Epoch[3] Batch [775]#011Speed: 13668.21 samples/sec#011loss=1.302216\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] Epoch[3] Batch[780] avg_epoch_loss=1.331624\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=780 train loss <loss>=1.22353405952\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] Epoch[3] Batch [780]#011Speed: 1712.91 samples/sec#011loss=1.223534\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] Epoch[3] Batch[785] avg_epoch_loss=1.330560\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=785 train loss <loss>=1.16434477568\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] Epoch[3] Batch [785]#011Speed: 11243.09 samples/sec#011loss=1.164345\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] Epoch[3] Batch[790] avg_epoch_loss=1.329751\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=790 train loss <loss>=1.20255124569\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] Epoch[3] Batch [790]#011Speed: 1640.80 samples/sec#011loss=1.202551\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] Epoch[3] Batch[795] avg_epoch_loss=1.329321\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=795 train loss <loss>=1.26130030155\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] Epoch[3] Batch [795]#011Speed: 12811.31 samples/sec#011loss=1.261300\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] Epoch[3] Batch[800] avg_epoch_loss=1.329856\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=800 train loss <loss>=1.41503641605\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] Epoch[3] Batch [800]#011Speed: 12887.71 samples/sec#011loss=1.415036\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] Epoch[3] Batch[805] avg_epoch_loss=1.329187\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=805 train loss <loss>=1.22196829319\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] Epoch[3] Batch [805]#011Speed: 1790.47 samples/sec#011loss=1.221968\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] Epoch[3] Batch[810] avg_epoch_loss=1.329534\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=810 train loss <loss>=1.38557817936\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] Epoch[3] Batch [810]#011Speed: 14402.74 samples/sec#011loss=1.385578\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] Epoch[3] Batch[815] avg_epoch_loss=1.331521\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=815 train loss <loss>=1.653814888\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] Epoch[3] Batch [815]#011Speed: 1820.63 samples/sec#011loss=1.653815\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] Epoch[3] Batch[820] avg_epoch_loss=1.331952\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=820 train loss <loss>=1.40218513012\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] Epoch[3] Batch [820]#011Speed: 13312.87 samples/sec#011loss=1.402185\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] Epoch[3] Batch[825] avg_epoch_loss=1.333796\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=825 train loss <loss>=1.63661687374\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:14 INFO 140088046479168] Epoch[3] Batch [825]#011Speed: 13363.91 samples/sec#011loss=1.636617\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] Epoch[3] Batch[830] avg_epoch_loss=1.333797\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=830 train loss <loss>=1.33395698071\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] Epoch[3] Batch [830]#011Speed: 1494.12 samples/sec#011loss=1.333957\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] Epoch[3] Batch[835] avg_epoch_loss=1.331822\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=835 train loss <loss>=1.00361696482\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] Epoch[3] Batch [835]#011Speed: 14784.62 samples/sec#011loss=1.003617\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] Epoch[3] Batch[840] avg_epoch_loss=1.331164\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=840 train loss <loss>=1.22113234997\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] Epoch[3] Batch [840]#011Speed: 14579.22 samples/sec#011loss=1.221132\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] Epoch[3] Batch[845] avg_epoch_loss=1.330523\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=845 train loss <loss>=1.22276982069\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] Epoch[3] Batch [845]#011Speed: 1624.11 samples/sec#011loss=1.222770\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] Epoch[3] Batch[850] avg_epoch_loss=1.329662\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=850 train loss <loss>=1.18394384384\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] Epoch[3] Batch [850]#011Speed: 14444.44 samples/sec#011loss=1.183944\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] Epoch[3] Batch[855] avg_epoch_loss=1.330112\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=855 train loss <loss>=1.40672369003\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] Epoch[3] Batch [855]#011Speed: 1825.13 samples/sec#011loss=1.406724\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] Epoch[3] Batch[860] avg_epoch_loss=1.329770\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=860 train loss <loss>=1.27124108076\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] Epoch[3] Batch [860]#011Speed: 14067.76 samples/sec#011loss=1.271241\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] Epoch[3] Batch[865] avg_epoch_loss=1.330244\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=865 train loss <loss>=1.41175405979\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] Epoch[3] Batch [865]#011Speed: 13618.15 samples/sec#011loss=1.411754\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] Epoch[3] Batch[870] avg_epoch_loss=1.328614\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=870 train loss <loss>=1.04636253119\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] Epoch[3] Batch [870]#011Speed: 1568.66 samples/sec#011loss=1.046363\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] Epoch[3] Batch[875] avg_epoch_loss=1.327551\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=875 train loss <loss>=1.14237989187\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] Epoch[3] Batch [875]#011Speed: 14287.60 samples/sec#011loss=1.142380\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] Epoch[3] Batch[880] avg_epoch_loss=1.327422\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=880 train loss <loss>=1.30476162434\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] Epoch[3] Batch [880]#011Speed: 1387.58 samples/sec#011loss=1.304762\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] Epoch[3] Batch[885] avg_epoch_loss=1.326924\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=885 train loss <loss>=1.23922393322\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:15 INFO 140088046479168] Epoch[3] Batch [885]#011Speed: 13953.69 samples/sec#011loss=1.239224\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] Epoch[3] Batch[890] avg_epoch_loss=1.328392\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=890 train loss <loss>=1.58849823475\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] Epoch[3] Batch [890]#011Speed: 14329.09 samples/sec#011loss=1.588498\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] Epoch[3] Batch[895] avg_epoch_loss=1.331778\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=895 train loss <loss>=1.93516614437\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] Epoch[3] Batch [895]#011Speed: 1525.41 samples/sec#011loss=1.935166\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] Epoch[3] Batch[900] avg_epoch_loss=1.335217\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=900 train loss <loss>=1.95157263279\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] Epoch[3] Batch [900]#011Speed: 14249.53 samples/sec#011loss=1.951573\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] Epoch[3] Batch[905] avg_epoch_loss=1.335951\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, batch=905 train loss <loss>=1.46818132401\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] Epoch[3] Batch [905]#011Speed: 8778.20 samples/sec#011loss=1.468181\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] processed a total of 57943 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15962.277889251709, \"sum\": 15962.277889251709, \"min\": 15962.277889251709}}, \"EndTime\": 1604320456.28709, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320440.324731}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] #throughput_metric: host=algo-1, train throughput=3629.96793382 records/second\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=3, train loss <loss>=1.33595126512\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] Saved checkpoint to \"/opt/ml/model/state_f6568a72-55fa-443b-bde7-d2e39922dd31-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 4.887104034423828, \"sum\": 4.887104034423828, \"min\": 4.887104034423828}}, \"EndTime\": 1604320456.29261, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320456.287171}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] Epoch[4] Batch[0] avg_epoch_loss=1.308711\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=1.30871093273\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] Epoch[4] Batch[5] avg_epoch_loss=1.296976\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=1.29697601\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] Epoch[4] Batch [5]#011Speed: 14293.99 samples/sec#011loss=1.296976\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] Epoch[4] Batch[10] avg_epoch_loss=1.268493\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=1.23431396484\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] Epoch[4] Batch [10]#011Speed: 13207.81 samples/sec#011loss=1.234314\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] Epoch[4] Batch[15] avg_epoch_loss=1.229955\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=15 train loss <loss>=1.14517049789\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] Epoch[4] Batch [15]#011Speed: 1815.83 samples/sec#011loss=1.145170\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] Epoch[4] Batch[20] avg_epoch_loss=1.214755\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=20 train loss <loss>=1.16611411572\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] Epoch[4] Batch [20]#011Speed: 12915.73 samples/sec#011loss=1.166114\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] Epoch[4] Batch[25] avg_epoch_loss=1.202936\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=25 train loss <loss>=1.15329488516\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] Epoch[4] Batch [25]#011Speed: 1683.13 samples/sec#011loss=1.153295\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] Epoch[4] Batch[30] avg_epoch_loss=1.227312\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=30 train loss <loss>=1.35407054424\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] Epoch[4] Batch [30]#011Speed: 14331.08 samples/sec#011loss=1.354071\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] Epoch[4] Batch[35] avg_epoch_loss=1.221073\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=35 train loss <loss>=1.18239052296\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:16 INFO 140088046479168] Epoch[4] Batch [35]#011Speed: 14064.67 samples/sec#011loss=1.182391\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] Epoch[4] Batch[40] avg_epoch_loss=1.228747\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=40 train loss <loss>=1.2839958787\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] Epoch[4] Batch [40]#011Speed: 1768.08 samples/sec#011loss=1.283996\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] Epoch[4] Batch[45] avg_epoch_loss=1.243675\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=45 train loss <loss>=1.36608686447\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] Epoch[4] Batch [45]#011Speed: 13528.92 samples/sec#011loss=1.366087\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] Epoch[4] Batch[50] avg_epoch_loss=1.253852\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=50 train loss <loss>=1.34748675823\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] Epoch[4] Batch [50]#011Speed: 14297.95 samples/sec#011loss=1.347487\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] Epoch[4] Batch[55] avg_epoch_loss=1.244635\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=55 train loss <loss>=1.15061234236\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] Epoch[4] Batch [55]#011Speed: 1670.78 samples/sec#011loss=1.150612\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] Epoch[4] Batch[60] avg_epoch_loss=1.223425\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=60 train loss <loss>=0.98587269783\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] Epoch[4] Batch [60]#011Speed: 13842.02 samples/sec#011loss=0.985873\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] Epoch[4] Batch[65] avg_epoch_loss=1.204489\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=65 train loss <loss>=0.97347714901\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] Epoch[4] Batch [65]#011Speed: 1719.92 samples/sec#011loss=0.973477\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] Epoch[4] Batch[70] avg_epoch_loss=1.205730\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=70 train loss <loss>=1.22211053371\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] Epoch[4] Batch [70]#011Speed: 14290.19 samples/sec#011loss=1.222111\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] Epoch[4] Batch[75] avg_epoch_loss=1.215224\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=75 train loss <loss>=1.35004110336\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] Epoch[4] Batch [75]#011Speed: 12700.99 samples/sec#011loss=1.350041\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] Epoch[4] Batch[80] avg_epoch_loss=1.217358\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=80 train loss <loss>=1.24978560209\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] Epoch[4] Batch [80]#011Speed: 1664.84 samples/sec#011loss=1.249786\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] Epoch[4] Batch[85] avg_epoch_loss=1.217705\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=85 train loss <loss>=1.22333350182\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:17 INFO 140088046479168] Epoch[4] Batch [85]#011Speed: 14281.82 samples/sec#011loss=1.223334\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] Epoch[4] Batch[90] avg_epoch_loss=1.221645\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=90 train loss <loss>=1.28941215277\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] Epoch[4] Batch [90]#011Speed: 1767.34 samples/sec#011loss=1.289412\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] Epoch[4] Batch[95] avg_epoch_loss=1.230081\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=95 train loss <loss>=1.38361098766\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] Epoch[4] Batch [95]#011Speed: 13937.75 samples/sec#011loss=1.383611\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] Epoch[4] Batch[100] avg_epoch_loss=1.251127\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=100 train loss <loss>=1.65521433353\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] Epoch[4] Batch [100]#011Speed: 14180.58 samples/sec#011loss=1.655214\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] Epoch[4] Batch[105] avg_epoch_loss=1.260644\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=105 train loss <loss>=1.45289607048\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] Epoch[4] Batch [105]#011Speed: 1509.85 samples/sec#011loss=1.452896\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] Epoch[4] Batch[110] avg_epoch_loss=1.272684\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=110 train loss <loss>=1.52792935371\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] Epoch[4] Batch [110]#011Speed: 13218.34 samples/sec#011loss=1.527929\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] Epoch[4] Batch[115] avg_epoch_loss=1.283136\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=115 train loss <loss>=1.51515884399\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] Epoch[4] Batch [115]#011Speed: 1849.84 samples/sec#011loss=1.515159\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] Epoch[4] Batch[120] avg_epoch_loss=1.293392\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=120 train loss <loss>=1.53133265972\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] Epoch[4] Batch [120]#011Speed: 14405.37 samples/sec#011loss=1.531333\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] Epoch[4] Batch[125] avg_epoch_loss=1.295503\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=125 train loss <loss>=1.34658383131\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] Epoch[4] Batch [125]#011Speed: 1858.34 samples/sec#011loss=1.346584\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] Epoch[4] Batch[130] avg_epoch_loss=1.305927\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=130 train loss <loss>=1.56863334179\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] Epoch[4] Batch [130]#011Speed: 13253.19 samples/sec#011loss=1.568633\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] Epoch[4] Batch[135] avg_epoch_loss=1.307013\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=135 train loss <loss>=1.33545467854\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] Epoch[4] Batch [135]#011Speed: 13995.88 samples/sec#011loss=1.335455\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] Epoch[4] Batch[140] avg_epoch_loss=1.312659\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=140 train loss <loss>=1.4662184\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] Epoch[4] Batch [140]#011Speed: 1855.75 samples/sec#011loss=1.466218\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] Epoch[4] Batch[145] avg_epoch_loss=1.316583\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=145 train loss <loss>=1.42725684643\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:18 INFO 140088046479168] Epoch[4] Batch [145]#011Speed: 14276.81 samples/sec#011loss=1.427257\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] Epoch[4] Batch[150] avg_epoch_loss=1.315464\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=150 train loss <loss>=1.28277289867\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] Epoch[4] Batch [150]#011Speed: 1880.23 samples/sec#011loss=1.282773\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] Epoch[4] Batch[155] avg_epoch_loss=1.317141\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=155 train loss <loss>=1.36780202389\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] Epoch[4] Batch [155]#011Speed: 14158.14 samples/sec#011loss=1.367802\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] Epoch[4] Batch[160] avg_epoch_loss=1.322098\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=160 train loss <loss>=1.47675397396\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] Epoch[4] Batch [160]#011Speed: 14194.52 samples/sec#011loss=1.476754\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] Epoch[4] Batch[165] avg_epoch_loss=1.327454\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=165 train loss <loss>=1.49991357327\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] Epoch[4] Batch [165]#011Speed: 1756.28 samples/sec#011loss=1.499914\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] Epoch[4] Batch[170] avg_epoch_loss=1.328063\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=170 train loss <loss>=1.34829757214\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] Epoch[4] Batch [170]#011Speed: 14260.88 samples/sec#011loss=1.348298\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] Epoch[4] Batch[175] avg_epoch_loss=1.333551\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=175 train loss <loss>=1.52121906281\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] Epoch[4] Batch [175]#011Speed: 1657.77 samples/sec#011loss=1.521219\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] Epoch[4] Batch[180] avg_epoch_loss=1.332455\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=180 train loss <loss>=1.29386610985\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] Epoch[4] Batch [180]#011Speed: 14288.97 samples/sec#011loss=1.293866\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] Epoch[4] Batch[185] avg_epoch_loss=1.331442\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=185 train loss <loss>=1.29479777813\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] Epoch[4] Batch [185]#011Speed: 13229.68 samples/sec#011loss=1.294798\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] Epoch[4] Batch[190] avg_epoch_loss=1.335186\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=190 train loss <loss>=1.47445883751\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] Epoch[4] Batch [190]#011Speed: 1791.60 samples/sec#011loss=1.474459\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] Epoch[4] Batch[195] avg_epoch_loss=1.334150\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=195 train loss <loss>=1.29458639622\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] Epoch[4] Batch [195]#011Speed: 13258.82 samples/sec#011loss=1.294586\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] Epoch[4] Batch[200] avg_epoch_loss=1.336963\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=200 train loss <loss>=1.44720077515\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] Epoch[4] Batch [200]#011Speed: 1763.02 samples/sec#011loss=1.447201\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] Epoch[4] Batch[205] avg_epoch_loss=1.332837\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=205 train loss <loss>=1.16697508097\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] Epoch[4] Batch [205]#011Speed: 14283.80 samples/sec#011loss=1.166975\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] Epoch[4] Batch[210] avg_epoch_loss=1.329420\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=210 train loss <loss>=1.18866951466\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:19 INFO 140088046479168] Epoch[4] Batch [210]#011Speed: 14234.26 samples/sec#011loss=1.188670\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] Epoch[4] Batch[215] avg_epoch_loss=1.328037\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=215 train loss <loss>=1.26964025497\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] Epoch[4] Batch [215]#011Speed: 1682.29 samples/sec#011loss=1.269640\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] Epoch[4] Batch[220] avg_epoch_loss=1.324192\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=220 train loss <loss>=1.15808205605\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] Epoch[4] Batch [220]#011Speed: 14363.29 samples/sec#011loss=1.158082\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] Epoch[4] Batch[225] avg_epoch_loss=1.319564\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=225 train loss <loss>=1.11504442692\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] Epoch[4] Batch [225]#011Speed: 11622.39 samples/sec#011loss=1.115044\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] Epoch[4] Batch[230] avg_epoch_loss=1.321134\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=230 train loss <loss>=1.3920933485\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] Epoch[4] Batch [230]#011Speed: 1727.48 samples/sec#011loss=1.392093\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] Epoch[4] Batch[235] avg_epoch_loss=1.319915\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=235 train loss <loss>=1.26360459328\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] Epoch[4] Batch [235]#011Speed: 14283.19 samples/sec#011loss=1.263605\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] Epoch[4] Batch[240] avg_epoch_loss=1.320590\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=240 train loss <loss>=1.35242202282\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] Epoch[4] Batch [240]#011Speed: 1744.49 samples/sec#011loss=1.352422\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] Epoch[4] Batch[245] avg_epoch_loss=1.319164\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=245 train loss <loss>=1.2504404068\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] Epoch[4] Batch [245]#011Speed: 14258.91 samples/sec#011loss=1.250440\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] Epoch[4] Batch[250] avg_epoch_loss=1.318780\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=250 train loss <loss>=1.2998657465\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] Epoch[4] Batch [250]#011Speed: 14241.21 samples/sec#011loss=1.299866\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] Epoch[4] Batch[255] avg_epoch_loss=1.317967\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=255 train loss <loss>=1.27718315125\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] Epoch[4] Batch [255]#011Speed: 1830.40 samples/sec#011loss=1.277183\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] Epoch[4] Batch[260] avg_epoch_loss=1.316301\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=260 train loss <loss>=1.23097286224\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:20 INFO 140088046479168] Epoch[4] Batch [260]#011Speed: 14345.17 samples/sec#011loss=1.230973\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] Epoch[4] Batch[265] avg_epoch_loss=1.311830\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=265 train loss <loss>=1.07847874165\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] Epoch[4] Batch [265]#011Speed: 1777.37 samples/sec#011loss=1.078479\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] Epoch[4] Batch[270] avg_epoch_loss=1.308466\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=270 train loss <loss>=1.12950997353\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] Epoch[4] Batch [270]#011Speed: 14352.38 samples/sec#011loss=1.129510\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] Epoch[4] Batch[275] avg_epoch_loss=1.305295\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=275 train loss <loss>=1.13339669704\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] Epoch[4] Batch [275]#011Speed: 13080.50 samples/sec#011loss=1.133397\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] Epoch[4] Batch[280] avg_epoch_loss=1.295495\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=280 train loss <loss>=0.754518222809\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] Epoch[4] Batch [280]#011Speed: 1579.35 samples/sec#011loss=0.754518\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] Epoch[4] Batch[285] avg_epoch_loss=1.289431\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=285 train loss <loss>=0.948683404922\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] Epoch[4] Batch [285]#011Speed: 15065.92 samples/sec#011loss=0.948683\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] Epoch[4] Batch[290] avg_epoch_loss=1.285960\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=290 train loss <loss>=1.08738590479\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] Epoch[4] Batch [290]#011Speed: 1782.19 samples/sec#011loss=1.087386\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] Epoch[4] Batch[295] avg_epoch_loss=1.286136\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=295 train loss <loss>=1.29638345242\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] Epoch[4] Batch [295]#011Speed: 14154.26 samples/sec#011loss=1.296383\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] Epoch[4] Batch[300] avg_epoch_loss=1.285059\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=300 train loss <loss>=1.22131859064\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] Epoch[4] Batch [300]#011Speed: 13565.02 samples/sec#011loss=1.221319\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] Epoch[4] Batch[305] avg_epoch_loss=1.290799\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=305 train loss <loss>=1.63634471893\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] Epoch[4] Batch [305]#011Speed: 1703.04 samples/sec#011loss=1.636345\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] Epoch[4] Batch[310] avg_epoch_loss=1.291146\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=310 train loss <loss>=1.31234345436\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] Epoch[4] Batch [310]#011Speed: 13231.37 samples/sec#011loss=1.312343\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] Epoch[4] Batch[315] avg_epoch_loss=1.291386\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=315 train loss <loss>=1.30634874105\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] Epoch[4] Batch [315]#011Speed: 1797.39 samples/sec#011loss=1.306349\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] Epoch[4] Batch[320] avg_epoch_loss=1.292152\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=320 train loss <loss>=1.34056901932\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] Epoch[4] Batch [320]#011Speed: 14286.99 samples/sec#011loss=1.340569\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] Epoch[4] Batch[325] avg_epoch_loss=1.293007\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=325 train loss <loss>=1.34787971973\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:21 INFO 140088046479168] Epoch[4] Batch [325]#011Speed: 14254.52 samples/sec#011loss=1.347880\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] Epoch[4] Batch[330] avg_epoch_loss=1.292711\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=330 train loss <loss>=1.27343735695\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] Epoch[4] Batch [330]#011Speed: 1718.97 samples/sec#011loss=1.273437\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] Epoch[4] Batch[335] avg_epoch_loss=1.290519\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=335 train loss <loss>=1.14536384344\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] Epoch[4] Batch [335]#011Speed: 13715.00 samples/sec#011loss=1.145364\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] Epoch[4] Batch[340] avg_epoch_loss=1.289618\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=340 train loss <loss>=1.22912182808\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] Epoch[4] Batch [340]#011Speed: 14224.76 samples/sec#011loss=1.229122\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] Epoch[4] Batch[345] avg_epoch_loss=1.289412\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=345 train loss <loss>=1.27535773516\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] Epoch[4] Batch [345]#011Speed: 1660.01 samples/sec#011loss=1.275358\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] Epoch[4] Batch[350] avg_epoch_loss=1.289555\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=350 train loss <loss>=1.29942493439\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] Epoch[4] Batch [350]#011Speed: 14691.73 samples/sec#011loss=1.299425\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] Epoch[4] Batch[355] avg_epoch_loss=1.289602\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=355 train loss <loss>=1.29287919998\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] Epoch[4] Batch [355]#011Speed: 1730.47 samples/sec#011loss=1.292879\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] Epoch[4] Batch[360] avg_epoch_loss=1.287861\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=360 train loss <loss>=1.16389322281\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] Epoch[4] Batch [360]#011Speed: 13242.86 samples/sec#011loss=1.163893\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] Epoch[4] Batch[365] avg_epoch_loss=1.285791\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=365 train loss <loss>=1.13640352488\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] Epoch[4] Batch [365]#011Speed: 13304.03 samples/sec#011loss=1.136404\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] Epoch[4] Batch[370] avg_epoch_loss=1.282403\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=370 train loss <loss>=1.03438113928\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] Epoch[4] Batch [370]#011Speed: 1766.16 samples/sec#011loss=1.034381\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] Epoch[4] Batch[375] avg_epoch_loss=1.280402\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=375 train loss <loss>=1.13190219402\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:22 INFO 140088046479168] Epoch[4] Batch [375]#011Speed: 12847.74 samples/sec#011loss=1.131902\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] Epoch[4] Batch[380] avg_epoch_loss=1.277042\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=380 train loss <loss>=1.02438269854\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] Epoch[4] Batch [380]#011Speed: 1721.36 samples/sec#011loss=1.024383\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] Epoch[4] Batch[385] avg_epoch_loss=1.273482\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=385 train loss <loss>=1.00218213797\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] Epoch[4] Batch [385]#011Speed: 14086.96 samples/sec#011loss=1.002182\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] Epoch[4] Batch[390] avg_epoch_loss=1.273122\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=390 train loss <loss>=1.24533804655\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] Epoch[4] Batch [390]#011Speed: 14183.12 samples/sec#011loss=1.245338\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] Epoch[4] Batch[395] avg_epoch_loss=1.272244\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=395 train loss <loss>=1.2036254406\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] Epoch[4] Batch [395]#011Speed: 1407.93 samples/sec#011loss=1.203625\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] Epoch[4] Batch[400] avg_epoch_loss=1.269507\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=400 train loss <loss>=1.05272439718\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] Epoch[4] Batch [400]#011Speed: 13495.32 samples/sec#011loss=1.052724\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] Epoch[4] Batch[405] avg_epoch_loss=1.264949\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=405 train loss <loss>=0.899400651455\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] Epoch[4] Batch [405]#011Speed: 1542.45 samples/sec#011loss=0.899401\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] Epoch[4] Batch[410] avg_epoch_loss=1.260200\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=410 train loss <loss>=0.874538290501\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] Epoch[4] Batch [410]#011Speed: 14030.71 samples/sec#011loss=0.874538\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] Epoch[4] Batch[415] avg_epoch_loss=1.257829\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=415 train loss <loss>=1.06292418242\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] Epoch[4] Batch [415]#011Speed: 14234.87 samples/sec#011loss=1.062924\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] Epoch[4] Batch[420] avg_epoch_loss=1.256657\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=420 train loss <loss>=1.159174335\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] Epoch[4] Batch [420]#011Speed: 1827.76 samples/sec#011loss=1.159174\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] Epoch[4] Batch[425] avg_epoch_loss=1.253057\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=425 train loss <loss>=0.94992377758\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] Epoch[4] Batch [425]#011Speed: 12962.26 samples/sec#011loss=0.949924\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] Epoch[4] Batch[430] avg_epoch_loss=1.251728\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=430 train loss <loss>=1.1384926796\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:23 INFO 140088046479168] Epoch[4] Batch [430]#011Speed: 1793.82 samples/sec#011loss=1.138493\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] Epoch[4] Batch[435] avg_epoch_loss=1.257905\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=435 train loss <loss>=1.79042682648\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] Epoch[4] Batch [435]#011Speed: 14294.60 samples/sec#011loss=1.790427\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] Epoch[4] Batch[440] avg_epoch_loss=1.258835\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=440 train loss <loss>=1.33988022804\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] Epoch[4] Batch [440]#011Speed: 13079.99 samples/sec#011loss=1.339880\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] Epoch[4] Batch[445] avg_epoch_loss=1.259716\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=445 train loss <loss>=1.33744843006\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] Epoch[4] Batch [445]#011Speed: 1717.68 samples/sec#011loss=1.337448\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] Epoch[4] Batch[450] avg_epoch_loss=1.266951\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=450 train loss <loss>=1.91228113174\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] Epoch[4] Batch [450]#011Speed: 14242.57 samples/sec#011loss=1.912281\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] Epoch[4] Batch[455] avg_epoch_loss=1.268528\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=455 train loss <loss>=1.41076145172\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] Epoch[4] Batch [455]#011Speed: 12502.93 samples/sec#011loss=1.410761\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] Epoch[4] Batch[460] avg_epoch_loss=1.274972\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=460 train loss <loss>=1.86269667149\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] Epoch[4] Batch [460]#011Speed: 1423.39 samples/sec#011loss=1.862697\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] Epoch[4] Batch[465] avg_epoch_loss=1.278001\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=465 train loss <loss>=1.55726823807\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] Epoch[4] Batch [465]#011Speed: 13577.64 samples/sec#011loss=1.557268\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] Epoch[4] Batch[470] avg_epoch_loss=1.280240\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=470 train loss <loss>=1.4889439106\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] Epoch[4] Batch [470]#011Speed: 1764.28 samples/sec#011loss=1.488944\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] Epoch[4] Batch[475] avg_epoch_loss=1.279469\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=475 train loss <loss>=1.20678232908\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] Epoch[4] Batch [475]#011Speed: 14212.11 samples/sec#011loss=1.206782\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] Epoch[4] Batch[480] avg_epoch_loss=1.278040\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=480 train loss <loss>=1.1420743227\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] Epoch[4] Batch [480]#011Speed: 14302.37 samples/sec#011loss=1.142074\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] Epoch[4] Batch[485] avg_epoch_loss=1.278408\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=485 train loss <loss>=1.3138035655\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] Epoch[4] Batch [485]#011Speed: 1653.24 samples/sec#011loss=1.313804\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] Epoch[4] Batch[490] avg_epoch_loss=1.278046\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=490 train loss <loss>=1.24282963276\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:24 INFO 140088046479168] Epoch[4] Batch [490]#011Speed: 13554.06 samples/sec#011loss=1.242830\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] Epoch[4] Batch[495] avg_epoch_loss=1.281082\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=495 train loss <loss>=1.57923717499\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] Epoch[4] Batch [495]#011Speed: 1879.39 samples/sec#011loss=1.579237\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] Epoch[4] Batch[500] avg_epoch_loss=1.283122\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=500 train loss <loss>=1.48542685509\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] Epoch[4] Batch [500]#011Speed: 14460.00 samples/sec#011loss=1.485427\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] Epoch[4] Batch[505] avg_epoch_loss=1.279808\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=505 train loss <loss>=0.947796416283\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] Epoch[4] Batch [505]#011Speed: 14284.56 samples/sec#011loss=0.947796\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] Epoch[4] Batch[510] avg_epoch_loss=1.279256\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=510 train loss <loss>=1.22335700989\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] Epoch[4] Batch [510]#011Speed: 1848.31 samples/sec#011loss=1.223357\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] Epoch[4] Batch[515] avg_epoch_loss=1.276396\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=515 train loss <loss>=0.984174442291\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] Epoch[4] Batch [515]#011Speed: 14305.57 samples/sec#011loss=0.984174\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] Epoch[4] Batch[520] avg_epoch_loss=1.275914\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=520 train loss <loss>=1.22607557774\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] Epoch[4] Batch [520]#011Speed: 1769.27 samples/sec#011loss=1.226076\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] Epoch[4] Batch[525] avg_epoch_loss=1.274892\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=525 train loss <loss>=1.16848907471\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] Epoch[4] Batch [525]#011Speed: 14406.61 samples/sec#011loss=1.168489\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] Epoch[4] Batch[530] avg_epoch_loss=1.273360\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=530 train loss <loss>=1.11219696999\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] Epoch[4] Batch [530]#011Speed: 14456.11 samples/sec#011loss=1.112197\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] Epoch[4] Batch[535] avg_epoch_loss=1.270456\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=535 train loss <loss>=0.961965382099\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] Epoch[4] Batch [535]#011Speed: 1686.96 samples/sec#011loss=0.961965\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] Epoch[4] Batch[540] avg_epoch_loss=1.268680\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=540 train loss <loss>=1.07831511497\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] Epoch[4] Batch [540]#011Speed: 12953.88 samples/sec#011loss=1.078315\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] Epoch[4] Batch[545] avg_epoch_loss=1.266575\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=545 train loss <loss>=1.03886042833\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:25 INFO 140088046479168] Epoch[4] Batch [545]#011Speed: 1724.27 samples/sec#011loss=1.038860\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] Epoch[4] Batch[550] avg_epoch_loss=1.265828\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=550 train loss <loss>=1.18425996304\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] Epoch[4] Batch [550]#011Speed: 14320.99 samples/sec#011loss=1.184260\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] Epoch[4] Batch[555] avg_epoch_loss=1.263864\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=555 train loss <loss>=1.04744813442\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] Epoch[4] Batch [555]#011Speed: 14346.55 samples/sec#011loss=1.047448\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] Epoch[4] Batch[560] avg_epoch_loss=1.261707\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=560 train loss <loss>=1.02180690765\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] Epoch[4] Batch [560]#011Speed: 1696.83 samples/sec#011loss=1.021807\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] Epoch[4] Batch[565] avg_epoch_loss=1.260735\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=565 train loss <loss>=1.15164721012\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] Epoch[4] Batch [565]#011Speed: 13781.19 samples/sec#011loss=1.151647\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] Epoch[4] Batch[570] avg_epoch_loss=1.263460\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=570 train loss <loss>=1.57197122574\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] Epoch[4] Batch [570]#011Speed: 1619.94 samples/sec#011loss=1.571971\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] Epoch[4] Batch[575] avg_epoch_loss=1.271585\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=575 train loss <loss>=2.19946792126\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] Epoch[4] Batch [575]#011Speed: 14122.38 samples/sec#011loss=2.199468\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] Epoch[4] Batch[580] avg_epoch_loss=1.279227\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=580 train loss <loss>=2.159567976\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] Epoch[4] Batch [580]#011Speed: 14722.18 samples/sec#011loss=2.159568\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] Epoch[4] Batch[585] avg_epoch_loss=1.283472\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=585 train loss <loss>=1.77673094273\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] Epoch[4] Batch [585]#011Speed: 1635.95 samples/sec#011loss=1.776731\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] Epoch[4] Batch[590] avg_epoch_loss=1.288367\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=590 train loss <loss>=1.86200635433\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] Epoch[4] Batch [590]#011Speed: 14294.60 samples/sec#011loss=1.862006\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] Epoch[4] Batch[595] avg_epoch_loss=1.289509\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=595 train loss <loss>=1.42456302643\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] Epoch[4] Batch [595]#011Speed: 1805.60 samples/sec#011loss=1.424563\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] Epoch[4] Batch[600] avg_epoch_loss=1.290962\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=600 train loss <loss>=1.46410815716\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] Epoch[4] Batch [600]#011Speed: 13224.72 samples/sec#011loss=1.464108\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] Epoch[4] Batch[605] avg_epoch_loss=1.292356\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=605 train loss <loss>=1.45993456841\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:26 INFO 140088046479168] Epoch[4] Batch [605]#011Speed: 13204.04 samples/sec#011loss=1.459935\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] Epoch[4] Batch[610] avg_epoch_loss=1.294516\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=610 train loss <loss>=1.55628023148\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] Epoch[4] Batch [610]#011Speed: 1763.92 samples/sec#011loss=1.556280\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] Epoch[4] Batch[615] avg_epoch_loss=1.296898\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=615 train loss <loss>=1.58800097704\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] Epoch[4] Batch [615]#011Speed: 14216.62 samples/sec#011loss=1.588001\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] Epoch[4] Batch[620] avg_epoch_loss=1.299575\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=620 train loss <loss>=1.62944340706\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] Epoch[4] Batch [620]#011Speed: 1785.29 samples/sec#011loss=1.629443\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] Epoch[4] Batch[625] avg_epoch_loss=1.300617\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=625 train loss <loss>=1.42993328571\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] Epoch[4] Batch [625]#011Speed: 11654.59 samples/sec#011loss=1.429933\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] Epoch[4] Batch[630] avg_epoch_loss=1.300642\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=630 train loss <loss>=1.30381793976\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] Epoch[4] Batch [630]#011Speed: 14246.81 samples/sec#011loss=1.303818\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] Epoch[4] Batch[635] avg_epoch_loss=1.303348\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=635 train loss <loss>=1.64480249882\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] Epoch[4] Batch [635]#011Speed: 1640.34 samples/sec#011loss=1.644802\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] Epoch[4] Batch[640] avg_epoch_loss=1.304590\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=640 train loss <loss>=1.46267888546\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] Epoch[4] Batch [640]#011Speed: 14370.36 samples/sec#011loss=1.462679\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] Epoch[4] Batch[645] avg_epoch_loss=1.304801\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=645 train loss <loss>=1.33179647923\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] Epoch[4] Batch [645]#011Speed: 13154.22 samples/sec#011loss=1.331796\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] Epoch[4] Batch[650] avg_epoch_loss=1.305651\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=650 train loss <loss>=1.41543579102\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] Epoch[4] Batch [650]#011Speed: 1771.24 samples/sec#011loss=1.415436\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] Epoch[4] Batch[655] avg_epoch_loss=1.307442\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=655 train loss <loss>=1.5407063961\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:27 INFO 140088046479168] Epoch[4] Batch [655]#011Speed: 13891.30 samples/sec#011loss=1.540706\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] Epoch[4] Batch[660] avg_epoch_loss=1.306781\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=660 train loss <loss>=1.22008968592\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] Epoch[4] Batch [660]#011Speed: 1653.50 samples/sec#011loss=1.220090\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] Epoch[4] Batch[665] avg_epoch_loss=1.308244\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=665 train loss <loss>=1.50165066719\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] Epoch[4] Batch [665]#011Speed: 14111.25 samples/sec#011loss=1.501651\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] Epoch[4] Batch[670] avg_epoch_loss=1.309122\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=670 train loss <loss>=1.42603064775\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] Epoch[4] Batch [670]#011Speed: 14278.63 samples/sec#011loss=1.426031\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] Epoch[4] Batch[675] avg_epoch_loss=1.310102\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=675 train loss <loss>=1.44157552719\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] Epoch[4] Batch [675]#011Speed: 1593.93 samples/sec#011loss=1.441576\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] Epoch[4] Batch[680] avg_epoch_loss=1.311539\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=680 train loss <loss>=1.50582547188\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] Epoch[4] Batch [680]#011Speed: 13839.16 samples/sec#011loss=1.505825\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] Epoch[4] Batch[685] avg_epoch_loss=1.311295\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=685 train loss <loss>=1.27814135551\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] Epoch[4] Batch [685]#011Speed: 1667.44 samples/sec#011loss=1.278141\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] Epoch[4] Batch[690] avg_epoch_loss=1.311721\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=690 train loss <loss>=1.37003917694\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] Epoch[4] Batch [690]#011Speed: 14181.17 samples/sec#011loss=1.370039\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] Epoch[4] Batch[695] avg_epoch_loss=1.313714\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=695 train loss <loss>=1.58925440311\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] Epoch[4] Batch [695]#011Speed: 13855.88 samples/sec#011loss=1.589254\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] Epoch[4] Batch[700] avg_epoch_loss=1.315485\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=700 train loss <loss>=1.56194975376\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] Epoch[4] Batch [700]#011Speed: 1733.53 samples/sec#011loss=1.561950\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] Epoch[4] Batch[705] avg_epoch_loss=1.315604\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=705 train loss <loss>=1.33225874901\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] Epoch[4] Batch [705]#011Speed: 14341.95 samples/sec#011loss=1.332259\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] Epoch[4] Batch[710] avg_epoch_loss=1.317716\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=710 train loss <loss>=1.61600315571\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] Epoch[4] Batch [710]#011Speed: 13574.90 samples/sec#011loss=1.616003\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] Epoch[4] Batch[715] avg_epoch_loss=1.318396\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=715 train loss <loss>=1.41505150795\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] Epoch[4] Batch [715]#011Speed: 1668.40 samples/sec#011loss=1.415052\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] Epoch[4] Batch[720] avg_epoch_loss=1.319798\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=720 train loss <loss>=1.52061460018\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:28 INFO 140088046479168] Epoch[4] Batch [720]#011Speed: 13336.15 samples/sec#011loss=1.520615\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] Epoch[4] Batch[725] avg_epoch_loss=1.320111\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=725 train loss <loss>=1.36527762413\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] Epoch[4] Batch [725]#011Speed: 1834.63 samples/sec#011loss=1.365278\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] Epoch[4] Batch[730] avg_epoch_loss=1.320518\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=730 train loss <loss>=1.37961378098\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] Epoch[4] Batch [730]#011Speed: 14296.58 samples/sec#011loss=1.379614\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] Epoch[4] Batch[735] avg_epoch_loss=1.320706\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=735 train loss <loss>=1.34816384315\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] Epoch[4] Batch [735]#011Speed: 1851.26 samples/sec#011loss=1.348164\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] Epoch[4] Batch[740] avg_epoch_loss=1.320953\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=740 train loss <loss>=1.35722458363\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] Epoch[4] Batch [740]#011Speed: 11967.59 samples/sec#011loss=1.357225\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] Epoch[4] Batch[745] avg_epoch_loss=1.322456\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=745 train loss <loss>=1.54522316456\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] Epoch[4] Batch [745]#011Speed: 12862.76 samples/sec#011loss=1.545223\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] Epoch[4] Batch[750] avg_epoch_loss=1.322199\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=750 train loss <loss>=1.28390903473\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] Epoch[4] Batch [750]#011Speed: 1319.54 samples/sec#011loss=1.283909\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] Epoch[4] Batch[755] avg_epoch_loss=1.322739\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=755 train loss <loss>=1.40380325317\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] Epoch[4] Batch [755]#011Speed: 13899.21 samples/sec#011loss=1.403803\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] Epoch[4] Batch[760] avg_epoch_loss=1.322625\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=760 train loss <loss>=1.30536248684\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] Epoch[4] Batch [760]#011Speed: 13307.86 samples/sec#011loss=1.305362\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] Epoch[4] Batch[765] avg_epoch_loss=1.321921\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=765 train loss <loss>=1.21488745213\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] Epoch[4] Batch [765]#011Speed: 1691.61 samples/sec#011loss=1.214887\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] Epoch[4] Batch[770] avg_epoch_loss=1.323307\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=770 train loss <loss>=1.53556640148\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:29 INFO 140088046479168] Epoch[4] Batch [770]#011Speed: 14066.59 samples/sec#011loss=1.535566\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] Epoch[4] Batch[775] avg_epoch_loss=1.323562\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=775 train loss <loss>=1.36295368671\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] Epoch[4] Batch [775]#011Speed: 1752.78 samples/sec#011loss=1.362954\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] Epoch[4] Batch[780] avg_epoch_loss=1.324354\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=780 train loss <loss>=1.44724469185\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] Epoch[4] Batch [780]#011Speed: 14200.23 samples/sec#011loss=1.447245\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] Epoch[4] Batch[785] avg_epoch_loss=1.325078\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=785 train loss <loss>=1.4380645752\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] Epoch[4] Batch [785]#011Speed: 14289.58 samples/sec#011loss=1.438065\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] Epoch[4] Batch[790] avg_epoch_loss=1.326206\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=790 train loss <loss>=1.50356068611\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] Epoch[4] Batch [790]#011Speed: 1804.09 samples/sec#011loss=1.503561\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] Epoch[4] Batch[795] avg_epoch_loss=1.325981\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=795 train loss <loss>=1.2903387785\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] Epoch[4] Batch [795]#011Speed: 14264.07 samples/sec#011loss=1.290339\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] Epoch[4] Batch[800] avg_epoch_loss=1.327361\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=800 train loss <loss>=1.54707829952\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] Epoch[4] Batch [800]#011Speed: 1830.08 samples/sec#011loss=1.547078\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] Epoch[4] Batch[805] avg_epoch_loss=1.329050\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=805 train loss <loss>=1.59970920086\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] Epoch[4] Batch [805]#011Speed: 13726.22 samples/sec#011loss=1.599709\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] Epoch[4] Batch[810] avg_epoch_loss=1.329434\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=810 train loss <loss>=1.39132227898\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] Epoch[4] Batch [810]#011Speed: 14195.12 samples/sec#011loss=1.391322\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] Epoch[4] Batch[815] avg_epoch_loss=1.329798\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=815 train loss <loss>=1.38877059221\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] Epoch[4] Batch [815]#011Speed: 1612.55 samples/sec#011loss=1.388771\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] Epoch[4] Batch[820] avg_epoch_loss=1.330110\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=820 train loss <loss>=1.38105034828\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] Epoch[4] Batch [820]#011Speed: 13679.91 samples/sec#011loss=1.381050\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] Epoch[4] Batch[825] avg_epoch_loss=1.329808\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=825 train loss <loss>=1.28017287254\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] Epoch[4] Batch [825]#011Speed: 13014.04 samples/sec#011loss=1.280173\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] Epoch[4] Batch[830] avg_epoch_loss=1.329456\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=830 train loss <loss>=1.27132265568\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] Epoch[4] Batch [830]#011Speed: 1824.70 samples/sec#011loss=1.271323\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] Epoch[4] Batch[835] avg_epoch_loss=1.329454\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=835 train loss <loss>=1.32911067009\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:30 INFO 140088046479168] Epoch[4] Batch [835]#011Speed: 13900.36 samples/sec#011loss=1.329111\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] Epoch[4] Batch[840] avg_epoch_loss=1.328521\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=840 train loss <loss>=1.17253705263\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] Epoch[4] Batch [840]#011Speed: 1785.03 samples/sec#011loss=1.172537\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] Epoch[4] Batch[845] avg_epoch_loss=1.328759\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=845 train loss <loss>=1.36882535219\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] Epoch[4] Batch [845]#011Speed: 13911.74 samples/sec#011loss=1.368825\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] Epoch[4] Batch[850] avg_epoch_loss=1.328621\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=850 train loss <loss>=1.30525647402\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] Epoch[4] Batch [850]#011Speed: 14188.82 samples/sec#011loss=1.305256\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] Epoch[4] Batch[855] avg_epoch_loss=1.327636\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=855 train loss <loss>=1.1599996686\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] Epoch[4] Batch [855]#011Speed: 1620.67 samples/sec#011loss=1.160000\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] Epoch[4] Batch[860] avg_epoch_loss=1.327683\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=860 train loss <loss>=1.33573473692\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] Epoch[4] Batch [860]#011Speed: 13041.48 samples/sec#011loss=1.335735\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] Epoch[4] Batch[865] avg_epoch_loss=1.327950\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=865 train loss <loss>=1.37390384674\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] Epoch[4] Batch [865]#011Speed: 1649.39 samples/sec#011loss=1.373904\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] Epoch[4] Batch[870] avg_epoch_loss=1.326848\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=870 train loss <loss>=1.13601720333\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] Epoch[4] Batch [870]#011Speed: 14167.40 samples/sec#011loss=1.136017\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] Epoch[4] Batch[875] avg_epoch_loss=1.326362\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=875 train loss <loss>=1.24166526794\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] Epoch[4] Batch [875]#011Speed: 14290.80 samples/sec#011loss=1.241665\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] Epoch[4] Batch[880] avg_epoch_loss=1.325070\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=880 train loss <loss>=1.09876810312\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] Epoch[4] Batch [880]#011Speed: 1739.43 samples/sec#011loss=1.098768\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] Epoch[4] Batch[885] avg_epoch_loss=1.324195\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=885 train loss <loss>=1.17003521919\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:31 INFO 140088046479168] Epoch[4] Batch [885]#011Speed: 13937.31 samples/sec#011loss=1.170035\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] Epoch[4] Batch[890] avg_epoch_loss=1.323187\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=890 train loss <loss>=1.1445404768\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] Epoch[4] Batch [890]#011Speed: 1701.77 samples/sec#011loss=1.144540\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] Epoch[4] Batch[895] avg_epoch_loss=1.322424\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=895 train loss <loss>=1.1864684701\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] Epoch[4] Batch [895]#011Speed: 13676.99 samples/sec#011loss=1.186468\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] Epoch[4] Batch[900] avg_epoch_loss=1.322437\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, batch=900 train loss <loss>=1.32475469112\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] Epoch[4] Batch [900]#011Speed: 13318.42 samples/sec#011loss=1.324755\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] processed a total of 57917 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15864.007949829102, \"sum\": 15864.007949829102, \"min\": 15864.007949829102}}, \"EndTime\": 1604320472.156723, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320456.292669}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] #throughput_metric: host=algo-1, train throughput=3650.81547125 records/second\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=4, train loss <loss>=1.32063763109\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] Saved checkpoint to \"/opt/ml/model/state_981cfc04-a7d1-4af7-840f-fad7c47d83ea-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 6.415128707885742, \"sum\": 6.415128707885742, \"min\": 6.415128707885742}}, \"EndTime\": 1604320472.163793, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320472.156812}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] Epoch[5] Batch[0] avg_epoch_loss=1.141224\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=1.14122378826\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] Epoch[5] Batch[5] avg_epoch_loss=1.300394\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=1.30039391915\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] Epoch[5] Batch [5]#011Speed: 13197.94 samples/sec#011loss=1.300394\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] Epoch[5] Batch[10] avg_epoch_loss=1.303848\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=1.30799314976\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] Epoch[5] Batch [10]#011Speed: 13557.07 samples/sec#011loss=1.307993\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] Epoch[5] Batch[15] avg_epoch_loss=1.284892\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=15 train loss <loss>=1.24318988323\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] Epoch[5] Batch [15]#011Speed: 1697.65 samples/sec#011loss=1.243190\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] Epoch[5] Batch[20] avg_epoch_loss=1.223638\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=20 train loss <loss>=1.02762392759\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] Epoch[5] Batch [20]#011Speed: 13695.69 samples/sec#011loss=1.027624\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] Epoch[5] Batch[25] avg_epoch_loss=1.226958\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=25 train loss <loss>=1.24090350866\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] Epoch[5] Batch [25]#011Speed: 12774.98 samples/sec#011loss=1.240904\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] Epoch[5] Batch[30] avg_epoch_loss=1.181926\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=30 train loss <loss>=0.947760951519\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] Epoch[5] Batch [30]#011Speed: 1748.47 samples/sec#011loss=0.947761\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] Epoch[5] Batch[35] avg_epoch_loss=1.154501\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=35 train loss <loss>=0.98446624279\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:32 INFO 140088046479168] Epoch[5] Batch [35]#011Speed: 13198.07 samples/sec#011loss=0.984466\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] Epoch[5] Batch[40] avg_epoch_loss=1.136945\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=40 train loss <loss>=1.01053516865\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] Epoch[5] Batch [40]#011Speed: 1817.25 samples/sec#011loss=1.010535\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] Epoch[5] Batch[45] avg_epoch_loss=1.154498\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=45 train loss <loss>=1.29843726158\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] Epoch[5] Batch [45]#011Speed: 13422.71 samples/sec#011loss=1.298437\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] Epoch[5] Batch[50] avg_epoch_loss=1.151455\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=50 train loss <loss>=1.12345421314\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] Epoch[5] Batch [50]#011Speed: 13172.03 samples/sec#011loss=1.123454\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] Epoch[5] Batch[55] avg_epoch_loss=1.139828\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=55 train loss <loss>=1.02124105692\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] Epoch[5] Batch [55]#011Speed: 1694.98 samples/sec#011loss=1.021241\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] Epoch[5] Batch[60] avg_epoch_loss=1.129135\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=60 train loss <loss>=1.00937222242\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] Epoch[5] Batch [60]#011Speed: 13503.20 samples/sec#011loss=1.009372\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] Epoch[5] Batch[65] avg_epoch_loss=1.120756\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=65 train loss <loss>=1.01852293015\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] Epoch[5] Batch [65]#011Speed: 1653.40 samples/sec#011loss=1.018523\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] Epoch[5] Batch[70] avg_epoch_loss=1.120248\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=70 train loss <loss>=1.11355307102\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] Epoch[5] Batch [70]#011Speed: 13315.65 samples/sec#011loss=1.113553\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] Epoch[5] Batch[75] avg_epoch_loss=1.120771\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=75 train loss <loss>=1.12819054127\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] Epoch[5] Batch [75]#011Speed: 13220.95 samples/sec#011loss=1.128191\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] Epoch[5] Batch[80] avg_epoch_loss=1.117050\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=80 train loss <loss>=1.06049758196\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] Epoch[5] Batch [80]#011Speed: 1812.07 samples/sec#011loss=1.060498\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] Epoch[5] Batch[85] avg_epoch_loss=1.112152\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=85 train loss <loss>=1.0327926755\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] Epoch[5] Batch [85]#011Speed: 14124.91 samples/sec#011loss=1.032793\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] Epoch[5] Batch[90] avg_epoch_loss=1.111770\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=90 train loss <loss>=1.10520739555\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] Epoch[5] Batch [90]#011Speed: 1883.59 samples/sec#011loss=1.105207\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] Epoch[5] Batch[95] avg_epoch_loss=1.136291\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=95 train loss <loss>=1.5825781703\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] Epoch[5] Batch [95]#011Speed: 14454.08 samples/sec#011loss=1.582578\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] Epoch[5] Batch[100] avg_epoch_loss=1.160925\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=100 train loss <loss>=1.63389980793\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:33 INFO 140088046479168] Epoch[5] Batch [100]#011Speed: 14227.32 samples/sec#011loss=1.633900\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] Epoch[5] Batch[105] avg_epoch_loss=1.174634\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=105 train loss <loss>=1.45153917074\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] Epoch[5] Batch [105]#011Speed: 1767.47 samples/sec#011loss=1.451539\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] Epoch[5] Batch[110] avg_epoch_loss=1.179624\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=110 train loss <loss>=1.28541532755\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] Epoch[5] Batch [110]#011Speed: 13812.81 samples/sec#011loss=1.285415\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] Epoch[5] Batch[115] avg_epoch_loss=1.212417\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=115 train loss <loss>=1.94042960405\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] Epoch[5] Batch [115]#011Speed: 1711.91 samples/sec#011loss=1.940430\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] Epoch[5] Batch[120] avg_epoch_loss=1.258787\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=120 train loss <loss>=2.33456726074\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] Epoch[5] Batch [120]#011Speed: 14227.17 samples/sec#011loss=2.334567\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] Epoch[5] Batch[125] avg_epoch_loss=1.296737\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=125 train loss <loss>=2.21512713432\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] Epoch[5] Batch [125]#011Speed: 13744.63 samples/sec#011loss=2.215127\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] Epoch[5] Batch[130] avg_epoch_loss=1.325436\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=130 train loss <loss>=2.04864765406\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] Epoch[5] Batch [130]#011Speed: 1733.69 samples/sec#011loss=2.048648\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] Epoch[5] Batch[135] avg_epoch_loss=1.337629\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=135 train loss <loss>=1.65708210468\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] Epoch[5] Batch [135]#011Speed: 13291.25 samples/sec#011loss=1.657082\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] Epoch[5] Batch[140] avg_epoch_loss=1.345636\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=140 train loss <loss>=1.5634291172\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] Epoch[5] Batch [140]#011Speed: 1608.13 samples/sec#011loss=1.563429\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] Epoch[5] Batch[145] avg_epoch_loss=1.350808\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=145 train loss <loss>=1.49666659832\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] Epoch[5] Batch [145]#011Speed: 14248.17 samples/sec#011loss=1.496667\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] Epoch[5] Batch[150] avg_epoch_loss=1.356818\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=150 train loss <loss>=1.53229913712\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] Epoch[5] Batch [150]#011Speed: 13639.04 samples/sec#011loss=1.532299\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] Epoch[5] Batch[155] avg_epoch_loss=1.365839\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=155 train loss <loss>=1.63827941418\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:34 INFO 140088046479168] Epoch[5] Batch [155]#011Speed: 1832.35 samples/sec#011loss=1.638279\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] Epoch[5] Batch[160] avg_epoch_loss=1.375424\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=160 train loss <loss>=1.67448818684\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] Epoch[5] Batch [160]#011Speed: 13227.07 samples/sec#011loss=1.674488\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] Epoch[5] Batch[165] avg_epoch_loss=1.375340\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=165 train loss <loss>=1.37263789177\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] Epoch[5] Batch [165]#011Speed: 1872.53 samples/sec#011loss=1.372638\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] Epoch[5] Batch[170] avg_epoch_loss=1.375745\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=170 train loss <loss>=1.38918175697\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] Epoch[5] Batch [170]#011Speed: 13220.95 samples/sec#011loss=1.389182\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] Epoch[5] Batch[175] avg_epoch_loss=1.375565\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=175 train loss <loss>=1.36941821575\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] Epoch[5] Batch [175]#011Speed: 13607.79 samples/sec#011loss=1.369418\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] Epoch[5] Batch[180] avg_epoch_loss=1.371501\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=180 train loss <loss>=1.22841880322\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] Epoch[5] Batch [180]#011Speed: 1777.50 samples/sec#011loss=1.228419\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] Epoch[5] Batch[185] avg_epoch_loss=1.370432\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=185 train loss <loss>=1.33175210953\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] Epoch[5] Batch [185]#011Speed: 14162.32 samples/sec#011loss=1.331752\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] Epoch[5] Batch[190] avg_epoch_loss=1.371705\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=190 train loss <loss>=1.41906611919\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] Epoch[5] Batch [190]#011Speed: 1484.27 samples/sec#011loss=1.419066\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] Epoch[5] Batch[195] avg_epoch_loss=1.372053\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=195 train loss <loss>=1.38534290791\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] Epoch[5] Batch [195]#011Speed: 13279.68 samples/sec#011loss=1.385343\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] Epoch[5] Batch[200] avg_epoch_loss=1.373079\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=200 train loss <loss>=1.41329491138\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] Epoch[5] Batch [200]#011Speed: 13240.12 samples/sec#011loss=1.413295\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] Epoch[5] Batch[205] avg_epoch_loss=1.374953\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=205 train loss <loss>=1.4503041029\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] Epoch[5] Batch [205]#011Speed: 1673.13 samples/sec#011loss=1.450304\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] Epoch[5] Batch[210] avg_epoch_loss=1.374192\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=210 train loss <loss>=1.34282038212\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:35 INFO 140088046479168] Epoch[5] Batch [210]#011Speed: 13259.87 samples/sec#011loss=1.342820\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] Epoch[5] Batch[215] avg_epoch_loss=1.373012\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=215 train loss <loss>=1.32320957184\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] Epoch[5] Batch [215]#011Speed: 1702.75 samples/sec#011loss=1.323210\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] Epoch[5] Batch[220] avg_epoch_loss=1.373074\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=220 train loss <loss>=1.37574291229\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] Epoch[5] Batch [220]#011Speed: 13261.05 samples/sec#011loss=1.375743\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] Epoch[5] Batch[225] avg_epoch_loss=1.373697\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=225 train loss <loss>=1.40127214193\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] Epoch[5] Batch [225]#011Speed: 13278.63 samples/sec#011loss=1.401272\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] Epoch[5] Batch[230] avg_epoch_loss=1.372433\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=230 train loss <loss>=1.31527305841\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] Epoch[5] Batch [230]#011Speed: 1798.98 samples/sec#011loss=1.315273\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] Epoch[5] Batch[235] avg_epoch_loss=1.374459\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=235 train loss <loss>=1.46806280613\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] Epoch[5] Batch [235]#011Speed: 14311.98 samples/sec#011loss=1.468063\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] Epoch[5] Batch[240] avg_epoch_loss=1.378423\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=240 train loss <loss>=1.56551442146\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] Epoch[5] Batch [240]#011Speed: 14134.28 samples/sec#011loss=1.565514\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] Epoch[5] Batch[245] avg_epoch_loss=1.378624\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=245 train loss <loss>=1.38832914829\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] Epoch[5] Batch [245]#011Speed: 1697.89 samples/sec#011loss=1.388329\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] Epoch[5] Batch[250] avg_epoch_loss=1.381537\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=250 train loss <loss>=1.52485402822\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] Epoch[5] Batch [250]#011Speed: 13225.25 samples/sec#011loss=1.524854\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] Epoch[5] Batch[255] avg_epoch_loss=1.382939\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=255 train loss <loss>=1.45331935883\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] Epoch[5] Batch [255]#011Speed: 1853.44 samples/sec#011loss=1.453319\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] Epoch[5] Batch[260] avg_epoch_loss=1.381186\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=260 train loss <loss>=1.29144601822\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] Epoch[5] Batch [260]#011Speed: 14174.44 samples/sec#011loss=1.291446\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] Epoch[5] Batch[265] avg_epoch_loss=1.382930\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=265 train loss <loss>=1.47394256592\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] Epoch[5] Batch [265]#011Speed: 14265.28 samples/sec#011loss=1.473943\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] Epoch[5] Batch[270] avg_epoch_loss=1.378888\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=270 train loss <loss>=1.1638374567\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:36 INFO 140088046479168] Epoch[5] Batch [270]#011Speed: 1782.68 samples/sec#011loss=1.163837\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] Epoch[5] Batch[275] avg_epoch_loss=1.378071\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=275 train loss <loss>=1.33382873535\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] Epoch[5] Batch [275]#011Speed: 14483.56 samples/sec#011loss=1.333829\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] Epoch[5] Batch[280] avg_epoch_loss=1.373898\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=280 train loss <loss>=1.14353756905\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] Epoch[5] Batch [280]#011Speed: 1604.55 samples/sec#011loss=1.143538\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] Epoch[5] Batch[285] avg_epoch_loss=1.373543\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=285 train loss <loss>=1.35361208916\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] Epoch[5] Batch [285]#011Speed: 13756.89 samples/sec#011loss=1.353612\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] Epoch[5] Batch[290] avg_epoch_loss=1.370472\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=290 train loss <loss>=1.19479869604\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] Epoch[5] Batch [290]#011Speed: 14254.52 samples/sec#011loss=1.194799\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] Epoch[5] Batch[295] avg_epoch_loss=1.371654\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=295 train loss <loss>=1.44044482708\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] Epoch[5] Batch [295]#011Speed: 1719.94 samples/sec#011loss=1.440445\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] Epoch[5] Batch[300] avg_epoch_loss=1.371207\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=300 train loss <loss>=1.34471145868\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] Epoch[5] Batch [300]#011Speed: 12976.55 samples/sec#011loss=1.344711\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] Epoch[5] Batch[305] avg_epoch_loss=1.370312\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=305 train loss <loss>=1.31643728018\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] Epoch[5] Batch [305]#011Speed: 1675.37 samples/sec#011loss=1.316437\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] Epoch[5] Batch[310] avg_epoch_loss=1.368766\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=310 train loss <loss>=1.27420003414\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] Epoch[5] Batch [310]#011Speed: 13470.94 samples/sec#011loss=1.274200\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] Epoch[5] Batch[315] avg_epoch_loss=1.367327\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=315 train loss <loss>=1.27778161764\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] Epoch[5] Batch [315]#011Speed: 13236.85 samples/sec#011loss=1.277782\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] Epoch[5] Batch[320] avg_epoch_loss=1.363835\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=320 train loss <loss>=1.1431776166\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] Epoch[5] Batch [320]#011Speed: 1824.17 samples/sec#011loss=1.143178\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] Epoch[5] Batch[325] avg_epoch_loss=1.360089\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=325 train loss <loss>=1.11955500841\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] Epoch[5] Batch [325]#011Speed: 14246.96 samples/sec#011loss=1.119555\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] Epoch[5] Batch[330] avg_epoch_loss=1.356257\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=330 train loss <loss>=1.10645209551\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:37 INFO 140088046479168] Epoch[5] Batch [330]#011Speed: 14184.92 samples/sec#011loss=1.106452\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] Epoch[5] Batch[335] avg_epoch_loss=1.355673\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=335 train loss <loss>=1.31697161198\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] Epoch[5] Batch [335]#011Speed: 1699.90 samples/sec#011loss=1.316972\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] Epoch[5] Batch[340] avg_epoch_loss=1.353084\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=340 train loss <loss>=1.17912617922\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] Epoch[5] Batch [340]#011Speed: 14002.45 samples/sec#011loss=1.179126\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] Epoch[5] Batch[345] avg_epoch_loss=1.354290\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=345 train loss <loss>=1.43654026985\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] Epoch[5] Batch [345]#011Speed: 1698.03 samples/sec#011loss=1.436540\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] Epoch[5] Batch[350] avg_epoch_loss=1.352704\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=350 train loss <loss>=1.2429181695\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] Epoch[5] Batch [350]#011Speed: 12739.33 samples/sec#011loss=1.242918\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] Epoch[5] Batch[355] avg_epoch_loss=1.351160\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=355 train loss <loss>=1.24275935888\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] Epoch[5] Batch [355]#011Speed: 14562.61 samples/sec#011loss=1.242759\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] Epoch[5] Batch[360] avg_epoch_loss=1.351052\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=360 train loss <loss>=1.34340043068\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] Epoch[5] Batch [360]#011Speed: 1565.04 samples/sec#011loss=1.343400\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] Epoch[5] Batch[365] avg_epoch_loss=1.349028\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=365 train loss <loss>=1.2029224515\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] Epoch[5] Batch [365]#011Speed: 14189.42 samples/sec#011loss=1.202922\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] Epoch[5] Batch[370] avg_epoch_loss=1.348911\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=370 train loss <loss>=1.34032469988\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] Epoch[5] Batch [370]#011Speed: 1739.38 samples/sec#011loss=1.340325\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] Epoch[5] Batch[375] avg_epoch_loss=1.344578\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=375 train loss <loss>=1.02305288315\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] Epoch[5] Batch [375]#011Speed: 14332.30 samples/sec#011loss=1.023053\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] Epoch[5] Batch[380] avg_epoch_loss=1.340594\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=380 train loss <loss>=1.04103868008\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:38 INFO 140088046479168] Epoch[5] Batch [380]#011Speed: 14245.60 samples/sec#011loss=1.041039\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] Epoch[5] Batch[385] avg_epoch_loss=1.338771\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=385 train loss <loss>=1.19980027676\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] Epoch[5] Batch [385]#011Speed: 1819.19 samples/sec#011loss=1.199800\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] Epoch[5] Batch[390] avg_epoch_loss=1.336397\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=390 train loss <loss>=1.15318208933\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] Epoch[5] Batch [390]#011Speed: 14290.19 samples/sec#011loss=1.153182\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] Epoch[5] Batch[395] avg_epoch_loss=1.332818\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=395 train loss <loss>=1.05289903879\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] Epoch[5] Batch [395]#011Speed: 1825.85 samples/sec#011loss=1.052899\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] Epoch[5] Batch[400] avg_epoch_loss=1.330200\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=400 train loss <loss>=1.1228561759\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] Epoch[5] Batch [400]#011Speed: 14267.86 samples/sec#011loss=1.122856\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] Epoch[5] Batch[405] avg_epoch_loss=1.325665\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=405 train loss <loss>=0.961963713169\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] Epoch[5] Batch [405]#011Speed: 13259.21 samples/sec#011loss=0.961964\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] Epoch[5] Batch[410] avg_epoch_loss=1.321958\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=410 train loss <loss>=1.02096799612\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] Epoch[5] Batch [410]#011Speed: 1775.29 samples/sec#011loss=1.020968\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] Epoch[5] Batch[415] avg_epoch_loss=1.317511\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=415 train loss <loss>=0.951960682869\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] Epoch[5] Batch [415]#011Speed: 13359.52 samples/sec#011loss=0.951961\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] Epoch[5] Batch[420] avg_epoch_loss=1.320839\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=420 train loss <loss>=1.59773852825\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] Epoch[5] Batch [420]#011Speed: 1789.89 samples/sec#011loss=1.597739\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] Epoch[5] Batch[425] avg_epoch_loss=1.317942\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=425 train loss <loss>=1.07402814627\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] Epoch[5] Batch [425]#011Speed: 13182.90 samples/sec#011loss=1.074028\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] Epoch[5] Batch[430] avg_epoch_loss=1.317404\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=430 train loss <loss>=1.2715593338\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] Epoch[5] Batch [430]#011Speed: 12833.98 samples/sec#011loss=1.271559\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] Epoch[5] Batch[435] avg_epoch_loss=1.326144\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=435 train loss <loss>=2.0794813633\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] Epoch[5] Batch [435]#011Speed: 1695.97 samples/sec#011loss=2.079481\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] Epoch[5] Batch[440] avg_epoch_loss=1.327605\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=440 train loss <loss>=1.45498919487\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:39 INFO 140088046479168] Epoch[5] Batch [440]#011Speed: 12920.96 samples/sec#011loss=1.454989\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] Epoch[5] Batch[445] avg_epoch_loss=1.332563\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=445 train loss <loss>=1.76993193626\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] Epoch[5] Batch [445]#011Speed: 1722.18 samples/sec#011loss=1.769932\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] Epoch[5] Batch[450] avg_epoch_loss=1.333521\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=450 train loss <loss>=1.41895265579\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] Epoch[5] Batch [450]#011Speed: 13307.20 samples/sec#011loss=1.418953\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] Epoch[5] Batch[455] avg_epoch_loss=1.330084\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=455 train loss <loss>=1.0200978756\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] Epoch[5] Batch [455]#011Speed: 14363.90 samples/sec#011loss=1.020098\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] Epoch[5] Batch[460] avg_epoch_loss=1.327542\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=460 train loss <loss>=1.09562474489\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] Epoch[5] Batch [460]#011Speed: 1770.01 samples/sec#011loss=1.095625\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] Epoch[5] Batch[465] avg_epoch_loss=1.326395\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=465 train loss <loss>=1.22064273357\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] Epoch[5] Batch [465]#011Speed: 14445.06 samples/sec#011loss=1.220643\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] Epoch[5] Batch[470] avg_epoch_loss=1.324380\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=470 train loss <loss>=1.13665286303\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] Epoch[5] Batch [470]#011Speed: 1725.94 samples/sec#011loss=1.136653\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] Epoch[5] Batch[475] avg_epoch_loss=1.321505\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=475 train loss <loss>=1.05060890913\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] Epoch[5] Batch [475]#011Speed: 12125.33 samples/sec#011loss=1.050609\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] Epoch[5] Batch[480] avg_epoch_loss=1.319431\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=480 train loss <loss>=1.12206755877\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] Epoch[5] Batch [480]#011Speed: 14726.22 samples/sec#011loss=1.122068\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] Epoch[5] Batch[485] avg_epoch_loss=1.315553\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=485 train loss <loss>=0.942407953739\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] Epoch[5] Batch [485]#011Speed: 1600.34 samples/sec#011loss=0.942408\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] Epoch[5] Batch[490] avg_epoch_loss=1.316392\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=490 train loss <loss>=1.39799796343\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] Epoch[5] Batch [490]#011Speed: 13390.71 samples/sec#011loss=1.397998\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] Epoch[5] Batch[495] avg_epoch_loss=1.316415\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=495 train loss <loss>=1.31868925095\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] Epoch[5] Batch [495]#011Speed: 14165.46 samples/sec#011loss=1.318689\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] Epoch[5] Batch[500] avg_epoch_loss=1.317390\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=500 train loss <loss>=1.41406531334\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:40 INFO 140088046479168] Epoch[5] Batch [500]#011Speed: 1735.59 samples/sec#011loss=1.414065\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] Epoch[5] Batch[505] avg_epoch_loss=1.321354\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=505 train loss <loss>=1.71858947277\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] Epoch[5] Batch [505]#011Speed: 14097.61 samples/sec#011loss=1.718589\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] Epoch[5] Batch[510] avg_epoch_loss=1.317776\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=510 train loss <loss>=0.955702018738\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] Epoch[5] Batch [510]#011Speed: 1800.82 samples/sec#011loss=0.955702\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] Epoch[5] Batch[515] avg_epoch_loss=1.320386\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=515 train loss <loss>=1.58710838556\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] Epoch[5] Batch [515]#011Speed: 13344.51 samples/sec#011loss=1.587108\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] Epoch[5] Batch[520] avg_epoch_loss=1.327445\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=520 train loss <loss>=2.05586359501\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] Epoch[5] Batch [520]#011Speed: 1779.40 samples/sec#011loss=2.055864\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] Epoch[5] Batch[525] avg_epoch_loss=1.334762\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=525 train loss <loss>=2.09721231461\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] Epoch[5] Batch [525]#011Speed: 13206.25 samples/sec#011loss=2.097212\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] Epoch[5] Batch[530] avg_epoch_loss=1.341214\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=530 train loss <loss>=2.02003781796\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] Epoch[5] Batch [530]#011Speed: 13270.75 samples/sec#011loss=2.020038\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] Epoch[5] Batch[535] avg_epoch_loss=1.344132\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=535 train loss <loss>=1.65399358273\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] Epoch[5] Batch [535]#011Speed: 1805.22 samples/sec#011loss=1.653994\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] Epoch[5] Batch[540] avg_epoch_loss=1.345497\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=540 train loss <loss>=1.49181127548\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] Epoch[5] Batch [540]#011Speed: 13206.77 samples/sec#011loss=1.491811\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] Epoch[5] Batch[545] avg_epoch_loss=1.348340\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=545 train loss <loss>=1.65598232746\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] Epoch[5] Batch [545]#011Speed: 1850.42 samples/sec#011loss=1.655982\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] Epoch[5] Batch[550] avg_epoch_loss=1.349886\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=550 train loss <loss>=1.51869390011\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] Epoch[5] Batch [550]#011Speed: 14238.79 samples/sec#011loss=1.518694\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] Epoch[5] Batch[555] avg_epoch_loss=1.349964\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=555 train loss <loss>=1.35855510235\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:41 INFO 140088046479168] Epoch[5] Batch [555]#011Speed: 14326.03 samples/sec#011loss=1.358555\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] Epoch[5] Batch[560] avg_epoch_loss=1.352537\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=560 train loss <loss>=1.6385945797\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] Epoch[5] Batch [560]#011Speed: 1686.26 samples/sec#011loss=1.638595\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] Epoch[5] Batch[565] avg_epoch_loss=1.350676\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=565 train loss <loss>=1.14186336994\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] Epoch[5] Batch [565]#011Speed: 14113.77 samples/sec#011loss=1.141863\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] Epoch[5] Batch[570] avg_epoch_loss=1.349829\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=570 train loss <loss>=1.25399981737\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] Epoch[5] Batch [570]#011Speed: 14224.76 samples/sec#011loss=1.254000\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] Epoch[5] Batch[575] avg_epoch_loss=1.351301\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=575 train loss <loss>=1.51934916973\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] Epoch[5] Batch [575]#011Speed: 1698.04 samples/sec#011loss=1.519349\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] Epoch[5] Batch[580] avg_epoch_loss=1.350456\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=580 train loss <loss>=1.25320961475\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] Epoch[5] Batch [580]#011Speed: 13244.56 samples/sec#011loss=1.253210\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] Epoch[5] Batch[585] avg_epoch_loss=1.349833\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=585 train loss <loss>=1.27735443115\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] Epoch[5] Batch [585]#011Speed: 1717.16 samples/sec#011loss=1.277354\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] Epoch[5] Batch[590] avg_epoch_loss=1.351085\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=590 train loss <loss>=1.497849226\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] Epoch[5] Batch [590]#011Speed: 14179.38 samples/sec#011loss=1.497849\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] Epoch[5] Batch[595] avg_epoch_loss=1.353022\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=595 train loss <loss>=1.58201398849\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] Epoch[5] Batch [595]#011Speed: 14291.56 samples/sec#011loss=1.582014\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] Epoch[5] Batch[600] avg_epoch_loss=1.352015\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=600 train loss <loss>=1.23194591999\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] Epoch[5] Batch [600]#011Speed: 1626.36 samples/sec#011loss=1.231946\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] Epoch[5] Batch[605] avg_epoch_loss=1.353195\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=605 train loss <loss>=1.49505355358\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] Epoch[5] Batch [605]#011Speed: 13136.32 samples/sec#011loss=1.495054\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] Epoch[5] Batch[610] avg_epoch_loss=1.353724\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=610 train loss <loss>=1.41785440445\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] Epoch[5] Batch [610]#011Speed: 1804.51 samples/sec#011loss=1.417854\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] Epoch[5] Batch[615] avg_epoch_loss=1.351913\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=615 train loss <loss>=1.13053920269\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] Epoch[5] Batch [615]#011Speed: 14392.40 samples/sec#011loss=1.130539\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] Epoch[5] Batch[620] avg_epoch_loss=1.351023\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=620 train loss <loss>=1.24136862755\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:42 INFO 140088046479168] Epoch[5] Batch [620]#011Speed: 14340.27 samples/sec#011loss=1.241369\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] Epoch[5] Batch[625] avg_epoch_loss=1.350561\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=625 train loss <loss>=1.2932664156\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] Epoch[5] Batch [625]#011Speed: 1789.72 samples/sec#011loss=1.293266\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] Epoch[5] Batch[630] avg_epoch_loss=1.351444\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=630 train loss <loss>=1.46190786362\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] Epoch[5] Batch [630]#011Speed: 14327.87 samples/sec#011loss=1.461908\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] Epoch[5] Batch[635] avg_epoch_loss=1.351979\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=635 train loss <loss>=1.4195971489\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] Epoch[5] Batch [635]#011Speed: 1517.49 samples/sec#011loss=1.419597\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] Epoch[5] Batch[640] avg_epoch_loss=1.349462\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=640 train loss <loss>=1.02930877209\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] Epoch[5] Batch [640]#011Speed: 14216.47 samples/sec#011loss=1.029309\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] Epoch[5] Batch[645] avg_epoch_loss=1.349429\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=645 train loss <loss>=1.34514353275\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] Epoch[5] Batch [645]#011Speed: 14132.35 samples/sec#011loss=1.345144\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] Epoch[5] Batch[650] avg_epoch_loss=1.348672\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=650 train loss <loss>=1.25082519054\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] Epoch[5] Batch [650]#011Speed: 1733.10 samples/sec#011loss=1.250825\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] Epoch[5] Batch[655] avg_epoch_loss=1.347413\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=655 train loss <loss>=1.18355672359\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] Epoch[5] Batch [655]#011Speed: 14368.51 samples/sec#011loss=1.183557\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] Epoch[5] Batch[660] avg_epoch_loss=1.346074\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=660 train loss <loss>=1.17032475471\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] Epoch[5] Batch [660]#011Speed: 13151.38 samples/sec#011loss=1.170325\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] Epoch[5] Batch[665] avg_epoch_loss=1.344410\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=665 train loss <loss>=1.12453644276\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] Epoch[5] Batch [665]#011Speed: 1792.82 samples/sec#011loss=1.124536\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] Epoch[5] Batch[670] avg_epoch_loss=1.343380\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=670 train loss <loss>=1.20616359711\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:43 INFO 140088046479168] Epoch[5] Batch [670]#011Speed: 13231.90 samples/sec#011loss=1.206164\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] Epoch[5] Batch[675] avg_epoch_loss=1.343620\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=675 train loss <loss>=1.37579199076\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] Epoch[5] Batch [675]#011Speed: 1677.51 samples/sec#011loss=1.375792\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] Epoch[5] Batch[680] avg_epoch_loss=1.343726\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=680 train loss <loss>=1.3580252409\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] Epoch[5] Batch [680]#011Speed: 14285.02 samples/sec#011loss=1.358025\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] Epoch[5] Batch[685] avg_epoch_loss=1.342565\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=685 train loss <loss>=1.18448306322\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] Epoch[5] Batch [685]#011Speed: 1818.85 samples/sec#011loss=1.184483\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] Epoch[5] Batch[690] avg_epoch_loss=1.343571\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=690 train loss <loss>=1.48163266182\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] Epoch[5] Batch [690]#011Speed: 13419.49 samples/sec#011loss=1.481633\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] Epoch[5] Batch[695] avg_epoch_loss=1.342705\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=695 train loss <loss>=1.22290632725\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] Epoch[5] Batch [695]#011Speed: 14658.03 samples/sec#011loss=1.222906\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] Epoch[5] Batch[700] avg_epoch_loss=1.341883\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=700 train loss <loss>=1.22751114368\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] Epoch[5] Batch [700]#011Speed: 1603.82 samples/sec#011loss=1.227511\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] Epoch[5] Batch[705] avg_epoch_loss=1.345357\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=705 train loss <loss>=1.83235657215\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] Epoch[5] Batch [705]#011Speed: 14442.42 samples/sec#011loss=1.832357\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] Epoch[5] Batch[710] avg_epoch_loss=1.345072\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=710 train loss <loss>=1.30495080948\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] Epoch[5] Batch [710]#011Speed: 13360.05 samples/sec#011loss=1.304951\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] Epoch[5] Batch[715] avg_epoch_loss=1.345048\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=715 train loss <loss>=1.3416172266\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] Epoch[5] Batch [715]#011Speed: 1677.25 samples/sec#011loss=1.341617\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] Epoch[5] Batch[720] avg_epoch_loss=1.343053\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=720 train loss <loss>=1.05728771687\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] Epoch[5] Batch [720]#011Speed: 14165.01 samples/sec#011loss=1.057288\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] Epoch[5] Batch[725] avg_epoch_loss=1.342620\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=725 train loss <loss>=1.28021073341\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] Epoch[5] Batch [725]#011Speed: 1731.77 samples/sec#011loss=1.280211\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] Epoch[5] Batch[730] avg_epoch_loss=1.341364\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=730 train loss <loss>=1.15902884007\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:44 INFO 140088046479168] Epoch[5] Batch [730]#011Speed: 13896.76 samples/sec#011loss=1.159029\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] Epoch[5] Batch[735] avg_epoch_loss=1.338192\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=735 train loss <loss>=0.874372780323\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] Epoch[5] Batch [735]#011Speed: 13330.46 samples/sec#011loss=0.874373\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] Epoch[5] Batch[740] avg_epoch_loss=1.338098\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=740 train loss <loss>=1.32425992489\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] Epoch[5] Batch [740]#011Speed: 1762.31 samples/sec#011loss=1.324260\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] Epoch[5] Batch[745] avg_epoch_loss=1.336782\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=745 train loss <loss>=1.14178085327\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] Epoch[5] Batch [745]#011Speed: 14080.75 samples/sec#011loss=1.141781\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] Epoch[5] Batch[750] avg_epoch_loss=1.337891\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=750 train loss <loss>=1.50330450535\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] Epoch[5] Batch [750]#011Speed: 1735.81 samples/sec#011loss=1.503305\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] Epoch[5] Batch[755] avg_epoch_loss=1.340212\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=755 train loss <loss>=1.68893754482\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] Epoch[5] Batch [755]#011Speed: 14364.52 samples/sec#011loss=1.688938\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] Epoch[5] Batch[760] avg_epoch_loss=1.343518\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=760 train loss <loss>=1.84339430332\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] Epoch[5] Batch [760]#011Speed: 13774.11 samples/sec#011loss=1.843394\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] Epoch[5] Batch[765] avg_epoch_loss=1.345301\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=765 train loss <loss>=1.61660966873\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] Epoch[5] Batch [765]#011Speed: 1646.78 samples/sec#011loss=1.616610\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] Epoch[5] Batch[770] avg_epoch_loss=1.343633\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=770 train loss <loss>=1.08817156553\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] Epoch[5] Batch [770]#011Speed: 13211.71 samples/sec#011loss=1.088172\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] Epoch[5] Batch[775] avg_epoch_loss=1.343069\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=775 train loss <loss>=1.2560721755\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] Epoch[5] Batch [775]#011Speed: 1811.75 samples/sec#011loss=1.256072\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] Epoch[5] Batch[780] avg_epoch_loss=1.341892\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=780 train loss <loss>=1.15911113024\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] Epoch[5] Batch [780]#011Speed: 14215.27 samples/sec#011loss=1.159111\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] Epoch[5] Batch[785] avg_epoch_loss=1.341367\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=785 train loss <loss>=1.25949778557\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:45 INFO 140088046479168] Epoch[5] Batch [785]#011Speed: 13433.46 samples/sec#011loss=1.259498\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] Epoch[5] Batch[790] avg_epoch_loss=1.341417\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=790 train loss <loss>=1.3491412878\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] Epoch[5] Batch [790]#011Speed: 1732.87 samples/sec#011loss=1.349141\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] Epoch[5] Batch[795] avg_epoch_loss=1.340151\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=795 train loss <loss>=1.13993647099\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] Epoch[5] Batch [795]#011Speed: 14213.31 samples/sec#011loss=1.139936\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] Epoch[5] Batch[800] avg_epoch_loss=1.341461\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=800 train loss <loss>=1.54995756149\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] Epoch[5] Batch [800]#011Speed: 1736.05 samples/sec#011loss=1.549958\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] Epoch[5] Batch[805] avg_epoch_loss=1.340779\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=805 train loss <loss>=1.23166694641\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] Epoch[5] Batch [805]#011Speed: 14240.00 samples/sec#011loss=1.231667\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] Epoch[5] Batch[810] avg_epoch_loss=1.340544\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=810 train loss <loss>=1.30252821445\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] Epoch[5] Batch [810]#011Speed: 14234.87 samples/sec#011loss=1.302528\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] Epoch[5] Batch[815] avg_epoch_loss=1.340106\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=815 train loss <loss>=1.26903501749\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] Epoch[5] Batch [815]#011Speed: 1714.58 samples/sec#011loss=1.269035\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] Epoch[5] Batch[820] avg_epoch_loss=1.338964\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=820 train loss <loss>=1.15265595913\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] Epoch[5] Batch [820]#011Speed: 14372.98 samples/sec#011loss=1.152656\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] Epoch[5] Batch[825] avg_epoch_loss=1.338575\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=825 train loss <loss>=1.27466188669\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] Epoch[5] Batch [825]#011Speed: 1668.99 samples/sec#011loss=1.274662\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] Epoch[5] Batch[830] avg_epoch_loss=1.337255\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=830 train loss <loss>=1.11921377182\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] Epoch[5] Batch [830]#011Speed: 14520.39 samples/sec#011loss=1.119214\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] Epoch[5] Batch[835] avg_epoch_loss=1.336917\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=835 train loss <loss>=1.28077682257\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] Epoch[5] Batch [835]#011Speed: 14675.50 samples/sec#011loss=1.280777\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] Epoch[5] Batch[840] avg_epoch_loss=1.338264\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=840 train loss <loss>=1.56339895725\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] Epoch[5] Batch [840]#011Speed: 1598.11 samples/sec#011loss=1.563399\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] Epoch[5] Batch[845] avg_epoch_loss=1.337845\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=845 train loss <loss>=1.2675296545\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:46 INFO 140088046479168] Epoch[5] Batch [845]#011Speed: 14227.17 samples/sec#011loss=1.267530\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] Epoch[5] Batch[850] avg_epoch_loss=1.336719\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=850 train loss <loss>=1.14612021446\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] Epoch[5] Batch [850]#011Speed: 14260.13 samples/sec#011loss=1.146120\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] Epoch[5] Batch[855] avg_epoch_loss=1.336274\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=855 train loss <loss>=1.26047723293\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] Epoch[5] Batch [855]#011Speed: 1690.37 samples/sec#011loss=1.260477\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] Epoch[5] Batch[860] avg_epoch_loss=1.336075\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=860 train loss <loss>=1.30197716951\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] Epoch[5] Batch [860]#011Speed: 14257.70 samples/sec#011loss=1.301977\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] Epoch[5] Batch[865] avg_epoch_loss=1.337764\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=865 train loss <loss>=1.6286629796\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] Epoch[5] Batch [865]#011Speed: 1695.31 samples/sec#011loss=1.628663\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] Epoch[5] Batch[870] avg_epoch_loss=1.338609\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=870 train loss <loss>=1.48499295712\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] Epoch[5] Batch [870]#011Speed: 14288.21 samples/sec#011loss=1.484993\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] Epoch[5] Batch[875] avg_epoch_loss=1.339158\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=875 train loss <loss>=1.43487963676\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] Epoch[5] Batch [875]#011Speed: 14471.85 samples/sec#011loss=1.434880\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] Epoch[5] Batch[880] avg_epoch_loss=1.339597\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=880 train loss <loss>=1.41642178297\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] Epoch[5] Batch [880]#011Speed: 1758.67 samples/sec#011loss=1.416422\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] Epoch[5] Batch[885] avg_epoch_loss=1.340455\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=885 train loss <loss>=1.49161975384\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] Epoch[5] Batch [885]#011Speed: 14172.49 samples/sec#011loss=1.491620\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] Epoch[5] Batch[890] avg_epoch_loss=1.339401\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=890 train loss <loss>=1.15270409584\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] Epoch[5] Batch [890]#011Speed: 1659.97 samples/sec#011loss=1.152704\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] Epoch[5] Batch[895] avg_epoch_loss=1.338381\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=895 train loss <loss>=1.15655187368\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] Epoch[5] Batch [895]#011Speed: 14410.63 samples/sec#011loss=1.156552\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] Epoch[5] Batch[900] avg_epoch_loss=1.336341\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, batch=900 train loss <loss>=0.970810127258\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] Epoch[5] Batch [900]#011Speed: 14254.52 samples/sec#011loss=0.970810\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] processed a total of 57725 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15742.857933044434, \"sum\": 15742.857933044434, \"min\": 15742.857933044434}}, \"EndTime\": 1604320487.906769, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320472.163852}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] #throughput_metric: host=algo-1, train throughput=3666.71439286 records/second\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=5, train loss <loss>=1.33668585984\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:47 INFO 140088046479168] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] Epoch[6] Batch[0] avg_epoch_loss=1.159537\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=1.15953719616\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] Epoch[6] Batch[5] avg_epoch_loss=1.161037\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=1.1610366106\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] Epoch[6] Batch [5]#011Speed: 14359.44 samples/sec#011loss=1.161037\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] Epoch[6] Batch[10] avg_epoch_loss=1.227770\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=1.30785050392\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] Epoch[6] Batch [10]#011Speed: 14094.36 samples/sec#011loss=1.307851\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] Epoch[6] Batch[15] avg_epoch_loss=1.152388\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=15 train loss <loss>=0.986548256874\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] Epoch[6] Batch [15]#011Speed: 1755.70 samples/sec#011loss=0.986548\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] Epoch[6] Batch[20] avg_epoch_loss=1.154850\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=20 train loss <loss>=1.16272685528\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] Epoch[6] Batch [20]#011Speed: 14279.85 samples/sec#011loss=1.162727\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] Epoch[6] Batch[25] avg_epoch_loss=1.165625\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=25 train loss <loss>=1.21087787151\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] Epoch[6] Batch [25]#011Speed: 1667.52 samples/sec#011loss=1.210878\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] Epoch[6] Batch[30] avg_epoch_loss=1.133544\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=30 train loss <loss>=0.966727101803\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] Epoch[6] Batch [30]#011Speed: 13418.95 samples/sec#011loss=0.966727\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] Epoch[6] Batch[35] avg_epoch_loss=1.158076\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=35 train loss <loss>=1.31017274857\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] Epoch[6] Batch [35]#011Speed: 12857.09 samples/sec#011loss=1.310173\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] Epoch[6] Batch[40] avg_epoch_loss=1.185633\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=40 train loss <loss>=1.38404695988\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] Epoch[6] Batch [40]#011Speed: 1645.32 samples/sec#011loss=1.384047\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] Epoch[6] Batch[45] avg_epoch_loss=1.200402\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=45 train loss <loss>=1.3215051651\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] Epoch[6] Batch [45]#011Speed: 14558.66 samples/sec#011loss=1.321505\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] Epoch[6] Batch[50] avg_epoch_loss=1.216926\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=50 train loss <loss>=1.36894207001\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] Epoch[6] Batch [50]#011Speed: 1837.57 samples/sec#011loss=1.368942\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] Epoch[6] Batch[55] avg_epoch_loss=1.207697\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=55 train loss <loss>=1.11356395483\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:48 INFO 140088046479168] Epoch[6] Batch [55]#011Speed: 14064.08 samples/sec#011loss=1.113564\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] Epoch[6] Batch[60] avg_epoch_loss=1.193249\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=60 train loss <loss>=1.03143446445\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] Epoch[6] Batch [60]#011Speed: 13695.13 samples/sec#011loss=1.031434\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] Epoch[6] Batch[65] avg_epoch_loss=1.183968\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=65 train loss <loss>=1.07073801756\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] Epoch[6] Batch [65]#011Speed: 1701.58 samples/sec#011loss=1.070738\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] Epoch[6] Batch[70] avg_epoch_loss=1.185169\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=70 train loss <loss>=1.20102844238\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] Epoch[6] Batch [70]#011Speed: 14187.02 samples/sec#011loss=1.201028\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] Epoch[6] Batch[75] avg_epoch_loss=1.187876\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=75 train loss <loss>=1.22631573677\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] Epoch[6] Batch [75]#011Speed: 1713.56 samples/sec#011loss=1.226316\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] Epoch[6] Batch[80] avg_epoch_loss=1.190996\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=80 train loss <loss>=1.23840575218\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] Epoch[6] Batch [80]#011Speed: 13286.78 samples/sec#011loss=1.238406\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] Epoch[6] Batch[85] avg_epoch_loss=1.193113\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=85 train loss <loss>=1.22742048502\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] Epoch[6] Batch [85]#011Speed: 13360.05 samples/sec#011loss=1.227420\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] Epoch[6] Batch[90] avg_epoch_loss=1.201171\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=90 train loss <loss>=1.33976011276\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] Epoch[6] Batch [90]#011Speed: 1797.58 samples/sec#011loss=1.339760\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] Epoch[6] Batch[95] avg_epoch_loss=1.194309\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=95 train loss <loss>=1.06941874027\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] Epoch[6] Batch [95]#011Speed: 13160.02 samples/sec#011loss=1.069419\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] Epoch[6] Batch[100] avg_epoch_loss=1.196020\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=100 train loss <loss>=1.22888624668\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] Epoch[6] Batch [100]#011Speed: 1434.75 samples/sec#011loss=1.228886\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] Epoch[6] Batch[105] avg_epoch_loss=1.207735\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=105 train loss <loss>=1.44435937405\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] Epoch[6] Batch [105]#011Speed: 14285.78 samples/sec#011loss=1.444359\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] Epoch[6] Batch[110] avg_epoch_loss=1.202458\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=110 train loss <loss>=1.09059522152\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:49 INFO 140088046479168] Epoch[6] Batch [110]#011Speed: 13415.47 samples/sec#011loss=1.090595\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] Epoch[6] Batch[115] avg_epoch_loss=1.219449\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=115 train loss <loss>=1.5966558218\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] Epoch[6] Batch [115]#011Speed: 1797.12 samples/sec#011loss=1.596656\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] Epoch[6] Batch[120] avg_epoch_loss=1.219745\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=120 train loss <loss>=1.22661468983\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] Epoch[6] Batch [120]#011Speed: 14113.62 samples/sec#011loss=1.226615\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] Epoch[6] Batch[125] avg_epoch_loss=1.215625\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=125 train loss <loss>=1.1159119606\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] Epoch[6] Batch [125]#011Speed: 13449.34 samples/sec#011loss=1.115912\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] Epoch[6] Batch[130] avg_epoch_loss=1.214915\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=130 train loss <loss>=1.19701360464\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] Epoch[6] Batch [130]#011Speed: 1618.41 samples/sec#011loss=1.197014\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] Epoch[6] Batch[135] avg_epoch_loss=1.219391\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=135 train loss <loss>=1.3366642952\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] Epoch[6] Batch [135]#011Speed: 14205.19 samples/sec#011loss=1.336664\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] Epoch[6] Batch[140] avg_epoch_loss=1.217631\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=140 train loss <loss>=1.16975761652\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] Epoch[6] Batch [140]#011Speed: 1882.60 samples/sec#011loss=1.169758\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] Epoch[6] Batch[145] avg_epoch_loss=1.215080\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=145 train loss <loss>=1.14315110445\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] Epoch[6] Batch [145]#011Speed: 14516.46 samples/sec#011loss=1.143151\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] Epoch[6] Batch[150] avg_epoch_loss=1.213917\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=150 train loss <loss>=1.17996172905\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] Epoch[6] Batch [150]#011Speed: 13389.24 samples/sec#011loss=1.179962\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] Epoch[6] Batch[155] avg_epoch_loss=1.217194\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=155 train loss <loss>=1.31616767645\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] Epoch[6] Batch [155]#011Speed: 1721.89 samples/sec#011loss=1.316168\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] Epoch[6] Batch[160] avg_epoch_loss=1.213757\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=160 train loss <loss>=1.10650122166\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] Epoch[6] Batch [160]#011Speed: 14265.28 samples/sec#011loss=1.106501\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] Epoch[6] Batch[165] avg_epoch_loss=1.213350\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=165 train loss <loss>=1.2002579689\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:50 INFO 140088046479168] Epoch[6] Batch [165]#011Speed: 1605.48 samples/sec#011loss=1.200258\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] Epoch[6] Batch[170] avg_epoch_loss=1.216348\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=170 train loss <loss>=1.31586465836\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] Epoch[6] Batch [170]#011Speed: 13277.45 samples/sec#011loss=1.315865\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] Epoch[6] Batch[175] avg_epoch_loss=1.222628\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=175 train loss <loss>=1.43741748333\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] Epoch[6] Batch [175]#011Speed: 12881.52 samples/sec#011loss=1.437417\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] Epoch[6] Batch[180] avg_epoch_loss=1.223616\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=180 train loss <loss>=1.25839608908\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] Epoch[6] Batch [180]#011Speed: 1677.19 samples/sec#011loss=1.258396\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] Epoch[6] Batch[185] avg_epoch_loss=1.231311\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=185 train loss <loss>=1.50987974405\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] Epoch[6] Batch [185]#011Speed: 14333.68 samples/sec#011loss=1.509880\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] Epoch[6] Batch[190] avg_epoch_loss=1.239317\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=190 train loss <loss>=1.5371378541\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] Epoch[6] Batch [190]#011Speed: 1755.03 samples/sec#011loss=1.537138\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] Epoch[6] Batch[195] avg_epoch_loss=1.258500\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=195 train loss <loss>=1.99127779007\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] Epoch[6] Batch [195]#011Speed: 14203.84 samples/sec#011loss=1.991278\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] Epoch[6] Batch[200] avg_epoch_loss=1.273536\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=200 train loss <loss>=1.86295650005\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] Epoch[6] Batch [200]#011Speed: 14212.86 samples/sec#011loss=1.862957\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] Epoch[6] Batch[205] avg_epoch_loss=1.280839\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=205 train loss <loss>=1.57440254688\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] Epoch[6] Batch [205]#011Speed: 1822.88 samples/sec#011loss=1.574403\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] Epoch[6] Batch[210] avg_epoch_loss=1.292303\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=210 train loss <loss>=1.76461670399\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] Epoch[6] Batch [210]#011Speed: 14257.70 samples/sec#011loss=1.764617\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] Epoch[6] Batch[215] avg_epoch_loss=1.294573\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=215 train loss <loss>=1.39035818577\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] Epoch[6] Batch [215]#011Speed: 1765.61 samples/sec#011loss=1.390358\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] Epoch[6] Batch[220] avg_epoch_loss=1.292246\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=220 train loss <loss>=1.19171916246\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] Epoch[6] Batch [220]#011Speed: 14418.84 samples/sec#011loss=1.191719\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] Epoch[6] Batch[225] avg_epoch_loss=1.290840\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=225 train loss <loss>=1.22870166302\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:51 INFO 140088046479168] Epoch[6] Batch [225]#011Speed: 13352.21 samples/sec#011loss=1.228702\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] Epoch[6] Batch[230] avg_epoch_loss=1.291359\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=230 train loss <loss>=1.31481974125\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] Epoch[6] Batch [230]#011Speed: 1630.22 samples/sec#011loss=1.314820\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] Epoch[6] Batch[235] avg_epoch_loss=1.291078\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=235 train loss <loss>=1.27812893391\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] Epoch[6] Batch [235]#011Speed: 14078.39 samples/sec#011loss=1.278129\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] Epoch[6] Batch[240] avg_epoch_loss=1.288115\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=240 train loss <loss>=1.14821931124\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] Epoch[6] Batch [240]#011Speed: 1682.05 samples/sec#011loss=1.148219\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] Epoch[6] Batch[245] avg_epoch_loss=1.284690\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=245 train loss <loss>=1.11960301399\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] Epoch[6] Batch [245]#011Speed: 13342.78 samples/sec#011loss=1.119603\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] Epoch[6] Batch[250] avg_epoch_loss=1.280392\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=250 train loss <loss>=1.06897084713\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] Epoch[6] Batch [250]#011Speed: 13261.97 samples/sec#011loss=1.068971\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] Epoch[6] Batch[255] avg_epoch_loss=1.277986\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=255 train loss <loss>=1.15716328621\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] Epoch[6] Batch [255]#011Speed: 1874.33 samples/sec#011loss=1.157163\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] Epoch[6] Batch[260] avg_epoch_loss=1.278830\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=260 train loss <loss>=1.3220772028\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] Epoch[6] Batch [260]#011Speed: 14367.90 samples/sec#011loss=1.322077\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] Epoch[6] Batch[265] avg_epoch_loss=1.272791\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=265 train loss <loss>=0.957547819614\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] Epoch[6] Batch [265]#011Speed: 1753.99 samples/sec#011loss=0.957548\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] Epoch[6] Batch[270] avg_epoch_loss=1.269992\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=270 train loss <loss>=1.12107684612\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] Epoch[6] Batch [270]#011Speed: 13662.37 samples/sec#011loss=1.121077\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] Epoch[6] Batch[275] avg_epoch_loss=1.265047\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=275 train loss <loss>=0.997036802769\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] Epoch[6] Batch [275]#011Speed: 13281.39 samples/sec#011loss=0.997037\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] Epoch[6] Batch[280] avg_epoch_loss=1.262280\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=280 train loss <loss>=1.10954854488\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] Epoch[6] Batch [280]#011Speed: 1731.86 samples/sec#011loss=1.109549\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] Epoch[6] Batch[285] avg_epoch_loss=1.260369\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=285 train loss <loss>=1.15298262835\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:52 INFO 140088046479168] Epoch[6] Batch [285]#011Speed: 13772.98 samples/sec#011loss=1.152983\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] Epoch[6] Batch[290] avg_epoch_loss=1.256633\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=290 train loss <loss>=1.04292535782\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] Epoch[6] Batch [290]#011Speed: 1761.28 samples/sec#011loss=1.042925\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] Epoch[6] Batch[295] avg_epoch_loss=1.257710\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=295 train loss <loss>=1.32037528753\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] Epoch[6] Batch [295]#011Speed: 14182.52 samples/sec#011loss=1.320375\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] Epoch[6] Batch[300] avg_epoch_loss=1.255656\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=300 train loss <loss>=1.13403594494\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] Epoch[6] Batch [300]#011Speed: 13252.15 samples/sec#011loss=1.134036\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] Epoch[6] Batch[305] avg_epoch_loss=1.251396\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=305 train loss <loss>=0.99496897459\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] Epoch[6] Batch [305]#011Speed: 1734.21 samples/sec#011loss=0.994969\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] Epoch[6] Batch[310] avg_epoch_loss=1.248852\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=310 train loss <loss>=1.09317606688\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] Epoch[6] Batch [310]#011Speed: 9895.73 samples/sec#011loss=1.093176\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] Epoch[6] Batch[315] avg_epoch_loss=1.246969\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=315 train loss <loss>=1.12985204458\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] Epoch[6] Batch [315]#011Speed: 14325.42 samples/sec#011loss=1.129852\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] Epoch[6] Batch[320] avg_epoch_loss=1.244689\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=320 train loss <loss>=1.1005833745\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] Epoch[6] Batch [320]#011Speed: 1610.37 samples/sec#011loss=1.100583\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] Epoch[6] Batch[325] avg_epoch_loss=1.245525\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=325 train loss <loss>=1.29920585155\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] Epoch[6] Batch [325]#011Speed: 14347.78 samples/sec#011loss=1.299206\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] Epoch[6] Batch[330] avg_epoch_loss=1.246050\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=330 train loss <loss>=1.28023622036\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] Epoch[6] Batch [330]#011Speed: 1719.87 samples/sec#011loss=1.280236\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] Epoch[6] Batch[335] avg_epoch_loss=1.251675\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=335 train loss <loss>=1.62406582832\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] Epoch[6] Batch [335]#011Speed: 14337.51 samples/sec#011loss=1.624066\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] Epoch[6] Batch[340] avg_epoch_loss=1.254840\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=340 train loss <loss>=1.46754598618\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:53 INFO 140088046479168] Epoch[6] Batch [340]#011Speed: 14452.84 samples/sec#011loss=1.467546\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] Epoch[6] Batch[345] avg_epoch_loss=1.252676\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=345 train loss <loss>=1.10509345531\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] Epoch[6] Batch [345]#011Speed: 1704.90 samples/sec#011loss=1.105093\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] Epoch[6] Batch[350] avg_epoch_loss=1.252492\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=350 train loss <loss>=1.23972963095\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] Epoch[6] Batch [350]#011Speed: 14016.79 samples/sec#011loss=1.239730\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] Epoch[6] Batch[355] avg_epoch_loss=1.250730\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=355 train loss <loss>=1.12708480358\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] Epoch[6] Batch [355]#011Speed: 1616.57 samples/sec#011loss=1.127085\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] Epoch[6] Batch[360] avg_epoch_loss=1.248556\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=360 train loss <loss>=1.09373204708\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] Epoch[6] Batch [360]#011Speed: 14306.79 samples/sec#011loss=1.093732\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] Epoch[6] Batch[365] avg_epoch_loss=1.252546\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=365 train loss <loss>=1.54063150883\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] Epoch[6] Batch [365]#011Speed: 14398.88 samples/sec#011loss=1.540632\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] Epoch[6] Batch[370] avg_epoch_loss=1.257626\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=370 train loss <loss>=1.62946689129\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] Epoch[6] Batch [370]#011Speed: 1693.63 samples/sec#011loss=1.629467\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] Epoch[6] Batch[375] avg_epoch_loss=1.263690\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=375 train loss <loss>=1.71368570328\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] Epoch[6] Batch [375]#011Speed: 13621.60 samples/sec#011loss=1.713686\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] Epoch[6] Batch[380] avg_epoch_loss=1.267031\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=380 train loss <loss>=1.51821830273\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] Epoch[6] Batch [380]#011Speed: 1639.83 samples/sec#011loss=1.518218\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] Epoch[6] Batch[385] avg_epoch_loss=1.267053\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=385 train loss <loss>=1.26871688366\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] Epoch[6] Batch [385]#011Speed: 13599.66 samples/sec#011loss=1.268717\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] Epoch[6] Batch[390] avg_epoch_loss=1.268257\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=390 train loss <loss>=1.36123919487\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:54 INFO 140088046479168] Epoch[6] Batch [390]#011Speed: 13318.29 samples/sec#011loss=1.361239\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] Epoch[6] Batch[395] avg_epoch_loss=1.269958\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=395 train loss <loss>=1.40298936367\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] Epoch[6] Batch [395]#011Speed: 1667.97 samples/sec#011loss=1.402989\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] Epoch[6] Batch[400] avg_epoch_loss=1.273585\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=400 train loss <loss>=1.56083173752\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] Epoch[6] Batch [400]#011Speed: 13232.94 samples/sec#011loss=1.560832\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] Epoch[6] Batch[405] avg_epoch_loss=1.278151\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=405 train loss <loss>=1.64432003498\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] Epoch[6] Batch [405]#011Speed: 1876.63 samples/sec#011loss=1.644320\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] Epoch[6] Batch[410] avg_epoch_loss=1.284423\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=410 train loss <loss>=1.79376399517\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] Epoch[6] Batch [410]#011Speed: 14324.81 samples/sec#011loss=1.793764\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] Epoch[6] Batch[415] avg_epoch_loss=1.289558\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=415 train loss <loss>=1.71159477234\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] Epoch[6] Batch [415]#011Speed: 1865.94 samples/sec#011loss=1.711595\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] Epoch[6] Batch[420] avg_epoch_loss=1.293647\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=420 train loss <loss>=1.63385767937\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] Epoch[6] Batch [420]#011Speed: 14180.58 samples/sec#011loss=1.633858\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] Epoch[6] Batch[425] avg_epoch_loss=1.295334\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=425 train loss <loss>=1.43743362427\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] Epoch[6] Batch [425]#011Speed: 14305.57 samples/sec#011loss=1.437434\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] Epoch[6] Batch[430] avg_epoch_loss=1.294725\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=430 train loss <loss>=1.24282164574\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] Epoch[6] Batch [430]#011Speed: 1717.78 samples/sec#011loss=1.242822\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] Epoch[6] Batch[435] avg_epoch_loss=1.293502\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=435 train loss <loss>=1.18805401325\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] Epoch[6] Batch [435]#011Speed: 14231.70 samples/sec#011loss=1.188054\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] Epoch[6] Batch[440] avg_epoch_loss=1.293771\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=440 train loss <loss>=1.31726485491\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] Epoch[6] Batch [440]#011Speed: 1704.39 samples/sec#011loss=1.317265\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] Epoch[6] Batch[445] avg_epoch_loss=1.292965\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=445 train loss <loss>=1.2218921423\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] Epoch[6] Batch [445]#011Speed: 14313.20 samples/sec#011loss=1.221892\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] Epoch[6] Batch[450] avg_epoch_loss=1.292132\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=450 train loss <loss>=1.21781914234\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:55 INFO 140088046479168] Epoch[6] Batch [450]#011Speed: 14226.12 samples/sec#011loss=1.217819\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] Epoch[6] Batch[455] avg_epoch_loss=1.290811\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=455 train loss <loss>=1.17163989544\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] Epoch[6] Batch [455]#011Speed: 1633.38 samples/sec#011loss=1.171640\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] Epoch[6] Batch[460] avg_epoch_loss=1.289129\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=460 train loss <loss>=1.13568456173\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] Epoch[6] Batch [460]#011Speed: 13230.72 samples/sec#011loss=1.135685\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] Epoch[6] Batch[465] avg_epoch_loss=1.286813\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=465 train loss <loss>=1.07330756187\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] Epoch[6] Batch [465]#011Speed: 1659.87 samples/sec#011loss=1.073308\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] Epoch[6] Batch[470] avg_epoch_loss=1.284442\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=470 train loss <loss>=1.06346725225\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] Epoch[6] Batch [470]#011Speed: 14206.54 samples/sec#011loss=1.063467\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] Epoch[6] Batch[475] avg_epoch_loss=1.283955\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=475 train loss <loss>=1.23810038567\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] Epoch[6] Batch [475]#011Speed: 14281.22 samples/sec#011loss=1.238100\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] Epoch[6] Batch[480] avg_epoch_loss=1.282545\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=480 train loss <loss>=1.14824485779\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] Epoch[6] Batch [480]#011Speed: 1697.80 samples/sec#011loss=1.148245\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] Epoch[6] Batch[485] avg_epoch_loss=1.282831\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=485 train loss <loss>=1.31042878628\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] Epoch[6] Batch [485]#011Speed: 13853.45 samples/sec#011loss=1.310429\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] Epoch[6] Batch[490] avg_epoch_loss=1.280777\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=490 train loss <loss>=1.08107893467\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] Epoch[6] Batch [490]#011Speed: 12705.92 samples/sec#011loss=1.081079\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] Epoch[6] Batch[495] avg_epoch_loss=1.279835\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=495 train loss <loss>=1.18736371994\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] Epoch[6] Batch [495]#011Speed: 1607.85 samples/sec#011loss=1.187364\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] Epoch[6] Batch[500] avg_epoch_loss=1.278888\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=500 train loss <loss>=1.18487913609\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:56 INFO 140088046479168] Epoch[6] Batch [500]#011Speed: 12863.25 samples/sec#011loss=1.184879\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] Epoch[6] Batch[505] avg_epoch_loss=1.275909\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=505 train loss <loss>=0.977411079407\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] Epoch[6] Batch [505]#011Speed: 1425.36 samples/sec#011loss=0.977411\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] Epoch[6] Batch[510] avg_epoch_loss=1.276206\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=510 train loss <loss>=1.30630567074\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] Epoch[6] Batch [510]#011Speed: 14181.17 samples/sec#011loss=1.306306\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] Epoch[6] Batch[515] avg_epoch_loss=1.274847\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=515 train loss <loss>=1.13600296974\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] Epoch[6] Batch [515]#011Speed: 14367.28 samples/sec#011loss=1.136003\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] Epoch[6] Batch[520] avg_epoch_loss=1.274243\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=520 train loss <loss>=1.21184450388\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] Epoch[6] Batch [520]#011Speed: 1748.78 samples/sec#011loss=1.211845\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] Epoch[6] Batch[525] avg_epoch_loss=1.272955\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=525 train loss <loss>=1.13877221346\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] Epoch[6] Batch [525]#011Speed: 14518.34 samples/sec#011loss=1.138772\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] Epoch[6] Batch[530] avg_epoch_loss=1.272179\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=530 train loss <loss>=1.19051426649\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] Epoch[6] Batch [530]#011Speed: 1828.70 samples/sec#011loss=1.190514\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] Epoch[6] Batch[535] avg_epoch_loss=1.270885\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=535 train loss <loss>=1.13343914747\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] Epoch[6] Batch [535]#011Speed: 13246.13 samples/sec#011loss=1.133439\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] Epoch[6] Batch[540] avg_epoch_loss=1.270011\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=540 train loss <loss>=1.17638068199\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] Epoch[6] Batch [540]#011Speed: 13254.37 samples/sec#011loss=1.176381\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] Epoch[6] Batch[545] avg_epoch_loss=1.267509\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=545 train loss <loss>=0.996757030487\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] Epoch[6] Batch [545]#011Speed: 1745.49 samples/sec#011loss=0.996757\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] Epoch[6] Batch[550] avg_epoch_loss=1.265444\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=550 train loss <loss>=1.03997058868\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] Epoch[6] Batch [550]#011Speed: 13925.75 samples/sec#011loss=1.039971\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] Epoch[6] Batch[555] avg_epoch_loss=1.262297\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=555 train loss <loss>=0.915451478958\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] Epoch[6] Batch [555]#011Speed: 1698.05 samples/sec#011loss=0.915451\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] Epoch[6] Batch[560] avg_epoch_loss=1.259237\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=560 train loss <loss>=0.918967068195\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] Epoch[6] Batch [560]#011Speed: 14243.03 samples/sec#011loss=0.918967\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] Epoch[6] Batch[565] avg_epoch_loss=1.258219\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=565 train loss <loss>=1.14408628941\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:57 INFO 140088046479168] Epoch[6] Batch [565]#011Speed: 13677.54 samples/sec#011loss=1.144086\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] Epoch[6] Batch[570] avg_epoch_loss=1.255514\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=570 train loss <loss>=0.949254488945\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] Epoch[6] Batch [570]#011Speed: 1808.25 samples/sec#011loss=0.949254\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] Epoch[6] Batch[575] avg_epoch_loss=1.253812\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=575 train loss <loss>=1.0594623208\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] Epoch[6] Batch [575]#011Speed: 13264.72 samples/sec#011loss=1.059462\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] Epoch[6] Batch[580] avg_epoch_loss=1.252126\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=580 train loss <loss>=1.05791442394\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] Epoch[6] Batch [580]#011Speed: 1764.05 samples/sec#011loss=1.057914\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] Epoch[6] Batch[585] avg_epoch_loss=1.250160\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=585 train loss <loss>=1.02169128656\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] Epoch[6] Batch [585]#011Speed: 12787.76 samples/sec#011loss=1.021691\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] Epoch[6] Batch[590] avg_epoch_loss=1.247594\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=590 train loss <loss>=0.94688013792\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] Epoch[6] Batch [590]#011Speed: 12774.49 samples/sec#011loss=0.946880\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] Epoch[6] Batch[595] avg_epoch_loss=1.248146\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=595 train loss <loss>=1.31341094971\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] Epoch[6] Batch [595]#011Speed: 1619.11 samples/sec#011loss=1.313411\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] Epoch[6] Batch[600] avg_epoch_loss=1.253022\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=600 train loss <loss>=1.83414826393\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] Epoch[6] Batch [600]#011Speed: 14267.25 samples/sec#011loss=1.834148\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] Epoch[6] Batch[605] avg_epoch_loss=1.258604\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=605 train loss <loss>=1.92962033749\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] Epoch[6] Batch [605]#011Speed: 1770.83 samples/sec#011loss=1.929620\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] Epoch[6] Batch[610] avg_epoch_loss=1.261966\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=610 train loss <loss>=1.66937139034\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] Epoch[6] Batch [610]#011Speed: 12196.07 samples/sec#011loss=1.669371\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] Epoch[6] Batch[615] avg_epoch_loss=1.267323\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=615 train loss <loss>=1.92204434872\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:58 INFO 140088046479168] Epoch[6] Batch [615]#011Speed: 13770.44 samples/sec#011loss=1.922044\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] Epoch[6] Batch[620] avg_epoch_loss=1.266655\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=620 train loss <loss>=1.18433876038\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] Epoch[6] Batch [620]#011Speed: 1852.04 samples/sec#011loss=1.184339\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] Epoch[6] Batch[625] avg_epoch_loss=1.266271\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=625 train loss <loss>=1.21861376762\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] Epoch[6] Batch [625]#011Speed: 14038.78 samples/sec#011loss=1.218614\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] Epoch[6] Batch[630] avg_epoch_loss=1.264477\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=630 train loss <loss>=1.03977431059\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] Epoch[6] Batch [630]#011Speed: 1638.29 samples/sec#011loss=1.039774\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] Epoch[6] Batch[635] avg_epoch_loss=1.264553\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=635 train loss <loss>=1.27416354418\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] Epoch[6] Batch [635]#011Speed: 13580.53 samples/sec#011loss=1.274164\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] Epoch[6] Batch[640] avg_epoch_loss=1.263831\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=640 train loss <loss>=1.17204432487\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] Epoch[6] Batch [640]#011Speed: 14068.50 samples/sec#011loss=1.172044\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] Epoch[6] Batch[645] avg_epoch_loss=1.263319\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=645 train loss <loss>=1.19760785103\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] Epoch[6] Batch [645]#011Speed: 1745.07 samples/sec#011loss=1.197608\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] Epoch[6] Batch[650] avg_epoch_loss=1.262502\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=650 train loss <loss>=1.15692706108\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] Epoch[6] Batch [650]#011Speed: 13157.44 samples/sec#011loss=1.156927\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] Epoch[6] Batch[655] avg_epoch_loss=1.262481\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=655 train loss <loss>=1.25976849794\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] Epoch[6] Batch [655]#011Speed: 13201.31 samples/sec#011loss=1.259768\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] Epoch[6] Batch[660] avg_epoch_loss=1.265083\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=660 train loss <loss>=1.60647218227\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] Epoch[6] Batch [660]#011Speed: 1744.33 samples/sec#011loss=1.606472\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] Epoch[6] Batch[665] avg_epoch_loss=1.268764\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=665 train loss <loss>=1.75541095734\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] Epoch[6] Batch [665]#011Speed: 13318.42 samples/sec#011loss=1.755411\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] Epoch[6] Batch[670] avg_epoch_loss=1.270103\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=670 train loss <loss>=1.44844923019\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] Epoch[6] Batch [670]#011Speed: 1640.27 samples/sec#011loss=1.448449\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] Epoch[6] Batch[675] avg_epoch_loss=1.274133\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=675 train loss <loss>=1.81497161388\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] Epoch[6] Batch [675]#011Speed: 14238.04 samples/sec#011loss=1.814972\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] Epoch[6] Batch[680] avg_epoch_loss=1.273776\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=680 train loss <loss>=1.22552095652\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:34:59 INFO 140088046479168] Epoch[6] Batch [680]#011Speed: 13458.38 samples/sec#011loss=1.225521\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] Epoch[6] Batch[685] avg_epoch_loss=1.273744\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=685 train loss <loss>=1.2694294095\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] Epoch[6] Batch [685]#011Speed: 1786.97 samples/sec#011loss=1.269429\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] Epoch[6] Batch[690] avg_epoch_loss=1.274234\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=690 train loss <loss>=1.34141175747\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] Epoch[6] Batch [690]#011Speed: 12780.57 samples/sec#011loss=1.341412\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] Epoch[6] Batch[695] avg_epoch_loss=1.275096\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=695 train loss <loss>=1.394277215\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] Epoch[6] Batch [695]#011Speed: 1746.47 samples/sec#011loss=1.394277\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] Epoch[6] Batch[700] avg_epoch_loss=1.275446\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=700 train loss <loss>=1.32414271832\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] Epoch[6] Batch [700]#011Speed: 13199.10 samples/sec#011loss=1.324143\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] Epoch[6] Batch[705] avg_epoch_loss=1.276801\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=705 train loss <loss>=1.46678693295\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] Epoch[6] Batch [705]#011Speed: 14370.98 samples/sec#011loss=1.466787\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] Epoch[6] Batch[710] avg_epoch_loss=1.276537\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=710 train loss <loss>=1.23923306465\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] Epoch[6] Batch [710]#011Speed: 1698.56 samples/sec#011loss=1.239233\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] Epoch[6] Batch[715] avg_epoch_loss=1.276399\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=715 train loss <loss>=1.2567922473\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] Epoch[6] Batch [715]#011Speed: 13263.15 samples/sec#011loss=1.256792\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] Epoch[6] Batch[720] avg_epoch_loss=1.275305\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=720 train loss <loss>=1.11856091022\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] Epoch[6] Batch [720]#011Speed: 1914.41 samples/sec#011loss=1.118561\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] Epoch[6] Batch[725] avg_epoch_loss=1.274078\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=725 train loss <loss>=1.09725874662\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] Epoch[6] Batch [725]#011Speed: 14361.90 samples/sec#011loss=1.097259\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] Epoch[6] Batch[730] avg_epoch_loss=1.272899\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=730 train loss <loss>=1.10165481567\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] Epoch[6] Batch [730]#011Speed: 1801.46 samples/sec#011loss=1.101655\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] Epoch[6] Batch[735] avg_epoch_loss=1.273370\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=735 train loss <loss>=1.34227149487\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:00 INFO 140088046479168] Epoch[6] Batch [735]#011Speed: 13566.25 samples/sec#011loss=1.342271\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] Epoch[6] Batch[740] avg_epoch_loss=1.271912\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=740 train loss <loss>=1.05717148781\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] Epoch[6] Batch [740]#011Speed: 14328.02 samples/sec#011loss=1.057171\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] Epoch[6] Batch[745] avg_epoch_loss=1.270614\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=745 train loss <loss>=1.07835408449\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] Epoch[6] Batch [745]#011Speed: 1752.19 samples/sec#011loss=1.078354\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] Epoch[6] Batch[750] avg_epoch_loss=1.269480\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=750 train loss <loss>=1.10019035339\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] Epoch[6] Batch [750]#011Speed: 13068.15 samples/sec#011loss=1.100190\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] Epoch[6] Batch[755] avg_epoch_loss=1.267432\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=755 train loss <loss>=0.959820306301\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] Epoch[6] Batch [755]#011Speed: 1697.46 samples/sec#011loss=0.959820\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] Epoch[6] Batch[760] avg_epoch_loss=1.265273\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=760 train loss <loss>=0.938918840885\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] Epoch[6] Batch [760]#011Speed: 13162.86 samples/sec#011loss=0.938919\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] Epoch[6] Batch[765] avg_epoch_loss=1.264527\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=765 train loss <loss>=1.15101001263\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] Epoch[6] Batch [765]#011Speed: 14580.48 samples/sec#011loss=1.151010\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] Epoch[6] Batch[770] avg_epoch_loss=1.262986\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=770 train loss <loss>=1.02680437565\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] Epoch[6] Batch [770]#011Speed: 1569.36 samples/sec#011loss=1.026804\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] Epoch[6] Batch[775] avg_epoch_loss=1.261994\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=775 train loss <loss>=1.10912687778\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] Epoch[6] Batch [775]#011Speed: 12517.16 samples/sec#011loss=1.109127\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] Epoch[6] Batch[780] avg_epoch_loss=1.261147\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=780 train loss <loss>=1.12968392372\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] Epoch[6] Batch [780]#011Speed: 12376.69 samples/sec#011loss=1.129684\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] Epoch[6] Batch[785] avg_epoch_loss=1.259821\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=785 train loss <loss>=1.05273374319\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] Epoch[6] Batch [785]#011Speed: 1454.99 samples/sec#011loss=1.052734\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] Epoch[6] Batch[790] avg_epoch_loss=1.258262\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=790 train loss <loss>=1.01311943531\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:01 INFO 140088046479168] Epoch[6] Batch [790]#011Speed: 14171.74 samples/sec#011loss=1.013119\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] Epoch[6] Batch[795] avg_epoch_loss=1.257921\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=795 train loss <loss>=1.20392811298\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] Epoch[6] Batch [795]#011Speed: 1684.12 samples/sec#011loss=1.203928\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] Epoch[6] Batch[800] avg_epoch_loss=1.259798\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=800 train loss <loss>=1.55868746042\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] Epoch[6] Batch [800]#011Speed: 13270.36 samples/sec#011loss=1.558687\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] Epoch[6] Batch[805] avg_epoch_loss=1.264826\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=805 train loss <loss>=2.07021579742\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] Epoch[6] Batch [805]#011Speed: 13770.58 samples/sec#011loss=2.070216\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] Epoch[6] Batch[810] avg_epoch_loss=1.270162\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=810 train loss <loss>=2.13044910431\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] Epoch[6] Batch [810]#011Speed: 1805.13 samples/sec#011loss=2.130449\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] Epoch[6] Batch[815] avg_epoch_loss=1.278109\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=815 train loss <loss>=2.56709713936\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] Epoch[6] Batch [815]#011Speed: 14221.60 samples/sec#011loss=2.567097\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] Epoch[6] Batch[820] avg_epoch_loss=1.285298\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=820 train loss <loss>=2.45854997635\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] Epoch[6] Batch [820]#011Speed: 1606.67 samples/sec#011loss=2.458550\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] Epoch[6] Batch[825] avg_epoch_loss=1.290627\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=825 train loss <loss>=2.16567780972\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] Epoch[6] Batch [825]#011Speed: 13356.73 samples/sec#011loss=2.165678\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] Epoch[6] Batch[830] avg_epoch_loss=1.297907\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=830 train loss <loss>=2.50042107105\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] Epoch[6] Batch [830]#011Speed: 13196.38 samples/sec#011loss=2.500421\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] Epoch[6] Batch[835] avg_epoch_loss=1.299989\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=835 train loss <loss>=1.64609084129\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] Epoch[6] Batch [835]#011Speed: 1773.87 samples/sec#011loss=1.646091\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] Epoch[6] Batch[840] avg_epoch_loss=1.304973\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=840 train loss <loss>=2.13825044632\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:02 INFO 140088046479168] Epoch[6] Batch [840]#011Speed: 14187.62 samples/sec#011loss=2.138250\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] Epoch[6] Batch[845] avg_epoch_loss=1.305217\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=845 train loss <loss>=1.34637286663\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] Epoch[6] Batch [845]#011Speed: 1611.83 samples/sec#011loss=1.346373\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] Epoch[6] Batch[850] avg_epoch_loss=1.306425\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=850 train loss <loss>=1.51070475578\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] Epoch[6] Batch [850]#011Speed: 14375.44 samples/sec#011loss=1.510705\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] Epoch[6] Batch[855] avg_epoch_loss=1.306307\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=855 train loss <loss>=1.28623316288\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] Epoch[6] Batch [855]#011Speed: 14151.12 samples/sec#011loss=1.286233\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] Epoch[6] Batch[860] avg_epoch_loss=1.305372\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=860 train loss <loss>=1.14537812471\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] Epoch[6] Batch [860]#011Speed: 1762.88 samples/sec#011loss=1.145378\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] Epoch[6] Batch[865] avg_epoch_loss=1.304913\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=865 train loss <loss>=1.22584249973\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] Epoch[6] Batch [865]#011Speed: 14276.81 samples/sec#011loss=1.225842\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] Epoch[6] Batch[870] avg_epoch_loss=1.304211\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=870 train loss <loss>=1.18267042637\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] Epoch[6] Batch [870]#011Speed: 14535.64 samples/sec#011loss=1.182670\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] Epoch[6] Batch[875] avg_epoch_loss=1.303695\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=875 train loss <loss>=1.21376523972\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] Epoch[6] Batch [875]#011Speed: 1643.74 samples/sec#011loss=1.213765\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] Epoch[6] Batch[880] avg_epoch_loss=1.302941\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=880 train loss <loss>=1.17078046799\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] Epoch[6] Batch [880]#011Speed: 14354.84 samples/sec#011loss=1.170780\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] Epoch[6] Batch[885] avg_epoch_loss=1.303050\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=885 train loss <loss>=1.32236256599\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] Epoch[6] Batch [885]#011Speed: 1800.57 samples/sec#011loss=1.322363\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] Epoch[6] Batch[890] avg_epoch_loss=1.301872\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=890 train loss <loss>=1.09304949045\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] Epoch[6] Batch [890]#011Speed: 13271.41 samples/sec#011loss=1.093049\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] Epoch[6] Batch[895] avg_epoch_loss=1.301125\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=895 train loss <loss>=1.16808314323\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] Epoch[6] Batch [895]#011Speed: 13272.46 samples/sec#011loss=1.168083\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] Epoch[6] Batch[900] avg_epoch_loss=1.298782\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, batch=900 train loss <loss>=0.878771549463\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] Epoch[6] Batch [900]#011Speed: 4158.49 samples/sec#011loss=0.878772\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] processed a total of 57624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15929.00800704956, \"sum\": 15929.00800704956, \"min\": 15929.00800704956}}, \"EndTime\": 1604320503.836362, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320487.906849}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] #throughput_metric: host=algo-1, train throughput=3617.52454119 records/second\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=6, train loss <loss>=1.29878155006\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:03 INFO 140088046479168] Saved checkpoint to \"/opt/ml/model/state_fe666f6b-23de-420e-bdc6-a009d6d9bfd0-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 6.9179534912109375, \"sum\": 6.9179534912109375, \"min\": 6.9179534912109375}}, \"EndTime\": 1604320503.843867, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320503.836438}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] Epoch[7] Batch[0] avg_epoch_loss=1.156311\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=1.15631103516\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] Epoch[7] Batch[5] avg_epoch_loss=1.269361\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=1.26936084032\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] Epoch[7] Batch [5]#011Speed: 13984.07 samples/sec#011loss=1.269361\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] Epoch[7] Batch[10] avg_epoch_loss=1.307869\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=1.35407969952\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] Epoch[7] Batch [10]#011Speed: 14370.98 samples/sec#011loss=1.354080\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] Epoch[7] Batch[15] avg_epoch_loss=1.251052\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=15 train loss <loss>=1.12605315447\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] Epoch[7] Batch [15]#011Speed: 1635.25 samples/sec#011loss=1.126053\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] Epoch[7] Batch[20] avg_epoch_loss=1.213871\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=20 train loss <loss>=1.09489406347\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] Epoch[7] Batch [20]#011Speed: 13684.52 samples/sec#011loss=1.094894\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] Epoch[7] Batch[25] avg_epoch_loss=1.193871\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=25 train loss <loss>=1.10986680984\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] Epoch[7] Batch [25]#011Speed: 13518.16 samples/sec#011loss=1.109867\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] Epoch[7] Batch[30] avg_epoch_loss=1.151153\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=30 train loss <loss>=0.929023659229\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] Epoch[7] Batch [30]#011Speed: 1681.19 samples/sec#011loss=0.929024\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] Epoch[7] Batch[35] avg_epoch_loss=1.129876\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=35 train loss <loss>=0.997957277298\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] Epoch[7] Batch [35]#011Speed: 13310.63 samples/sec#011loss=0.997957\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] Epoch[7] Batch[40] avg_epoch_loss=1.158722\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=40 train loss <loss>=1.36641196012\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] Epoch[7] Batch [40]#011Speed: 1678.20 samples/sec#011loss=1.366412\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] Epoch[7] Batch[45] avg_epoch_loss=1.235035\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=45 train loss <loss>=1.86079950333\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] Epoch[7] Batch [45]#011Speed: 13008.11 samples/sec#011loss=1.860800\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] Epoch[7] Batch[50] avg_epoch_loss=1.278174\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=50 train loss <loss>=1.6750565052\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] Epoch[7] Batch [50]#011Speed: 13315.51 samples/sec#011loss=1.675057\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] Epoch[7] Batch[55] avg_epoch_loss=1.270104\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=55 train loss <loss>=1.18778469563\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] Epoch[7] Batch [55]#011Speed: 1771.85 samples/sec#011loss=1.187785\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] Epoch[7] Batch[60] avg_epoch_loss=1.250565\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=60 train loss <loss>=1.0317351222\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:04 INFO 140088046479168] Epoch[7] Batch [60]#011Speed: 14216.47 samples/sec#011loss=1.031735\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] Epoch[7] Batch[65] avg_epoch_loss=1.260506\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=65 train loss <loss>=1.38178881407\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] Epoch[7] Batch [65]#011Speed: 1639.78 samples/sec#011loss=1.381789\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] Epoch[7] Batch[70] avg_epoch_loss=1.267282\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=70 train loss <loss>=1.35672571659\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] Epoch[7] Batch [70]#011Speed: 14101.17 samples/sec#011loss=1.356726\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] Epoch[7] Batch[75] avg_epoch_loss=1.254628\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=75 train loss <loss>=1.07492833138\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] Epoch[7] Batch [75]#011Speed: 14219.03 samples/sec#011loss=1.074928\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] Epoch[7] Batch[80] avg_epoch_loss=1.241140\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=80 train loss <loss>=1.03612178564\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] Epoch[7] Batch [80]#011Speed: 1784.95 samples/sec#011loss=1.036122\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] Epoch[7] Batch[85] avg_epoch_loss=1.226391\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=85 train loss <loss>=0.987461853027\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] Epoch[7] Batch [85]#011Speed: 14099.98 samples/sec#011loss=0.987462\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] Epoch[7] Batch[90] avg_epoch_loss=1.215606\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=90 train loss <loss>=1.030116117\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] Epoch[7] Batch [90]#011Speed: 1737.52 samples/sec#011loss=1.030116\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] Epoch[7] Batch[95] avg_epoch_loss=1.208980\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=95 train loss <loss>=1.08837207556\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] Epoch[7] Batch [95]#011Speed: 14292.77 samples/sec#011loss=1.088372\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] Epoch[7] Batch[100] avg_epoch_loss=1.197044\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=100 train loss <loss>=0.967875945568\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] Epoch[7] Batch [100]#011Speed: 14088.88 samples/sec#011loss=0.967876\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] Epoch[7] Batch[105] avg_epoch_loss=1.183050\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=105 train loss <loss>=0.900382125378\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] Epoch[7] Batch [105]#011Speed: 1476.58 samples/sec#011loss=0.900382\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] Epoch[7] Batch[110] avg_epoch_loss=1.186047\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=110 train loss <loss>=1.24958566427\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] Epoch[7] Batch [110]#011Speed: 12010.21 samples/sec#011loss=1.249586\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] Epoch[7] Batch[115] avg_epoch_loss=1.182082\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=115 train loss <loss>=1.09405341148\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:05 INFO 140088046479168] Epoch[7] Batch [115]#011Speed: 14309.23 samples/sec#011loss=1.094053\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] Epoch[7] Batch[120] avg_epoch_loss=1.189269\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=120 train loss <loss>=1.35600152016\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] Epoch[7] Batch [120]#011Speed: 1743.40 samples/sec#011loss=1.356002\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] Epoch[7] Batch[125] avg_epoch_loss=1.181992\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=125 train loss <loss>=1.00589647293\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] Epoch[7] Batch [125]#011Speed: 14033.35 samples/sec#011loss=1.005896\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] Epoch[7] Batch[130] avg_epoch_loss=1.200979\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=130 train loss <loss>=1.67943537235\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] Epoch[7] Batch [130]#011Speed: 1549.16 samples/sec#011loss=1.679435\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] Epoch[7] Batch[135] avg_epoch_loss=1.197306\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=135 train loss <loss>=1.10108178854\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] Epoch[7] Batch [135]#011Speed: 14116.89 samples/sec#011loss=1.101082\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] Epoch[7] Batch[140] avg_epoch_loss=1.183088\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=140 train loss <loss>=0.79637311697\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] Epoch[7] Batch [140]#011Speed: 14350.39 samples/sec#011loss=0.796373\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] Epoch[7] Batch[145] avg_epoch_loss=1.180671\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=145 train loss <loss>=1.11249046326\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] Epoch[7] Batch [145]#011Speed: 1673.53 samples/sec#011loss=1.112490\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] Epoch[7] Batch[150] avg_epoch_loss=1.180202\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=150 train loss <loss>=1.16651544571\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] Epoch[7] Batch [150]#011Speed: 13069.80 samples/sec#011loss=1.166515\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] Epoch[7] Batch[155] avg_epoch_loss=1.185611\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=155 train loss <loss>=1.34896390438\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] Epoch[7] Batch [155]#011Speed: 1632.69 samples/sec#011loss=1.348964\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] Epoch[7] Batch[160] avg_epoch_loss=1.210927\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=160 train loss <loss>=2.00077314377\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] Epoch[7] Batch [160]#011Speed: 12914.12 samples/sec#011loss=2.000773\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] Epoch[7] Batch[165] avg_epoch_loss=1.219368\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=165 train loss <loss>=1.49118001461\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:06 INFO 140088046479168] Epoch[7] Batch [165]#011Speed: 12908.41 samples/sec#011loss=1.491180\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] Epoch[7] Batch[170] avg_epoch_loss=1.226144\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=170 train loss <loss>=1.45109772682\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] Epoch[7] Batch [170]#011Speed: 1611.08 samples/sec#011loss=1.451098\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] Epoch[7] Batch[175] avg_epoch_loss=1.229845\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=175 train loss <loss>=1.35642652512\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] Epoch[7] Batch [175]#011Speed: 14030.71 samples/sec#011loss=1.356427\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] Epoch[7] Batch[180] avg_epoch_loss=1.229832\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=180 train loss <loss>=1.22935897112\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] Epoch[7] Batch [180]#011Speed: 13154.09 samples/sec#011loss=1.229359\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] Epoch[7] Batch[185] avg_epoch_loss=1.228275\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=185 train loss <loss>=1.1719147563\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] Epoch[7] Batch [185]#011Speed: 1625.56 samples/sec#011loss=1.171915\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] Epoch[7] Batch[190] avg_epoch_loss=1.226950\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=190 train loss <loss>=1.17766082287\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] Epoch[7] Batch [190]#011Speed: 14127.44 samples/sec#011loss=1.177661\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] Epoch[7] Batch[195] avg_epoch_loss=1.229881\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=195 train loss <loss>=1.34185724258\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] Epoch[7] Batch [195]#011Speed: 1713.00 samples/sec#011loss=1.341857\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] Epoch[7] Batch[200] avg_epoch_loss=1.222669\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=200 train loss <loss>=0.939962363243\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] Epoch[7] Batch [200]#011Speed: 14166.81 samples/sec#011loss=0.939962\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] Epoch[7] Batch[205] avg_epoch_loss=1.223241\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=205 train loss <loss>=1.24621779919\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] Epoch[7] Batch [205]#011Speed: 13911.74 samples/sec#011loss=1.246218\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] Epoch[7] Batch[210] avg_epoch_loss=1.223154\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=210 train loss <loss>=1.2195950985\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] Epoch[7] Batch [210]#011Speed: 1640.35 samples/sec#011loss=1.219595\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] Epoch[7] Batch[215] avg_epoch_loss=1.223478\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=215 train loss <loss>=1.23715872765\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] Epoch[7] Batch [215]#011Speed: 14264.07 samples/sec#011loss=1.237159\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] Epoch[7] Batch[220] avg_epoch_loss=1.224039\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=220 train loss <loss>=1.24825558662\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] Epoch[7] Batch [220]#011Speed: 1633.87 samples/sec#011loss=1.248256\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] Epoch[7] Batch[225] avg_epoch_loss=1.223570\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=225 train loss <loss>=1.20284792185\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:07 INFO 140088046479168] Epoch[7] Batch [225]#011Speed: 13076.81 samples/sec#011loss=1.202848\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] Epoch[7] Batch[230] avg_epoch_loss=1.232892\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=230 train loss <loss>=1.65421882868\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] Epoch[7] Batch [230]#011Speed: 13160.02 samples/sec#011loss=1.654219\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] Epoch[7] Batch[235] avg_epoch_loss=1.239704\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=235 train loss <loss>=1.55444358587\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] Epoch[7] Batch [235]#011Speed: 1754.07 samples/sec#011loss=1.554444\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] Epoch[7] Batch[240] avg_epoch_loss=1.245629\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=240 train loss <loss>=1.52529833317\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] Epoch[7] Batch [240]#011Speed: 14519.76 samples/sec#011loss=1.525298\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] Epoch[7] Batch[245] avg_epoch_loss=1.246880\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=245 train loss <loss>=1.30714740753\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] Epoch[7] Batch [245]#011Speed: 14677.59 samples/sec#011loss=1.307147\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] Epoch[7] Batch[250] avg_epoch_loss=1.252469\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=250 train loss <loss>=1.52747926712\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] Epoch[7] Batch [250]#011Speed: 1603.96 samples/sec#011loss=1.527479\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] Epoch[7] Batch[255] avg_epoch_loss=1.258372\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=255 train loss <loss>=1.55467541218\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] Epoch[7] Batch [255]#011Speed: 13111.04 samples/sec#011loss=1.554675\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] Epoch[7] Batch[260] avg_epoch_loss=1.265173\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=260 train loss <loss>=1.6134146452\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] Epoch[7] Batch [260]#011Speed: 1518.34 samples/sec#011loss=1.613415\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] Epoch[7] Batch[265] avg_epoch_loss=1.271643\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=265 train loss <loss>=1.60938408375\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] Epoch[7] Batch [265]#011Speed: 14007.42 samples/sec#011loss=1.609384\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] Epoch[7] Batch[270] avg_epoch_loss=1.272742\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=270 train loss <loss>=1.33116773367\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] Epoch[7] Batch [270]#011Speed: 14019.71 samples/sec#011loss=1.331168\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] Epoch[7] Batch[275] avg_epoch_loss=1.272562\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=275 train loss <loss>=1.26281398535\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] Epoch[7] Batch [275]#011Speed: 1765.04 samples/sec#011loss=1.262814\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] Epoch[7] Batch[280] avg_epoch_loss=1.269289\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=280 train loss <loss>=1.08862638474\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:08 INFO 140088046479168] Epoch[7] Batch [280]#011Speed: 14288.82 samples/sec#011loss=1.088626\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] Epoch[7] Batch[285] avg_epoch_loss=1.269274\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=285 train loss <loss>=1.26841564178\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] Epoch[7] Batch [285]#011Speed: 1782.56 samples/sec#011loss=1.268416\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] Epoch[7] Batch[290] avg_epoch_loss=1.273068\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=290 train loss <loss>=1.49008557796\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] Epoch[7] Batch [290]#011Speed: 14062.75 samples/sec#011loss=1.490086\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] Epoch[7] Batch[295] avg_epoch_loss=1.271346\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=295 train loss <loss>=1.17111541033\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] Epoch[7] Batch [295]#011Speed: 13877.37 samples/sec#011loss=1.171115\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] Epoch[7] Batch[300] avg_epoch_loss=1.271120\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=300 train loss <loss>=1.25776810646\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] Epoch[7] Batch [300]#011Speed: 1767.02 samples/sec#011loss=1.257768\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] Epoch[7] Batch[305] avg_epoch_loss=1.272944\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=305 train loss <loss>=1.38276726007\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] Epoch[7] Batch [305]#011Speed: 13236.33 samples/sec#011loss=1.382767\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] Epoch[7] Batch[310] avg_epoch_loss=1.270360\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=310 train loss <loss>=1.11221959591\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] Epoch[7] Batch [310]#011Speed: 1794.99 samples/sec#011loss=1.112220\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] Epoch[7] Batch[315] avg_epoch_loss=1.266284\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=315 train loss <loss>=1.0127173543\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] Epoch[7] Batch [315]#011Speed: 13573.66 samples/sec#011loss=1.012717\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] Epoch[7] Batch[320] avg_epoch_loss=1.262574\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=320 train loss <loss>=1.02809848785\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] Epoch[7] Batch [320]#011Speed: 1517.39 samples/sec#011loss=1.028098\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] Epoch[7] Batch[325] avg_epoch_loss=1.260830\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=325 train loss <loss>=1.14889376163\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] Epoch[7] Batch [325]#011Speed: 14617.32 samples/sec#011loss=1.148894\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] Epoch[7] Batch[330] avg_epoch_loss=1.257928\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=330 train loss <loss>=1.06871240139\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] Epoch[7] Batch [330]#011Speed: 14165.46 samples/sec#011loss=1.068712\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] Epoch[7] Batch[335] avg_epoch_loss=1.259049\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=335 train loss <loss>=1.33323557377\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:09 INFO 140088046479168] Epoch[7] Batch [335]#011Speed: 1713.55 samples/sec#011loss=1.333236\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] Epoch[7] Batch[340] avg_epoch_loss=1.259707\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=340 train loss <loss>=1.30396682024\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] Epoch[7] Batch [340]#011Speed: 13243.38 samples/sec#011loss=1.303967\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] Epoch[7] Batch[345] avg_epoch_loss=1.258844\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=345 train loss <loss>=1.1999864459\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] Epoch[7] Batch [345]#011Speed: 13111.04 samples/sec#011loss=1.199986\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] Epoch[7] Batch[350] avg_epoch_loss=1.258629\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=350 train loss <loss>=1.24374730587\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] Epoch[7] Batch [350]#011Speed: 1704.37 samples/sec#011loss=1.243747\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] Epoch[7] Batch[355] avg_epoch_loss=1.256302\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=355 train loss <loss>=1.09293355942\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] Epoch[7] Batch [355]#011Speed: 13173.07 samples/sec#011loss=1.092934\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] Epoch[7] Batch[360] avg_epoch_loss=1.258698\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=360 train loss <loss>=1.42928589582\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] Epoch[7] Batch [360]#011Speed: 1675.76 samples/sec#011loss=1.429286\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] Epoch[7] Batch[365] avg_epoch_loss=1.265835\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=365 train loss <loss>=1.78116576672\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] Epoch[7] Batch [365]#011Speed: 13219.25 samples/sec#011loss=1.781166\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] Epoch[7] Batch[370] avg_epoch_loss=1.272669\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=370 train loss <loss>=1.77288775444\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] Epoch[7] Batch [370]#011Speed: 13093.26 samples/sec#011loss=1.772888\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] Epoch[7] Batch[375] avg_epoch_loss=1.278891\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=375 train loss <loss>=1.7405698061\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] Epoch[7] Batch [375]#011Speed: 1595.44 samples/sec#011loss=1.740570\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] Epoch[7] Batch[380] avg_epoch_loss=1.279143\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=380 train loss <loss>=1.29809144735\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] Epoch[7] Batch [380]#011Speed: 13295.07 samples/sec#011loss=1.298091\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] Epoch[7] Batch[385] avg_epoch_loss=1.279002\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=385 train loss <loss>=1.26826286316\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] Epoch[7] Batch [385]#011Speed: 1736.28 samples/sec#011loss=1.268263\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] Epoch[7] Batch[390] avg_epoch_loss=1.276658\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=390 train loss <loss>=1.09571232796\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] Epoch[7] Batch [390]#011Speed: 13247.18 samples/sec#011loss=1.095712\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] Epoch[7] Batch[395] avg_epoch_loss=1.277340\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=395 train loss <loss>=1.33065423965\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:10 INFO 140088046479168] Epoch[7] Batch [395]#011Speed: 13289.02 samples/sec#011loss=1.330654\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] Epoch[7] Batch[400] avg_epoch_loss=1.279595\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=400 train loss <loss>=1.45820159912\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] Epoch[7] Batch [400]#011Speed: 1508.07 samples/sec#011loss=1.458202\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] Epoch[7] Batch[405] avg_epoch_loss=1.277707\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=405 train loss <loss>=1.12624150515\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] Epoch[7] Batch [405]#011Speed: 12876.70 samples/sec#011loss=1.126242\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] Epoch[7] Batch[410] avg_epoch_loss=1.277931\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=410 train loss <loss>=1.29613957405\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] Epoch[7] Batch [410]#011Speed: 14380.68 samples/sec#011loss=1.296140\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] Epoch[7] Batch[415] avg_epoch_loss=1.278496\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=415 train loss <loss>=1.32497558594\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] Epoch[7] Batch [415]#011Speed: 1717.77 samples/sec#011loss=1.324976\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] Epoch[7] Batch[420] avg_epoch_loss=1.278636\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=420 train loss <loss>=1.29023039341\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] Epoch[7] Batch [420]#011Speed: 14181.92 samples/sec#011loss=1.290230\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] Epoch[7] Batch[425] avg_epoch_loss=1.279855\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=425 train loss <loss>=1.38253641129\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] Epoch[7] Batch [425]#011Speed: 1689.01 samples/sec#011loss=1.382536\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] Epoch[7] Batch[430] avg_epoch_loss=1.281062\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=430 train loss <loss>=1.38391880989\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] Epoch[7] Batch [430]#011Speed: 14210.30 samples/sec#011loss=1.383919\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] Epoch[7] Batch[435] avg_epoch_loss=1.281640\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=435 train loss <loss>=1.33146258593\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] Epoch[7] Batch [435]#011Speed: 14088.14 samples/sec#011loss=1.331463\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] Epoch[7] Batch[440] avg_epoch_loss=1.283869\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=440 train loss <loss>=1.47818617821\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] Epoch[7] Batch [440]#011Speed: 1823.17 samples/sec#011loss=1.478186\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] Epoch[7] Batch[445] avg_epoch_loss=1.285714\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=445 train loss <loss>=1.44849307537\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:11 INFO 140088046479168] Epoch[7] Batch [445]#011Speed: 14374.82 samples/sec#011loss=1.448493\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] Epoch[7] Batch[450] avg_epoch_loss=1.284842\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=450 train loss <loss>=1.20706269741\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] Epoch[7] Batch [450]#011Speed: 1666.09 samples/sec#011loss=1.207063\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] Epoch[7] Batch[455] avg_epoch_loss=1.283738\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=455 train loss <loss>=1.18409459591\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] Epoch[7] Batch [455]#011Speed: 14311.21 samples/sec#011loss=1.184095\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] Epoch[7] Batch[460] avg_epoch_loss=1.281445\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=460 train loss <loss>=1.07238763571\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] Epoch[7] Batch [460]#011Speed: 14278.79 samples/sec#011loss=1.072388\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] Epoch[7] Batch[465] avg_epoch_loss=1.281820\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=465 train loss <loss>=1.31639010906\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] Epoch[7] Batch [465]#011Speed: 1612.27 samples/sec#011loss=1.316390\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] Epoch[7] Batch[470] avg_epoch_loss=1.281591\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=470 train loss <loss>=1.26023939848\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] Epoch[7] Batch [470]#011Speed: 13923.29 samples/sec#011loss=1.260239\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] Epoch[7] Batch[475] avg_epoch_loss=1.280503\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=475 train loss <loss>=1.17798836231\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] Epoch[7] Batch [475]#011Speed: 1715.85 samples/sec#011loss=1.177988\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] Epoch[7] Batch[480] avg_epoch_loss=1.276579\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=480 train loss <loss>=0.903058218956\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] Epoch[7] Batch [480]#011Speed: 13793.79 samples/sec#011loss=0.903058\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] Epoch[7] Batch[485] avg_epoch_loss=1.273343\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=485 train loss <loss>=0.961997884512\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] Epoch[7] Batch [485]#011Speed: 14603.80 samples/sec#011loss=0.961998\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] Epoch[7] Batch[490] avg_epoch_loss=1.271964\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=490 train loss <loss>=1.13787593842\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] Epoch[7] Batch [490]#011Speed: 1703.26 samples/sec#011loss=1.137876\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] Epoch[7] Batch[495] avg_epoch_loss=1.271005\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=495 train loss <loss>=1.17687255144\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] Epoch[7] Batch [495]#011Speed: 14324.04 samples/sec#011loss=1.176873\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] Epoch[7] Batch[500] avg_epoch_loss=1.268119\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=500 train loss <loss>=0.981851804256\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] Epoch[7] Batch [500]#011Speed: 1844.51 samples/sec#011loss=0.981852\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] Epoch[7] Batch[505] avg_epoch_loss=1.266455\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=505 train loss <loss>=1.09972795248\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] Epoch[7] Batch [505]#011Speed: 13228.63 samples/sec#011loss=1.099728\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] Epoch[7] Batch[510] avg_epoch_loss=1.265725\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=510 train loss <loss>=1.19179885387\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:12 INFO 140088046479168] Epoch[7] Batch [510]#011Speed: 14561.98 samples/sec#011loss=1.191799\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] Epoch[7] Batch[515] avg_epoch_loss=1.267830\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=515 train loss <loss>=1.48298535347\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] Epoch[7] Batch [515]#011Speed: 1457.49 samples/sec#011loss=1.482985\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] Epoch[7] Batch[520] avg_epoch_loss=1.270143\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=520 train loss <loss>=1.50884058475\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] Epoch[7] Batch [520]#011Speed: 14319.00 samples/sec#011loss=1.508841\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] Epoch[7] Batch[525] avg_epoch_loss=1.269719\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=525 train loss <loss>=1.22559689283\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] Epoch[7] Batch [525]#011Speed: 13543.80 samples/sec#011loss=1.225597\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] Epoch[7] Batch[530] avg_epoch_loss=1.268785\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=530 train loss <loss>=1.1704932332\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] Epoch[7] Batch [530]#011Speed: 1722.86 samples/sec#011loss=1.170493\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] Epoch[7] Batch[535] avg_epoch_loss=1.265792\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=535 train loss <loss>=0.947939908504\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] Epoch[7] Batch [535]#011Speed: 13261.05 samples/sec#011loss=0.947940\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] Epoch[7] Batch[540] avg_epoch_loss=1.261056\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=540 train loss <loss>=0.753320944309\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] Epoch[7] Batch [540]#011Speed: 1581.19 samples/sec#011loss=0.753321\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] Epoch[7] Batch[545] avg_epoch_loss=1.260657\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=545 train loss <loss>=1.21744858027\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] Epoch[7] Batch [545]#011Speed: 13206.77 samples/sec#011loss=1.217449\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] Epoch[7] Batch[550] avg_epoch_loss=1.258946\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=550 train loss <loss>=1.07219555378\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] Epoch[7] Batch [550]#011Speed: 12527.44 samples/sec#011loss=1.072196\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] Epoch[7] Batch[555] avg_epoch_loss=1.260009\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=555 train loss <loss>=1.37709412575\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] Epoch[7] Batch [555]#011Speed: 1828.27 samples/sec#011loss=1.377094\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] Epoch[7] Batch[560] avg_epoch_loss=1.259415\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=560 train loss <loss>=1.19340424538\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:13 INFO 140088046479168] Epoch[7] Batch [560]#011Speed: 13098.12 samples/sec#011loss=1.193404\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] Epoch[7] Batch[565] avg_epoch_loss=1.260119\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=565 train loss <loss>=1.33911998272\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] Epoch[7] Batch [565]#011Speed: 1593.51 samples/sec#011loss=1.339120\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] Epoch[7] Batch[570] avg_epoch_loss=1.259682\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=570 train loss <loss>=1.21012320518\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] Epoch[7] Batch [570]#011Speed: 13850.44 samples/sec#011loss=1.210123\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] Epoch[7] Batch[575] avg_epoch_loss=1.259479\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=575 train loss <loss>=1.23635077477\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] Epoch[7] Batch [575]#011Speed: 13443.15 samples/sec#011loss=1.236351\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] Epoch[7] Batch[580] avg_epoch_loss=1.260637\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=580 train loss <loss>=1.39399218559\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] Epoch[7] Batch [580]#011Speed: 1828.00 samples/sec#011loss=1.393992\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] Epoch[7] Batch[585] avg_epoch_loss=1.260406\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=585 train loss <loss>=1.23364636898\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] Epoch[7] Batch [585]#011Speed: 14231.10 samples/sec#011loss=1.233646\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] Epoch[7] Batch[590] avg_epoch_loss=1.259682\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=590 train loss <loss>=1.17478876114\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] Epoch[7] Batch [590]#011Speed: 1663.69 samples/sec#011loss=1.174789\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] Epoch[7] Batch[595] avg_epoch_loss=1.258403\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=595 train loss <loss>=1.10724840164\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] Epoch[7] Batch [595]#011Speed: 14257.70 samples/sec#011loss=1.107248\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] Epoch[7] Batch[600] avg_epoch_loss=1.256905\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=600 train loss <loss>=1.07827494144\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] Epoch[7] Batch [600]#011Speed: 14293.38 samples/sec#011loss=1.078275\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] Epoch[7] Batch[605] avg_epoch_loss=1.254773\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=605 train loss <loss>=0.998518252373\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] Epoch[7] Batch [605]#011Speed: 1742.85 samples/sec#011loss=0.998518\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] Epoch[7] Batch[610] avg_epoch_loss=1.252159\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=610 train loss <loss>=0.935403573513\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] Epoch[7] Batch [610]#011Speed: 12956.50 samples/sec#011loss=0.935404\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] Epoch[7] Batch[615] avg_epoch_loss=1.252909\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=615 train loss <loss>=1.34451014996\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:14 INFO 140088046479168] Epoch[7] Batch [615]#011Speed: 1690.84 samples/sec#011loss=1.344510\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] Epoch[7] Batch[620] avg_epoch_loss=1.253977\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=620 train loss <loss>=1.3856076479\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] Epoch[7] Batch [620]#011Speed: 12913.62 samples/sec#011loss=1.385608\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] Epoch[7] Batch[625] avg_epoch_loss=1.252391\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=625 train loss <loss>=1.05533581972\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] Epoch[7] Batch [625]#011Speed: 12547.00 samples/sec#011loss=1.055336\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] Epoch[7] Batch[630] avg_epoch_loss=1.251080\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=630 train loss <loss>=1.08704377413\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] Epoch[7] Batch [630]#011Speed: 1643.21 samples/sec#011loss=1.087044\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] Epoch[7] Batch[635] avg_epoch_loss=1.250791\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=635 train loss <loss>=1.21425976753\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] Epoch[7] Batch [635]#011Speed: 14292.17 samples/sec#011loss=1.214260\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] Epoch[7] Batch[640] avg_epoch_loss=1.249925\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=640 train loss <loss>=1.13982961178\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] Epoch[7] Batch [640]#011Speed: 1828.40 samples/sec#011loss=1.139830\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] Epoch[7] Batch[645] avg_epoch_loss=1.250486\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=645 train loss <loss>=1.32230457067\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] Epoch[7] Batch [645]#011Speed: 13919.68 samples/sec#011loss=1.322305\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] Epoch[7] Batch[650] avg_epoch_loss=1.256037\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=650 train loss <loss>=1.97332954407\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] Epoch[7] Batch [650]#011Speed: 12800.56 samples/sec#011loss=1.973330\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] Epoch[7] Batch[655] avg_epoch_loss=1.262682\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=655 train loss <loss>=2.12778834105\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] Epoch[7] Batch [655]#011Speed: 1816.33 samples/sec#011loss=2.127788\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] Epoch[7] Batch[660] avg_epoch_loss=1.269675\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=660 train loss <loss>=2.18713374138\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] Epoch[7] Batch [660]#011Speed: 14453.46 samples/sec#011loss=2.187134\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] Epoch[7] Batch[665] avg_epoch_loss=1.272504\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=665 train loss <loss>=1.64656264782\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] Epoch[7] Batch [665]#011Speed: 1793.76 samples/sec#011loss=1.646563\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] Epoch[7] Batch[670] avg_epoch_loss=1.272895\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=670 train loss <loss>=1.32495212555\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] Epoch[7] Batch [670]#011Speed: 12846.75 samples/sec#011loss=1.324952\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] Epoch[7] Batch[675] avg_epoch_loss=1.276923\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=675 train loss <loss>=1.81743974686\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:15 INFO 140088046479168] Epoch[7] Batch [675]#011Speed: 13247.83 samples/sec#011loss=1.817440\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] Epoch[7] Batch[680] avg_epoch_loss=1.281489\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=680 train loss <loss>=1.8987869978\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] Epoch[7] Batch [680]#011Speed: 1668.07 samples/sec#011loss=1.898787\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] Epoch[7] Batch[685] avg_epoch_loss=1.286243\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=685 train loss <loss>=1.93382053375\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] Epoch[7] Batch [685]#011Speed: 11071.51 samples/sec#011loss=1.933821\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] Epoch[7] Batch[690] avg_epoch_loss=1.291475\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=690 train loss <loss>=2.00925655365\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] Epoch[7] Batch [690]#011Speed: 1658.28 samples/sec#011loss=2.009257\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] Epoch[7] Batch[695] avg_epoch_loss=1.297292\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=695 train loss <loss>=2.1012873888\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] Epoch[7] Batch [695]#011Speed: 14058.48 samples/sec#011loss=2.101287\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] Epoch[7] Batch[700] avg_epoch_loss=1.302055\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=700 train loss <loss>=1.96503736973\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] Epoch[7] Batch [700]#011Speed: 13091.22 samples/sec#011loss=1.965037\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] Epoch[7] Batch[705] avg_epoch_loss=1.305768\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=705 train loss <loss>=1.82623593807\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] Epoch[7] Batch [705]#011Speed: 1609.01 samples/sec#011loss=1.826236\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] Epoch[7] Batch[710] avg_epoch_loss=1.308040\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=710 train loss <loss>=1.62894380093\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] Epoch[7] Batch [710]#011Speed: 13746.89 samples/sec#011loss=1.628944\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] Epoch[7] Batch[715] avg_epoch_loss=1.307613\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=715 train loss <loss>=1.24690759182\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] Epoch[7] Batch [715]#011Speed: 14076.47 samples/sec#011loss=1.246908\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] Epoch[7] Batch[720] avg_epoch_loss=1.306700\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=720 train loss <loss>=1.17595169544\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] Epoch[7] Batch [720]#011Speed: 1766.12 samples/sec#011loss=1.175952\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] Epoch[7] Batch[725] avg_epoch_loss=1.306478\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=725 train loss <loss>=1.27437443733\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:16 INFO 140088046479168] Epoch[7] Batch [725]#011Speed: 13093.90 samples/sec#011loss=1.274374\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] Epoch[7] Batch[730] avg_epoch_loss=1.305775\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=730 train loss <loss>=1.20375432968\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] Epoch[7] Batch [730]#011Speed: 1696.40 samples/sec#011loss=1.203754\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] Epoch[7] Batch[735] avg_epoch_loss=1.304712\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=735 train loss <loss>=1.14927932024\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] Epoch[7] Batch [735]#011Speed: 14269.22 samples/sec#011loss=1.149279\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] Epoch[7] Batch[740] avg_epoch_loss=1.304118\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=740 train loss <loss>=1.21670944691\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] Epoch[7] Batch [740]#011Speed: 1712.55 samples/sec#011loss=1.216709\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] Epoch[7] Batch[745] avg_epoch_loss=1.303622\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=745 train loss <loss>=1.2300814867\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] Epoch[7] Batch [745]#011Speed: 12930.42 samples/sec#011loss=1.230081\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] Epoch[7] Batch[750] avg_epoch_loss=1.302743\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=750 train loss <loss>=1.17159301043\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] Epoch[7] Batch [750]#011Speed: 14186.87 samples/sec#011loss=1.171593\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] Epoch[7] Batch[755] avg_epoch_loss=1.303357\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=755 train loss <loss>=1.39568191767\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] Epoch[7] Batch [755]#011Speed: 1744.40 samples/sec#011loss=1.395682\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] Epoch[7] Batch[760] avg_epoch_loss=1.301570\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=760 train loss <loss>=1.03133320808\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] Epoch[7] Batch [760]#011Speed: 14407.85 samples/sec#011loss=1.031333\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] Epoch[7] Batch[765] avg_epoch_loss=1.299533\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=765 train loss <loss>=0.989498853683\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] Epoch[7] Batch [765]#011Speed: 14051.71 samples/sec#011loss=0.989499\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] Epoch[7] Batch[770] avg_epoch_loss=1.298073\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=770 train loss <loss>=1.07436834574\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] Epoch[7] Batch [770]#011Speed: 1739.88 samples/sec#011loss=1.074368\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] Epoch[7] Batch[775] avg_epoch_loss=1.296809\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=775 train loss <loss>=1.10187978745\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] Epoch[7] Batch [775]#011Speed: 14334.45 samples/sec#011loss=1.101880\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] Epoch[7] Batch[780] avg_epoch_loss=1.295571\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=780 train loss <loss>=1.1035344243\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] Epoch[7] Batch [780]#011Speed: 1746.05 samples/sec#011loss=1.103534\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] Epoch[7] Batch[785] avg_epoch_loss=1.294694\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=785 train loss <loss>=1.15765135288\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] Epoch[7] Batch [785]#011Speed: 13403.14 samples/sec#011loss=1.157651\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] Epoch[7] Batch[790] avg_epoch_loss=1.294225\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=790 train loss <loss>=1.22040771246\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:17 INFO 140088046479168] Epoch[7] Batch [790]#011Speed: 13341.72 samples/sec#011loss=1.220408\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] Epoch[7] Batch[795] avg_epoch_loss=1.293628\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=795 train loss <loss>=1.19923570156\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] Epoch[7] Batch [795]#011Speed: 1660.47 samples/sec#011loss=1.199236\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] Epoch[7] Batch[800] avg_epoch_loss=1.294502\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=800 train loss <loss>=1.43366774321\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] Epoch[7] Batch [800]#011Speed: 14351.77 samples/sec#011loss=1.433668\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] Epoch[7] Batch[805] avg_epoch_loss=1.295023\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=805 train loss <loss>=1.37846012115\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] Epoch[7] Batch [805]#011Speed: 1883.56 samples/sec#011loss=1.378460\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] Epoch[7] Batch[810] avg_epoch_loss=1.294525\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=810 train loss <loss>=1.21425397396\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] Epoch[7] Batch [810]#011Speed: 13539.84 samples/sec#011loss=1.214254\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] Epoch[7] Batch[815] avg_epoch_loss=1.296149\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=815 train loss <loss>=1.55959284306\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] Epoch[7] Batch [815]#011Speed: 14253.16 samples/sec#011loss=1.559593\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] Epoch[7] Batch[820] avg_epoch_loss=1.296280\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=820 train loss <loss>=1.31760457754\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] Epoch[7] Batch [820]#011Speed: 1780.61 samples/sec#011loss=1.317605\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] Epoch[7] Batch[825] avg_epoch_loss=1.298329\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=825 train loss <loss>=1.63486901522\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] Epoch[7] Batch [825]#011Speed: 14159.33 samples/sec#011loss=1.634869\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] Epoch[7] Batch[830] avg_epoch_loss=1.300086\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=830 train loss <loss>=1.59027810097\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] Epoch[7] Batch [830]#011Speed: 1655.06 samples/sec#011loss=1.590278\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] Epoch[7] Batch[835] avg_epoch_loss=1.300833\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=835 train loss <loss>=1.42496933937\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] Epoch[7] Batch [835]#011Speed: 14269.22 samples/sec#011loss=1.424969\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] Epoch[7] Batch[840] avg_epoch_loss=1.301781\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=840 train loss <loss>=1.46032927036\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] Epoch[7] Batch [840]#011Speed: 14329.24 samples/sec#011loss=1.460329\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] Epoch[7] Batch[845] avg_epoch_loss=1.302187\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=845 train loss <loss>=1.37039213181\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:18 INFO 140088046479168] Epoch[7] Batch [845]#011Speed: 1815.53 samples/sec#011loss=1.370392\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] Epoch[7] Batch[850] avg_epoch_loss=1.302953\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=850 train loss <loss>=1.43253719807\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] Epoch[7] Batch [850]#011Speed: 14370.36 samples/sec#011loss=1.432537\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] Epoch[7] Batch[855] avg_epoch_loss=1.302648\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=855 train loss <loss>=1.25080810785\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] Epoch[7] Batch [855]#011Speed: 1641.18 samples/sec#011loss=1.250808\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] Epoch[7] Batch[860] avg_epoch_loss=1.301411\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=860 train loss <loss>=1.08958171606\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] Epoch[7] Batch [860]#011Speed: 14309.99 samples/sec#011loss=1.089582\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] Epoch[7] Batch[865] avg_epoch_loss=1.300359\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=865 train loss <loss>=1.1193213582\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] Epoch[7] Batch [865]#011Speed: 14347.78 samples/sec#011loss=1.119321\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] Epoch[7] Batch[870] avg_epoch_loss=1.299923\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=870 train loss <loss>=1.22436639071\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] Epoch[7] Batch [870]#011Speed: 1858.31 samples/sec#011loss=1.224366\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] Epoch[7] Batch[875] avg_epoch_loss=1.299849\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=875 train loss <loss>=1.28698711395\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] Epoch[7] Batch [875]#011Speed: 14277.42 samples/sec#011loss=1.286987\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] Epoch[7] Batch[880] avg_epoch_loss=1.299227\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=880 train loss <loss>=1.19017696381\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] Epoch[7] Batch [880]#011Speed: 1746.64 samples/sec#011loss=1.190177\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] Epoch[7] Batch[885] avg_epoch_loss=1.299507\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=885 train loss <loss>=1.34892053604\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] Epoch[7] Batch [885]#011Speed: 13428.49 samples/sec#011loss=1.348921\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] Epoch[7] Batch[890] avg_epoch_loss=1.299312\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=890 train loss <loss>=1.26478993893\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] Epoch[7] Batch [890]#011Speed: 14320.83 samples/sec#011loss=1.264790\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] Epoch[7] Batch[895] avg_epoch_loss=1.298370\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=895 train loss <loss>=1.13043560982\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] Epoch[7] Batch [895]#011Speed: 2290.26 samples/sec#011loss=1.130436\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] Epoch[7] Batch[900] avg_epoch_loss=1.298999\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, batch=900 train loss <loss>=1.41165554523\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] Epoch[7] Batch [900]#011Speed: 13707.44 samples/sec#011loss=1.411656\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] processed a total of 57730 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15999.821901321411, \"sum\": 15999.821901321411, \"min\": 15999.821901321411}}, \"EndTime\": 1604320519.843807, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320503.843926}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] #throughput_metric: host=algo-1, train throughput=3608.13763488 records/second\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=7, train loss <loss>=1.30126878137\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:19 INFO 140088046479168] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] Epoch[8] Batch[0] avg_epoch_loss=0.724423\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=0.724422812462\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] Epoch[8] Batch[5] avg_epoch_loss=1.261636\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=1.26163615783\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] Epoch[8] Batch [5]#011Speed: 14327.87 samples/sec#011loss=1.261636\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] Epoch[8] Batch[10] avg_epoch_loss=1.237513\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=1.2085642457\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] Epoch[8] Batch [10]#011Speed: 14350.39 samples/sec#011loss=1.208564\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] Epoch[8] Batch[15] avg_epoch_loss=1.216153\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=15 train loss <loss>=1.16916232109\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] Epoch[8] Batch [15]#011Speed: 1785.76 samples/sec#011loss=1.169162\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] Epoch[8] Batch[20] avg_epoch_loss=1.207413\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=20 train loss <loss>=1.17944321632\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] Epoch[8] Batch [20]#011Speed: 14798.31 samples/sec#011loss=1.179443\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] Epoch[8] Batch[25] avg_epoch_loss=1.175998\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=25 train loss <loss>=1.04405647516\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] Epoch[8] Batch [25]#011Speed: 1655.88 samples/sec#011loss=1.044056\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] Epoch[8] Batch[30] avg_epoch_loss=1.163095\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=30 train loss <loss>=1.09600040913\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] Epoch[8] Batch [30]#011Speed: 13341.72 samples/sec#011loss=1.096000\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] Epoch[8] Batch[35] avg_epoch_loss=1.222454\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=35 train loss <loss>=1.59047825336\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] Epoch[8] Batch [35]#011Speed: 13758.16 samples/sec#011loss=1.590478\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] Epoch[8] Batch[40] avg_epoch_loss=1.234820\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=40 train loss <loss>=1.3238517642\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] Epoch[8] Batch [40]#011Speed: 1701.42 samples/sec#011loss=1.323852\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] Epoch[8] Batch[45] avg_epoch_loss=1.282817\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=45 train loss <loss>=1.67639921904\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] Epoch[8] Batch [45]#011Speed: 14488.25 samples/sec#011loss=1.676399\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] Epoch[8] Batch[50] avg_epoch_loss=1.326388\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=50 train loss <loss>=1.72723412514\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] Epoch[8] Batch [50]#011Speed: 13254.37 samples/sec#011loss=1.727234\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] Epoch[8] Batch[55] avg_epoch_loss=1.334849\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=55 train loss <loss>=1.42115113735\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] Epoch[8] Batch [55]#011Speed: 1819.34 samples/sec#011loss=1.421151\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] Epoch[8] Batch[60] avg_epoch_loss=1.328907\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=60 train loss <loss>=1.26236284971\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:20 INFO 140088046479168] Epoch[8] Batch [60]#011Speed: 13552.42 samples/sec#011loss=1.262363\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] Epoch[8] Batch[65] avg_epoch_loss=1.320702\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=65 train loss <loss>=1.2205997467\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] Epoch[8] Batch [65]#011Speed: 1607.31 samples/sec#011loss=1.220600\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] Epoch[8] Batch[70] avg_epoch_loss=1.305548\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=70 train loss <loss>=1.10551939011\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] Epoch[8] Batch [70]#011Speed: 11066.86 samples/sec#011loss=1.105519\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] Epoch[8] Batch[75] avg_epoch_loss=1.290239\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=75 train loss <loss>=1.07285119295\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] Epoch[8] Batch [75]#011Speed: 13890.00 samples/sec#011loss=1.072851\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] Epoch[8] Batch[80] avg_epoch_loss=1.290523\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=80 train loss <loss>=1.29483611584\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] Epoch[8] Batch [80]#011Speed: 1615.10 samples/sec#011loss=1.294836\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] Epoch[8] Batch[85] avg_epoch_loss=1.287819\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=85 train loss <loss>=1.24401526451\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] Epoch[8] Batch [85]#011Speed: 13346.23 samples/sec#011loss=1.244015\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] Epoch[8] Batch[90] avg_epoch_loss=1.278969\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=90 train loss <loss>=1.12674539089\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] Epoch[8] Batch [90]#011Speed: 13127.58 samples/sec#011loss=1.126745\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] Epoch[8] Batch[95] avg_epoch_loss=1.283026\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=95 train loss <loss>=1.35686564445\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] Epoch[8] Batch [95]#011Speed: 1686.95 samples/sec#011loss=1.356866\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] Epoch[8] Batch[100] avg_epoch_loss=1.281746\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=100 train loss <loss>=1.2571788311\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] Epoch[8] Batch [100]#011Speed: 13644.31 samples/sec#011loss=1.257179\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] Epoch[8] Batch[105] avg_epoch_loss=1.279748\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=105 train loss <loss>=1.23936872482\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] Epoch[8] Batch [105]#011Speed: 1677.53 samples/sec#011loss=1.239369\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] Epoch[8] Batch[110] avg_epoch_loss=1.277979\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=110 train loss <loss>=1.24048192501\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] Epoch[8] Batch [110]#011Speed: 13423.38 samples/sec#011loss=1.240482\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] Epoch[8] Batch[115] avg_epoch_loss=1.284709\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=115 train loss <loss>=1.43412883282\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:21 INFO 140088046479168] Epoch[8] Batch [115]#011Speed: 13238.42 samples/sec#011loss=1.434129\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] Epoch[8] Batch[120] avg_epoch_loss=1.282695\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=120 train loss <loss>=1.2359585166\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] Epoch[8] Batch [120]#011Speed: 1727.48 samples/sec#011loss=1.235959\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] Epoch[8] Batch[125] avg_epoch_loss=1.281777\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=125 train loss <loss>=1.2595702529\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] Epoch[8] Batch [125]#011Speed: 13358.85 samples/sec#011loss=1.259570\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] Epoch[8] Batch[130] avg_epoch_loss=1.286419\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=130 train loss <loss>=1.40338218212\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] Epoch[8] Batch [130]#011Speed: 1657.48 samples/sec#011loss=1.403382\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] Epoch[8] Batch[135] avg_epoch_loss=1.280952\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=135 train loss <loss>=1.13773343563\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] Epoch[8] Batch [135]#011Speed: 14282.58 samples/sec#011loss=1.137733\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] Epoch[8] Batch[140] avg_epoch_loss=1.270148\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=140 train loss <loss>=0.976275479794\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] Epoch[8] Batch [140]#011Speed: 13795.49 samples/sec#011loss=0.976275\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] Epoch[8] Batch[145] avg_epoch_loss=1.274732\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=145 train loss <loss>=1.40400671959\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] Epoch[8] Batch [145]#011Speed: 1528.35 samples/sec#011loss=1.404007\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] Epoch[8] Batch[150] avg_epoch_loss=1.268971\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=150 train loss <loss>=1.10074794292\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] Epoch[8] Batch [150]#011Speed: 14192.57 samples/sec#011loss=1.100748\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] Epoch[8] Batch[155] avg_epoch_loss=1.273370\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=155 train loss <loss>=1.40621033907\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] Epoch[8] Batch [155]#011Speed: 12698.83 samples/sec#011loss=1.406210\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] Epoch[8] Batch[160] avg_epoch_loss=1.278930\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=160 train loss <loss>=1.45240540504\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] Epoch[8] Batch [160]#011Speed: 1656.86 samples/sec#011loss=1.452405\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] Epoch[8] Batch[165] avg_epoch_loss=1.288909\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=165 train loss <loss>=1.61024069786\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] Epoch[8] Batch [165]#011Speed: 14331.84 samples/sec#011loss=1.610241\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] Epoch[8] Batch[170] avg_epoch_loss=1.292155\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=170 train loss <loss>=1.39992079735\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:22 INFO 140088046479168] Epoch[8] Batch [170]#011Speed: 1757.51 samples/sec#011loss=1.399921\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] Epoch[8] Batch[175] avg_epoch_loss=1.295896\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=175 train loss <loss>=1.42382845879\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] Epoch[8] Batch [175]#011Speed: 14320.83 samples/sec#011loss=1.423828\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] Epoch[8] Batch[180] avg_epoch_loss=1.292009\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=180 train loss <loss>=1.15517115593\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] Epoch[8] Batch [180]#011Speed: 14187.02 samples/sec#011loss=1.155171\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] Epoch[8] Batch[185] avg_epoch_loss=1.292794\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=185 train loss <loss>=1.32124037743\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] Epoch[8] Batch [185]#011Speed: 1675.18 samples/sec#011loss=1.321240\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] Epoch[8] Batch[190] avg_epoch_loss=1.290864\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=190 train loss <loss>=1.21904265881\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] Epoch[8] Batch [190]#011Speed: 13363.37 samples/sec#011loss=1.219043\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] Epoch[8] Batch[195] avg_epoch_loss=1.286392\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=195 train loss <loss>=1.11558049917\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] Epoch[8] Batch [195]#011Speed: 1766.39 samples/sec#011loss=1.115580\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] Epoch[8] Batch[200] avg_epoch_loss=1.287771\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=200 train loss <loss>=1.34181358814\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] Epoch[8] Batch [200]#011Speed: 14314.42 samples/sec#011loss=1.341814\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] Epoch[8] Batch[205] avg_epoch_loss=1.286037\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=205 train loss <loss>=1.21632326841\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] Epoch[8] Batch [205]#011Speed: 13395.38 samples/sec#011loss=1.216323\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] Epoch[8] Batch[210] avg_epoch_loss=1.286715\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=210 train loss <loss>=1.3146528244\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] Epoch[8] Batch [210]#011Speed: 1752.66 samples/sec#011loss=1.314653\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] Epoch[8] Batch[215] avg_epoch_loss=1.283901\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=215 train loss <loss>=1.16517328024\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] Epoch[8] Batch [215]#011Speed: 14221.60 samples/sec#011loss=1.165173\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] Epoch[8] Batch[220] avg_epoch_loss=1.280955\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=220 train loss <loss>=1.1536532402\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] Epoch[8] Batch [220]#011Speed: 1778.74 samples/sec#011loss=1.153653\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] Epoch[8] Batch[225] avg_epoch_loss=1.282682\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=225 train loss <loss>=1.35903680325\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] Epoch[8] Batch [225]#011Speed: 13562.83 samples/sec#011loss=1.359037\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] Epoch[8] Batch[230] avg_epoch_loss=1.278615\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=230 train loss <loss>=1.09477527142\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:23 INFO 140088046479168] Epoch[8] Batch [230]#011Speed: 13688.14 samples/sec#011loss=1.094775\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] Epoch[8] Batch[235] avg_epoch_loss=1.273547\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=235 train loss <loss>=1.03941326141\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] Epoch[8] Batch [235]#011Speed: 1717.49 samples/sec#011loss=1.039413\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] Epoch[8] Batch[240] avg_epoch_loss=1.274629\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=240 train loss <loss>=1.32568778992\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] Epoch[8] Batch [240]#011Speed: 14253.92 samples/sec#011loss=1.325688\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] Epoch[8] Batch[245] avg_epoch_loss=1.274349\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=245 train loss <loss>=1.26088067293\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] Epoch[8] Batch [245]#011Speed: 14269.22 samples/sec#011loss=1.260881\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] Epoch[8] Batch[250] avg_epoch_loss=1.273931\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=250 train loss <loss>=1.25336749554\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] Epoch[8] Batch [250]#011Speed: 1750.38 samples/sec#011loss=1.253367\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] Epoch[8] Batch[255] avg_epoch_loss=1.274990\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=255 train loss <loss>=1.32814748287\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] Epoch[8] Batch [255]#011Speed: 13309.57 samples/sec#011loss=1.328147\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] Epoch[8] Batch[260] avg_epoch_loss=1.275146\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=260 train loss <loss>=1.28312473297\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] Epoch[8] Batch [260]#011Speed: 1690.83 samples/sec#011loss=1.283125\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] Epoch[8] Batch[265] avg_epoch_loss=1.273450\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=265 train loss <loss>=1.18492232561\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] Epoch[8] Batch [265]#011Speed: 14175.63 samples/sec#011loss=1.184922\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] Epoch[8] Batch[270] avg_epoch_loss=1.268050\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=270 train loss <loss>=0.98076788187\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] Epoch[8] Batch [270]#011Speed: 14586.51 samples/sec#011loss=0.980768\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] Epoch[8] Batch[275] avg_epoch_loss=1.260122\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=275 train loss <loss>=0.830398499966\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] Epoch[8] Batch [275]#011Speed: 1856.98 samples/sec#011loss=0.830398\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] Epoch[8] Batch[280] avg_epoch_loss=1.251921\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=280 train loss <loss>=0.799237525463\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] Epoch[8] Batch [280]#011Speed: 13696.80 samples/sec#011loss=0.799238\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] Epoch[8] Batch[285] avg_epoch_loss=1.246667\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=285 train loss <loss>=0.951395249367\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] Epoch[8] Batch [285]#011Speed: 1786.46 samples/sec#011loss=0.951395\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] Epoch[8] Batch[290] avg_epoch_loss=1.242653\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=290 train loss <loss>=1.01303254366\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:24 INFO 140088046479168] Epoch[8] Batch [290]#011Speed: 14390.39 samples/sec#011loss=1.013033\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] Epoch[8] Batch[295] avg_epoch_loss=1.236760\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=295 train loss <loss>=0.893804776669\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] Epoch[8] Batch [295]#011Speed: 14280.00 samples/sec#011loss=0.893805\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] Epoch[8] Batch[300] avg_epoch_loss=1.234477\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=300 train loss <loss>=1.09934817553\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] Epoch[8] Batch [300]#011Speed: 1726.14 samples/sec#011loss=1.099348\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] Epoch[8] Batch[305] avg_epoch_loss=1.233766\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=305 train loss <loss>=1.19094566107\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] Epoch[8] Batch [305]#011Speed: 11067.31 samples/sec#011loss=1.190946\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] Epoch[8] Batch[310] avg_epoch_loss=1.244520\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=310 train loss <loss>=1.90268154144\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] Epoch[8] Batch [310]#011Speed: 1725.55 samples/sec#011loss=1.902682\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] Epoch[8] Batch[315] avg_epoch_loss=1.256552\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=315 train loss <loss>=2.00495877266\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] Epoch[8] Batch [315]#011Speed: 14281.98 samples/sec#011loss=2.004959\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] Epoch[8] Batch[320] avg_epoch_loss=1.262375\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=320 train loss <loss>=1.6303453207\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] Epoch[8] Batch [320]#011Speed: 14232.91 samples/sec#011loss=1.630345\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] Epoch[8] Batch[325] avg_epoch_loss=1.266034\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=325 train loss <loss>=1.50097792149\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] Epoch[8] Batch [325]#011Speed: 1811.48 samples/sec#011loss=1.500978\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] Epoch[8] Batch[330] avg_epoch_loss=1.271079\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=330 train loss <loss>=1.59995992184\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] Epoch[8] Batch [330]#011Speed: 14287.60 samples/sec#011loss=1.599960\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] Epoch[8] Batch[335] avg_epoch_loss=1.274272\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=335 train loss <loss>=1.48568422794\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] Epoch[8] Batch [335]#011Speed: 1681.27 samples/sec#011loss=1.485684\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] Epoch[8] Batch[340] avg_epoch_loss=1.283323\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=340 train loss <loss>=1.89156696796\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] Epoch[8] Batch [340]#011Speed: 14243.78 samples/sec#011loss=1.891567\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] Epoch[8] Batch[345] avg_epoch_loss=1.283724\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=345 train loss <loss>=1.31102466583\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:25 INFO 140088046479168] Epoch[8] Batch [345]#011Speed: 13828.75 samples/sec#011loss=1.311025\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] Epoch[8] Batch[350] avg_epoch_loss=1.284250\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=350 train loss <loss>=1.3206520319\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] Epoch[8] Batch [350]#011Speed: 1801.45 samples/sec#011loss=1.320652\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] Epoch[8] Batch[355] avg_epoch_loss=1.280961\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=355 train loss <loss>=1.05008307695\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] Epoch[8] Batch [355]#011Speed: 14278.03 samples/sec#011loss=1.050083\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] Epoch[8] Batch[360] avg_epoch_loss=1.280611\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=360 train loss <loss>=1.25572531223\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] Epoch[8] Batch [360]#011Speed: 1735.40 samples/sec#011loss=1.255725\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] Epoch[8] Batch[365] avg_epoch_loss=1.279615\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=365 train loss <loss>=1.20765478611\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] Epoch[8] Batch [365]#011Speed: 14329.86 samples/sec#011loss=1.207655\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] Epoch[8] Batch[370] avg_epoch_loss=1.280635\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=370 train loss <loss>=1.35531554222\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] Epoch[8] Batch [370]#011Speed: 14205.79 samples/sec#011loss=1.355316\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] Epoch[8] Batch[375] avg_epoch_loss=1.278122\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=375 train loss <loss>=1.09169334173\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] Epoch[8] Batch [375]#011Speed: 1803.38 samples/sec#011loss=1.091693\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] Epoch[8] Batch[380] avg_epoch_loss=1.277299\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=380 train loss <loss>=1.21539369822\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] Epoch[8] Batch [380]#011Speed: 14225.97 samples/sec#011loss=1.215394\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] Epoch[8] Batch[385] avg_epoch_loss=1.276136\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=385 train loss <loss>=1.18753452301\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] Epoch[8] Batch [385]#011Speed: 1760.14 samples/sec#011loss=1.187535\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] Epoch[8] Batch[390] avg_epoch_loss=1.274911\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=390 train loss <loss>=1.1803178668\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] Epoch[8] Batch [390]#011Speed: 13217.17 samples/sec#011loss=1.180318\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] Epoch[8] Batch[395] avg_epoch_loss=1.274049\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=395 train loss <loss>=1.20664145947\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] Epoch[8] Batch [395]#011Speed: 14390.39 samples/sec#011loss=1.206641\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] Epoch[8] Batch[400] avg_epoch_loss=1.271389\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=400 train loss <loss>=1.06071413755\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] Epoch[8] Batch [400]#011Speed: 1754.43 samples/sec#011loss=1.060714\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] Epoch[8] Batch[405] avg_epoch_loss=1.268253\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=405 train loss <loss>=1.01674146652\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:26 INFO 140088046479168] Epoch[8] Batch [405]#011Speed: 14388.54 samples/sec#011loss=1.016741\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] Epoch[8] Batch[410] avg_epoch_loss=1.265378\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=410 train loss <loss>=1.03191853762\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] Epoch[8] Batch [410]#011Speed: 1710.13 samples/sec#011loss=1.031919\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] Epoch[8] Batch[415] avg_epoch_loss=1.261494\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=415 train loss <loss>=0.942216408253\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] Epoch[8] Batch [415]#011Speed: 14232.45 samples/sec#011loss=0.942216\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] Epoch[8] Batch[420] avg_epoch_loss=1.257622\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=420 train loss <loss>=0.93549284935\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] Epoch[8] Batch [420]#011Speed: 14402.13 samples/sec#011loss=0.935493\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] Epoch[8] Batch[425] avg_epoch_loss=1.254172\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=425 train loss <loss>=0.963702070713\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] Epoch[8] Batch [425]#011Speed: 1745.75 samples/sec#011loss=0.963702\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] Epoch[8] Batch[430] avg_epoch_loss=1.251903\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=430 train loss <loss>=1.05855777264\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] Epoch[8] Batch [430]#011Speed: 14235.62 samples/sec#011loss=1.058558\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] Epoch[8] Batch[435] avg_epoch_loss=1.248259\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=435 train loss <loss>=0.934191524982\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] Epoch[8] Batch [435]#011Speed: 14175.03 samples/sec#011loss=0.934192\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] Epoch[8] Batch[440] avg_epoch_loss=1.249718\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=440 train loss <loss>=1.37689664364\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] Epoch[8] Batch [440]#011Speed: 1653.15 samples/sec#011loss=1.376897\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] Epoch[8] Batch[445] avg_epoch_loss=1.251860\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=445 train loss <loss>=1.44079267979\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] Epoch[8] Batch [445]#011Speed: 14193.17 samples/sec#011loss=1.440793\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] Epoch[8] Batch[450] avg_epoch_loss=1.252074\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=450 train loss <loss>=1.27115987539\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] Epoch[8] Batch [450]#011Speed: 1761.42 samples/sec#011loss=1.271160\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] Epoch[8] Batch[455] avg_epoch_loss=1.250118\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=455 train loss <loss>=1.07368258238\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] Epoch[8] Batch [455]#011Speed: 14307.40 samples/sec#011loss=1.073683\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] Epoch[8] Batch[460] avg_epoch_loss=1.249084\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=460 train loss <loss>=1.15475107431\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:27 INFO 140088046479168] Epoch[8] Batch [460]#011Speed: 13727.91 samples/sec#011loss=1.154751\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] Epoch[8] Batch[465] avg_epoch_loss=1.249175\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=465 train loss <loss>=1.25759978294\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] Epoch[8] Batch [465]#011Speed: 1723.29 samples/sec#011loss=1.257600\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] Epoch[8] Batch[470] avg_epoch_loss=1.250617\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=470 train loss <loss>=1.38499964476\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] Epoch[8] Batch [470]#011Speed: 13385.77 samples/sec#011loss=1.385000\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] Epoch[8] Batch[475] avg_epoch_loss=1.250789\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=475 train loss <loss>=1.26701486111\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] Epoch[8] Batch [475]#011Speed: 1861.55 samples/sec#011loss=1.267015\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] Epoch[8] Batch[480] avg_epoch_loss=1.249526\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=480 train loss <loss>=1.12932070494\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] Epoch[8] Batch [480]#011Speed: 11035.55 samples/sec#011loss=1.129321\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] Epoch[8] Batch[485] avg_epoch_loss=1.246592\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=485 train loss <loss>=0.964347660542\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] Epoch[8] Batch [485]#011Speed: 13142.75 samples/sec#011loss=0.964348\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] Epoch[8] Batch[490] avg_epoch_loss=1.247380\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=490 train loss <loss>=1.32391742468\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] Epoch[8] Batch [490]#011Speed: 1693.73 samples/sec#011loss=1.323917\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] Epoch[8] Batch[495] avg_epoch_loss=1.244911\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=495 train loss <loss>=1.00241758823\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] Epoch[8] Batch [495]#011Speed: 13282.97 samples/sec#011loss=1.002418\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] Epoch[8] Batch[500] avg_epoch_loss=1.243125\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=500 train loss <loss>=1.06602722406\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] Epoch[8] Batch [500]#011Speed: 1698.67 samples/sec#011loss=1.066027\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] Epoch[8] Batch[505] avg_epoch_loss=1.240913\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=505 train loss <loss>=1.01927855015\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] Epoch[8] Batch [505]#011Speed: 11222.12 samples/sec#011loss=1.019279\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] Epoch[8] Batch[510] avg_epoch_loss=1.239241\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=510 train loss <loss>=1.0700404048\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] Epoch[8] Batch [510]#011Speed: 13126.68 samples/sec#011loss=1.070040\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] Epoch[8] Batch[515] avg_epoch_loss=1.238731\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=515 train loss <loss>=1.18659137487\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] Epoch[8] Batch [515]#011Speed: 1744.44 samples/sec#011loss=1.186591\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] Epoch[8] Batch[520] avg_epoch_loss=1.242475\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=520 train loss <loss>=1.62884333134\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:28 INFO 140088046479168] Epoch[8] Batch [520]#011Speed: 13118.60 samples/sec#011loss=1.628843\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] Epoch[8] Batch[525] avg_epoch_loss=1.243124\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=525 train loss <loss>=1.31073328257\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] Epoch[8] Batch [525]#011Speed: 1774.47 samples/sec#011loss=1.310733\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] Epoch[8] Batch[530] avg_epoch_loss=1.244787\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=530 train loss <loss>=1.41969736814\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] Epoch[8] Batch [530]#011Speed: 13274.16 samples/sec#011loss=1.419697\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] Epoch[8] Batch[535] avg_epoch_loss=1.252428\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=535 train loss <loss>=2.0640011549\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] Epoch[8] Batch [535]#011Speed: 13305.61 samples/sec#011loss=2.064001\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] Epoch[8] Batch[540] avg_epoch_loss=1.257535\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=540 train loss <loss>=1.80494220257\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] Epoch[8] Batch [540]#011Speed: 1608.40 samples/sec#011loss=1.804942\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] Epoch[8] Batch[545] avg_epoch_loss=1.266234\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=545 train loss <loss>=2.20750296116\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] Epoch[8] Batch [545]#011Speed: 14311.21 samples/sec#011loss=2.207503\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] Epoch[8] Batch[550] avg_epoch_loss=1.274351\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=550 train loss <loss>=2.16065986156\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] Epoch[8] Batch [550]#011Speed: 1657.37 samples/sec#011loss=2.160660\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] Epoch[8] Batch[555] avg_epoch_loss=1.278845\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=555 train loss <loss>=1.77410223484\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] Epoch[8] Batch [555]#011Speed: 14261.64 samples/sec#011loss=1.774102\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] Epoch[8] Batch[560] avg_epoch_loss=1.285224\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=560 train loss <loss>=1.99463288784\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] Epoch[8] Batch [560]#011Speed: 14418.84 samples/sec#011loss=1.994633\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] Epoch[8] Batch[565] avg_epoch_loss=1.290290\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=565 train loss <loss>=1.85869252682\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] Epoch[8] Batch [565]#011Speed: 1758.77 samples/sec#011loss=1.858693\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] Epoch[8] Batch[570] avg_epoch_loss=1.295860\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=570 train loss <loss>=1.92633748055\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:29 INFO 140088046479168] Epoch[8] Batch [570]#011Speed: 13257.12 samples/sec#011loss=1.926337\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] Epoch[8] Batch[575] avg_epoch_loss=1.300658\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=575 train loss <loss>=1.84854393005\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] Epoch[8] Batch [575]#011Speed: 1836.88 samples/sec#011loss=1.848544\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] Epoch[8] Batch[580] avg_epoch_loss=1.301508\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=580 train loss <loss>=1.39949672222\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] Epoch[8] Batch [580]#011Speed: 12837.05 samples/sec#011loss=1.399497\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] Epoch[8] Batch[585] avg_epoch_loss=1.303274\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=585 train loss <loss>=1.50851871967\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] Epoch[8] Batch [585]#011Speed: 14109.32 samples/sec#011loss=1.508519\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] Epoch[8] Batch[590] avg_epoch_loss=1.303831\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=590 train loss <loss>=1.36904006004\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] Epoch[8] Batch [590]#011Speed: 1659.89 samples/sec#011loss=1.369040\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] Epoch[8] Batch[595] avg_epoch_loss=1.302637\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=595 train loss <loss>=1.16154021025\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] Epoch[8] Batch [595]#011Speed: 10644.01 samples/sec#011loss=1.161540\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] Epoch[8] Batch[600] avg_epoch_loss=1.304210\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=600 train loss <loss>=1.49171340466\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] Epoch[8] Batch [600]#011Speed: 1604.90 samples/sec#011loss=1.491713\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] Epoch[8] Batch[605] avg_epoch_loss=1.303750\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=605 train loss <loss>=1.24845507145\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] Epoch[8] Batch [605]#011Speed: 13746.32 samples/sec#011loss=1.248455\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] Epoch[8] Batch[610] avg_epoch_loss=1.303359\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=610 train loss <loss>=1.25597071648\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] Epoch[8] Batch [610]#011Speed: 13523.20 samples/sec#011loss=1.255971\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] Epoch[8] Batch[615] avg_epoch_loss=1.303305\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=615 train loss <loss>=1.29674084187\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] Epoch[8] Batch [615]#011Speed: 1800.82 samples/sec#011loss=1.296741\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] Epoch[8] Batch[620] avg_epoch_loss=1.302603\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=620 train loss <loss>=1.21609634161\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] Epoch[8] Batch [620]#011Speed: 12733.16 samples/sec#011loss=1.216096\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] Epoch[8] Batch[625] avg_epoch_loss=1.304172\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=625 train loss <loss>=1.49896569252\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] Epoch[8] Batch [625]#011Speed: 1851.52 samples/sec#011loss=1.498966\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] Epoch[8] Batch[630] avg_epoch_loss=1.303904\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=630 train loss <loss>=1.27042386532\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] Epoch[8] Batch [630]#011Speed: 13213.27 samples/sec#011loss=1.270424\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] Epoch[8] Batch[635] avg_epoch_loss=1.302290\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=635 train loss <loss>=1.09855254889\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:30 INFO 140088046479168] Epoch[8] Batch [635]#011Speed: 13246.13 samples/sec#011loss=1.098553\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] Epoch[8] Batch[640] avg_epoch_loss=1.303488\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=640 train loss <loss>=1.45593457222\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] Epoch[8] Batch [640]#011Speed: 1720.95 samples/sec#011loss=1.455935\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] Epoch[8] Batch[645] avg_epoch_loss=1.303417\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=645 train loss <loss>=1.29432384968\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] Epoch[8] Batch [645]#011Speed: 13284.02 samples/sec#011loss=1.294324\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] Epoch[8] Batch[650] avg_epoch_loss=1.301791\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=650 train loss <loss>=1.09160968065\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] Epoch[8] Batch [650]#011Speed: 1685.61 samples/sec#011loss=1.091610\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] Epoch[8] Batch[655] avg_epoch_loss=1.300640\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=655 train loss <loss>=1.15088970661\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] Epoch[8] Batch [655]#011Speed: 13242.73 samples/sec#011loss=1.150890\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] Epoch[8] Batch[660] avg_epoch_loss=1.299705\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=660 train loss <loss>=1.17697336674\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] Epoch[8] Batch [660]#011Speed: 13238.42 samples/sec#011loss=1.176973\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] Epoch[8] Batch[665] avg_epoch_loss=1.298577\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=665 train loss <loss>=1.1495126009\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] Epoch[8] Batch [665]#011Speed: 1689.66 samples/sec#011loss=1.149513\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] Epoch[8] Batch[670] avg_epoch_loss=1.298904\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=670 train loss <loss>=1.34246556759\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] Epoch[8] Batch [670]#011Speed: 13470.81 samples/sec#011loss=1.342466\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] Epoch[8] Batch[675] avg_epoch_loss=1.297361\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=675 train loss <loss>=1.09020342827\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] Epoch[8] Batch [675]#011Speed: 1786.31 samples/sec#011loss=1.090203\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] Epoch[8] Batch[680] avg_epoch_loss=1.297158\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=680 train loss <loss>=1.26969450712\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] Epoch[8] Batch [680]#011Speed: 13708.00 samples/sec#011loss=1.269695\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] Epoch[8] Batch[685] avg_epoch_loss=1.298164\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=685 train loss <loss>=1.43526169062\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:31 INFO 140088046479168] Epoch[8] Batch [685]#011Speed: 14363.29 samples/sec#011loss=1.435262\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] Epoch[8] Batch[690] avg_epoch_loss=1.296919\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=690 train loss <loss>=1.12605537176\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] Epoch[8] Batch [690]#011Speed: 1856.21 samples/sec#011loss=1.126055\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] Epoch[8] Batch[695] avg_epoch_loss=1.297266\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=695 train loss <loss>=1.34518659115\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] Epoch[8] Batch [695]#011Speed: 14313.81 samples/sec#011loss=1.345187\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] Epoch[8] Batch[700] avg_epoch_loss=1.297276\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=700 train loss <loss>=1.29868764877\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] Epoch[8] Batch [700]#011Speed: 1808.80 samples/sec#011loss=1.298688\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] Epoch[8] Batch[705] avg_epoch_loss=1.298806\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=705 train loss <loss>=1.5133023262\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] Epoch[8] Batch [705]#011Speed: 12943.51 samples/sec#011loss=1.513302\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] Epoch[8] Batch[710] avg_epoch_loss=1.299250\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=710 train loss <loss>=1.3619368434\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] Epoch[8] Batch [710]#011Speed: 12942.39 samples/sec#011loss=1.361937\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] Epoch[8] Batch[715] avg_epoch_loss=1.300702\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=715 train loss <loss>=1.50718502998\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] Epoch[8] Batch [715]#011Speed: 1614.81 samples/sec#011loss=1.507185\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] Epoch[8] Batch[720] avg_epoch_loss=1.300106\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=720 train loss <loss>=1.21476951838\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] Epoch[8] Batch [720]#011Speed: 14225.97 samples/sec#011loss=1.214770\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] Epoch[8] Batch[725] avg_epoch_loss=1.302415\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=725 train loss <loss>=1.63546316624\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] Epoch[8] Batch [725]#011Speed: 1691.83 samples/sec#011loss=1.635463\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] Epoch[8] Batch[730] avg_epoch_loss=1.305815\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=730 train loss <loss>=1.79936842918\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] Epoch[8] Batch [730]#011Speed: 14285.78 samples/sec#011loss=1.799368\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] Epoch[8] Batch[735] avg_epoch_loss=1.305415\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=735 train loss <loss>=1.24693882465\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] Epoch[8] Batch [735]#011Speed: 14261.49 samples/sec#011loss=1.246939\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] Epoch[8] Batch[740] avg_epoch_loss=1.304379\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=740 train loss <loss>=1.1519600153\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] Epoch[8] Batch [740]#011Speed: 1700.09 samples/sec#011loss=1.151960\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] Epoch[8] Batch[745] avg_epoch_loss=1.303526\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=745 train loss <loss>=1.1770334959\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:32 INFO 140088046479168] Epoch[8] Batch [745]#011Speed: 13726.22 samples/sec#011loss=1.177033\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] Epoch[8] Batch[750] avg_epoch_loss=1.302361\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=750 train loss <loss>=1.12854408026\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] Epoch[8] Batch [750]#011Speed: 1677.39 samples/sec#011loss=1.128544\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] Epoch[8] Batch[755] avg_epoch_loss=1.300937\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=755 train loss <loss>=1.08711900711\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] Epoch[8] Batch [755]#011Speed: 14338.73 samples/sec#011loss=1.087119\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] Epoch[8] Batch[760] avg_epoch_loss=1.300130\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=760 train loss <loss>=1.17811834812\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] Epoch[8] Batch [760]#011Speed: 14122.38 samples/sec#011loss=1.178118\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] Epoch[8] Batch[765] avg_epoch_loss=1.299615\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=765 train loss <loss>=1.22117267847\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] Epoch[8] Batch [765]#011Speed: 1772.76 samples/sec#011loss=1.221173\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] Epoch[8] Batch[770] avg_epoch_loss=1.298015\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=770 train loss <loss>=1.05298261642\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] Epoch[8] Batch [770]#011Speed: 14276.81 samples/sec#011loss=1.052983\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] Epoch[8] Batch[775] avg_epoch_loss=1.297182\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=775 train loss <loss>=1.16870617867\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] Epoch[8] Batch [775]#011Speed: 14150.52 samples/sec#011loss=1.168706\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] Epoch[8] Batch[780] avg_epoch_loss=1.295809\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=780 train loss <loss>=1.08265471458\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] Epoch[8] Batch [780]#011Speed: 1703.25 samples/sec#011loss=1.082655\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] Epoch[8] Batch[785] avg_epoch_loss=1.295927\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=785 train loss <loss>=1.31444208622\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] Epoch[8] Batch [785]#011Speed: 14391.78 samples/sec#011loss=1.314442\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] Epoch[8] Batch[790] avg_epoch_loss=1.296618\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=790 train loss <loss>=1.4052448988\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] Epoch[8] Batch [790]#011Speed: 1711.31 samples/sec#011loss=1.405245\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] Epoch[8] Batch[795] avg_epoch_loss=1.296745\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=795 train loss <loss>=1.31676015854\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] Epoch[8] Batch [795]#011Speed: 13975.04 samples/sec#011loss=1.316760\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] Epoch[8] Batch[800] avg_epoch_loss=1.295398\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=800 train loss <loss>=1.08092619181\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:33 INFO 140088046479168] Epoch[8] Batch [800]#011Speed: 13989.03 samples/sec#011loss=1.080926\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] Epoch[8] Batch[805] avg_epoch_loss=1.296517\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=805 train loss <loss>=1.47586621046\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] Epoch[8] Batch [805]#011Speed: 1490.33 samples/sec#011loss=1.475866\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] Epoch[8] Batch[810] avg_epoch_loss=1.296066\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=810 train loss <loss>=1.22333015203\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] Epoch[8] Batch [810]#011Speed: 13695.69 samples/sec#011loss=1.223330\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] Epoch[8] Batch[815] avg_epoch_loss=1.295879\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=815 train loss <loss>=1.26560031176\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] Epoch[8] Batch [815]#011Speed: 1631.89 samples/sec#011loss=1.265600\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] Epoch[8] Batch[820] avg_epoch_loss=1.294961\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=820 train loss <loss>=1.1451539278\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] Epoch[8] Batch [820]#011Speed: 14353.76 samples/sec#011loss=1.145154\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] Epoch[8] Batch[825] avg_epoch_loss=1.294518\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=825 train loss <loss>=1.22174448967\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] Epoch[8] Batch [825]#011Speed: 14442.42 samples/sec#011loss=1.221744\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] Epoch[8] Batch[830] avg_epoch_loss=1.293746\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=830 train loss <loss>=1.1662211895\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] Epoch[8] Batch [830]#011Speed: 1511.16 samples/sec#011loss=1.166221\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] Epoch[8] Batch[835] avg_epoch_loss=1.292474\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=835 train loss <loss>=1.08105191588\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] Epoch[8] Batch [835]#011Speed: 13308.91 samples/sec#011loss=1.081052\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] Epoch[8] Batch[840] avg_epoch_loss=1.290608\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=840 train loss <loss>=0.978561162949\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] Epoch[8] Batch [840]#011Speed: 14244.99 samples/sec#011loss=0.978561\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] Epoch[8] Batch[845] avg_epoch_loss=1.288967\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=845 train loss <loss>=1.01291911602\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] Epoch[8] Batch [845]#011Speed: 1745.16 samples/sec#011loss=1.012919\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] Epoch[8] Batch[850] avg_epoch_loss=1.288131\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=850 train loss <loss>=1.1466755271\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] Epoch[8] Batch [850]#011Speed: 14024.11 samples/sec#011loss=1.146676\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] Epoch[8] Batch[855] avg_epoch_loss=1.286985\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=855 train loss <loss>=1.09200571775\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] Epoch[8] Batch [855]#011Speed: 1680.78 samples/sec#011loss=1.092006\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] Epoch[8] Batch[860] avg_epoch_loss=1.283953\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=860 train loss <loss>=0.764959490299\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:34 INFO 140088046479168] Epoch[8] Batch [860]#011Speed: 14179.38 samples/sec#011loss=0.764959\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] Epoch[8] Batch[865] avg_epoch_loss=1.283165\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=865 train loss <loss>=1.14744025469\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] Epoch[8] Batch [865]#011Speed: 14087.55 samples/sec#011loss=1.147440\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] Epoch[8] Batch[870] avg_epoch_loss=1.282702\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=870 train loss <loss>=1.20238950253\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] Epoch[8] Batch [870]#011Speed: 1707.87 samples/sec#011loss=1.202390\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] Epoch[8] Batch[875] avg_epoch_loss=1.280506\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=875 train loss <loss>=0.89803789854\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] Epoch[8] Batch [875]#011Speed: 13194.17 samples/sec#011loss=0.898038\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] Epoch[8] Batch[880] avg_epoch_loss=1.278570\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=880 train loss <loss>=0.939408123493\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] Epoch[8] Batch [880]#011Speed: 1541.08 samples/sec#011loss=0.939408\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] Epoch[8] Batch[885] avg_epoch_loss=1.277117\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=885 train loss <loss>=1.02108207941\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] Epoch[8] Batch [885]#011Speed: 13359.52 samples/sec#011loss=1.021082\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] Epoch[8] Batch[890] avg_epoch_loss=1.275741\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=890 train loss <loss>=1.03195838928\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] Epoch[8] Batch [890]#011Speed: 13665.29 samples/sec#011loss=1.031958\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] Epoch[8] Batch[895] avg_epoch_loss=1.273966\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, batch=895 train loss <loss>=0.957673883438\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] Epoch[8] Batch [895]#011Speed: 2856.78 samples/sec#011loss=0.957674\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] processed a total of 57586 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15777.063131332397, \"sum\": 15777.063131332397, \"min\": 15777.063131332397}}, \"EndTime\": 1604320535.621469, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320519.843891}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] #throughput_metric: host=algo-1, train throughput=3649.95707385 records/second\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=8, train loss <loss>=1.27178214553\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] Saved checkpoint to \"/opt/ml/model/state_5610f513-6662-4342-9f20-fa56c5904cca-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 4.812955856323242, \"sum\": 4.812955856323242, \"min\": 4.812955856323242}}, \"EndTime\": 1604320535.626892, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320535.621543}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] Epoch[9] Batch[0] avg_epoch_loss=0.957712\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=0.957712054253\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] Epoch[9] Batch[5] avg_epoch_loss=1.055289\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=1.05528918902\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] Epoch[9] Batch [5]#011Speed: 14298.41 samples/sec#011loss=1.055289\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] Epoch[9] Batch[10] avg_epoch_loss=1.152076\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=1.26821956635\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:35 INFO 140088046479168] Epoch[9] Batch [10]#011Speed: 13426.88 samples/sec#011loss=1.268220\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] Epoch[9] Batch[15] avg_epoch_loss=1.441818\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=15 train loss <loss>=2.07925131321\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] Epoch[9] Batch [15]#011Speed: 1666.25 samples/sec#011loss=2.079251\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] Epoch[9] Batch[20] avg_epoch_loss=1.445571\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=20 train loss <loss>=1.45757985115\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] Epoch[9] Batch [20]#011Speed: 14239.40 samples/sec#011loss=1.457580\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] Epoch[9] Batch[25] avg_epoch_loss=1.512652\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=25 train loss <loss>=1.79439246655\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] Epoch[9] Batch [25]#011Speed: 1830.05 samples/sec#011loss=1.794392\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] Epoch[9] Batch[30] avg_epoch_loss=1.609859\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=30 train loss <loss>=2.11533844471\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] Epoch[9] Batch [30]#011Speed: 13246.65 samples/sec#011loss=2.115338\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] Epoch[9] Batch[35] avg_epoch_loss=1.642534\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=35 train loss <loss>=1.84511711597\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] Epoch[9] Batch [35]#011Speed: 14417.75 samples/sec#011loss=1.845117\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] Epoch[9] Batch[40] avg_epoch_loss=1.663675\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=40 train loss <loss>=1.8158921957\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] Epoch[9] Batch [40]#011Speed: 1581.15 samples/sec#011loss=1.815892\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] Epoch[9] Batch[45] avg_epoch_loss=1.679304\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=45 train loss <loss>=1.8074630022\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] Epoch[9] Batch [45]#011Speed: 13120.14 samples/sec#011loss=1.807463\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] Epoch[9] Batch[50] avg_epoch_loss=1.639004\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=50 train loss <loss>=1.26823593378\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] Epoch[9] Batch [50]#011Speed: 1651.81 samples/sec#011loss=1.268236\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] Epoch[9] Batch[55] avg_epoch_loss=1.627029\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=55 train loss <loss>=1.50488427877\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] Epoch[9] Batch [55]#011Speed: 14166.81 samples/sec#011loss=1.504884\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] Epoch[9] Batch[60] avg_epoch_loss=1.589027\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=60 train loss <loss>=1.16340579987\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] Epoch[9] Batch [60]#011Speed: 14091.99 samples/sec#011loss=1.163406\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] Epoch[9] Batch[65] avg_epoch_loss=1.582681\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=65 train loss <loss>=1.50526640415\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] Epoch[9] Batch [65]#011Speed: 1750.28 samples/sec#011loss=1.505266\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] Epoch[9] Batch[70] avg_epoch_loss=1.559740\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=70 train loss <loss>=1.25691498518\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] Epoch[9] Batch [70]#011Speed: 13306.14 samples/sec#011loss=1.256915\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] Epoch[9] Batch[75] avg_epoch_loss=1.544100\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=75 train loss <loss>=1.32201859951\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:36 INFO 140088046479168] Epoch[9] Batch [75]#011Speed: 13186.14 samples/sec#011loss=1.322019\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] Epoch[9] Batch[80] avg_epoch_loss=1.530274\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=80 train loss <loss>=1.32011594772\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] Epoch[9] Batch [80]#011Speed: 1694.52 samples/sec#011loss=1.320116\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] Epoch[9] Batch[85] avg_epoch_loss=1.530506\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=85 train loss <loss>=1.5342669487\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] Epoch[9] Batch [85]#011Speed: 13482.85 samples/sec#011loss=1.534267\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] Epoch[9] Batch[90] avg_epoch_loss=1.521701\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=90 train loss <loss>=1.37025468349\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] Epoch[9] Batch [90]#011Speed: 1859.80 samples/sec#011loss=1.370255\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] Epoch[9] Batch[95] avg_epoch_loss=1.526208\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=95 train loss <loss>=1.60822343826\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] Epoch[9] Batch [95]#011Speed: 10798.41 samples/sec#011loss=1.608223\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] Epoch[9] Batch[100] avg_epoch_loss=1.511487\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=100 train loss <loss>=1.22885715961\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] Epoch[9] Batch [100]#011Speed: 14295.36 samples/sec#011loss=1.228857\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] Epoch[9] Batch[105] avg_epoch_loss=1.495297\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=105 train loss <loss>=1.16824871302\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] Epoch[9] Batch [105]#011Speed: 1655.04 samples/sec#011loss=1.168249\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] Epoch[9] Batch[110] avg_epoch_loss=1.481168\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=110 train loss <loss>=1.18164541721\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] Epoch[9] Batch [110]#011Speed: 13562.83 samples/sec#011loss=1.181645\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] Epoch[9] Batch[115] avg_epoch_loss=1.475154\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=115 train loss <loss>=1.34164383411\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] Epoch[9] Batch [115]#011Speed: 1853.30 samples/sec#011loss=1.341644\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] Epoch[9] Batch[120] avg_epoch_loss=1.468538\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=120 train loss <loss>=1.31503725052\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] Epoch[9] Batch [120]#011Speed: 14283.04 samples/sec#011loss=1.315037\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] Epoch[9] Batch[125] avg_epoch_loss=1.466099\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=125 train loss <loss>=1.40708273649\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:37 INFO 140088046479168] Epoch[9] Batch [125]#011Speed: 13919.10 samples/sec#011loss=1.407083\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] Epoch[9] Batch[130] avg_epoch_loss=1.452749\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=130 train loss <loss>=1.11631919146\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] Epoch[9] Batch [130]#011Speed: 1729.62 samples/sec#011loss=1.116319\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] Epoch[9] Batch[135] avg_epoch_loss=1.444049\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=135 train loss <loss>=1.21612231731\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] Epoch[9] Batch [135]#011Speed: 14279.85 samples/sec#011loss=1.216122\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] Epoch[9] Batch[140] avg_epoch_loss=1.442195\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=140 train loss <loss>=1.39175856113\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] Epoch[9] Batch [140]#011Speed: 1624.14 samples/sec#011loss=1.391759\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] Epoch[9] Batch[145] avg_epoch_loss=1.443499\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=145 train loss <loss>=1.48025989532\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] Epoch[9] Batch [145]#011Speed: 14326.80 samples/sec#011loss=1.480260\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] Epoch[9] Batch[150] avg_epoch_loss=1.452597\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=150 train loss <loss>=1.71827025414\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] Epoch[9] Batch [150]#011Speed: 13160.02 samples/sec#011loss=1.718270\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] Epoch[9] Batch[155] avg_epoch_loss=1.460993\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=155 train loss <loss>=1.71454815865\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] Epoch[9] Batch [155]#011Speed: 1720.10 samples/sec#011loss=1.714548\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] Epoch[9] Batch[160] avg_epoch_loss=1.463328\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=160 train loss <loss>=1.53617602587\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] Epoch[9] Batch [160]#011Speed: 14276.20 samples/sec#011loss=1.536176\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] Epoch[9] Batch[165] avg_epoch_loss=1.475865\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=165 train loss <loss>=1.87955126762\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] Epoch[9] Batch [165]#011Speed: 1724.95 samples/sec#011loss=1.879551\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] Epoch[9] Batch[170] avg_epoch_loss=1.477365\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=170 train loss <loss>=1.52718586922\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] Epoch[9] Batch [170]#011Speed: 13482.17 samples/sec#011loss=1.527186\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] Epoch[9] Batch[175] avg_epoch_loss=1.475915\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=175 train loss <loss>=1.42633037567\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] Epoch[9] Batch [175]#011Speed: 1676.90 samples/sec#011loss=1.426330\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] Epoch[9] Batch[180] avg_epoch_loss=1.471446\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=180 train loss <loss>=1.31413772106\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] Epoch[9] Batch [180]#011Speed: 14306.79 samples/sec#011loss=1.314138\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] Epoch[9] Batch[185] avg_epoch_loss=1.468067\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=185 train loss <loss>=1.34573669434\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:38 INFO 140088046479168] Epoch[9] Batch [185]#011Speed: 14385.92 samples/sec#011loss=1.345737\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] Epoch[9] Batch[190] avg_epoch_loss=1.459874\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=190 train loss <loss>=1.15508705378\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] Epoch[9] Batch [190]#011Speed: 1770.56 samples/sec#011loss=1.155087\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] Epoch[9] Batch[195] avg_epoch_loss=1.455948\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=195 train loss <loss>=1.30597600937\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] Epoch[9] Batch [195]#011Speed: 13806.85 samples/sec#011loss=1.305976\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] Epoch[9] Batch[200] avg_epoch_loss=1.452910\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=200 train loss <loss>=1.3338391304\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] Epoch[9] Batch [200]#011Speed: 1752.88 samples/sec#011loss=1.333839\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] Epoch[9] Batch[205] avg_epoch_loss=1.445504\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=205 train loss <loss>=1.14774706364\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] Epoch[9] Batch [205]#011Speed: 14569.88 samples/sec#011loss=1.147747\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] Epoch[9] Batch[210] avg_epoch_loss=1.440387\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=210 train loss <loss>=1.22960221767\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] Epoch[9] Batch [210]#011Speed: 14651.95 samples/sec#011loss=1.229602\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] Epoch[9] Batch[215] avg_epoch_loss=1.440563\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=215 train loss <loss>=1.44797198772\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] Epoch[9] Batch [215]#011Speed: 1718.40 samples/sec#011loss=1.447972\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] Epoch[9] Batch[220] avg_epoch_loss=1.435519\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=220 train loss <loss>=1.21760382652\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] Epoch[9] Batch [220]#011Speed: 14188.82 samples/sec#011loss=1.217604\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] Epoch[9] Batch[225] avg_epoch_loss=1.425397\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=225 train loss <loss>=0.978021681309\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] Epoch[9] Batch [225]#011Speed: 14306.18 samples/sec#011loss=0.978022\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] Epoch[9] Batch[230] avg_epoch_loss=1.421545\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=230 train loss <loss>=1.24741079807\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] Epoch[9] Batch [230]#011Speed: 1696.64 samples/sec#011loss=1.247411\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] Epoch[9] Batch[235] avg_epoch_loss=1.416190\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=235 train loss <loss>=1.16878944635\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:39 INFO 140088046479168] Epoch[9] Batch [235]#011Speed: 14404.75 samples/sec#011loss=1.168789\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] Epoch[9] Batch[240] avg_epoch_loss=1.413991\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=240 train loss <loss>=1.31021420956\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] Epoch[9] Batch [240]#011Speed: 1746.44 samples/sec#011loss=1.310214\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] Epoch[9] Batch[245] avg_epoch_loss=1.409094\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=245 train loss <loss>=1.17305876017\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] Epoch[9] Batch [245]#011Speed: 14251.34 samples/sec#011loss=1.173059\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] Epoch[9] Batch[250] avg_epoch_loss=1.406057\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=250 train loss <loss>=1.25665570498\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] Epoch[9] Batch [250]#011Speed: 13330.06 samples/sec#011loss=1.256656\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] Epoch[9] Batch[255] avg_epoch_loss=1.400057\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=255 train loss <loss>=1.0988345623\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] Epoch[9] Batch [255]#011Speed: 1696.61 samples/sec#011loss=1.098835\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] Epoch[9] Batch[260] avg_epoch_loss=1.395229\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=260 train loss <loss>=1.14803164005\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] Epoch[9] Batch [260]#011Speed: 14313.81 samples/sec#011loss=1.148032\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] Epoch[9] Batch[265] avg_epoch_loss=1.388601\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=265 train loss <loss>=1.04261444807\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] Epoch[9] Batch [265]#011Speed: 1666.72 samples/sec#011loss=1.042614\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] Epoch[9] Batch[270] avg_epoch_loss=1.380375\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=270 train loss <loss>=0.942786324024\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] Epoch[9] Batch [270]#011Speed: 13235.68 samples/sec#011loss=0.942786\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] Epoch[9] Batch[275] avg_epoch_loss=1.374132\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=275 train loss <loss>=1.0357514143\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] Epoch[9] Batch [275]#011Speed: 13285.73 samples/sec#011loss=1.035751\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] Epoch[9] Batch[280] avg_epoch_loss=1.368981\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=280 train loss <loss>=1.08463442326\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] Epoch[9] Batch [280]#011Speed: 1770.36 samples/sec#011loss=1.084634\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] Epoch[9] Batch[285] avg_epoch_loss=1.364019\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=285 train loss <loss>=1.08516405821\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] Epoch[9] Batch [285]#011Speed: 14317.02 samples/sec#011loss=1.085164\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] Epoch[9] Batch[290] avg_epoch_loss=1.360125\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=290 train loss <loss>=1.13740006685\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] Epoch[9] Batch [290]#011Speed: 1802.06 samples/sec#011loss=1.137400\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] Epoch[9] Batch[295] avg_epoch_loss=1.358668\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=295 train loss <loss>=1.27387157679\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] Epoch[9] Batch [295]#011Speed: 13304.96 samples/sec#011loss=1.273872\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] Epoch[9] Batch[300] avg_epoch_loss=1.359684\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=300 train loss <loss>=1.41983326674\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:40 INFO 140088046479168] Epoch[9] Batch [300]#011Speed: 14317.02 samples/sec#011loss=1.419833\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] Epoch[9] Batch[305] avg_epoch_loss=1.364566\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=305 train loss <loss>=1.65846990347\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] Epoch[9] Batch [305]#011Speed: 1801.81 samples/sec#011loss=1.658470\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] Epoch[9] Batch[310] avg_epoch_loss=1.371516\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=310 train loss <loss>=1.79682871103\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] Epoch[9] Batch [310]#011Speed: 13183.93 samples/sec#011loss=1.796829\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] Epoch[9] Batch[315] avg_epoch_loss=1.375586\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=315 train loss <loss>=1.62874438763\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] Epoch[9] Batch [315]#011Speed: 1849.32 samples/sec#011loss=1.628744\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] Epoch[9] Batch[320] avg_epoch_loss=1.374771\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=320 train loss <loss>=1.32322509289\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] Epoch[9] Batch [320]#011Speed: 13761.69 samples/sec#011loss=1.323225\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] Epoch[9] Batch[325] avg_epoch_loss=1.375452\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=325 train loss <loss>=1.41918549538\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] Epoch[9] Batch [325]#011Speed: 13358.85 samples/sec#011loss=1.419185\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] Epoch[9] Batch[330] avg_epoch_loss=1.374080\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=330 train loss <loss>=1.28467383385\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] Epoch[9] Batch [330]#011Speed: 1689.14 samples/sec#011loss=1.284674\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] Epoch[9] Batch[335] avg_epoch_loss=1.375278\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=335 train loss <loss>=1.45458447933\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] Epoch[9] Batch [335]#011Speed: 13254.37 samples/sec#011loss=1.454584\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] Epoch[9] Batch[340] avg_epoch_loss=1.372015\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=340 train loss <loss>=1.15273737907\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] Epoch[9] Batch [340]#011Speed: 1758.60 samples/sec#011loss=1.152737\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] Epoch[9] Batch[345] avg_epoch_loss=1.372641\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=345 train loss <loss>=1.41530537605\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] Epoch[9] Batch [345]#011Speed: 13329.40 samples/sec#011loss=1.415305\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] Epoch[9] Batch[350] avg_epoch_loss=1.371786\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=350 train loss <loss>=1.31263442039\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:41 INFO 140088046479168] Epoch[9] Batch [350]#011Speed: 13017.58 samples/sec#011loss=1.312634\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] Epoch[9] Batch[355] avg_epoch_loss=1.373686\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=355 train loss <loss>=1.50702781677\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] Epoch[9] Batch [355]#011Speed: 1520.44 samples/sec#011loss=1.507028\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] Epoch[9] Batch[360] avg_epoch_loss=1.374451\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=360 train loss <loss>=1.42896301746\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] Epoch[9] Batch [360]#011Speed: 14178.78 samples/sec#011loss=1.428963\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] Epoch[9] Batch[365] avg_epoch_loss=1.373559\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=365 train loss <loss>=1.30912585258\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] Epoch[9] Batch [365]#011Speed: 13300.08 samples/sec#011loss=1.309126\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] Epoch[9] Batch[370] avg_epoch_loss=1.374619\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=370 train loss <loss>=1.45220155716\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] Epoch[9] Batch [370]#011Speed: 1778.33 samples/sec#011loss=1.452202\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] Epoch[9] Batch[375] avg_epoch_loss=1.373021\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=375 train loss <loss>=1.25446412563\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] Epoch[9] Batch [375]#011Speed: 13738.02 samples/sec#011loss=1.254464\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] Epoch[9] Batch[380] avg_epoch_loss=1.374413\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=380 train loss <loss>=1.47912282944\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] Epoch[9] Batch [380]#011Speed: 1854.97 samples/sec#011loss=1.479123\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] Epoch[9] Batch[385] avg_epoch_loss=1.377206\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=385 train loss <loss>=1.58999097347\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] Epoch[9] Batch [385]#011Speed: 13819.92 samples/sec#011loss=1.589991\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] Epoch[9] Batch[390] avg_epoch_loss=1.377556\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=390 train loss <loss>=1.40462712049\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] Epoch[9] Batch [390]#011Speed: 14119.26 samples/sec#011loss=1.404627\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] Epoch[9] Batch[395] avg_epoch_loss=1.374877\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=395 train loss <loss>=1.16534647942\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] Epoch[9] Batch [395]#011Speed: 1701.27 samples/sec#011loss=1.165346\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] Epoch[9] Batch[400] avg_epoch_loss=1.372335\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=400 train loss <loss>=1.17097172737\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] Epoch[9] Batch [400]#011Speed: 14225.97 samples/sec#011loss=1.170972\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] Epoch[9] Batch[405] avg_epoch_loss=1.371604\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=405 train loss <loss>=1.31298060417\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] Epoch[9] Batch [405]#011Speed: 1578.72 samples/sec#011loss=1.312981\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] Epoch[9] Batch[410] avg_epoch_loss=1.370448\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=410 train loss <loss>=1.2766017437\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] Epoch[9] Batch [410]#011Speed: 14302.98 samples/sec#011loss=1.276602\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] Epoch[9] Batch[415] avg_epoch_loss=1.369914\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=415 train loss <loss>=1.32606947422\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:42 INFO 140088046479168] Epoch[9] Batch [415]#011Speed: 14274.23 samples/sec#011loss=1.326069\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] Epoch[9] Batch[420] avg_epoch_loss=1.369221\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=420 train loss <loss>=1.31151256561\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] Epoch[9] Batch [420]#011Speed: 1835.31 samples/sec#011loss=1.311513\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] Epoch[9] Batch[425] avg_epoch_loss=1.368413\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=425 train loss <loss>=1.30041373968\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] Epoch[9] Batch [425]#011Speed: 14362.06 samples/sec#011loss=1.300414\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] Epoch[9] Batch[430] avg_epoch_loss=1.365057\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=430 train loss <loss>=1.07909967899\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] Epoch[9] Batch [430]#011Speed: 1810.36 samples/sec#011loss=1.079100\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] Epoch[9] Batch[435] avg_epoch_loss=1.361945\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=435 train loss <loss>=1.09367997646\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] Epoch[9] Batch [435]#011Speed: 14327.26 samples/sec#011loss=1.093680\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] Epoch[9] Batch[440] avg_epoch_loss=1.359088\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=440 train loss <loss>=1.10993533134\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] Epoch[9] Batch [440]#011Speed: 13672.81 samples/sec#011loss=1.109935\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] Epoch[9] Batch[445] avg_epoch_loss=1.358963\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=445 train loss <loss>=1.34793891907\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] Epoch[9] Batch [445]#011Speed: 1733.07 samples/sec#011loss=1.347939\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] Epoch[9] Batch[450] avg_epoch_loss=1.356018\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=450 train loss <loss>=1.09337968826\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] Epoch[9] Batch [450]#011Speed: 14538.79 samples/sec#011loss=1.093380\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] Epoch[9] Batch[455] avg_epoch_loss=1.352517\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=455 train loss <loss>=1.0367054224\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] Epoch[9] Batch [455]#011Speed: 1856.61 samples/sec#011loss=1.036705\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] Epoch[9] Batch[460] avg_epoch_loss=1.349276\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=460 train loss <loss>=1.05367982388\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] Epoch[9] Batch [460]#011Speed: 14196.92 samples/sec#011loss=1.053680\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] Epoch[9] Batch[465] avg_epoch_loss=1.346681\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=465 train loss <loss>=1.10745513439\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] Epoch[9] Batch [465]#011Speed: 14272.26 samples/sec#011loss=1.107455\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] Epoch[9] Batch[470] avg_epoch_loss=1.344889\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=470 train loss <loss>=1.17787114382\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] Epoch[9] Batch [470]#011Speed: 1716.78 samples/sec#011loss=1.177871\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] Epoch[9] Batch[475] avg_epoch_loss=1.342351\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=475 train loss <loss>=1.10325206518\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:43 INFO 140088046479168] Epoch[9] Batch [475]#011Speed: 14071.45 samples/sec#011loss=1.103252\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] Epoch[9] Batch[480] avg_epoch_loss=1.342784\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=480 train loss <loss>=1.38398993015\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] Epoch[9] Batch [480]#011Speed: 1689.38 samples/sec#011loss=1.383990\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] Epoch[9] Batch[485] avg_epoch_loss=1.342161\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=485 train loss <loss>=1.28223631382\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] Epoch[9] Batch [485]#011Speed: 14301.61 samples/sec#011loss=1.282236\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] Epoch[9] Batch[490] avg_epoch_loss=1.339377\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=490 train loss <loss>=1.06878969669\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] Epoch[9] Batch [490]#011Speed: 14323.43 samples/sec#011loss=1.068790\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] Epoch[9] Batch[495] avg_epoch_loss=1.336354\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=495 train loss <loss>=1.03947402239\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] Epoch[9] Batch [495]#011Speed: 1720.29 samples/sec#011loss=1.039474\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] Epoch[9] Batch[500] avg_epoch_loss=1.336039\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=500 train loss <loss>=1.30476756096\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] Epoch[9] Batch [500]#011Speed: 14402.13 samples/sec#011loss=1.304768\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] Epoch[9] Batch[505] avg_epoch_loss=1.337326\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=505 train loss <loss>=1.46630284786\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] Epoch[9] Batch [505]#011Speed: 1588.96 samples/sec#011loss=1.466303\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] Epoch[9] Batch[510] avg_epoch_loss=1.338262\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=510 train loss <loss>=1.43300210238\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] Epoch[9] Batch [510]#011Speed: 13279.15 samples/sec#011loss=1.433002\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] Epoch[9] Batch[515] avg_epoch_loss=1.339841\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=515 train loss <loss>=1.5012285471\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] Epoch[9] Batch [515]#011Speed: 13808.55 samples/sec#011loss=1.501229\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] Epoch[9] Batch[520] avg_epoch_loss=1.343004\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=520 train loss <loss>=1.66940283775\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] Epoch[9] Batch [520]#011Speed: 1774.57 samples/sec#011loss=1.669403\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] Epoch[9] Batch[525] avg_epoch_loss=1.345659\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=525 train loss <loss>=1.62230505943\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:44 INFO 140088046479168] Epoch[9] Batch [525]#011Speed: 14272.26 samples/sec#011loss=1.622305\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] Epoch[9] Batch[530] avg_epoch_loss=1.343788\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=530 train loss <loss>=1.14696329832\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] Epoch[9] Batch [530]#011Speed: 1671.42 samples/sec#011loss=1.146963\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] Epoch[9] Batch[535] avg_epoch_loss=1.340849\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=535 train loss <loss>=1.02878882885\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] Epoch[9] Batch [535]#011Speed: 13306.14 samples/sec#011loss=1.028789\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] Epoch[9] Batch[540] avg_epoch_loss=1.339990\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=540 train loss <loss>=1.24780958891\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] Epoch[9] Batch [540]#011Speed: 14124.91 samples/sec#011loss=1.247810\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] Epoch[9] Batch[545] avg_epoch_loss=1.339138\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=545 train loss <loss>=1.24698352814\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] Epoch[9] Batch [545]#011Speed: 1714.94 samples/sec#011loss=1.246984\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] Epoch[9] Batch[550] avg_epoch_loss=1.337201\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=550 train loss <loss>=1.12569253445\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] Epoch[9] Batch [550]#011Speed: 12726.64 samples/sec#011loss=1.125693\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] Epoch[9] Batch[555] avg_epoch_loss=1.333162\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=555 train loss <loss>=0.888118231297\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] Epoch[9] Batch [555]#011Speed: 13310.63 samples/sec#011loss=0.888118\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] Epoch[9] Batch[560] avg_epoch_loss=1.330945\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=560 train loss <loss>=1.08433786631\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] Epoch[9] Batch [560]#011Speed: 1732.18 samples/sec#011loss=1.084338\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] Epoch[9] Batch[565] avg_epoch_loss=1.326173\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=565 train loss <loss>=0.790805160999\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] Epoch[9] Batch [565]#011Speed: 14511.75 samples/sec#011loss=0.790805\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] Epoch[9] Batch[570] avg_epoch_loss=1.323906\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=570 train loss <loss>=1.06725746393\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] Epoch[9] Batch [570]#011Speed: 1785.62 samples/sec#011loss=1.067257\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] Epoch[9] Batch[575] avg_epoch_loss=1.322770\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=575 train loss <loss>=1.1930511713\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] Epoch[9] Batch [575]#011Speed: 13190.41 samples/sec#011loss=1.193051\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] Epoch[9] Batch[580] avg_epoch_loss=1.325198\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=580 train loss <loss>=1.60490767956\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] Epoch[9] Batch [580]#011Speed: 13164.41 samples/sec#011loss=1.604908\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] Epoch[9] Batch[585] avg_epoch_loss=1.329038\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=585 train loss <loss>=1.7751791954\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:45 INFO 140088046479168] Epoch[9] Batch [585]#011Speed: 1732.20 samples/sec#011loss=1.775179\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] Epoch[9] Batch[590] avg_epoch_loss=1.333494\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=590 train loss <loss>=1.85581698418\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] Epoch[9] Batch [590]#011Speed: 13358.99 samples/sec#011loss=1.855817\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] Epoch[9] Batch[595] avg_epoch_loss=1.335439\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=595 train loss <loss>=1.56533823013\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] Epoch[9] Batch [595]#011Speed: 1793.69 samples/sec#011loss=1.565338\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] Epoch[9] Batch[600] avg_epoch_loss=1.335001\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=600 train loss <loss>=1.28272446394\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] Epoch[9] Batch [600]#011Speed: 14295.36 samples/sec#011loss=1.282724\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] Epoch[9] Batch[605] avg_epoch_loss=1.333610\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=605 train loss <loss>=1.1664296031\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] Epoch[9] Batch [605]#011Speed: 13183.93 samples/sec#011loss=1.166430\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] Epoch[9] Batch[610] avg_epoch_loss=1.331092\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=610 train loss <loss>=1.02590265274\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] Epoch[9] Batch [610]#011Speed: 1359.90 samples/sec#011loss=1.025903\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] Epoch[9] Batch[615] avg_epoch_loss=1.328379\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=615 train loss <loss>=0.996888077259\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] Epoch[9] Batch [615]#011Speed: 14114.36 samples/sec#011loss=0.996888\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] Epoch[9] Batch[620] avg_epoch_loss=1.327711\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=620 train loss <loss>=1.24538142681\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] Epoch[9] Batch [620]#011Speed: 1835.30 samples/sec#011loss=1.245381\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] Epoch[9] Batch[625] avg_epoch_loss=1.326448\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=625 train loss <loss>=1.16957592964\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] Epoch[9] Batch [625]#011Speed: 14096.87 samples/sec#011loss=1.169576\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] Epoch[9] Batch[630] avg_epoch_loss=1.325647\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=630 train loss <loss>=1.2254160881\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] Epoch[9] Batch [630]#011Speed: 1754.68 samples/sec#011loss=1.225416\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] Epoch[9] Batch[635] avg_epoch_loss=1.325936\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=635 train loss <loss>=1.36233326197\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] Epoch[9] Batch [635]#011Speed: 13295.07 samples/sec#011loss=1.362333\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] Epoch[9] Batch[640] avg_epoch_loss=1.325279\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=640 train loss <loss>=1.24179086685\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:46 INFO 140088046479168] Epoch[9] Batch [640]#011Speed: 13295.20 samples/sec#011loss=1.241791\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] Epoch[9] Batch[645] avg_epoch_loss=1.322966\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=645 train loss <loss>=1.02636182904\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] Epoch[9] Batch [645]#011Speed: 1860.77 samples/sec#011loss=1.026362\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] Epoch[9] Batch[650] avg_epoch_loss=1.320584\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=650 train loss <loss>=1.01289429665\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] Epoch[9] Batch [650]#011Speed: 14277.42 samples/sec#011loss=1.012894\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] Epoch[9] Batch[655] avg_epoch_loss=1.318868\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=655 train loss <loss>=1.09543732405\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] Epoch[9] Batch [655]#011Speed: 1787.89 samples/sec#011loss=1.095437\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] Epoch[9] Batch[660] avg_epoch_loss=1.316092\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=660 train loss <loss>=0.9518196702\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] Epoch[9] Batch [660]#011Speed: 13491.39 samples/sec#011loss=0.951820\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] Epoch[9] Batch[665] avg_epoch_loss=1.315321\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=665 train loss <loss>=1.21338829994\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] Epoch[9] Batch [665]#011Speed: 13409.84 samples/sec#011loss=1.213388\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] Epoch[9] Batch[670] avg_epoch_loss=1.314408\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=670 train loss <loss>=1.19280817509\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] Epoch[9] Batch [670]#011Speed: 1810.43 samples/sec#011loss=1.192808\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] Epoch[9] Batch[675] avg_epoch_loss=1.313945\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=675 train loss <loss>=1.25184409618\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] Epoch[9] Batch [675]#011Speed: 10882.11 samples/sec#011loss=1.251844\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] Epoch[9] Batch[680] avg_epoch_loss=1.318514\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=680 train loss <loss>=1.93626606464\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] Epoch[9] Batch [680]#011Speed: 1837.19 samples/sec#011loss=1.936266\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] Epoch[9] Batch[685] avg_epoch_loss=1.323285\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=685 train loss <loss>=1.97303688526\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] Epoch[9] Batch [685]#011Speed: 14548.24 samples/sec#011loss=1.973037\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] Epoch[9] Batch[690] avg_epoch_loss=1.329765\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=690 train loss <loss>=2.21883802414\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] Epoch[9] Batch [690]#011Speed: 14479.66 samples/sec#011loss=2.218838\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] Epoch[9] Batch[695] avg_epoch_loss=1.335624\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=695 train loss <loss>=2.14533848763\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] Epoch[9] Batch [695]#011Speed: 1701.35 samples/sec#011loss=2.145338\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] Epoch[9] Batch[700] avg_epoch_loss=1.341951\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=700 train loss <loss>=2.2227104187\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:47 INFO 140088046479168] Epoch[9] Batch [700]#011Speed: 14325.27 samples/sec#011loss=2.222710\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] Epoch[9] Batch[705] avg_epoch_loss=1.347188\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=705 train loss <loss>=2.08135268688\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] Epoch[9] Batch [705]#011Speed: 1735.97 samples/sec#011loss=2.081353\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] Epoch[9] Batch[710] avg_epoch_loss=1.350124\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=710 train loss <loss>=1.7648070097\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] Epoch[9] Batch [710]#011Speed: 13922.71 samples/sec#011loss=1.764807\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] Epoch[9] Batch[715] avg_epoch_loss=1.353327\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=715 train loss <loss>=1.8087495327\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] Epoch[9] Batch [715]#011Speed: 12841.10 samples/sec#011loss=1.808750\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] Epoch[9] Batch[720] avg_epoch_loss=1.353685\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=720 train loss <loss>=1.40492637157\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] Epoch[9] Batch [720]#011Speed: 1684.60 samples/sec#011loss=1.404926\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] Epoch[9] Batch[725] avg_epoch_loss=1.353833\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=725 train loss <loss>=1.37523646355\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] Epoch[9] Batch [725]#011Speed: 13398.59 samples/sec#011loss=1.375236\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] Epoch[9] Batch[730] avg_epoch_loss=1.355284\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=730 train loss <loss>=1.56596989632\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] Epoch[9] Batch [730]#011Speed: 14164.41 samples/sec#011loss=1.565970\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] Epoch[9] Batch[735] avg_epoch_loss=1.356418\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=735 train loss <loss>=1.52209664583\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] Epoch[9] Batch [735]#011Speed: 1717.35 samples/sec#011loss=1.522097\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] Epoch[9] Batch[740] avg_epoch_loss=1.357284\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=740 train loss <loss>=1.48478872776\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] Epoch[9] Batch [740]#011Speed: 14333.07 samples/sec#011loss=1.484789\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] Epoch[9] Batch[745] avg_epoch_loss=1.357548\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=745 train loss <loss>=1.3967509985\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] Epoch[9] Batch [745]#011Speed: 1863.34 samples/sec#011loss=1.396751\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] Epoch[9] Batch[750] avg_epoch_loss=1.358556\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=750 train loss <loss>=1.50886423588\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:48 INFO 140088046479168] Epoch[9] Batch [750]#011Speed: 11561.92 samples/sec#011loss=1.508864\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] Epoch[9] Batch[755] avg_epoch_loss=1.359828\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=755 train loss <loss>=1.55094766617\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] Epoch[9] Batch [755]#011Speed: 1798.96 samples/sec#011loss=1.550948\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] Epoch[9] Batch[760] avg_epoch_loss=1.360255\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=760 train loss <loss>=1.42478399277\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] Epoch[9] Batch [760]#011Speed: 14272.41 samples/sec#011loss=1.424784\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] Epoch[9] Batch[765] avg_epoch_loss=1.360378\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=765 train loss <loss>=1.37912523746\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] Epoch[9] Batch [765]#011Speed: 14348.39 samples/sec#011loss=1.379125\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] Epoch[9] Batch[770] avg_epoch_loss=1.361525\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=770 train loss <loss>=1.53719592094\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] Epoch[9] Batch [770]#011Speed: 1754.45 samples/sec#011loss=1.537196\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] Epoch[9] Batch[775] avg_epoch_loss=1.361456\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=775 train loss <loss>=1.35086798668\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] Epoch[9] Batch [775]#011Speed: 14271.80 samples/sec#011loss=1.350868\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] Epoch[9] Batch[780] avg_epoch_loss=1.363641\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=780 train loss <loss>=1.70265033245\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] Epoch[9] Batch [780]#011Speed: 1814.91 samples/sec#011loss=1.702650\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] Epoch[9] Batch[785] avg_epoch_loss=1.364833\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=785 train loss <loss>=1.55106213093\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] Epoch[9] Batch [785]#011Speed: 13607.79 samples/sec#011loss=1.551062\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] Epoch[9] Batch[790] avg_epoch_loss=1.366612\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=790 train loss <loss>=1.64634537697\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] Epoch[9] Batch [790]#011Speed: 14255.13 samples/sec#011loss=1.646345\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] Epoch[9] Batch[795] avg_epoch_loss=1.365922\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=795 train loss <loss>=1.25677709579\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] Epoch[9] Batch [795]#011Speed: 1664.44 samples/sec#011loss=1.256777\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] Epoch[9] Batch[800] avg_epoch_loss=1.367522\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=800 train loss <loss>=1.62218084335\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] Epoch[9] Batch [800]#011Speed: 13940.93 samples/sec#011loss=1.622181\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] Epoch[9] Batch[805] avg_epoch_loss=1.368220\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=805 train loss <loss>=1.48004848957\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] Epoch[9] Batch [805]#011Speed: 1730.10 samples/sec#011loss=1.480048\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] Epoch[9] Batch[810] avg_epoch_loss=1.368378\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=810 train loss <loss>=1.39385602474\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] Epoch[9] Batch [810]#011Speed: 13375.09 samples/sec#011loss=1.393856\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] Epoch[9] Batch[815] avg_epoch_loss=1.368772\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=815 train loss <loss>=1.43272237778\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:49 INFO 140088046479168] Epoch[9] Batch [815]#011Speed: 14248.17 samples/sec#011loss=1.432722\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] Epoch[9] Batch[820] avg_epoch_loss=1.368254\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=820 train loss <loss>=1.28370120525\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] Epoch[9] Batch [820]#011Speed: 1698.23 samples/sec#011loss=1.283701\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] Epoch[9] Batch[825] avg_epoch_loss=1.367166\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=825 train loss <loss>=1.18854982853\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] Epoch[9] Batch [825]#011Speed: 14408.46 samples/sec#011loss=1.188550\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] Epoch[9] Batch[830] avg_epoch_loss=1.366293\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=830 train loss <loss>=1.22196871042\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] Epoch[9] Batch [830]#011Speed: 1724.44 samples/sec#011loss=1.221969\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] Epoch[9] Batch[835] avg_epoch_loss=1.366029\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=835 train loss <loss>=1.32210639715\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] Epoch[9] Batch [835]#011Speed: 14170.69 samples/sec#011loss=1.322106\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] Epoch[9] Batch[840] avg_epoch_loss=1.364770\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=840 train loss <loss>=1.15438319445\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] Epoch[9] Batch [840]#011Speed: 14134.13 samples/sec#011loss=1.154383\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] Epoch[9] Batch[845] avg_epoch_loss=1.363799\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=845 train loss <loss>=1.20044028759\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] Epoch[9] Batch [845]#011Speed: 1584.92 samples/sec#011loss=1.200440\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] Epoch[9] Batch[850] avg_epoch_loss=1.362410\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=850 train loss <loss>=1.12732622623\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] Epoch[9] Batch [850]#011Speed: 14293.99 samples/sec#011loss=1.127326\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] Epoch[9] Batch[855] avg_epoch_loss=1.362121\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=855 train loss <loss>=1.31300678253\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] Epoch[9] Batch [855]#011Speed: 14188.22 samples/sec#011loss=1.313007\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] Epoch[9] Batch[860] avg_epoch_loss=1.360655\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=860 train loss <loss>=1.10964154005\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] Epoch[9] Batch [860]#011Speed: 1730.13 samples/sec#011loss=1.109642\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] Epoch[9] Batch[865] avg_epoch_loss=1.359295\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=865 train loss <loss>=1.12507878542\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:50 INFO 140088046479168] Epoch[9] Batch [865]#011Speed: 14433.88 samples/sec#011loss=1.125079\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[9] Batch[870] avg_epoch_loss=1.357888\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=870 train loss <loss>=1.11419039965\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[9] Batch [870]#011Speed: 1750.73 samples/sec#011loss=1.114190\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[9] Batch[875] avg_epoch_loss=1.357048\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=875 train loss <loss>=1.2106844902\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[9] Batch [875]#011Speed: 14265.89 samples/sec#011loss=1.210684\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[9] Batch[880] avg_epoch_loss=1.356388\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=880 train loss <loss>=1.24092309475\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[9] Batch [880]#011Speed: 13311.69 samples/sec#011loss=1.240923\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[9] Batch[885] avg_epoch_loss=1.354944\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=885 train loss <loss>=1.10041464567\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[9] Batch [885]#011Speed: 1715.58 samples/sec#011loss=1.100415\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[9] Batch[890] avg_epoch_loss=1.353909\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=890 train loss <loss>=1.17048515081\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[9] Batch [890]#011Speed: 13348.36 samples/sec#011loss=1.170485\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[9] Batch[895] avg_epoch_loss=1.353494\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, batch=895 train loss <loss>=1.2795031786\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[9] Batch [895]#011Speed: 11914.47 samples/sec#011loss=1.279503\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] processed a total of 57309 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15692.121982574463, \"sum\": 15692.121982574463, \"min\": 15692.121982574463}}, \"EndTime\": 1604320551.319131, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320535.626952}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] #throughput_metric: host=algo-1, train throughput=3652.06403323 records/second\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=9, train loss <loss>=1.3534935803\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[10] Batch[0] avg_epoch_loss=1.195795\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=1.19579482079\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[10] Batch[5] avg_epoch_loss=1.183844\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=1.18384389083\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[10] Batch [5]#011Speed: 13333.90 samples/sec#011loss=1.183844\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[10] Batch[10] avg_epoch_loss=1.213178\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=1.24837905169\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[10] Batch [10]#011Speed: 13258.69 samples/sec#011loss=1.248379\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[10] Batch[15] avg_epoch_loss=1.212738\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=15 train loss <loss>=1.21176848412\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[10] Batch [15]#011Speed: 1778.33 samples/sec#011loss=1.211768\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[10] Batch[20] avg_epoch_loss=1.190347\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=20 train loss <loss>=1.11869513988\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[10] Batch [20]#011Speed: 13461.75 samples/sec#011loss=1.118695\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[10] Batch[25] avg_epoch_loss=1.166156\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=25 train loss <loss>=1.06455765963\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[10] Batch [25]#011Speed: 1625.14 samples/sec#011loss=1.064558\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[10] Batch[30] avg_epoch_loss=1.166879\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=30 train loss <loss>=1.17063516378\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[10] Batch [30]#011Speed: 14429.38 samples/sec#011loss=1.170635\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[10] Batch[35] avg_epoch_loss=1.170760\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=35 train loss <loss>=1.19482607841\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:51 INFO 140088046479168] Epoch[10] Batch [35]#011Speed: 14394.25 samples/sec#011loss=1.194826\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] Epoch[10] Batch[40] avg_epoch_loss=1.180385\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=40 train loss <loss>=1.2496851325\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] Epoch[10] Batch [40]#011Speed: 1737.40 samples/sec#011loss=1.249685\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] Epoch[10] Batch[45] avg_epoch_loss=1.206634\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=45 train loss <loss>=1.42187666893\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] Epoch[10] Batch [45]#011Speed: 14062.90 samples/sec#011loss=1.421877\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] Epoch[10] Batch[50] avg_epoch_loss=1.214048\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=50 train loss <loss>=1.2822560668\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] Epoch[10] Batch [50]#011Speed: 13024.52 samples/sec#011loss=1.282256\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] Epoch[10] Batch[55] avg_epoch_loss=1.199128\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=55 train loss <loss>=1.0469410181\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] Epoch[10] Batch [55]#011Speed: 1700.68 samples/sec#011loss=1.046941\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] Epoch[10] Batch[60] avg_epoch_loss=1.179966\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=60 train loss <loss>=0.965354406834\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] Epoch[10] Batch [60]#011Speed: 14353.61 samples/sec#011loss=0.965354\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] Epoch[10] Batch[65] avg_epoch_loss=1.172721\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=65 train loss <loss>=1.08432472944\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] Epoch[10] Batch [65]#011Speed: 1706.07 samples/sec#011loss=1.084325\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] Epoch[10] Batch[70] avg_epoch_loss=1.175905\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=70 train loss <loss>=1.21793476343\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] Epoch[10] Batch [70]#011Speed: 12803.13 samples/sec#011loss=1.217935\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] Epoch[10] Batch[75] avg_epoch_loss=1.173399\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=75 train loss <loss>=1.13781051636\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] Epoch[10] Batch [75]#011Speed: 14595.23 samples/sec#011loss=1.137811\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] Epoch[10] Batch[80] avg_epoch_loss=1.168161\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=80 train loss <loss>=1.08854604959\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] Epoch[10] Batch [80]#011Speed: 1792.49 samples/sec#011loss=1.088546\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] Epoch[10] Batch[85] avg_epoch_loss=1.169241\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=85 train loss <loss>=1.18674211502\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:52 INFO 140088046479168] Epoch[10] Batch [85]#011Speed: 13748.15 samples/sec#011loss=1.186742\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] Epoch[10] Batch[90] avg_epoch_loss=1.175856\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=90 train loss <loss>=1.2896320343\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] Epoch[10] Batch [90]#011Speed: 1796.14 samples/sec#011loss=1.289632\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] Epoch[10] Batch[95] avg_epoch_loss=1.171847\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=95 train loss <loss>=1.09887840748\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] Epoch[10] Batch [95]#011Speed: 14280.61 samples/sec#011loss=1.098878\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] Epoch[10] Batch[100] avg_epoch_loss=1.175529\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=100 train loss <loss>=1.24623060226\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] Epoch[10] Batch [100]#011Speed: 14285.62 samples/sec#011loss=1.246231\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] Epoch[10] Batch[105] avg_epoch_loss=1.174311\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=105 train loss <loss>=1.14971506596\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] Epoch[10] Batch [105]#011Speed: 1763.27 samples/sec#011loss=1.149715\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] Epoch[10] Batch[110] avg_epoch_loss=1.178939\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=110 train loss <loss>=1.27704827785\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] Epoch[10] Batch [110]#011Speed: 14260.28 samples/sec#011loss=1.277048\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] Epoch[10] Batch[115] avg_epoch_loss=1.179890\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=115 train loss <loss>=1.20099008083\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] Epoch[10] Batch [115]#011Speed: 14101.32 samples/sec#011loss=1.200990\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] Epoch[10] Batch[120] avg_epoch_loss=1.179436\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=120 train loss <loss>=1.16890151501\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] Epoch[10] Batch [120]#011Speed: 1770.80 samples/sec#011loss=1.168902\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] Epoch[10] Batch[125] avg_epoch_loss=1.187671\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=125 train loss <loss>=1.38697357178\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] Epoch[10] Batch [125]#011Speed: 14344.10 samples/sec#011loss=1.386974\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] Epoch[10] Batch[130] avg_epoch_loss=1.211150\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=130 train loss <loss>=1.80281362534\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] Epoch[10] Batch [130]#011Speed: 1704.46 samples/sec#011loss=1.802814\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] Epoch[10] Batch[135] avg_epoch_loss=1.232115\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=135 train loss <loss>=1.78140759468\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] Epoch[10] Batch [135]#011Speed: 13305.09 samples/sec#011loss=1.781408\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] Epoch[10] Batch[140] avg_epoch_loss=1.228707\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=140 train loss <loss>=1.13600283861\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] Epoch[10] Batch [140]#011Speed: 13291.78 samples/sec#011loss=1.136003\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] Epoch[10] Batch[145] avg_epoch_loss=1.221866\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=145 train loss <loss>=1.02894579172\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] Epoch[10] Batch [145]#011Speed: 1741.85 samples/sec#011loss=1.028946\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] Epoch[10] Batch[150] avg_epoch_loss=1.222320\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=150 train loss <loss>=1.2355650425\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:53 INFO 140088046479168] Epoch[10] Batch [150]#011Speed: 14261.49 samples/sec#011loss=1.235565\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] Epoch[10] Batch[155] avg_epoch_loss=1.216945\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=155 train loss <loss>=1.05464636087\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] Epoch[10] Batch [155]#011Speed: 1756.74 samples/sec#011loss=1.054646\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] Epoch[10] Batch[160] avg_epoch_loss=1.209562\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=160 train loss <loss>=0.979194295406\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] Epoch[10] Batch [160]#011Speed: 14393.01 samples/sec#011loss=0.979194\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] Epoch[10] Batch[165] avg_epoch_loss=1.212845\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=165 train loss <loss>=1.31856021881\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] Epoch[10] Batch [165]#011Speed: 14330.47 samples/sec#011loss=1.318560\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] Epoch[10] Batch[170] avg_epoch_loss=1.220959\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=170 train loss <loss>=1.49034533501\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] Epoch[10] Batch [170]#011Speed: 1692.88 samples/sec#011loss=1.490345\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] Epoch[10] Batch[175] avg_epoch_loss=1.211510\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=175 train loss <loss>=0.888345766068\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] Epoch[10] Batch [175]#011Speed: 14190.62 samples/sec#011loss=0.888346\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] Epoch[10] Batch[180] avg_epoch_loss=1.207737\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=180 train loss <loss>=1.0749332428\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] Epoch[10] Batch [180]#011Speed: 1788.55 samples/sec#011loss=1.074933\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] Epoch[10] Batch[185] avg_epoch_loss=1.204198\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=185 train loss <loss>=1.07608777285\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] Epoch[10] Batch [185]#011Speed: 14240.61 samples/sec#011loss=1.076088\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] Epoch[10] Batch[190] avg_epoch_loss=1.193089\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=190 train loss <loss>=0.779846888781\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] Epoch[10] Batch [190]#011Speed: 13321.59 samples/sec#011loss=0.779847\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] Epoch[10] Batch[195] avg_epoch_loss=1.193663\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=195 train loss <loss>=1.2155870676\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] Epoch[10] Batch [195]#011Speed: 1537.31 samples/sec#011loss=1.215587\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] Epoch[10] Batch[200] avg_epoch_loss=1.191355\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=200 train loss <loss>=1.10088050365\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:54 INFO 140088046479168] Epoch[10] Batch [200]#011Speed: 14147.99 samples/sec#011loss=1.100881\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] Epoch[10] Batch[205] avg_epoch_loss=1.190793\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=205 train loss <loss>=1.16819667816\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] Epoch[10] Batch [205]#011Speed: 1874.16 samples/sec#011loss=1.168197\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] Epoch[10] Batch[210] avg_epoch_loss=1.187908\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=210 train loss <loss>=1.06903376579\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] Epoch[10] Batch [210]#011Speed: 13743.37 samples/sec#011loss=1.069034\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] Epoch[10] Batch[215] avg_epoch_loss=1.186236\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=215 train loss <loss>=1.11567363739\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] Epoch[10] Batch [215]#011Speed: 14203.99 samples/sec#011loss=1.115674\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] Epoch[10] Batch[220] avg_epoch_loss=1.182538\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=220 train loss <loss>=1.02281905413\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] Epoch[10] Batch [220]#011Speed: 1758.92 samples/sec#011loss=1.022819\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] Epoch[10] Batch[225] avg_epoch_loss=1.187975\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=225 train loss <loss>=1.4282630682\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] Epoch[10] Batch [225]#011Speed: 13783.03 samples/sec#011loss=1.428263\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] Epoch[10] Batch[230] avg_epoch_loss=1.186950\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=230 train loss <loss>=1.14062290192\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] Epoch[10] Batch [230]#011Speed: 1834.98 samples/sec#011loss=1.140623\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] Epoch[10] Batch[235] avg_epoch_loss=1.188629\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=235 train loss <loss>=1.26621948481\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] Epoch[10] Batch [235]#011Speed: 14238.64 samples/sec#011loss=1.266219\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] Epoch[10] Batch[240] avg_epoch_loss=1.198733\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=240 train loss <loss>=1.67560975552\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] Epoch[10] Batch [240]#011Speed: 14292.01 samples/sec#011loss=1.675610\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] Epoch[10] Batch[245] avg_epoch_loss=1.217660\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=245 train loss <loss>=2.12995541096\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] Epoch[10] Batch [245]#011Speed: 1785.08 samples/sec#011loss=2.129955\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] Epoch[10] Batch[250] avg_epoch_loss=1.232778\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=250 train loss <loss>=1.97658729553\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] Epoch[10] Batch [250]#011Speed: 13467.43 samples/sec#011loss=1.976587\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] Epoch[10] Batch[255] avg_epoch_loss=1.234386\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=255 train loss <loss>=1.31508982182\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] Epoch[10] Batch [255]#011Speed: 1629.64 samples/sec#011loss=1.315090\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] Epoch[10] Batch[260] avg_epoch_loss=1.234574\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=260 train loss <loss>=1.24419789314\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] Epoch[10] Batch [260]#011Speed: 13507.27 samples/sec#011loss=1.244198\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] Epoch[10] Batch[265] avg_epoch_loss=1.232768\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=265 train loss <loss>=1.13850779533\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:55 INFO 140088046479168] Epoch[10] Batch [265]#011Speed: 13351.15 samples/sec#011loss=1.138508\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] Epoch[10] Batch[270] avg_epoch_loss=1.230228\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=270 train loss <loss>=1.09512337446\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] Epoch[10] Batch [270]#011Speed: 1739.18 samples/sec#011loss=1.095123\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] Epoch[10] Batch[275] avg_epoch_loss=1.227646\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=275 train loss <loss>=1.08770151138\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] Epoch[10] Batch [275]#011Speed: 13317.23 samples/sec#011loss=1.087702\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] Epoch[10] Batch[280] avg_epoch_loss=1.230903\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=280 train loss <loss>=1.41068282127\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] Epoch[10] Batch [280]#011Speed: 14391.62 samples/sec#011loss=1.410683\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] Epoch[10] Batch[285] avg_epoch_loss=1.232781\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=285 train loss <loss>=1.33833346367\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] Epoch[10] Batch [285]#011Speed: 1864.32 samples/sec#011loss=1.338333\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] Epoch[10] Batch[290] avg_epoch_loss=1.231304\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=290 train loss <loss>=1.14680253267\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] Epoch[10] Batch [290]#011Speed: 13715.00 samples/sec#011loss=1.146803\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] Epoch[10] Batch[295] avg_epoch_loss=1.235396\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=295 train loss <loss>=1.4735219717\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] Epoch[10] Batch [295]#011Speed: 1729.82 samples/sec#011loss=1.473522\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] Epoch[10] Batch[300] avg_epoch_loss=1.233650\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=300 train loss <loss>=1.13028769493\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] Epoch[10] Batch [300]#011Speed: 12999.67 samples/sec#011loss=1.130288\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] Epoch[10] Batch[305] avg_epoch_loss=1.230879\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=305 train loss <loss>=1.06408103704\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] Epoch[10] Batch [305]#011Speed: 12860.17 samples/sec#011loss=1.064081\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] Epoch[10] Batch[310] avg_epoch_loss=1.230599\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=310 train loss <loss>=1.21344749928\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] Epoch[10] Batch [310]#011Speed: 1748.81 samples/sec#011loss=1.213447\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] Epoch[10] Batch[315] avg_epoch_loss=1.227369\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=315 train loss <loss>=1.02650774717\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] Epoch[10] Batch [315]#011Speed: 13541.62 samples/sec#011loss=1.026508\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] Epoch[10] Batch[320] avg_epoch_loss=1.225392\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=320 train loss <loss>=1.10039095879\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:56 INFO 140088046479168] Epoch[10] Batch [320]#011Speed: 1728.41 samples/sec#011loss=1.100391\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] Epoch[10] Batch[325] avg_epoch_loss=1.225227\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=325 train loss <loss>=1.21469099522\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] Epoch[10] Batch [325]#011Speed: 14374.21 samples/sec#011loss=1.214691\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] Epoch[10] Batch[330] avg_epoch_loss=1.225190\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=330 train loss <loss>=1.22272410393\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] Epoch[10] Batch [330]#011Speed: 14244.99 samples/sec#011loss=1.222724\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] Epoch[10] Batch[335] avg_epoch_loss=1.225581\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=335 train loss <loss>=1.25152384043\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] Epoch[10] Batch [335]#011Speed: 1667.77 samples/sec#011loss=1.251524\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] Epoch[10] Batch[340] avg_epoch_loss=1.224239\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=340 train loss <loss>=1.13405818939\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] Epoch[10] Batch [340]#011Speed: 14217.23 samples/sec#011loss=1.134058\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] Epoch[10] Batch[345] avg_epoch_loss=1.228193\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=345 train loss <loss>=1.49781675339\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] Epoch[10] Batch [345]#011Speed: 1606.74 samples/sec#011loss=1.497817\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] Epoch[10] Batch[350] avg_epoch_loss=1.232123\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=350 train loss <loss>=1.50410091877\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] Epoch[10] Batch [350]#011Speed: 14407.85 samples/sec#011loss=1.504101\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] Epoch[10] Batch[355] avg_epoch_loss=1.234904\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=355 train loss <loss>=1.43009570837\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] Epoch[10] Batch [355]#011Speed: 13299.55 samples/sec#011loss=1.430096\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] Epoch[10] Batch[360] avg_epoch_loss=1.232668\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=360 train loss <loss>=1.07347552776\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] Epoch[10] Batch [360]#011Speed: 1757.44 samples/sec#011loss=1.073476\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] Epoch[10] Batch[365] avg_epoch_loss=1.234343\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=365 train loss <loss>=1.35526525974\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] Epoch[10] Batch [365]#011Speed: 11494.59 samples/sec#011loss=1.355265\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] Epoch[10] Batch[370] avg_epoch_loss=1.234770\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=370 train loss <loss>=1.26602714062\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] Epoch[10] Batch [370]#011Speed: 12720.13 samples/sec#011loss=1.266027\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] Epoch[10] Batch[375] avg_epoch_loss=1.232189\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=375 train loss <loss>=1.04072310925\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] Epoch[10] Batch [375]#011Speed: 1579.74 samples/sec#011loss=1.040723\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] Epoch[10] Batch[380] avg_epoch_loss=1.231405\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=380 train loss <loss>=1.17245692015\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:57 INFO 140088046479168] Epoch[10] Batch [380]#011Speed: 13300.08 samples/sec#011loss=1.172457\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] Epoch[10] Batch[385] avg_epoch_loss=1.229080\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=385 train loss <loss>=1.05191705227\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] Epoch[10] Batch [385]#011Speed: 1756.05 samples/sec#011loss=1.051917\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] Epoch[10] Batch[390] avg_epoch_loss=1.227305\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=390 train loss <loss>=1.09027270079\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] Epoch[10] Batch [390]#011Speed: 14259.07 samples/sec#011loss=1.090273\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] Epoch[10] Batch[395] avg_epoch_loss=1.229751\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=395 train loss <loss>=1.42097771168\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] Epoch[10] Batch [395]#011Speed: 13870.91 samples/sec#011loss=1.420978\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] Epoch[10] Batch[400] avg_epoch_loss=1.232992\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=400 train loss <loss>=1.48971823454\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] Epoch[10] Batch [400]#011Speed: 1646.14 samples/sec#011loss=1.489718\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] Epoch[10] Batch[405] avg_epoch_loss=1.237018\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=405 train loss <loss>=1.55990488529\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] Epoch[10] Batch [405]#011Speed: 13416.00 samples/sec#011loss=1.559905\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] Epoch[10] Batch[410] avg_epoch_loss=1.238198\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=410 train loss <loss>=1.33395328522\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] Epoch[10] Batch [410]#011Speed: 1832.70 samples/sec#011loss=1.333953\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] Epoch[10] Batch[415] avg_epoch_loss=1.240206\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=415 train loss <loss>=1.40533595085\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] Epoch[10] Batch [415]#011Speed: 13203.52 samples/sec#011loss=1.405336\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] Epoch[10] Batch[420] avg_epoch_loss=1.241815\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=420 train loss <loss>=1.37564182281\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] Epoch[10] Batch [420]#011Speed: 14409.86 samples/sec#011loss=1.375642\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] Epoch[10] Batch[425] avg_epoch_loss=1.245460\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=425 train loss <loss>=1.55234470367\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] Epoch[10] Batch [425]#011Speed: 1453.45 samples/sec#011loss=1.552345\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] Epoch[10] Batch[430] avg_epoch_loss=1.247636\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=430 train loss <loss>=1.43306775093\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:58 INFO 140088046479168] Epoch[10] Batch [430]#011Speed: 13261.44 samples/sec#011loss=1.433068\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] Epoch[10] Batch[435] avg_epoch_loss=1.246657\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=435 train loss <loss>=1.16222648621\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] Epoch[10] Batch [435]#011Speed: 1587.66 samples/sec#011loss=1.162226\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] Epoch[10] Batch[440] avg_epoch_loss=1.245954\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=440 train loss <loss>=1.18468204737\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] Epoch[10] Batch [440]#011Speed: 13984.22 samples/sec#011loss=1.184682\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] Epoch[10] Batch[445] avg_epoch_loss=1.248321\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=445 train loss <loss>=1.45707743168\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] Epoch[10] Batch [445]#011Speed: 13219.38 samples/sec#011loss=1.457077\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] Epoch[10] Batch[450] avg_epoch_loss=1.247978\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=450 train loss <loss>=1.217390728\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] Epoch[10] Batch [450]#011Speed: 1783.35 samples/sec#011loss=1.217391\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] Epoch[10] Batch[455] avg_epoch_loss=1.247885\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=455 train loss <loss>=1.23952511549\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] Epoch[10] Batch [455]#011Speed: 16967.25 samples/sec#011loss=1.239525\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] Epoch[10] Batch[460] avg_epoch_loss=1.248019\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=460 train loss <loss>=1.26017727852\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] Epoch[10] Batch [460]#011Speed: 1867.75 samples/sec#011loss=1.260177\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] Epoch[10] Batch[465] avg_epoch_loss=1.248154\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=465 train loss <loss>=1.26061751842\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] Epoch[10] Batch [465]#011Speed: 14349.77 samples/sec#011loss=1.260618\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] Epoch[10] Batch[470] avg_epoch_loss=1.245762\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=470 train loss <loss>=1.02288687229\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] Epoch[10] Batch [470]#011Speed: 13326.62 samples/sec#011loss=1.022887\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] Epoch[10] Batch[475] avg_epoch_loss=1.244459\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=475 train loss <loss>=1.12172682285\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] Epoch[10] Batch [475]#011Speed: 1672.32 samples/sec#011loss=1.121727\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] Epoch[10] Batch[480] avg_epoch_loss=1.243429\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=480 train loss <loss>=1.14535884857\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] Epoch[10] Batch [480]#011Speed: 14198.88 samples/sec#011loss=1.145359\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] Epoch[10] Batch[485] avg_epoch_loss=1.242297\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=485 train loss <loss>=1.13339362144\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] Epoch[10] Batch [485]#011Speed: 14469.82 samples/sec#011loss=1.133394\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] Epoch[10] Batch[490] avg_epoch_loss=1.242608\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=490 train loss <loss>=1.27277446985\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] Epoch[10] Batch [490]#011Speed: 1678.84 samples/sec#011loss=1.272774\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] Epoch[10] Batch[495] avg_epoch_loss=1.242190\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=495 train loss <loss>=1.20116424561\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:35:59 INFO 140088046479168] Epoch[10] Batch [495]#011Speed: 14561.98 samples/sec#011loss=1.201164\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] Epoch[10] Batch[500] avg_epoch_loss=1.239684\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=500 train loss <loss>=0.991116046906\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] Epoch[10] Batch [500]#011Speed: 1653.71 samples/sec#011loss=0.991116\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] Epoch[10] Batch[505] avg_epoch_loss=1.239471\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=505 train loss <loss>=1.21809313297\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] Epoch[10] Batch [505]#011Speed: 13241.82 samples/sec#011loss=1.218093\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] Epoch[10] Batch[510] avg_epoch_loss=1.238882\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=510 train loss <loss>=1.17925728559\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] Epoch[10] Batch [510]#011Speed: 13920.98 samples/sec#011loss=1.179257\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] Epoch[10] Batch[515] avg_epoch_loss=1.237404\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=515 train loss <loss>=1.08644578457\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] Epoch[10] Batch [515]#011Speed: 1757.12 samples/sec#011loss=1.086446\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] Epoch[10] Batch[520] avg_epoch_loss=1.235475\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=520 train loss <loss>=1.03637042046\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] Epoch[10] Batch [520]#011Speed: 13233.46 samples/sec#011loss=1.036370\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] Epoch[10] Batch[525] avg_epoch_loss=1.235799\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=525 train loss <loss>=1.26959153414\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] Epoch[10] Batch [525]#011Speed: 1718.28 samples/sec#011loss=1.269592\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] Epoch[10] Batch[530] avg_epoch_loss=1.239244\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=530 train loss <loss>=1.60162887573\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] Epoch[10] Batch [530]#011Speed: 13287.31 samples/sec#011loss=1.601629\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] Epoch[10] Batch[535] avg_epoch_loss=1.243613\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=535 train loss <loss>=1.70758427382\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] Epoch[10] Batch [535]#011Speed: 13274.16 samples/sec#011loss=1.707584\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] Epoch[10] Batch[540] avg_epoch_loss=1.243086\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=540 train loss <loss>=1.18654307127\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] Epoch[10] Batch [540]#011Speed: 1640.38 samples/sec#011loss=1.186543\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] Epoch[10] Batch[545] avg_epoch_loss=1.239977\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=545 train loss <loss>=0.903628361225\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:00 INFO 140088046479168] Epoch[10] Batch [545]#011Speed: 14451.44 samples/sec#011loss=0.903628\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] Epoch[10] Batch[550] avg_epoch_loss=1.238730\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=550 train loss <loss>=1.10255792141\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] Epoch[10] Batch [550]#011Speed: 1850.31 samples/sec#011loss=1.102558\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] Epoch[10] Batch[555] avg_epoch_loss=1.239372\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=555 train loss <loss>=1.3101733923\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] Epoch[10] Batch [555]#011Speed: 14216.47 samples/sec#011loss=1.310173\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] Epoch[10] Batch[560] avg_epoch_loss=1.240009\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=560 train loss <loss>=1.31080431938\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] Epoch[10] Batch [560]#011Speed: 13825.90 samples/sec#011loss=1.310804\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] Epoch[10] Batch[565] avg_epoch_loss=1.243261\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=565 train loss <loss>=1.60815882683\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] Epoch[10] Batch [565]#011Speed: 1658.23 samples/sec#011loss=1.608159\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] Epoch[10] Batch[570] avg_epoch_loss=1.244273\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=570 train loss <loss>=1.35874980688\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] Epoch[10] Batch [570]#011Speed: 13335.49 samples/sec#011loss=1.358750\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] Epoch[10] Batch[575] avg_epoch_loss=1.243327\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=575 train loss <loss>=1.13533744812\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] Epoch[10] Batch [575]#011Speed: 1869.29 samples/sec#011loss=1.135337\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] Epoch[10] Batch[580] avg_epoch_loss=1.242809\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=580 train loss <loss>=1.18314720392\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] Epoch[10] Batch [580]#011Speed: 14263.31 samples/sec#011loss=1.183147\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] Epoch[10] Batch[585] avg_epoch_loss=1.240375\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=585 train loss <loss>=0.95751645565\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] Epoch[10] Batch [585]#011Speed: 14272.41 samples/sec#011loss=0.957516\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] Epoch[10] Batch[590] avg_epoch_loss=1.239176\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=590 train loss <loss>=1.09863493443\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] Epoch[10] Batch [590]#011Speed: 1796.52 samples/sec#011loss=1.098635\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] Epoch[10] Batch[595] avg_epoch_loss=1.238821\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=595 train loss <loss>=1.19693574905\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] Epoch[10] Batch [595]#011Speed: 12078.19 samples/sec#011loss=1.196936\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] Epoch[10] Batch[600] avg_epoch_loss=1.237859\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=600 train loss <loss>=1.12320711613\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] Epoch[10] Batch [600]#011Speed: 1409.05 samples/sec#011loss=1.123207\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] Epoch[10] Batch[605] avg_epoch_loss=1.236440\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=605 train loss <loss>=1.06587545872\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:01 INFO 140088046479168] Epoch[10] Batch [605]#011Speed: 13875.07 samples/sec#011loss=1.065875\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] Epoch[10] Batch[610] avg_epoch_loss=1.234915\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=610 train loss <loss>=1.05003851652\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] Epoch[10] Batch [610]#011Speed: 14337.05 samples/sec#011loss=1.050039\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] Epoch[10] Batch[615] avg_epoch_loss=1.232898\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=615 train loss <loss>=0.986399507523\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] Epoch[10] Batch [615]#011Speed: 1612.43 samples/sec#011loss=0.986400\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] Epoch[10] Batch[620] avg_epoch_loss=1.230452\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=620 train loss <loss>=0.929102134705\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] Epoch[10] Batch [620]#011Speed: 14230.94 samples/sec#011loss=0.929102\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] Epoch[10] Batch[625] avg_epoch_loss=1.227857\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=625 train loss <loss>=0.905512082577\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] Epoch[10] Batch [625]#011Speed: 13166.47 samples/sec#011loss=0.905512\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] Epoch[10] Batch[630] avg_epoch_loss=1.227132\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=630 train loss <loss>=1.13639515638\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] Epoch[10] Batch [630]#011Speed: 1718.77 samples/sec#011loss=1.136395\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] Epoch[10] Batch[635] avg_epoch_loss=1.227223\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=635 train loss <loss>=1.23876986504\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] Epoch[10] Batch [635]#011Speed: 13018.71 samples/sec#011loss=1.238770\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] Epoch[10] Batch[640] avg_epoch_loss=1.227330\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=640 train loss <loss>=1.24094114304\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] Epoch[10] Batch [640]#011Speed: 1688.87 samples/sec#011loss=1.240941\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] Epoch[10] Batch[645] avg_epoch_loss=1.229417\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=645 train loss <loss>=1.49689434767\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] Epoch[10] Batch [645]#011Speed: 13738.02 samples/sec#011loss=1.496894\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] Epoch[10] Batch[650] avg_epoch_loss=1.234933\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=650 train loss <loss>=1.94757926464\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] Epoch[10] Batch [650]#011Speed: 14280.61 samples/sec#011loss=1.947579\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] Epoch[10] Batch[655] avg_epoch_loss=1.239376\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=655 train loss <loss>=1.81792383194\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] Epoch[10] Batch [655]#011Speed: 1683.60 samples/sec#011loss=1.817924\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] Epoch[10] Batch[660] avg_epoch_loss=1.240959\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=660 train loss <loss>=1.44867213964\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:02 INFO 140088046479168] Epoch[10] Batch [660]#011Speed: 14272.41 samples/sec#011loss=1.448672\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] Epoch[10] Batch[665] avg_epoch_loss=1.237999\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=665 train loss <loss>=0.846718680859\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] Epoch[10] Batch [665]#011Speed: 1806.75 samples/sec#011loss=0.846719\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] Epoch[10] Batch[670] avg_epoch_loss=1.237819\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=670 train loss <loss>=1.21378327608\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] Epoch[10] Batch [670]#011Speed: 13775.81 samples/sec#011loss=1.213783\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] Epoch[10] Batch[675] avg_epoch_loss=1.238049\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=675 train loss <loss>=1.26890944242\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] Epoch[10] Batch [675]#011Speed: 14289.58 samples/sec#011loss=1.268909\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] Epoch[10] Batch[680] avg_epoch_loss=1.238147\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=680 train loss <loss>=1.25140404701\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] Epoch[10] Batch [680]#011Speed: 1898.03 samples/sec#011loss=1.251404\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] Epoch[10] Batch[685] avg_epoch_loss=1.238672\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=685 train loss <loss>=1.31016591787\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] Epoch[10] Batch [685]#011Speed: 13577.09 samples/sec#011loss=1.310166\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] Epoch[10] Batch[690] avg_epoch_loss=1.239351\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=690 train loss <loss>=1.33247208595\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] Epoch[10] Batch [690]#011Speed: 1694.10 samples/sec#011loss=1.332472\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] Epoch[10] Batch[695] avg_epoch_loss=1.237960\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=695 train loss <loss>=1.0457798481\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] Epoch[10] Batch [695]#011Speed: 14258.31 samples/sec#011loss=1.045780\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] Epoch[10] Batch[700] avg_epoch_loss=1.239199\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=700 train loss <loss>=1.41165561676\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] Epoch[10] Batch [700]#011Speed: 14186.87 samples/sec#011loss=1.411656\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] Epoch[10] Batch[705] avg_epoch_loss=1.242224\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=705 train loss <loss>=1.66636948586\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] Epoch[10] Batch [705]#011Speed: 1725.45 samples/sec#011loss=1.666369\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] Epoch[10] Batch[710] avg_epoch_loss=1.245248\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=710 train loss <loss>=1.67221705914\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:03 INFO 140088046479168] Epoch[10] Batch [710]#011Speed: 14131.75 samples/sec#011loss=1.672217\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] Epoch[10] Batch[715] avg_epoch_loss=1.246143\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=715 train loss <loss>=1.37337362766\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] Epoch[10] Batch [715]#011Speed: 1471.30 samples/sec#011loss=1.373374\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] Epoch[10] Batch[720] avg_epoch_loss=1.247950\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=720 train loss <loss>=1.50674517155\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] Epoch[10] Batch [720]#011Speed: 13220.95 samples/sec#011loss=1.506745\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] Epoch[10] Batch[725] avg_epoch_loss=1.247899\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=725 train loss <loss>=1.24057132006\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] Epoch[10] Batch [725]#011Speed: 14299.17 samples/sec#011loss=1.240571\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] Epoch[10] Batch[730] avg_epoch_loss=1.247685\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=730 train loss <loss>=1.21658068895\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] Epoch[10] Batch [730]#011Speed: 1844.86 samples/sec#011loss=1.216581\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] Epoch[10] Batch[735] avg_epoch_loss=1.246728\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=735 train loss <loss>=1.10677518845\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] Epoch[10] Batch [735]#011Speed: 14168.00 samples/sec#011loss=1.106775\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] Epoch[10] Batch[740] avg_epoch_loss=1.245686\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=740 train loss <loss>=1.09237027168\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] Epoch[10] Batch [740]#011Speed: 1910.75 samples/sec#011loss=1.092370\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] Epoch[10] Batch[745] avg_epoch_loss=1.245538\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=745 train loss <loss>=1.22349735498\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] Epoch[10] Batch [745]#011Speed: 14192.57 samples/sec#011loss=1.223497\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] Epoch[10] Batch[750] avg_epoch_loss=1.245052\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=750 train loss <loss>=1.17265638113\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] Epoch[10] Batch [750]#011Speed: 1695.73 samples/sec#011loss=1.172656\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] Epoch[10] Batch[755] avg_epoch_loss=1.245238\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=755 train loss <loss>=1.2731148839\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] Epoch[10] Batch [755]#011Speed: 13230.85 samples/sec#011loss=1.273115\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] Epoch[10] Batch[760] avg_epoch_loss=1.244425\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=760 train loss <loss>=1.12145922184\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] Epoch[10] Batch [760]#011Speed: 13285.73 samples/sec#011loss=1.121459\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] Epoch[10] Batch[765] avg_epoch_loss=1.243535\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=765 train loss <loss>=1.10812362432\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] Epoch[10] Batch [765]#011Speed: 1656.45 samples/sec#011loss=1.108124\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] Epoch[10] Batch[770] avg_epoch_loss=1.242072\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=770 train loss <loss>=1.01798439026\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] Epoch[10] Batch [770]#011Speed: 14001.87 samples/sec#011loss=1.017984\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] Epoch[10] Batch[775] avg_epoch_loss=1.242380\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=775 train loss <loss>=1.28978106976\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:04 INFO 140088046479168] Epoch[10] Batch [775]#011Speed: 13681.59 samples/sec#011loss=1.289781\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] Epoch[10] Batch[780] avg_epoch_loss=1.241433\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=780 train loss <loss>=1.09445986748\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] Epoch[10] Batch [780]#011Speed: 1773.57 samples/sec#011loss=1.094460\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] Epoch[10] Batch[785] avg_epoch_loss=1.242740\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=785 train loss <loss>=1.44694817066\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] Epoch[10] Batch [785]#011Speed: 14032.03 samples/sec#011loss=1.446948\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] Epoch[10] Batch[790] avg_epoch_loss=1.242764\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=790 train loss <loss>=1.24657274485\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] Epoch[10] Batch [790]#011Speed: 1712.58 samples/sec#011loss=1.246573\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] Epoch[10] Batch[795] avg_epoch_loss=1.242115\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=795 train loss <loss>=1.13938341141\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] Epoch[10] Batch [795]#011Speed: 14222.80 samples/sec#011loss=1.139383\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] Epoch[10] Batch[800] avg_epoch_loss=1.243620\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=800 train loss <loss>=1.48320692778\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] Epoch[10] Batch [800]#011Speed: 14246.20 samples/sec#011loss=1.483207\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] Epoch[10] Batch[805] avg_epoch_loss=1.244599\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=805 train loss <loss>=1.40151181221\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] Epoch[10] Batch [805]#011Speed: 1795.79 samples/sec#011loss=1.401512\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] Epoch[10] Batch[810] avg_epoch_loss=1.247063\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=810 train loss <loss>=1.64417333603\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] Epoch[10] Batch [810]#011Speed: 13174.75 samples/sec#011loss=1.644173\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] Epoch[10] Batch[815] avg_epoch_loss=1.249659\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=815 train loss <loss>=1.67080676556\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] Epoch[10] Batch [815]#011Speed: 13095.43 samples/sec#011loss=1.670807\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] Epoch[10] Batch[820] avg_epoch_loss=1.250886\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=820 train loss <loss>=1.45106666088\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] Epoch[10] Batch [820]#011Speed: 1746.14 samples/sec#011loss=1.451067\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] Epoch[10] Batch[825] avg_epoch_loss=1.251832\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=825 train loss <loss>=1.4071346283\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] Epoch[10] Batch [825]#011Speed: 13231.90 samples/sec#011loss=1.407135\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] Epoch[10] Batch[830] avg_epoch_loss=1.251578\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=830 train loss <loss>=1.20963938236\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] Epoch[10] Batch [830]#011Speed: 1763.75 samples/sec#011loss=1.209639\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] Epoch[10] Batch[835] avg_epoch_loss=1.251957\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=835 train loss <loss>=1.31497409344\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:05 INFO 140088046479168] Epoch[10] Batch [835]#011Speed: 13154.09 samples/sec#011loss=1.314974\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] Epoch[10] Batch[840] avg_epoch_loss=1.253526\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=840 train loss <loss>=1.51584466696\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] Epoch[10] Batch [840]#011Speed: 1679.11 samples/sec#011loss=1.515845\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] Epoch[10] Batch[845] avg_epoch_loss=1.252994\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=845 train loss <loss>=1.16357978582\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] Epoch[10] Batch [845]#011Speed: 13250.05 samples/sec#011loss=1.163580\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] Epoch[10] Batch[850] avg_epoch_loss=1.253228\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=850 train loss <loss>=1.29278798103\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] Epoch[10] Batch [850]#011Speed: 13252.67 samples/sec#011loss=1.292788\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] Epoch[10] Batch[855] avg_epoch_loss=1.252968\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=855 train loss <loss>=1.20864050388\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] Epoch[10] Batch [855]#011Speed: 1710.45 samples/sec#011loss=1.208641\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] Epoch[10] Batch[860] avg_epoch_loss=1.252210\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=860 train loss <loss>=1.12251720428\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] Epoch[10] Batch [860]#011Speed: 13165.44 samples/sec#011loss=1.122517\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] Epoch[10] Batch[865] avg_epoch_loss=1.251247\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=865 train loss <loss>=1.08547080755\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] Epoch[10] Batch [865]#011Speed: 13261.44 samples/sec#011loss=1.085471\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] Epoch[10] Batch[870] avg_epoch_loss=1.250491\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=870 train loss <loss>=1.11955590248\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] Epoch[10] Batch [870]#011Speed: 1798.70 samples/sec#011loss=1.119556\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] Epoch[10] Batch[875] avg_epoch_loss=1.249939\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=875 train loss <loss>=1.15373231173\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] Epoch[10] Batch [875]#011Speed: 14723.48 samples/sec#011loss=1.153732\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] Epoch[10] Batch[880] avg_epoch_loss=1.249193\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=880 train loss <loss>=1.11848884821\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] Epoch[10] Batch [880]#011Speed: 1632.88 samples/sec#011loss=1.118489\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] Epoch[10] Batch[885] avg_epoch_loss=1.248654\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=885 train loss <loss>=1.15367319584\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] Epoch[10] Batch [885]#011Speed: 14178.18 samples/sec#011loss=1.153673\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] Epoch[10] Batch[890] avg_epoch_loss=1.248757\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=890 train loss <loss>=1.26704456806\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:06 INFO 140088046479168] Epoch[10] Batch [890]#011Speed: 14317.63 samples/sec#011loss=1.267045\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] Epoch[10] Batch[895] avg_epoch_loss=1.248211\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=895 train loss <loss>=1.15080391169\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] Epoch[10] Batch [895]#011Speed: 2005.19 samples/sec#011loss=1.150804\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] Epoch[10] Batch[900] avg_epoch_loss=1.248060\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, batch=900 train loss <loss>=1.22106705904\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] Epoch[10] Batch [900]#011Speed: 13231.90 samples/sec#011loss=1.221067\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] processed a total of 57842 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15784.981966018677, \"sum\": 15784.981966018677, \"min\": 15784.981966018677}}, \"EndTime\": 1604320567.104665, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320551.319193}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] #throughput_metric: host=algo-1, train throughput=3664.33267178 records/second\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=10, train loss <loss>=1.24806557408\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] Saved checkpoint to \"/opt/ml/model/state_24adae7c-1d20-45bf-95ad-338e4aaa639f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 5.0029754638671875, \"sum\": 5.0029754638671875, \"min\": 5.0029754638671875}}, \"EndTime\": 1604320567.110331, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320567.104779}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] Epoch[11] Batch[0] avg_epoch_loss=1.324910\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=1.32490980625\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] Epoch[11] Batch[5] avg_epoch_loss=1.077453\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=1.07745293776\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] Epoch[11] Batch [5]#011Speed: 14203.84 samples/sec#011loss=1.077453\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] Epoch[11] Batch[10] avg_epoch_loss=1.157888\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=1.25441039801\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] Epoch[11] Batch [10]#011Speed: 14264.07 samples/sec#011loss=1.254410\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] Epoch[11] Batch[15] avg_epoch_loss=1.170341\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=15 train loss <loss>=1.19773721695\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] Epoch[11] Batch [15]#011Speed: 1802.56 samples/sec#011loss=1.197737\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] Epoch[11] Batch[20] avg_epoch_loss=1.136155\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=20 train loss <loss>=1.02675967216\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] Epoch[11] Batch [20]#011Speed: 14238.04 samples/sec#011loss=1.026760\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] Epoch[11] Batch[25] avg_epoch_loss=1.140094\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=25 train loss <loss>=1.15663830042\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] Epoch[11] Batch [25]#011Speed: 14318.24 samples/sec#011loss=1.156638\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] Epoch[11] Batch[30] avg_epoch_loss=1.108364\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=30 train loss <loss>=0.943365693092\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] Epoch[11] Batch [30]#011Speed: 1677.19 samples/sec#011loss=0.943366\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] Epoch[11] Batch[35] avg_epoch_loss=1.089032\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=35 train loss <loss>=0.969174766541\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] Epoch[11] Batch [35]#011Speed: 13450.96 samples/sec#011loss=0.969175\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] Epoch[11] Batch[40] avg_epoch_loss=1.082193\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=40 train loss <loss>=1.0329547286\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] Epoch[11] Batch [40]#011Speed: 1747.95 samples/sec#011loss=1.032955\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] Epoch[11] Batch[45] avg_epoch_loss=1.083709\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=45 train loss <loss>=1.09614225626\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] Epoch[11] Batch [45]#011Speed: 13292.31 samples/sec#011loss=1.096142\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] Epoch[11] Batch[50] avg_epoch_loss=1.073104\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=50 train loss <loss>=0.975535047054\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:07 INFO 140088046479168] Epoch[11] Batch [50]#011Speed: 13170.35 samples/sec#011loss=0.975535\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] Epoch[11] Batch[55] avg_epoch_loss=1.047842\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=55 train loss <loss>=0.790173119307\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] Epoch[11] Batch [55]#011Speed: 1678.87 samples/sec#011loss=0.790173\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] Epoch[11] Batch[60] avg_epoch_loss=1.044615\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=60 train loss <loss>=1.00846732855\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] Epoch[11] Batch [60]#011Speed: 13217.17 samples/sec#011loss=1.008467\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] Epoch[11] Batch[65] avg_epoch_loss=1.035340\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=65 train loss <loss>=0.922191786766\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] Epoch[11] Batch [65]#011Speed: 14151.87 samples/sec#011loss=0.922192\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] Epoch[11] Batch[70] avg_epoch_loss=1.035326\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=70 train loss <loss>=1.03513412476\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] Epoch[11] Batch [70]#011Speed: 1717.74 samples/sec#011loss=1.035134\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] Epoch[11] Batch[75] avg_epoch_loss=1.032370\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=75 train loss <loss>=0.990394866467\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] Epoch[11] Batch [75]#011Speed: 14170.54 samples/sec#011loss=0.990395\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] Epoch[11] Batch[80] avg_epoch_loss=1.017810\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=80 train loss <loss>=0.796495592594\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] Epoch[11] Batch [80]#011Speed: 1749.80 samples/sec#011loss=0.796496\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] Epoch[11] Batch[85] avg_epoch_loss=1.021209\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=85 train loss <loss>=1.07628219128\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] Epoch[11] Batch [85]#011Speed: 14310.60 samples/sec#011loss=1.076282\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] Epoch[11] Batch[90] avg_epoch_loss=1.023931\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=90 train loss <loss>=1.07074763775\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] Epoch[11] Batch [90]#011Speed: 14083.85 samples/sec#011loss=1.070748\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] Epoch[11] Batch[95] avg_epoch_loss=1.017341\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=95 train loss <loss>=0.897395813465\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] Epoch[11] Batch [95]#011Speed: 1747.24 samples/sec#011loss=0.897396\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] Epoch[11] Batch[100] avg_epoch_loss=1.024327\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=100 train loss <loss>=1.15846204758\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:08 INFO 140088046479168] Epoch[11] Batch [100]#011Speed: 11531.53 samples/sec#011loss=1.158462\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] Epoch[11] Batch[105] avg_epoch_loss=1.031178\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=105 train loss <loss>=1.16957712173\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] Epoch[11] Batch [105]#011Speed: 1622.63 samples/sec#011loss=1.169577\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] Epoch[11] Batch[110] avg_epoch_loss=1.061479\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=110 train loss <loss>=1.70385386944\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] Epoch[11] Batch [110]#011Speed: 14160.53 samples/sec#011loss=1.703854\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] Epoch[11] Batch[115] avg_epoch_loss=1.072058\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=115 train loss <loss>=1.30690588951\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] Epoch[11] Batch [115]#011Speed: 14008.01 samples/sec#011loss=1.306906\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] Epoch[11] Batch[120] avg_epoch_loss=1.083316\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=120 train loss <loss>=1.3445062995\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] Epoch[11] Batch [120]#011Speed: 1745.71 samples/sec#011loss=1.344506\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] Epoch[11] Batch[125] avg_epoch_loss=1.096802\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=125 train loss <loss>=1.42316733599\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] Epoch[11] Batch [125]#011Speed: 14352.23 samples/sec#011loss=1.423167\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] Epoch[11] Batch[130] avg_epoch_loss=1.102556\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=130 train loss <loss>=1.24754459858\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] Epoch[11] Batch [130]#011Speed: 13067.13 samples/sec#011loss=1.247545\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] Epoch[11] Batch[135] avg_epoch_loss=1.098915\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=135 train loss <loss>=1.0035292387\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] Epoch[11] Batch [135]#011Speed: 1681.34 samples/sec#011loss=1.003529\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] Epoch[11] Batch[140] avg_epoch_loss=1.100401\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=140 train loss <loss>=1.14082561731\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] Epoch[11] Batch [140]#011Speed: 14179.38 samples/sec#011loss=1.140826\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] Epoch[11] Batch[145] avg_epoch_loss=1.121565\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=145 train loss <loss>=1.71837425232\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] Epoch[11] Batch [145]#011Speed: 1712.65 samples/sec#011loss=1.718374\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] Epoch[11] Batch[150] avg_epoch_loss=1.133367\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=150 train loss <loss>=1.47798964977\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] Epoch[11] Batch [150]#011Speed: 14273.62 samples/sec#011loss=1.477990\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] Epoch[11] Batch[155] avg_epoch_loss=1.149093\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=155 train loss <loss>=1.62401442528\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] Epoch[11] Batch [155]#011Speed: 14089.47 samples/sec#011loss=1.624014\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] Epoch[11] Batch[160] avg_epoch_loss=1.158405\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=160 train loss <loss>=1.44894881248\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:09 INFO 140088046479168] Epoch[11] Batch [160]#011Speed: 1807.97 samples/sec#011loss=1.448949\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] Epoch[11] Batch[165] avg_epoch_loss=1.174114\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=165 train loss <loss>=1.67995717525\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] Epoch[11] Batch [165]#011Speed: 13241.16 samples/sec#011loss=1.679957\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] Epoch[11] Batch[170] avg_epoch_loss=1.179140\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=170 train loss <loss>=1.34597456455\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] Epoch[11] Batch [170]#011Speed: 1768.53 samples/sec#011loss=1.345975\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] Epoch[11] Batch[175] avg_epoch_loss=1.179338\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=175 train loss <loss>=1.18613957167\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] Epoch[11] Batch [175]#011Speed: 14542.88 samples/sec#011loss=1.186140\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] Epoch[11] Batch[180] avg_epoch_loss=1.186774\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=180 train loss <loss>=1.44849698544\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] Epoch[11] Batch [180]#011Speed: 14469.20 samples/sec#011loss=1.448497\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] Epoch[11] Batch[185] avg_epoch_loss=1.191390\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=185 train loss <loss>=1.3584941864\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] Epoch[11] Batch [185]#011Speed: 1684.70 samples/sec#011loss=1.358494\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] Epoch[11] Batch[190] avg_epoch_loss=1.190291\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=190 train loss <loss>=1.1494127512\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] Epoch[11] Batch [190]#011Speed: 14339.35 samples/sec#011loss=1.149413\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] Epoch[11] Batch[195] avg_epoch_loss=1.194343\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=195 train loss <loss>=1.34911860824\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] Epoch[11] Batch [195]#011Speed: 1757.41 samples/sec#011loss=1.349119\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] Epoch[11] Batch[200] avg_epoch_loss=1.194461\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=200 train loss <loss>=1.1990950346\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] Epoch[11] Batch [200]#011Speed: 14272.41 samples/sec#011loss=1.199095\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] Epoch[11] Batch[205] avg_epoch_loss=1.199496\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=205 train loss <loss>=1.40190315247\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] Epoch[11] Batch [205]#011Speed: 13394.18 samples/sec#011loss=1.401903\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] Epoch[11] Batch[210] avg_epoch_loss=1.197981\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=210 train loss <loss>=1.13557888269\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] Epoch[11] Batch [210]#011Speed: 1738.17 samples/sec#011loss=1.135579\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] Epoch[11] Batch[215] avg_epoch_loss=1.194236\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=215 train loss <loss>=1.03619437218\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:10 INFO 140088046479168] Epoch[11] Batch [215]#011Speed: 14961.79 samples/sec#011loss=1.036194\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] Epoch[11] Batch[220] avg_epoch_loss=1.194804\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=220 train loss <loss>=1.21934316158\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] Epoch[11] Batch [220]#011Speed: 1647.86 samples/sec#011loss=1.219343\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] Epoch[11] Batch[225] avg_epoch_loss=1.189916\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=225 train loss <loss>=0.97386405468\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] Epoch[11] Batch [225]#011Speed: 13900.94 samples/sec#011loss=0.973864\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] Epoch[11] Batch[230] avg_epoch_loss=1.186932\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=230 train loss <loss>=1.05206418037\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] Epoch[11] Batch [230]#011Speed: 14315.79 samples/sec#011loss=1.052064\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] Epoch[11] Batch[235] avg_epoch_loss=1.184526\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=235 train loss <loss>=1.07334301472\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] Epoch[11] Batch [235]#011Speed: 1829.06 samples/sec#011loss=1.073343\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] Epoch[11] Batch[240] avg_epoch_loss=1.180690\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=240 train loss <loss>=0.999629831314\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] Epoch[11] Batch [240]#011Speed: 13904.54 samples/sec#011loss=0.999630\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] Epoch[11] Batch[245] avg_epoch_loss=1.177703\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=245 train loss <loss>=1.0337110281\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] Epoch[11] Batch [245]#011Speed: 1717.31 samples/sec#011loss=1.033711\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] Epoch[11] Batch[250] avg_epoch_loss=1.177541\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=250 train loss <loss>=1.16961320639\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] Epoch[11] Batch [250]#011Speed: 13363.91 samples/sec#011loss=1.169613\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] Epoch[11] Batch[255] avg_epoch_loss=1.177982\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=255 train loss <loss>=1.20010739565\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] Epoch[11] Batch [255]#011Speed: 13062.81 samples/sec#011loss=1.200107\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] Epoch[11] Batch[260] avg_epoch_loss=1.171627\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=260 train loss <loss>=0.846262490749\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] Epoch[11] Batch [260]#011Speed: 1754.20 samples/sec#011loss=0.846262\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] Epoch[11] Batch[265] avg_epoch_loss=1.166313\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=265 train loss <loss>=0.888880074024\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] Epoch[11] Batch [265]#011Speed: 13210.02 samples/sec#011loss=0.888880\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] Epoch[11] Batch[270] avg_epoch_loss=1.163897\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=270 train loss <loss>=1.03539409637\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] Epoch[11] Batch [270]#011Speed: 1602.79 samples/sec#011loss=1.035394\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] Epoch[11] Batch[275] avg_epoch_loss=1.153599\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=275 train loss <loss>=0.595417410135\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:11 INFO 140088046479168] Epoch[11] Batch [275]#011Speed: 13105.66 samples/sec#011loss=0.595417\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] Epoch[11] Batch[280] avg_epoch_loss=1.149776\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=280 train loss <loss>=0.938792037964\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] Epoch[11] Batch [280]#011Speed: 13235.81 samples/sec#011loss=0.938792\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] Epoch[11] Batch[285] avg_epoch_loss=1.141015\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=285 train loss <loss>=0.648601734638\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] Epoch[11] Batch [285]#011Speed: 1787.99 samples/sec#011loss=0.648602\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] Epoch[11] Batch[290] avg_epoch_loss=1.138275\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=290 train loss <loss>=0.981591296196\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] Epoch[11] Batch [290]#011Speed: 13245.08 samples/sec#011loss=0.981591\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] Epoch[11] Batch[295] avg_epoch_loss=1.138571\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=295 train loss <loss>=1.15580420494\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] Epoch[11] Batch [295]#011Speed: 1761.21 samples/sec#011loss=1.155804\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] Epoch[11] Batch[300] avg_epoch_loss=1.145535\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=300 train loss <loss>=1.55779986382\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] Epoch[11] Batch [300]#011Speed: 13186.65 samples/sec#011loss=1.557800\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] Epoch[11] Batch[305] avg_epoch_loss=1.168184\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=305 train loss <loss>=2.53164467812\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] Epoch[11] Batch [305]#011Speed: 13376.83 samples/sec#011loss=2.531645\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] Epoch[11] Batch[310] avg_epoch_loss=1.172672\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=310 train loss <loss>=1.44734435081\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] Epoch[11] Batch [310]#011Speed: 1613.63 samples/sec#011loss=1.447344\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] Epoch[11] Batch[315] avg_epoch_loss=1.171075\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=315 train loss <loss>=1.07173490524\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] Epoch[11] Batch [315]#011Speed: 13971.99 samples/sec#011loss=1.071735\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] Epoch[11] Batch[320] avg_epoch_loss=1.165826\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=320 train loss <loss>=0.834068644047\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] Epoch[11] Batch [320]#011Speed: 1695.81 samples/sec#011loss=0.834069\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] Epoch[11] Batch[325] avg_epoch_loss=1.164660\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=325 train loss <loss>=1.08980746269\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] Epoch[11] Batch [325]#011Speed: 13481.09 samples/sec#011loss=1.089807\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] Epoch[11] Batch[330] avg_epoch_loss=1.160148\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=330 train loss <loss>=0.865984225273\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:12 INFO 140088046479168] Epoch[11] Batch [330]#011Speed: 14285.02 samples/sec#011loss=0.865984\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] Epoch[11] Batch[335] avg_epoch_loss=1.160094\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=335 train loss <loss>=1.15648882389\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] Epoch[11] Batch [335]#011Speed: 1741.95 samples/sec#011loss=1.156489\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] Epoch[11] Batch[340] avg_epoch_loss=1.157415\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=340 train loss <loss>=0.977380019426\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] Epoch[11] Batch [340]#011Speed: 14471.85 samples/sec#011loss=0.977380\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] Epoch[11] Batch[345] avg_epoch_loss=1.156596\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=345 train loss <loss>=1.10073645115\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] Epoch[11] Batch [345]#011Speed: 1806.22 samples/sec#011loss=1.100736\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] Epoch[11] Batch[350] avg_epoch_loss=1.159457\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=350 train loss <loss>=1.35747871399\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] Epoch[11] Batch [350]#011Speed: 14237.44 samples/sec#011loss=1.357479\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] Epoch[11] Batch[355] avg_epoch_loss=1.161959\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=355 train loss <loss>=1.33761963844\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] Epoch[11] Batch [355]#011Speed: 14419.61 samples/sec#011loss=1.337620\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] Epoch[11] Batch[360] avg_epoch_loss=1.163197\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=360 train loss <loss>=1.25130879879\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] Epoch[11] Batch [360]#011Speed: 1626.95 samples/sec#011loss=1.251309\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] Epoch[11] Batch[365] avg_epoch_loss=1.169213\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=365 train loss <loss>=1.6035692215\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] Epoch[11] Batch [365]#011Speed: 14360.83 samples/sec#011loss=1.603569\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] Epoch[11] Batch[370] avg_epoch_loss=1.174010\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=370 train loss <loss>=1.5251816988\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] Epoch[11] Batch [370]#011Speed: 13675.31 samples/sec#011loss=1.525182\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] Epoch[11] Batch[375] avg_epoch_loss=1.172342\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=375 train loss <loss>=1.04857945442\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] Epoch[11] Batch [375]#011Speed: 1816.89 samples/sec#011loss=1.048579\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] Epoch[11] Batch[380] avg_epoch_loss=1.177541\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=380 train loss <loss>=1.56848298311\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] Epoch[11] Batch [380]#011Speed: 13269.83 samples/sec#011loss=1.568483\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] Epoch[11] Batch[385] avg_epoch_loss=1.186490\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=385 train loss <loss>=1.86842081547\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] Epoch[11] Batch [385]#011Speed: 1893.82 samples/sec#011loss=1.868421\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] Epoch[11] Batch[390] avg_epoch_loss=1.194199\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=390 train loss <loss>=1.78933823109\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:13 INFO 140088046479168] Epoch[11] Batch [390]#011Speed: 11995.83 samples/sec#011loss=1.789338\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] Epoch[11] Batch[395] avg_epoch_loss=1.194996\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=395 train loss <loss>=1.25732365847\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] Epoch[11] Batch [395]#011Speed: 1439.17 samples/sec#011loss=1.257324\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] Epoch[11] Batch[400] avg_epoch_loss=1.194932\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=400 train loss <loss>=1.1898430109\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] Epoch[11] Batch [400]#011Speed: 14069.53 samples/sec#011loss=1.189843\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] Epoch[11] Batch[405] avg_epoch_loss=1.194501\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=405 train loss <loss>=1.15994018316\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] Epoch[11] Batch [405]#011Speed: 14024.11 samples/sec#011loss=1.159940\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] Epoch[11] Batch[410] avg_epoch_loss=1.192002\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=410 train loss <loss>=0.989036726952\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] Epoch[11] Batch [410]#011Speed: 1770.77 samples/sec#011loss=0.989037\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] Epoch[11] Batch[415] avg_epoch_loss=1.189853\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=415 train loss <loss>=1.01325616837\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] Epoch[11] Batch [415]#011Speed: 14031.44 samples/sec#011loss=1.013256\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] Epoch[11] Batch[420] avg_epoch_loss=1.189367\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=420 train loss <loss>=1.14891499281\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] Epoch[11] Batch [420]#011Speed: 1671.49 samples/sec#011loss=1.148915\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] Epoch[11] Batch[425] avg_epoch_loss=1.189695\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=425 train loss <loss>=1.21731395721\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] Epoch[11] Batch [425]#011Speed: 14407.23 samples/sec#011loss=1.217314\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] Epoch[11] Batch[430] avg_epoch_loss=1.191071\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=430 train loss <loss>=1.30829231739\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] Epoch[11] Batch [430]#011Speed: 14281.22 samples/sec#011loss=1.308292\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] Epoch[11] Batch[435] avg_epoch_loss=1.188658\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=435 train loss <loss>=0.980648338795\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] Epoch[11] Batch [435]#011Speed: 1835.23 samples/sec#011loss=0.980648\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] Epoch[11] Batch[440] avg_epoch_loss=1.188543\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=440 train loss <loss>=1.17852187157\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:14 INFO 140088046479168] Epoch[11] Batch [440]#011Speed: 14329.86 samples/sec#011loss=1.178522\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] Epoch[11] Batch[445] avg_epoch_loss=1.191771\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=445 train loss <loss>=1.47646788359\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] Epoch[11] Batch [445]#011Speed: 1742.34 samples/sec#011loss=1.476468\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] Epoch[11] Batch[450] avg_epoch_loss=1.189852\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=450 train loss <loss>=1.01872138977\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] Epoch[11] Batch [450]#011Speed: 14412.33 samples/sec#011loss=1.018721\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] Epoch[11] Batch[455] avg_epoch_loss=1.192515\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=455 train loss <loss>=1.43272514343\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] Epoch[11] Batch [455]#011Speed: 14106.80 samples/sec#011loss=1.432725\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] Epoch[11] Batch[460] avg_epoch_loss=1.192183\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=460 train loss <loss>=1.16185200214\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] Epoch[11] Batch [460]#011Speed: 1701.27 samples/sec#011loss=1.161852\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] Epoch[11] Batch[465] avg_epoch_loss=1.191966\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=465 train loss <loss>=1.17194176912\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] Epoch[11] Batch [465]#011Speed: 14118.67 samples/sec#011loss=1.171942\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] Epoch[11] Batch[470] avg_epoch_loss=1.191264\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=470 train loss <loss>=1.12590260506\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] Epoch[11] Batch [470]#011Speed: 1809.33 samples/sec#011loss=1.125903\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] Epoch[11] Batch[475] avg_epoch_loss=1.193328\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=475 train loss <loss>=1.38770952225\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] Epoch[11] Batch [475]#011Speed: 13108.86 samples/sec#011loss=1.387710\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] Epoch[11] Batch[480] avg_epoch_loss=1.192639\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=480 train loss <loss>=1.12708699703\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] Epoch[11] Batch [480]#011Speed: 13755.62 samples/sec#011loss=1.127087\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] Epoch[11] Batch[485] avg_epoch_loss=1.191867\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=485 train loss <loss>=1.11760491133\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] Epoch[11] Batch [485]#011Speed: 1759.00 samples/sec#011loss=1.117605\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] Epoch[11] Batch[490] avg_epoch_loss=1.192411\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=490 train loss <loss>=1.24528040886\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] Epoch[11] Batch [490]#011Speed: 13879.95 samples/sec#011loss=1.245280\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] Epoch[11] Batch[495] avg_epoch_loss=1.193178\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=495 train loss <loss>=1.26852531433\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] Epoch[11] Batch [495]#011Speed: 14205.19 samples/sec#011loss=1.268525\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] Epoch[11] Batch[500] avg_epoch_loss=1.192846\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=500 train loss <loss>=1.15990191698\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] Epoch[11] Batch [500]#011Speed: 1792.41 samples/sec#011loss=1.159902\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] Epoch[11] Batch[505] avg_epoch_loss=1.190943\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=505 train loss <loss>=1.00022482872\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:15 INFO 140088046479168] Epoch[11] Batch [505]#011Speed: 13696.25 samples/sec#011loss=1.000225\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] Epoch[11] Batch[510] avg_epoch_loss=1.188483\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=510 train loss <loss>=0.939561760426\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] Epoch[11] Batch [510]#011Speed: 1722.49 samples/sec#011loss=0.939562\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] Epoch[11] Batch[515] avg_epoch_loss=1.188479\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=515 train loss <loss>=1.18799008131\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] Epoch[11] Batch [515]#011Speed: 13358.99 samples/sec#011loss=1.187990\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] Epoch[11] Batch[520] avg_epoch_loss=1.187056\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=520 train loss <loss>=1.04021340609\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] Epoch[11] Batch [520]#011Speed: 14301.61 samples/sec#011loss=1.040213\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] Epoch[11] Batch[525] avg_epoch_loss=1.185372\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=525 train loss <loss>=1.00995028019\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] Epoch[11] Batch [525]#011Speed: 1654.31 samples/sec#011loss=1.009950\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] Epoch[11] Batch[530] avg_epoch_loss=1.184137\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=530 train loss <loss>=1.05419566631\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] Epoch[11] Batch [530]#011Speed: 10795.19 samples/sec#011loss=1.054196\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] Epoch[11] Batch[535] avg_epoch_loss=1.183248\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=535 train loss <loss>=1.08889535666\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] Epoch[11] Batch [535]#011Speed: 1598.23 samples/sec#011loss=1.088895\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] Epoch[11] Batch[540] avg_epoch_loss=1.182298\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=540 train loss <loss>=1.08037660122\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] Epoch[11] Batch [540]#011Speed: 14236.83 samples/sec#011loss=1.080377\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] Epoch[11] Batch[545] avg_epoch_loss=1.182339\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=545 train loss <loss>=1.1867770195\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] Epoch[11] Batch [545]#011Speed: 13642.51 samples/sec#011loss=1.186777\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] Epoch[11] Batch[550] avg_epoch_loss=1.183704\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=550 train loss <loss>=1.33273444176\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] Epoch[11] Batch [550]#011Speed: 1724.63 samples/sec#011loss=1.332734\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] Epoch[11] Batch[555] avg_epoch_loss=1.183767\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=555 train loss <loss>=1.1907905817\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:16 INFO 140088046479168] Epoch[11] Batch [555]#011Speed: 14483.56 samples/sec#011loss=1.190791\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] Epoch[11] Batch[560] avg_epoch_loss=1.183532\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=560 train loss <loss>=1.15735434294\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] Epoch[11] Batch [560]#011Speed: 1670.39 samples/sec#011loss=1.157354\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] Epoch[11] Batch[565] avg_epoch_loss=1.183645\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=565 train loss <loss>=1.19631156921\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] Epoch[11] Batch [565]#011Speed: 14276.20 samples/sec#011loss=1.196312\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] Epoch[11] Batch[570] avg_epoch_loss=1.181058\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=570 train loss <loss>=0.888272082806\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] Epoch[11] Batch [570]#011Speed: 14213.46 samples/sec#011loss=0.888272\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] Epoch[11] Batch[575] avg_epoch_loss=1.185654\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=575 train loss <loss>=1.71050291061\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] Epoch[11] Batch [575]#011Speed: 1784.70 samples/sec#011loss=1.710503\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] Epoch[11] Batch[580] avg_epoch_loss=1.192355\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=580 train loss <loss>=1.96434957981\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] Epoch[11] Batch [580]#011Speed: 14422.86 samples/sec#011loss=1.964350\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] Epoch[11] Batch[585] avg_epoch_loss=1.198784\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=585 train loss <loss>=1.94572229385\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] Epoch[11] Batch [585]#011Speed: 1780.73 samples/sec#011loss=1.945722\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] Epoch[11] Batch[590] avg_epoch_loss=1.204360\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=590 train loss <loss>=1.85795810223\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] Epoch[11] Batch [590]#011Speed: 14221.60 samples/sec#011loss=1.857958\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] Epoch[11] Batch[595] avg_epoch_loss=1.209041\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=595 train loss <loss>=1.76230504513\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] Epoch[11] Batch [595]#011Speed: 14200.83 samples/sec#011loss=1.762305\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] Epoch[11] Batch[600] avg_epoch_loss=1.211431\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=600 train loss <loss>=1.49632976055\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] Epoch[11] Batch [600]#011Speed: 1717.96 samples/sec#011loss=1.496330\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] Epoch[11] Batch[605] avg_epoch_loss=1.214523\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=605 train loss <loss>=1.58620729446\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] Epoch[11] Batch [605]#011Speed: 14375.59 samples/sec#011loss=1.586207\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] Epoch[11] Batch[610] avg_epoch_loss=1.216684\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=610 train loss <loss>=1.47852210999\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] Epoch[11] Batch [610]#011Speed: 1780.86 samples/sec#011loss=1.478522\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] Epoch[11] Batch[615] avg_epoch_loss=1.217800\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=615 train loss <loss>=1.35422079563\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] Epoch[11] Batch [615]#011Speed: 13947.02 samples/sec#011loss=1.354221\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] Epoch[11] Batch[620] avg_epoch_loss=1.221437\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=620 train loss <loss>=1.66951882839\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:17 INFO 140088046479168] Epoch[11] Batch [620]#011Speed: 14037.60 samples/sec#011loss=1.669519\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] Epoch[11] Batch[625] avg_epoch_loss=1.223814\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=625 train loss <loss>=1.51908159256\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] Epoch[11] Batch [625]#011Speed: 1431.03 samples/sec#011loss=1.519082\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] Epoch[11] Batch[630] avg_epoch_loss=1.223693\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=630 train loss <loss>=1.20849052668\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] Epoch[11] Batch [630]#011Speed: 13360.05 samples/sec#011loss=1.208491\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] Epoch[11] Batch[635] avg_epoch_loss=1.225020\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=635 train loss <loss>=1.39242238998\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] Epoch[11] Batch [635]#011Speed: 13177.85 samples/sec#011loss=1.392422\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] Epoch[11] Batch[640] avg_epoch_loss=1.223894\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=640 train loss <loss>=1.08073256016\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] Epoch[11] Batch [640]#011Speed: 1801.86 samples/sec#011loss=1.080733\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] Epoch[11] Batch[645] avg_epoch_loss=1.223595\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=645 train loss <loss>=1.18524136543\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] Epoch[11] Batch [645]#011Speed: 14320.22 samples/sec#011loss=1.185241\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] Epoch[11] Batch[650] avg_epoch_loss=1.222244\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=650 train loss <loss>=1.04768607616\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] Epoch[11] Batch [650]#011Speed: 1681.68 samples/sec#011loss=1.047686\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] Epoch[11] Batch[655] avg_epoch_loss=1.220617\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=655 train loss <loss>=1.00883125067\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] Epoch[11] Batch [655]#011Speed: 14132.35 samples/sec#011loss=1.008831\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] Epoch[11] Batch[660] avg_epoch_loss=1.220623\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=660 train loss <loss>=1.22131891251\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] Epoch[11] Batch [660]#011Speed: 14225.97 samples/sec#011loss=1.221319\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] Epoch[11] Batch[665] avg_epoch_loss=1.219195\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=665 train loss <loss>=1.03042629957\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] Epoch[11] Batch [665]#011Speed: 1856.67 samples/sec#011loss=1.030426\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] Epoch[11] Batch[670] avg_epoch_loss=1.218868\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=670 train loss <loss>=1.17538704872\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:18 INFO 140088046479168] Epoch[11] Batch [670]#011Speed: 13734.51 samples/sec#011loss=1.175387\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] Epoch[11] Batch[675] avg_epoch_loss=1.218270\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=675 train loss <loss>=1.13804503679\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] Epoch[11] Batch [675]#011Speed: 1599.34 samples/sec#011loss=1.138045\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] Epoch[11] Batch[680] avg_epoch_loss=1.217653\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=680 train loss <loss>=1.13420622349\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] Epoch[11] Batch [680]#011Speed: 11288.29 samples/sec#011loss=1.134206\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] Epoch[11] Batch[685] avg_epoch_loss=1.218307\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=685 train loss <loss>=1.30730037689\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] Epoch[11] Batch [685]#011Speed: 14499.99 samples/sec#011loss=1.307300\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] Epoch[11] Batch[690] avg_epoch_loss=1.218505\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=690 train loss <loss>=1.2457249403\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] Epoch[11] Batch [690]#011Speed: 1507.78 samples/sec#011loss=1.245725\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] Epoch[11] Batch[695] avg_epoch_loss=1.218121\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=695 train loss <loss>=1.16499031782\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] Epoch[11] Batch [695]#011Speed: 16759.20 samples/sec#011loss=1.164990\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] Epoch[11] Batch[700] avg_epoch_loss=1.218893\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=700 train loss <loss>=1.32637162209\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] Epoch[11] Batch [700]#011Speed: 13089.05 samples/sec#011loss=1.326372\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] Epoch[11] Batch[705] avg_epoch_loss=1.218804\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=705 train loss <loss>=1.20644263029\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] Epoch[11] Batch [705]#011Speed: 1683.67 samples/sec#011loss=1.206443\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] Epoch[11] Batch[710] avg_epoch_loss=1.217660\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=710 train loss <loss>=1.05600953102\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] Epoch[11] Batch [710]#011Speed: 13064.46 samples/sec#011loss=1.056010\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] Epoch[11] Batch[715] avg_epoch_loss=1.217677\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=715 train loss <loss>=1.22007894516\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] Epoch[11] Batch [715]#011Speed: 1709.00 samples/sec#011loss=1.220079\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] Epoch[11] Batch[720] avg_epoch_loss=1.218850\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=720 train loss <loss>=1.38694095612\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] Epoch[11] Batch [720]#011Speed: 14306.18 samples/sec#011loss=1.386941\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] Epoch[11] Batch[725] avg_epoch_loss=1.221171\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=725 train loss <loss>=1.55574457645\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] Epoch[11] Batch [725]#011Speed: 14257.70 samples/sec#011loss=1.555745\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] Epoch[11] Batch[730] avg_epoch_loss=1.221362\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=730 train loss <loss>=1.2491604805\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:19 INFO 140088046479168] Epoch[11] Batch [730]#011Speed: 1876.85 samples/sec#011loss=1.249160\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] Epoch[11] Batch[735] avg_epoch_loss=1.222862\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=735 train loss <loss>=1.44208847284\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] Epoch[11] Batch [735]#011Speed: 13664.73 samples/sec#011loss=1.442088\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] Epoch[11] Batch[740] avg_epoch_loss=1.224166\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=740 train loss <loss>=1.41615486145\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] Epoch[11] Batch [740]#011Speed: 1710.51 samples/sec#011loss=1.416155\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] Epoch[11] Batch[745] avg_epoch_loss=1.224396\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=745 train loss <loss>=1.25849641562\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] Epoch[11] Batch [745]#011Speed: 14222.20 samples/sec#011loss=1.258496\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] Epoch[11] Batch[750] avg_epoch_loss=1.225610\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=750 train loss <loss>=1.40682570934\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] Epoch[11] Batch [750]#011Speed: 14335.67 samples/sec#011loss=1.406826\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] Epoch[11] Batch[755] avg_epoch_loss=1.226365\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=755 train loss <loss>=1.33966857195\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] Epoch[11] Batch [755]#011Speed: 1762.72 samples/sec#011loss=1.339669\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] Epoch[11] Batch[760] avg_epoch_loss=1.227110\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=760 train loss <loss>=1.33974897861\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] Epoch[11] Batch [760]#011Speed: 14585.24 samples/sec#011loss=1.339749\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] Epoch[11] Batch[765] avg_epoch_loss=1.228945\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=765 train loss <loss>=1.50821816921\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] Epoch[11] Batch [765]#011Speed: 1686.54 samples/sec#011loss=1.508218\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] Epoch[11] Batch[770] avg_epoch_loss=1.230458\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=770 train loss <loss>=1.46235579252\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] Epoch[11] Batch [770]#011Speed: 13241.29 samples/sec#011loss=1.462356\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] Epoch[11] Batch[775] avg_epoch_loss=1.229761\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=775 train loss <loss>=1.12216699123\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] Epoch[11] Batch [775]#011Speed: 14171.89 samples/sec#011loss=1.122167\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] Epoch[11] Batch[780] avg_epoch_loss=1.230582\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=780 train loss <loss>=1.35806467533\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] Epoch[11] Batch [780]#011Speed: 1771.19 samples/sec#011loss=1.358065\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] Epoch[11] Batch[785] avg_epoch_loss=1.233309\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=785 train loss <loss>=1.6593173027\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:20 INFO 140088046479168] Epoch[11] Batch [785]#011Speed: 12952.25 samples/sec#011loss=1.659317\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] Epoch[11] Batch[790] avg_epoch_loss=1.233448\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=790 train loss <loss>=1.25519399643\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] Epoch[11] Batch [790]#011Speed: 1630.43 samples/sec#011loss=1.255194\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] Epoch[11] Batch[795] avg_epoch_loss=1.234826\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=795 train loss <loss>=1.45295038223\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] Epoch[11] Batch [795]#011Speed: 14034.52 samples/sec#011loss=1.452950\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] Epoch[11] Batch[800] avg_epoch_loss=1.236084\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=800 train loss <loss>=1.436308074\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] Epoch[11] Batch [800]#011Speed: 14156.20 samples/sec#011loss=1.436308\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] Epoch[11] Batch[805] avg_epoch_loss=1.236596\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=805 train loss <loss>=1.31854846478\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] Epoch[11] Batch [805]#011Speed: 1741.03 samples/sec#011loss=1.318548\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] Epoch[11] Batch[810] avg_epoch_loss=1.236881\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=810 train loss <loss>=1.28291956186\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] Epoch[11] Batch [810]#011Speed: 13783.59 samples/sec#011loss=1.282920\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] Epoch[11] Batch[815] avg_epoch_loss=1.238125\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=815 train loss <loss>=1.43992362022\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] Epoch[11] Batch [815]#011Speed: 1780.39 samples/sec#011loss=1.439924\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] Epoch[11] Batch[820] avg_epoch_loss=1.238404\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=820 train loss <loss>=1.28393480778\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] Epoch[11] Batch [820]#011Speed: 14206.39 samples/sec#011loss=1.283935\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] Epoch[11] Batch[825] avg_epoch_loss=1.238267\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=825 train loss <loss>=1.21563419104\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] Epoch[11] Batch [825]#011Speed: 14360.67 samples/sec#011loss=1.215634\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] Epoch[11] Batch[830] avg_epoch_loss=1.239247\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=830 train loss <loss>=1.40121388435\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] Epoch[11] Batch [830]#011Speed: 1702.54 samples/sec#011loss=1.401214\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] Epoch[11] Batch[835] avg_epoch_loss=1.239220\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=835 train loss <loss>=1.234681499\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] Epoch[11] Batch [835]#011Speed: 14109.91 samples/sec#011loss=1.234681\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] Epoch[11] Batch[840] avg_epoch_loss=1.239500\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=840 train loss <loss>=1.28632526398\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] Epoch[11] Batch [840]#011Speed: 1698.86 samples/sec#011loss=1.286325\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] Epoch[11] Batch[845] avg_epoch_loss=1.239413\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=845 train loss <loss>=1.22477442026\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:21 INFO 140088046479168] Epoch[11] Batch [845]#011Speed: 14273.02 samples/sec#011loss=1.224774\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] Epoch[11] Batch[850] avg_epoch_loss=1.239325\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=850 train loss <loss>=1.22442625761\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] Epoch[11] Batch [850]#011Speed: 14203.99 samples/sec#011loss=1.224426\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] Epoch[11] Batch[855] avg_epoch_loss=1.241472\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=855 train loss <loss>=1.60688836575\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] Epoch[11] Batch [855]#011Speed: 1659.42 samples/sec#011loss=1.606888\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] Epoch[11] Batch[860] avg_epoch_loss=1.241782\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=860 train loss <loss>=1.29482953548\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] Epoch[11] Batch [860]#011Speed: 13139.02 samples/sec#011loss=1.294830\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] Epoch[11] Batch[865] avg_epoch_loss=1.241995\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=865 train loss <loss>=1.27876679897\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] Epoch[11] Batch [865]#011Speed: 13228.50 samples/sec#011loss=1.278767\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] Epoch[11] Batch[870] avg_epoch_loss=1.240645\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=870 train loss <loss>=1.00679146051\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] Epoch[11] Batch [870]#011Speed: 1738.80 samples/sec#011loss=1.006791\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] Epoch[11] Batch[875] avg_epoch_loss=1.239347\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=875 train loss <loss>=1.01321504116\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] Epoch[11] Batch [875]#011Speed: 13210.02 samples/sec#011loss=1.013215\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] Epoch[11] Batch[880] avg_epoch_loss=1.239628\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=880 train loss <loss>=1.28894095421\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] Epoch[11] Batch [880]#011Speed: 1752.14 samples/sec#011loss=1.288941\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] Epoch[11] Batch[885] avg_epoch_loss=1.239106\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=885 train loss <loss>=1.14714144468\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] Epoch[11] Batch [885]#011Speed: 14296.58 samples/sec#011loss=1.147141\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] Epoch[11] Batch[890] avg_epoch_loss=1.237650\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=890 train loss <loss>=0.979599249363\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] Epoch[11] Batch [890]#011Speed: 13081.01 samples/sec#011loss=0.979599\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] Epoch[11] Batch[895] avg_epoch_loss=1.238326\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=895 train loss <loss>=1.35878763199\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] Epoch[11] Batch [895]#011Speed: 1837.90 samples/sec#011loss=1.358788\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] Epoch[11] Batch[900] avg_epoch_loss=1.237062\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, batch=900 train loss <loss>=1.01048942804\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] Epoch[11] Batch [900]#011Speed: 13210.02 samples/sec#011loss=1.010489\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] processed a total of 57879 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15809.331178665161, \"sum\": 15809.331178665161, \"min\": 15809.331178665161}}, \"EndTime\": 1604320582.919779, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320567.110395}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] #throughput_metric: host=algo-1, train throughput=3661.04261402 records/second\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=11, train loss <loss>=1.23473324176\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:22 INFO 140088046479168] Saved checkpoint to \"/opt/ml/model/state_5bafb79e-c0ec-4428-be98-c2260c616df6-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 6.428956985473633, \"sum\": 6.428956985473633, \"min\": 6.428956985473633}}, \"EndTime\": 1604320582.926807, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320582.919849}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] Epoch[12] Batch[0] avg_epoch_loss=1.247569\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=1.24756860733\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] Epoch[12] Batch[5] avg_epoch_loss=1.111223\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=1.11122311155\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] Epoch[12] Batch [5]#011Speed: 14093.76 samples/sec#011loss=1.111223\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] Epoch[12] Batch[10] avg_epoch_loss=1.157322\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=1.21263962984\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] Epoch[12] Batch [10]#011Speed: 13614.69 samples/sec#011loss=1.212640\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] Epoch[12] Batch[15] avg_epoch_loss=1.124386\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=15 train loss <loss>=1.05192835331\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] Epoch[12] Batch [15]#011Speed: 1638.68 samples/sec#011loss=1.051928\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] Epoch[12] Batch[20] avg_epoch_loss=1.085484\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=20 train loss <loss>=0.960997486115\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] Epoch[12] Batch [20]#011Speed: 13312.21 samples/sec#011loss=0.960997\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] Epoch[12] Batch[25] avg_epoch_loss=1.078188\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=25 train loss <loss>=1.04754340649\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] Epoch[12] Batch [25]#011Speed: 14027.77 samples/sec#011loss=1.047543\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] Epoch[12] Batch[30] avg_epoch_loss=1.086780\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=30 train loss <loss>=1.13146092892\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] Epoch[12] Batch [30]#011Speed: 1820.73 samples/sec#011loss=1.131461\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] Epoch[12] Batch[35] avg_epoch_loss=1.108003\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=35 train loss <loss>=1.23958269358\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] Epoch[12] Batch [35]#011Speed: 14319.00 samples/sec#011loss=1.239583\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] Epoch[12] Batch[40] avg_epoch_loss=1.128691\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=40 train loss <loss>=1.27764635086\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] Epoch[12] Batch [40]#011Speed: 1637.95 samples/sec#011loss=1.277646\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] Epoch[12] Batch[45] avg_epoch_loss=1.149447\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=45 train loss <loss>=1.31965024471\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] Epoch[12] Batch [45]#011Speed: 13167.12 samples/sec#011loss=1.319650\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] Epoch[12] Batch[50] avg_epoch_loss=1.141058\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=50 train loss <loss>=1.06387884617\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:23 INFO 140088046479168] Epoch[12] Batch [50]#011Speed: 13090.07 samples/sec#011loss=1.063879\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] Epoch[12] Batch[55] avg_epoch_loss=1.136079\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=55 train loss <loss>=1.08529297113\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] Epoch[12] Batch [55]#011Speed: 1799.93 samples/sec#011loss=1.085293\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] Epoch[12] Batch[60] avg_epoch_loss=1.127390\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=60 train loss <loss>=1.03006674647\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] Epoch[12] Batch [60]#011Speed: 13353.93 samples/sec#011loss=1.030067\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] Epoch[12] Batch[65] avg_epoch_loss=1.115663\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=65 train loss <loss>=0.9725949049\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] Epoch[12] Batch [65]#011Speed: 1537.70 samples/sec#011loss=0.972595\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] Epoch[12] Batch[70] avg_epoch_loss=1.118587\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=70 train loss <loss>=1.15718234777\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] Epoch[12] Batch [70]#011Speed: 13249.40 samples/sec#011loss=1.157182\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] Epoch[12] Batch[75] avg_epoch_loss=1.139464\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=75 train loss <loss>=1.4359185338\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] Epoch[12] Batch [75]#011Speed: 13263.80 samples/sec#011loss=1.435919\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] Epoch[12] Batch[80] avg_epoch_loss=1.139915\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=80 train loss <loss>=1.1467738986\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] Epoch[12] Batch [80]#011Speed: 1650.43 samples/sec#011loss=1.146774\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] Epoch[12] Batch[85] avg_epoch_loss=1.131465\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=85 train loss <loss>=0.994565212727\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] Epoch[12] Batch [85]#011Speed: 13179.53 samples/sec#011loss=0.994565\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] Epoch[12] Batch[90] avg_epoch_loss=1.135932\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=90 train loss <loss>=1.21278041601\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] Epoch[12] Batch [90]#011Speed: 1678.50 samples/sec#011loss=1.212780\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] Epoch[12] Batch[95] avg_epoch_loss=1.139381\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=95 train loss <loss>=1.20215017796\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] Epoch[12] Batch [95]#011Speed: 14211.51 samples/sec#011loss=1.202150\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] Epoch[12] Batch[100] avg_epoch_loss=1.155260\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=100 train loss <loss>=1.46013281345\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] Epoch[12] Batch [100]#011Speed: 14283.19 samples/sec#011loss=1.460133\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] Epoch[12] Batch[105] avg_epoch_loss=1.175986\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=105 train loss <loss>=1.59465904236\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] Epoch[12] Batch [105]#011Speed: 1755.95 samples/sec#011loss=1.594659\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] Epoch[12] Batch[110] avg_epoch_loss=1.171191\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=110 train loss <loss>=1.06952260733\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] Epoch[12] Batch [110]#011Speed: 13002.82 samples/sec#011loss=1.069523\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] Epoch[12] Batch[115] avg_epoch_loss=1.169765\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=115 train loss <loss>=1.13812069893\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:24 INFO 140088046479168] Epoch[12] Batch [115]#011Speed: 13729.17 samples/sec#011loss=1.138121\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] Epoch[12] Batch[120] avg_epoch_loss=1.169150\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=120 train loss <loss>=1.15487347841\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] Epoch[12] Batch [120]#011Speed: 1603.10 samples/sec#011loss=1.154873\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] Epoch[12] Batch[125] avg_epoch_loss=1.174998\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=125 train loss <loss>=1.31650998592\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] Epoch[12] Batch [125]#011Speed: 13235.81 samples/sec#011loss=1.316510\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] Epoch[12] Batch[130] avg_epoch_loss=1.187995\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=130 train loss <loss>=1.5155305624\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] Epoch[12] Batch [130]#011Speed: 1633.02 samples/sec#011loss=1.515531\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] Epoch[12] Batch[135] avg_epoch_loss=1.188976\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=135 train loss <loss>=1.21469010115\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] Epoch[12] Batch [135]#011Speed: 12587.59 samples/sec#011loss=1.214690\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] Epoch[12] Batch[140] avg_epoch_loss=1.183079\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=140 train loss <loss>=1.0226557374\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] Epoch[12] Batch [140]#011Speed: 14433.26 samples/sec#011loss=1.022656\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] Epoch[12] Batch[145] avg_epoch_loss=1.173297\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=145 train loss <loss>=0.897458350658\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] Epoch[12] Batch [145]#011Speed: 1763.44 samples/sec#011loss=0.897458\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] Epoch[12] Batch[150] avg_epoch_loss=1.160840\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=150 train loss <loss>=0.797091817856\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] Epoch[12] Batch [150]#011Speed: 13551.87 samples/sec#011loss=0.797092\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] Epoch[12] Batch[155] avg_epoch_loss=1.152653\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=155 train loss <loss>=0.90540561676\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] Epoch[12] Batch [155]#011Speed: 1747.69 samples/sec#011loss=0.905406\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] Epoch[12] Batch[160] avg_epoch_loss=1.147007\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=160 train loss <loss>=0.97083953619\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] Epoch[12] Batch [160]#011Speed: 13362.31 samples/sec#011loss=0.970840\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] Epoch[12] Batch[165] avg_epoch_loss=1.150517\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=165 train loss <loss>=1.26356394291\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:25 INFO 140088046479168] Epoch[12] Batch [165]#011Speed: 13758.72 samples/sec#011loss=1.263564\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] Epoch[12] Batch[170] avg_epoch_loss=1.151062\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=170 train loss <loss>=1.16912835836\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] Epoch[12] Batch [170]#011Speed: 1611.80 samples/sec#011loss=1.169128\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] Epoch[12] Batch[175] avg_epoch_loss=1.157036\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=175 train loss <loss>=1.36135019064\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] Epoch[12] Batch [175]#011Speed: 14292.01 samples/sec#011loss=1.361350\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] Epoch[12] Batch[180] avg_epoch_loss=1.164404\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=180 train loss <loss>=1.42375403643\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] Epoch[12] Batch [180]#011Speed: 1630.81 samples/sec#011loss=1.423754\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] Epoch[12] Batch[185] avg_epoch_loss=1.169188\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=185 train loss <loss>=1.34239513874\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] Epoch[12] Batch [185]#011Speed: 13367.90 samples/sec#011loss=1.342395\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] Epoch[12] Batch[190] avg_epoch_loss=1.174000\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=190 train loss <loss>=1.35298886299\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] Epoch[12] Batch [190]#011Speed: 13855.16 samples/sec#011loss=1.352989\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] Epoch[12] Batch[195] avg_epoch_loss=1.180168\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=195 train loss <loss>=1.41580588818\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] Epoch[12] Batch [195]#011Speed: 1743.97 samples/sec#011loss=1.415806\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] Epoch[12] Batch[200] avg_epoch_loss=1.187862\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=200 train loss <loss>=1.48946359158\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] Epoch[12] Batch [200]#011Speed: 14424.26 samples/sec#011loss=1.489464\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] Epoch[12] Batch[205] avg_epoch_loss=1.193395\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=205 train loss <loss>=1.41583163738\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] Epoch[12] Batch [205]#011Speed: 14079.57 samples/sec#011loss=1.415832\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] Epoch[12] Batch[210] avg_epoch_loss=1.197051\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=210 train loss <loss>=1.34766721725\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] Epoch[12] Batch [210]#011Speed: 1601.66 samples/sec#011loss=1.347667\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] Epoch[12] Batch[215] avg_epoch_loss=1.202742\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=215 train loss <loss>=1.4428765893\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] Epoch[12] Batch [215]#011Speed: 13907.56 samples/sec#011loss=1.442877\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] Epoch[12] Batch[220] avg_epoch_loss=1.204623\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=220 train loss <loss>=1.28588805199\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:26 INFO 140088046479168] Epoch[12] Batch [220]#011Speed: 1599.09 samples/sec#011loss=1.285888\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] Epoch[12] Batch[225] avg_epoch_loss=1.209380\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=225 train loss <loss>=1.41966063976\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] Epoch[12] Batch [225]#011Speed: 14206.99 samples/sec#011loss=1.419661\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] Epoch[12] Batch[230] avg_epoch_loss=1.216768\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=230 train loss <loss>=1.55070073605\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] Epoch[12] Batch [230]#011Speed: 14165.61 samples/sec#011loss=1.550701\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] Epoch[12] Batch[235] avg_epoch_loss=1.227123\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=235 train loss <loss>=1.70553901196\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] Epoch[12] Batch [235]#011Speed: 1604.33 samples/sec#011loss=1.705539\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] Epoch[12] Batch[240] avg_epoch_loss=1.231023\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=240 train loss <loss>=1.41509188414\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] Epoch[12] Batch [240]#011Speed: 13250.44 samples/sec#011loss=1.415092\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] Epoch[12] Batch[245] avg_epoch_loss=1.236875\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=245 train loss <loss>=1.51893815994\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] Epoch[12] Batch [245]#011Speed: 13408.23 samples/sec#011loss=1.518938\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] Epoch[12] Batch[250] avg_epoch_loss=1.242827\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=250 train loss <loss>=1.53565065861\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] Epoch[12] Batch [250]#011Speed: 1776.09 samples/sec#011loss=1.535651\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] Epoch[12] Batch[255] avg_epoch_loss=1.246153\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=255 train loss <loss>=1.41311364174\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] Epoch[12] Batch [255]#011Speed: 14200.68 samples/sec#011loss=1.413114\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] Epoch[12] Batch[260] avg_epoch_loss=1.249925\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=260 train loss <loss>=1.44304144382\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] Epoch[12] Batch [260]#011Speed: 1719.88 samples/sec#011loss=1.443041\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] Epoch[12] Batch[265] avg_epoch_loss=1.249822\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=265 train loss <loss>=1.24448778629\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] Epoch[12] Batch [265]#011Speed: 14362.06 samples/sec#011loss=1.244488\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] Epoch[12] Batch[270] avg_epoch_loss=1.247185\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=270 train loss <loss>=1.10689388514\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] Epoch[12] Batch [270]#011Speed: 13832.46 samples/sec#011loss=1.106894\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] Epoch[12] Batch[275] avg_epoch_loss=1.243668\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=275 train loss <loss>=1.05300744772\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] Epoch[12] Batch [275]#011Speed: 1775.85 samples/sec#011loss=1.053007\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] Epoch[12] Batch[280] avg_epoch_loss=1.239578\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=280 train loss <loss>=1.0138381362\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:27 INFO 140088046479168] Epoch[12] Batch [280]#011Speed: 13718.64 samples/sec#011loss=1.013838\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] Epoch[12] Batch[285] avg_epoch_loss=1.237208\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=285 train loss <loss>=1.10402283669\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] Epoch[12] Batch [285]#011Speed: 1670.91 samples/sec#011loss=1.104023\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] Epoch[12] Batch[290] avg_epoch_loss=1.236837\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=290 train loss <loss>=1.21558556557\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] Epoch[12] Batch [290]#011Speed: 13813.38 samples/sec#011loss=1.215586\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] Epoch[12] Batch[295] avg_epoch_loss=1.236424\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=295 train loss <loss>=1.21241817474\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] Epoch[12] Batch [295]#011Speed: 11636.80 samples/sec#011loss=1.212418\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] Epoch[12] Batch[300] avg_epoch_loss=1.241082\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=300 train loss <loss>=1.51680464745\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] Epoch[12] Batch [300]#011Speed: 1698.56 samples/sec#011loss=1.516805\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] Epoch[12] Batch[305] avg_epoch_loss=1.238954\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=305 train loss <loss>=1.11085541248\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] Epoch[12] Batch [305]#011Speed: 13156.79 samples/sec#011loss=1.110855\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] Epoch[12] Batch[310] avg_epoch_loss=1.235881\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=310 train loss <loss>=1.04780954123\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] Epoch[12] Batch [310]#011Speed: 1726.19 samples/sec#011loss=1.047810\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] Epoch[12] Batch[315] avg_epoch_loss=1.232707\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=315 train loss <loss>=1.03527798653\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] Epoch[12] Batch [315]#011Speed: 14246.35 samples/sec#011loss=1.035278\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] Epoch[12] Batch[320] avg_epoch_loss=1.230961\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=320 train loss <loss>=1.12060201168\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] Epoch[12] Batch [320]#011Speed: 14344.10 samples/sec#011loss=1.120602\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] Epoch[12] Batch[325] avg_epoch_loss=1.226993\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=325 train loss <loss>=0.972272229195\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] Epoch[12] Batch [325]#011Speed: 1696.76 samples/sec#011loss=0.972272\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] Epoch[12] Batch[330] avg_epoch_loss=1.224106\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=330 train loss <loss>=1.03587017059\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] Epoch[12] Batch [330]#011Speed: 13787.13 samples/sec#011loss=1.035870\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] Epoch[12] Batch[335] avg_epoch_loss=1.225961\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=335 train loss <loss>=1.34875047207\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:28 INFO 140088046479168] Epoch[12] Batch [335]#011Speed: 14082.67 samples/sec#011loss=1.348750\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] Epoch[12] Batch[340] avg_epoch_loss=1.226105\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=340 train loss <loss>=1.23582465649\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] Epoch[12] Batch [340]#011Speed: 1780.05 samples/sec#011loss=1.235825\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] Epoch[12] Batch[345] avg_epoch_loss=1.226740\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=345 train loss <loss>=1.26999732256\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] Epoch[12] Batch [345]#011Speed: 14373.59 samples/sec#011loss=1.269997\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] Epoch[12] Batch[350] avg_epoch_loss=1.225766\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=350 train loss <loss>=1.15842111111\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] Epoch[12] Batch [350]#011Speed: 1644.56 samples/sec#011loss=1.158421\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] Epoch[12] Batch[355] avg_epoch_loss=1.225858\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=355 train loss <loss>=1.23228740692\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] Epoch[12] Batch [355]#011Speed: 14215.87 samples/sec#011loss=1.232287\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] Epoch[12] Batch[360] avg_epoch_loss=1.226447\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=360 train loss <loss>=1.26839277744\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] Epoch[12] Batch [360]#011Speed: 13805.57 samples/sec#011loss=1.268393\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] Epoch[12] Batch[365] avg_epoch_loss=1.226078\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=365 train loss <loss>=1.19941403866\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] Epoch[12] Batch [365]#011Speed: 1762.06 samples/sec#011loss=1.199414\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] Epoch[12] Batch[370] avg_epoch_loss=1.226046\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=370 train loss <loss>=1.22374982834\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] Epoch[12] Batch [370]#011Speed: 13055.44 samples/sec#011loss=1.223750\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] Epoch[12] Batch[375] avg_epoch_loss=1.223578\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=375 train loss <loss>=1.04045727253\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] Epoch[12] Batch [375]#011Speed: 1836.77 samples/sec#011loss=1.040457\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] Epoch[12] Batch[380] avg_epoch_loss=1.220140\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=380 train loss <loss>=0.961571311951\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] Epoch[12] Batch [380]#011Speed: 14347.78 samples/sec#011loss=0.961571\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] Epoch[12] Batch[385] avg_epoch_loss=1.220293\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=385 train loss <loss>=1.23191728592\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] Epoch[12] Batch [385]#011Speed: 1821.70 samples/sec#011loss=1.231917\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] Epoch[12] Batch[390] avg_epoch_loss=1.218962\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=390 train loss <loss>=1.11623295546\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] Epoch[12] Batch [390]#011Speed: 14247.56 samples/sec#011loss=1.116233\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] Epoch[12] Batch[395] avg_epoch_loss=1.215303\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=395 train loss <loss>=0.929148077965\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:29 INFO 140088046479168] Epoch[12] Batch [395]#011Speed: 13261.05 samples/sec#011loss=0.929148\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] Epoch[12] Batch[400] avg_epoch_loss=1.212141\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=400 train loss <loss>=0.961703050137\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] Epoch[12] Batch [400]#011Speed: 1755.06 samples/sec#011loss=0.961703\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] Epoch[12] Batch[405] avg_epoch_loss=1.210515\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=405 train loss <loss>=1.08016664982\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] Epoch[12] Batch [405]#011Speed: 13221.47 samples/sec#011loss=1.080167\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] Epoch[12] Batch[410] avg_epoch_loss=1.209693\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=410 train loss <loss>=1.14289530516\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] Epoch[12] Batch [410]#011Speed: 1727.11 samples/sec#011loss=1.142895\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] Epoch[12] Batch[415] avg_epoch_loss=1.211634\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=415 train loss <loss>=1.37118604183\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] Epoch[12] Batch [415]#011Speed: 13252.67 samples/sec#011loss=1.371186\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] Epoch[12] Batch[420] avg_epoch_loss=1.214590\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=420 train loss <loss>=1.46056878567\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] Epoch[12] Batch [420]#011Speed: 13285.73 samples/sec#011loss=1.460569\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] Epoch[12] Batch[425] avg_epoch_loss=1.222445\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=425 train loss <loss>=1.88379654884\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] Epoch[12] Batch [425]#011Speed: 1790.72 samples/sec#011loss=1.883797\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] Epoch[12] Batch[430] avg_epoch_loss=1.235209\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=430 train loss <loss>=2.32270307541\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] Epoch[12] Batch [430]#011Speed: 13205.21 samples/sec#011loss=2.322703\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] Epoch[12] Batch[435] avg_epoch_loss=1.245083\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=435 train loss <loss>=2.09621553421\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] Epoch[12] Batch [435]#011Speed: 1896.08 samples/sec#011loss=2.096216\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] Epoch[12] Batch[440] avg_epoch_loss=1.257533\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=440 train loss <loss>=2.3431999445\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] Epoch[12] Batch [440]#011Speed: 14272.86 samples/sec#011loss=2.343200\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] Epoch[12] Batch[445] avg_epoch_loss=1.264406\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=445 train loss <loss>=1.87056612968\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] Epoch[12] Batch [445]#011Speed: 14349.16 samples/sec#011loss=1.870566\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] Epoch[12] Batch[450] avg_epoch_loss=1.267836\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=450 train loss <loss>=1.57383601665\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] Epoch[12] Batch [450]#011Speed: 1674.43 samples/sec#011loss=1.573836\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] Epoch[12] Batch[455] avg_epoch_loss=1.268143\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=455 train loss <loss>=1.29584143162\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:30 INFO 140088046479168] Epoch[12] Batch [455]#011Speed: 13241.82 samples/sec#011loss=1.295841\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] Epoch[12] Batch[460] avg_epoch_loss=1.267179\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=460 train loss <loss>=1.17922012806\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] Epoch[12] Batch [460]#011Speed: 1748.21 samples/sec#011loss=1.179220\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] Epoch[12] Batch[465] avg_epoch_loss=1.267491\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=465 train loss <loss>=1.29630644321\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] Epoch[12] Batch [465]#011Speed: 14179.38 samples/sec#011loss=1.296306\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] Epoch[12] Batch[470] avg_epoch_loss=1.265104\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=470 train loss <loss>=1.04262422323\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] Epoch[12] Batch [470]#011Speed: 12085.92 samples/sec#011loss=1.042624\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] Epoch[12] Batch[475] avg_epoch_loss=1.264167\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=475 train loss <loss>=1.17591860294\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] Epoch[12] Batch [475]#011Speed: 1685.06 samples/sec#011loss=1.175919\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] Epoch[12] Batch[480] avg_epoch_loss=1.259994\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=480 train loss <loss>=0.862662768364\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] Epoch[12] Batch [480]#011Speed: 13349.42 samples/sec#011loss=0.862663\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] Epoch[12] Batch[485] avg_epoch_loss=1.257226\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=485 train loss <loss>=0.990991270542\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] Epoch[12] Batch [485]#011Speed: 1722.62 samples/sec#011loss=0.990991\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] Epoch[12] Batch[490] avg_epoch_loss=1.255057\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=490 train loss <loss>=1.04421987534\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] Epoch[12] Batch [490]#011Speed: 13206.77 samples/sec#011loss=1.044220\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] Epoch[12] Batch[495] avg_epoch_loss=1.253932\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=495 train loss <loss>=1.14346066713\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] Epoch[12] Batch [495]#011Speed: 13259.21 samples/sec#011loss=1.143461\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] Epoch[12] Batch[500] avg_epoch_loss=1.252837\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=500 train loss <loss>=1.14420925379\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] Epoch[12] Batch [500]#011Speed: 1759.86 samples/sec#011loss=1.144209\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] Epoch[12] Batch[505] avg_epoch_loss=1.253514\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=505 train loss <loss>=1.32136893272\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] Epoch[12] Batch [505]#011Speed: 14069.09 samples/sec#011loss=1.321369\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] Epoch[12] Batch[510] avg_epoch_loss=1.252501\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=510 train loss <loss>=1.14998307228\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:31 INFO 140088046479168] Epoch[12] Batch [510]#011Speed: 13170.35 samples/sec#011loss=1.149983\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] Epoch[12] Batch[515] avg_epoch_loss=1.249343\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=515 train loss <loss>=0.926616346836\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] Epoch[12] Batch [515]#011Speed: 1717.13 samples/sec#011loss=0.926616\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] Epoch[12] Batch[520] avg_epoch_loss=1.248253\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=520 train loss <loss>=1.13575985432\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] Epoch[12] Batch [520]#011Speed: 13793.65 samples/sec#011loss=1.135760\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] Epoch[12] Batch[525] avg_epoch_loss=1.247576\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=525 train loss <loss>=1.17699973583\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] Epoch[12] Batch [525]#011Speed: 1698.63 samples/sec#011loss=1.177000\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] Epoch[12] Batch[530] avg_epoch_loss=1.245696\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=530 train loss <loss>=1.04789612293\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] Epoch[12] Batch [530]#011Speed: 12906.79 samples/sec#011loss=1.047896\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] Epoch[12] Batch[535] avg_epoch_loss=1.242327\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=535 train loss <loss>=0.8845241189\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] Epoch[12] Batch [535]#011Speed: 14456.73 samples/sec#011loss=0.884524\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] Epoch[12] Batch[540] avg_epoch_loss=1.240804\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=540 train loss <loss>=1.07756955624\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] Epoch[12] Batch [540]#011Speed: 1693.73 samples/sec#011loss=1.077570\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] Epoch[12] Batch[545] avg_epoch_loss=1.237776\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=545 train loss <loss>=0.910200214386\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] Epoch[12] Batch [545]#011Speed: 14151.12 samples/sec#011loss=0.910200\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] Epoch[12] Batch[550] avg_epoch_loss=1.234913\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=550 train loss <loss>=0.92218221426\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] Epoch[12] Batch [550]#011Speed: 1701.05 samples/sec#011loss=0.922182\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] Epoch[12] Batch[555] avg_epoch_loss=1.232361\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=555 train loss <loss>=0.95116212368\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] Epoch[12] Batch [555]#011Speed: 14188.22 samples/sec#011loss=0.951162\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] Epoch[12] Batch[560] avg_epoch_loss=1.229982\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=560 train loss <loss>=0.965510547161\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] Epoch[12] Batch [560]#011Speed: 14438.53 samples/sec#011loss=0.965511\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] Epoch[12] Batch[565] avg_epoch_loss=1.228290\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=565 train loss <loss>=1.03842408657\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] Epoch[12] Batch [565]#011Speed: 1746.07 samples/sec#011loss=1.038424\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] Epoch[12] Batch[570] avg_epoch_loss=1.227065\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=570 train loss <loss>=1.0883805871\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:32 INFO 140088046479168] Epoch[12] Batch [570]#011Speed: 14233.06 samples/sec#011loss=1.088381\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] Epoch[12] Batch[575] avg_epoch_loss=1.226900\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=575 train loss <loss>=1.20805938244\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] Epoch[12] Batch [575]#011Speed: 14325.27 samples/sec#011loss=1.208059\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] Epoch[12] Batch[580] avg_epoch_loss=1.224992\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=580 train loss <loss>=1.00515071154\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] Epoch[12] Batch [580]#011Speed: 1716.04 samples/sec#011loss=1.005151\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] Epoch[12] Batch[585] avg_epoch_loss=1.223474\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=585 train loss <loss>=1.04707319736\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] Epoch[12] Batch [585]#011Speed: 13388.57 samples/sec#011loss=1.047073\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] Epoch[12] Batch[590] avg_epoch_loss=1.224579\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=590 train loss <loss>=1.35408084393\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] Epoch[12] Batch [590]#011Speed: 1652.85 samples/sec#011loss=1.354081\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] Epoch[12] Batch[595] avg_epoch_loss=1.224463\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=595 train loss <loss>=1.21076983213\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] Epoch[12] Batch [595]#011Speed: 14318.39 samples/sec#011loss=1.210770\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] Epoch[12] Batch[600] avg_epoch_loss=1.228643\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=600 train loss <loss>=1.7269112587\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] Epoch[12] Batch [600]#011Speed: 13807.98 samples/sec#011loss=1.726911\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] Epoch[12] Batch[605] avg_epoch_loss=1.236066\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=605 train loss <loss>=2.12833653688\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] Epoch[12] Batch [605]#011Speed: 1741.41 samples/sec#011loss=2.128337\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] Epoch[12] Batch[610] avg_epoch_loss=1.241667\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=610 train loss <loss>=1.92048195601\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] Epoch[12] Batch [610]#011Speed: 14167.40 samples/sec#011loss=1.920482\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] Epoch[12] Batch[615] avg_epoch_loss=1.250470\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=615 train loss <loss>=2.32617297173\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] Epoch[12] Batch [615]#011Speed: 1759.70 samples/sec#011loss=2.326173\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] Epoch[12] Batch[620] avg_epoch_loss=1.253757\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=620 train loss <loss>=1.65875103474\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] Epoch[12] Batch [620]#011Speed: 13287.96 samples/sec#011loss=1.658751\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] Epoch[12] Batch[625] avg_epoch_loss=1.253828\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=625 train loss <loss>=1.26268759966\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:33 INFO 140088046479168] Epoch[12] Batch [625]#011Speed: 14193.17 samples/sec#011loss=1.262688\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] Epoch[12] Batch[630] avg_epoch_loss=1.253836\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=630 train loss <loss>=1.25475267172\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] Epoch[12] Batch [630]#011Speed: 1774.85 samples/sec#011loss=1.254753\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] Epoch[12] Batch[635] avg_epoch_loss=1.253868\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=635 train loss <loss>=1.25795350075\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] Epoch[12] Batch [635]#011Speed: 13244.56 samples/sec#011loss=1.257954\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] Epoch[12] Batch[640] avg_epoch_loss=1.252578\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=640 train loss <loss>=1.08844788074\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] Epoch[12] Batch [640]#011Speed: 1626.39 samples/sec#011loss=1.088448\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] Epoch[12] Batch[645] avg_epoch_loss=1.251519\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=645 train loss <loss>=1.11581743956\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] Epoch[12] Batch [645]#011Speed: 13163.89 samples/sec#011loss=1.115817\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] Epoch[12] Batch[650] avg_epoch_loss=1.249948\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=650 train loss <loss>=1.04696823359\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] Epoch[12] Batch [650]#011Speed: 13187.69 samples/sec#011loss=1.046968\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] Epoch[12] Batch[655] avg_epoch_loss=1.248240\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=655 train loss <loss>=1.02584267855\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] Epoch[12] Batch [655]#011Speed: 1764.41 samples/sec#011loss=1.025843\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] Epoch[12] Batch[660] avg_epoch_loss=1.246189\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=660 train loss <loss>=0.977082455158\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] Epoch[12] Batch [660]#011Speed: 13350.08 samples/sec#011loss=0.977082\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] Epoch[12] Batch[665] avg_epoch_loss=1.244532\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=665 train loss <loss>=1.02547522783\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] Epoch[12] Batch [665]#011Speed: 1803.11 samples/sec#011loss=1.025475\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] Epoch[12] Batch[670] avg_epoch_loss=1.242546\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=670 train loss <loss>=0.978002071381\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] Epoch[12] Batch [670]#011Speed: 13217.17 samples/sec#011loss=0.978002\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] Epoch[12] Batch[675] avg_epoch_loss=1.242801\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=675 train loss <loss>=1.27706918716\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] Epoch[12] Batch [675]#011Speed: 14306.79 samples/sec#011loss=1.277069\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] Epoch[12] Batch[680] avg_epoch_loss=1.247369\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=680 train loss <loss>=1.86497888565\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:34 INFO 140088046479168] Epoch[12] Batch [680]#011Speed: 1617.43 samples/sec#011loss=1.864979\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] Epoch[12] Batch[685] avg_epoch_loss=1.247352\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=685 train loss <loss>=1.24494173527\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] Epoch[12] Batch [685]#011Speed: 14471.69 samples/sec#011loss=1.244942\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] Epoch[12] Batch[690] avg_epoch_loss=1.247598\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=690 train loss <loss>=1.28142101765\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] Epoch[12] Batch [690]#011Speed: 1723.56 samples/sec#011loss=1.281421\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] Epoch[12] Batch[695] avg_epoch_loss=1.248691\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=695 train loss <loss>=1.39969150424\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] Epoch[12] Batch [695]#011Speed: 14075.14 samples/sec#011loss=1.399692\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] Epoch[12] Batch[700] avg_epoch_loss=1.250044\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=700 train loss <loss>=1.43840060234\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] Epoch[12] Batch [700]#011Speed: 14467.17 samples/sec#011loss=1.438401\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] Epoch[12] Batch[705] avg_epoch_loss=1.251583\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=705 train loss <loss>=1.46735360622\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] Epoch[12] Batch [705]#011Speed: 1564.51 samples/sec#011loss=1.467354\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] Epoch[12] Batch[710] avg_epoch_loss=1.253997\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=710 train loss <loss>=1.59487123489\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] Epoch[12] Batch [710]#011Speed: 13993.84 samples/sec#011loss=1.594871\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] Epoch[12] Batch[715] avg_epoch_loss=1.256299\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=715 train loss <loss>=1.58356361389\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] Epoch[12] Batch [715]#011Speed: 1864.96 samples/sec#011loss=1.583564\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] Epoch[12] Batch[720] avg_epoch_loss=1.258429\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=720 train loss <loss>=1.56354371309\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] Epoch[12] Batch [720]#011Speed: 14403.98 samples/sec#011loss=1.563544\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] Epoch[12] Batch[725] avg_epoch_loss=1.261581\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=725 train loss <loss>=1.71599817276\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] Epoch[12] Batch [725]#011Speed: 14214.67 samples/sec#011loss=1.715998\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] Epoch[12] Batch[730] avg_epoch_loss=1.263247\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=730 train loss <loss>=1.50522165298\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] Epoch[12] Batch [730]#011Speed: 1834.89 samples/sec#011loss=1.505222\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] Epoch[12] Batch[735] avg_epoch_loss=1.264995\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=735 train loss <loss>=1.5205165863\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:35 INFO 140088046479168] Epoch[12] Batch [735]#011Speed: 14633.26 samples/sec#011loss=1.520517\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] Epoch[12] Batch[740] avg_epoch_loss=1.266822\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=740 train loss <loss>=1.5358137846\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] Epoch[12] Batch [740]#011Speed: 1667.04 samples/sec#011loss=1.535814\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] Epoch[12] Batch[745] avg_epoch_loss=1.265984\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=745 train loss <loss>=1.14182204008\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] Epoch[12] Batch [745]#011Speed: 14249.53 samples/sec#011loss=1.141822\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] Epoch[12] Batch[750] avg_epoch_loss=1.265642\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=750 train loss <loss>=1.21453714371\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] Epoch[12] Batch [750]#011Speed: 14273.62 samples/sec#011loss=1.214537\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] Epoch[12] Batch[755] avg_epoch_loss=1.265847\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=755 train loss <loss>=1.29663510323\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] Epoch[12] Batch [755]#011Speed: 1779.46 samples/sec#011loss=1.296635\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] Epoch[12] Batch[760] avg_epoch_loss=1.264802\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=760 train loss <loss>=1.10682859421\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] Epoch[12] Batch [760]#011Speed: 13436.96 samples/sec#011loss=1.106829\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] Epoch[12] Batch[765] avg_epoch_loss=1.264563\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=765 train loss <loss>=1.22817444801\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] Epoch[12] Batch [765]#011Speed: 1826.29 samples/sec#011loss=1.228174\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] Epoch[12] Batch[770] avg_epoch_loss=1.263007\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=770 train loss <loss>=1.02471008301\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] Epoch[12] Batch [770]#011Speed: 13134.14 samples/sec#011loss=1.024710\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] Epoch[12] Batch[775] avg_epoch_loss=1.263256\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=775 train loss <loss>=1.30158538818\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] Epoch[12] Batch [775]#011Speed: 13272.46 samples/sec#011loss=1.301585\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] Epoch[12] Batch[780] avg_epoch_loss=1.262857\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=780 train loss <loss>=1.20099333525\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] Epoch[12] Batch [780]#011Speed: 1719.76 samples/sec#011loss=1.200993\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] Epoch[12] Batch[785] avg_epoch_loss=1.262277\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=785 train loss <loss>=1.17164627314\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] Epoch[12] Batch [785]#011Speed: 13147.64 samples/sec#011loss=1.171646\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] Epoch[12] Batch[790] avg_epoch_loss=1.260849\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=790 train loss <loss>=1.03627583981\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] Epoch[12] Batch [790]#011Speed: 1800.02 samples/sec#011loss=1.036276\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] Epoch[12] Batch[795] avg_epoch_loss=1.260225\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=795 train loss <loss>=1.16150021553\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] Epoch[12] Batch [795]#011Speed: 13111.04 samples/sec#011loss=1.161500\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] Epoch[12] Batch[800] avg_epoch_loss=1.260906\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=800 train loss <loss>=1.36941468716\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:36 INFO 140088046479168] Epoch[12] Batch [800]#011Speed: 14388.54 samples/sec#011loss=1.369415\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] Epoch[12] Batch[805] avg_epoch_loss=1.261177\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=805 train loss <loss>=1.30460379124\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] Epoch[12] Batch [805]#011Speed: 1603.74 samples/sec#011loss=1.304604\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] Epoch[12] Batch[810] avg_epoch_loss=1.261517\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=810 train loss <loss>=1.31636505127\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] Epoch[12] Batch [810]#011Speed: 13222.64 samples/sec#011loss=1.316365\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] Epoch[12] Batch[815] avg_epoch_loss=1.261949\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=815 train loss <loss>=1.33189611435\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] Epoch[12] Batch [815]#011Speed: 13276.40 samples/sec#011loss=1.331896\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] Epoch[12] Batch[820] avg_epoch_loss=1.262409\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=820 train loss <loss>=1.33754081726\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] Epoch[12] Batch [820]#011Speed: 1743.13 samples/sec#011loss=1.337541\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] Epoch[12] Batch[825] avg_epoch_loss=1.261994\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=825 train loss <loss>=1.19387975931\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] Epoch[12] Batch [825]#011Speed: 13713.88 samples/sec#011loss=1.193880\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] Epoch[12] Batch[830] avg_epoch_loss=1.260395\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=830 train loss <loss>=0.996187734604\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] Epoch[12] Batch [830]#011Speed: 1591.18 samples/sec#011loss=0.996188\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] Epoch[12] Batch[835] avg_epoch_loss=1.260894\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=835 train loss <loss>=1.34387340546\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] Epoch[12] Batch [835]#011Speed: 14281.98 samples/sec#011loss=1.343873\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] Epoch[12] Batch[840] avg_epoch_loss=1.261393\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=840 train loss <loss>=1.34480443001\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] Epoch[12] Batch [840]#011Speed: 14377.60 samples/sec#011loss=1.344804\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] Epoch[12] Batch[845] avg_epoch_loss=1.260333\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=845 train loss <loss>=1.08198003769\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] Epoch[12] Batch [845]#011Speed: 1745.09 samples/sec#011loss=1.081980\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] Epoch[12] Batch[850] avg_epoch_loss=1.259336\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=850 train loss <loss>=1.09069753885\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:37 INFO 140088046479168] Epoch[12] Batch [850]#011Speed: 14295.36 samples/sec#011loss=1.090698\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] Epoch[12] Batch[855] avg_epoch_loss=1.259189\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=855 train loss <loss>=1.23414667845\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] Epoch[12] Batch [855]#011Speed: 1835.99 samples/sec#011loss=1.234147\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] Epoch[12] Batch[860] avg_epoch_loss=1.258879\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=860 train loss <loss>=1.20588638783\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] Epoch[12] Batch [860]#011Speed: 13308.39 samples/sec#011loss=1.205886\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] Epoch[12] Batch[865] avg_epoch_loss=1.258653\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=865 train loss <loss>=1.2196736455\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] Epoch[12] Batch [865]#011Speed: 13243.38 samples/sec#011loss=1.219674\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] Epoch[12] Batch[870] avg_epoch_loss=1.257155\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=870 train loss <loss>=0.997667348385\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] Epoch[12] Batch [870]#011Speed: 1665.77 samples/sec#011loss=0.997667\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] Epoch[12] Batch[875] avg_epoch_loss=1.256446\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=875 train loss <loss>=1.1329531312\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] Epoch[12] Batch [875]#011Speed: 12322.82 samples/sec#011loss=1.132953\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] Epoch[12] Batch[880] avg_epoch_loss=1.255637\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=880 train loss <loss>=1.11388530731\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] Epoch[12] Batch [880]#011Speed: 1865.62 samples/sec#011loss=1.113885\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] Epoch[12] Batch[885] avg_epoch_loss=1.255442\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=885 train loss <loss>=1.22120058537\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] Epoch[12] Batch [885]#011Speed: 13157.96 samples/sec#011loss=1.221201\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] Epoch[12] Batch[890] avg_epoch_loss=1.255587\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=890 train loss <loss>=1.28111209869\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] Epoch[12] Batch [890]#011Speed: 13218.21 samples/sec#011loss=1.281112\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] Epoch[12] Batch[895] avg_epoch_loss=1.254592\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=895 train loss <loss>=1.07740483284\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] Epoch[12] Batch [895]#011Speed: 1856.31 samples/sec#011loss=1.077405\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] Epoch[12] Batch[900] avg_epoch_loss=1.254092\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, batch=900 train loss <loss>=1.16441434622\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] Epoch[12] Batch [900]#011Speed: 13290.20 samples/sec#011loss=1.164414\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] processed a total of 57893 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15837.208032608032, \"sum\": 15837.208032608032, \"min\": 15837.208032608032}}, \"EndTime\": 1604320598.76411, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320582.926847}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] #throughput_metric: host=algo-1, train throughput=3655.47819234 records/second\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=12, train loss <loss>=1.25672949902\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] Epoch[13] Batch[0] avg_epoch_loss=1.466534\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=1.46653437614\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] Epoch[13] Batch[5] avg_epoch_loss=1.236951\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=1.23695088426\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] Epoch[13] Batch [5]#011Speed: 13004.46 samples/sec#011loss=1.236951\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] Epoch[13] Batch[10] avg_epoch_loss=1.142121\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=1.02832442522\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:38 INFO 140088046479168] Epoch[13] Batch [10]#011Speed: 13092.11 samples/sec#011loss=1.028324\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] Epoch[13] Batch[15] avg_epoch_loss=1.154339\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=15 train loss <loss>=1.18121937513\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] Epoch[13] Batch [15]#011Speed: 1649.12 samples/sec#011loss=1.181219\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] Epoch[13] Batch[20] avg_epoch_loss=1.165732\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=20 train loss <loss>=1.20218911171\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] Epoch[13] Batch [20]#011Speed: 13431.31 samples/sec#011loss=1.202189\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] Epoch[13] Batch[25] avg_epoch_loss=1.155795\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=25 train loss <loss>=1.11406207085\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] Epoch[13] Batch [25]#011Speed: 12761.25 samples/sec#011loss=1.114062\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] Epoch[13] Batch[30] avg_epoch_loss=1.134270\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=30 train loss <loss>=1.02234045267\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] Epoch[13] Batch [30]#011Speed: 1565.54 samples/sec#011loss=1.022340\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] Epoch[13] Batch[35] avg_epoch_loss=1.103728\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=35 train loss <loss>=0.914364910126\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] Epoch[13] Batch [35]#011Speed: 13331.65 samples/sec#011loss=0.914365\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] Epoch[13] Batch[40] avg_epoch_loss=1.095736\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=40 train loss <loss>=1.03819162846\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] Epoch[13] Batch [40]#011Speed: 1793.28 samples/sec#011loss=1.038192\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] Epoch[13] Batch[45] avg_epoch_loss=1.128646\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=45 train loss <loss>=1.39850871563\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] Epoch[13] Batch [45]#011Speed: 13176.43 samples/sec#011loss=1.398509\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] Epoch[13] Batch[50] avg_epoch_loss=1.141085\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=50 train loss <loss>=1.25552654266\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] Epoch[13] Batch [50]#011Speed: 13122.19 samples/sec#011loss=1.255527\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] Epoch[13] Batch[55] avg_epoch_loss=1.116525\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=55 train loss <loss>=0.866012680531\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] Epoch[13] Batch [55]#011Speed: 1848.11 samples/sec#011loss=0.866013\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] Epoch[13] Batch[60] avg_epoch_loss=1.106562\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=60 train loss <loss>=0.99498090744\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:39 INFO 140088046479168] Epoch[13] Batch [60]#011Speed: 14243.78 samples/sec#011loss=0.994981\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] Epoch[13] Batch[65] avg_epoch_loss=1.114676\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=65 train loss <loss>=1.21365611553\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] Epoch[13] Batch [65]#011Speed: 1825.47 samples/sec#011loss=1.213656\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] Epoch[13] Batch[70] avg_epoch_loss=1.122550\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=70 train loss <loss>=1.22649025917\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] Epoch[13] Batch [70]#011Speed: 14295.36 samples/sec#011loss=1.226490\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] Epoch[13] Batch[75] avg_epoch_loss=1.118133\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=75 train loss <loss>=1.05542056561\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] Epoch[13] Batch [75]#011Speed: 1801.42 samples/sec#011loss=1.055421\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] Epoch[13] Batch[80] avg_epoch_loss=1.117551\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=80 train loss <loss>=1.10869796276\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] Epoch[13] Batch [80]#011Speed: 14155.60 samples/sec#011loss=1.108698\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] Epoch[13] Batch[85] avg_epoch_loss=1.117698\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=85 train loss <loss>=1.1200766921\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] Epoch[13] Batch [85]#011Speed: 12968.02 samples/sec#011loss=1.120077\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] Epoch[13] Batch[90] avg_epoch_loss=1.130783\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=90 train loss <loss>=1.35583846569\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] Epoch[13] Batch [90]#011Speed: 1747.35 samples/sec#011loss=1.355838\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] Epoch[13] Batch[95] avg_epoch_loss=1.153050\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=95 train loss <loss>=1.55831830502\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] Epoch[13] Batch [95]#011Speed: 13783.59 samples/sec#011loss=1.558318\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] Epoch[13] Batch[100] avg_epoch_loss=1.159552\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=100 train loss <loss>=1.28439260721\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] Epoch[13] Batch [100]#011Speed: 1769.25 samples/sec#011loss=1.284393\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] Epoch[13] Batch[105] avg_epoch_loss=1.157188\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=105 train loss <loss>=1.10942463875\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] Epoch[13] Batch [105]#011Speed: 13950.64 samples/sec#011loss=1.109425\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] Epoch[13] Batch[110] avg_epoch_loss=1.156213\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=110 train loss <loss>=1.1355445385\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] Epoch[13] Batch [110]#011Speed: 14113.77 samples/sec#011loss=1.135545\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] Epoch[13] Batch[115] avg_epoch_loss=1.159945\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=115 train loss <loss>=1.24280757904\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] Epoch[13] Batch [115]#011Speed: 1627.58 samples/sec#011loss=1.242808\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] Epoch[13] Batch[120] avg_epoch_loss=1.157083\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=120 train loss <loss>=1.09068025351\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:40 INFO 140088046479168] Epoch[13] Batch [120]#011Speed: 14599.20 samples/sec#011loss=1.090680\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] Epoch[13] Batch[125] avg_epoch_loss=1.150219\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=125 train loss <loss>=0.984102666378\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] Epoch[13] Batch [125]#011Speed: 1735.19 samples/sec#011loss=0.984103\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] Epoch[13] Batch[130] avg_epoch_loss=1.152680\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=130 train loss <loss>=1.21470770836\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] Epoch[13] Batch [130]#011Speed: 14227.32 samples/sec#011loss=1.214708\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] Epoch[13] Batch[135] avg_epoch_loss=1.149285\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=135 train loss <loss>=1.06033933163\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] Epoch[13] Batch [135]#011Speed: 14413.11 samples/sec#011loss=1.060339\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] Epoch[13] Batch[140] avg_epoch_loss=1.146450\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=140 train loss <loss>=1.06931821108\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] Epoch[13] Batch [140]#011Speed: 1718.99 samples/sec#011loss=1.069318\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] Epoch[13] Batch[145] avg_epoch_loss=1.144013\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=145 train loss <loss>=1.07529989481\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] Epoch[13] Batch [145]#011Speed: 13326.62 samples/sec#011loss=1.075300\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] Epoch[13] Batch[150] avg_epoch_loss=1.143581\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=150 train loss <loss>=1.1309612751\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] Epoch[13] Batch [150]#011Speed: 1693.90 samples/sec#011loss=1.130961\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] Epoch[13] Batch[155] avg_epoch_loss=1.140576\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=155 train loss <loss>=1.04982727766\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] Epoch[13] Batch [155]#011Speed: 14333.07 samples/sec#011loss=1.049827\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] Epoch[13] Batch[160] avg_epoch_loss=1.145440\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=160 train loss <loss>=1.2971909523\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] Epoch[13] Batch [160]#011Speed: 13203.00 samples/sec#011loss=1.297191\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] Epoch[13] Batch[165] avg_epoch_loss=1.145102\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=165 train loss <loss>=1.13422765732\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] Epoch[13] Batch [165]#011Speed: 1744.20 samples/sec#011loss=1.134228\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] Epoch[13] Batch[170] avg_epoch_loss=1.141950\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=170 train loss <loss>=1.03730899096\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:41 INFO 140088046479168] Epoch[13] Batch [170]#011Speed: 13277.45 samples/sec#011loss=1.037309\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] Epoch[13] Batch[175] avg_epoch_loss=1.153487\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=175 train loss <loss>=1.54804074764\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] Epoch[13] Batch [175]#011Speed: 1644.64 samples/sec#011loss=1.548041\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] Epoch[13] Batch[180] avg_epoch_loss=1.161970\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=180 train loss <loss>=1.4605871439\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] Epoch[13] Batch [180]#011Speed: 13218.21 samples/sec#011loss=1.460587\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] Epoch[13] Batch[185] avg_epoch_loss=1.179743\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=185 train loss <loss>=1.82313605547\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] Epoch[13] Batch [185]#011Speed: 13205.73 samples/sec#011loss=1.823136\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] Epoch[13] Batch[190] avg_epoch_loss=1.203932\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=190 train loss <loss>=2.10375406742\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] Epoch[13] Batch [190]#011Speed: 1857.09 samples/sec#011loss=2.103754\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] Epoch[13] Batch[195] avg_epoch_loss=1.212349\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=195 train loss <loss>=1.53385095596\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] Epoch[13] Batch [195]#011Speed: 14112.44 samples/sec#011loss=1.533851\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] Epoch[13] Batch[200] avg_epoch_loss=1.225091\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=200 train loss <loss>=1.72461283207\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] Epoch[13] Batch [200]#011Speed: 1788.97 samples/sec#011loss=1.724613\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] Epoch[13] Batch[205] avg_epoch_loss=1.235124\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=205 train loss <loss>=1.63842270374\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] Epoch[13] Batch [205]#011Speed: 14353.00 samples/sec#011loss=1.638423\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] Epoch[13] Batch[210] avg_epoch_loss=1.233443\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=210 train loss <loss>=1.16418004036\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] Epoch[13] Batch [210]#011Speed: 14273.02 samples/sec#011loss=1.164180\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] Epoch[13] Batch[215] avg_epoch_loss=1.231932\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=215 train loss <loss>=1.1681946516\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] Epoch[13] Batch [215]#011Speed: 1596.64 samples/sec#011loss=1.168195\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] Epoch[13] Batch[220] avg_epoch_loss=1.231718\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=220 train loss <loss>=1.22244161367\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] Epoch[13] Batch [220]#011Speed: 14181.17 samples/sec#011loss=1.222442\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] Epoch[13] Batch[225] avg_epoch_loss=1.229675\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=225 train loss <loss>=1.13941406012\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] Epoch[13] Batch [225]#011Speed: 1846.79 samples/sec#011loss=1.139414\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] Epoch[13] Batch[230] avg_epoch_loss=1.229383\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=230 train loss <loss>=1.21614726782\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] Epoch[13] Batch [230]#011Speed: 14195.12 samples/sec#011loss=1.216147\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] Epoch[13] Batch[235] avg_epoch_loss=1.227968\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=235 train loss <loss>=1.16260002851\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:42 INFO 140088046479168] Epoch[13] Batch [235]#011Speed: 14345.17 samples/sec#011loss=1.162600\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] Epoch[13] Batch[240] avg_epoch_loss=1.226640\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=240 train loss <loss>=1.16398553848\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] Epoch[13] Batch [240]#011Speed: 1819.18 samples/sec#011loss=1.163986\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] Epoch[13] Batch[245] avg_epoch_loss=1.228044\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=245 train loss <loss>=1.29572203159\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] Epoch[13] Batch [245]#011Speed: 13261.44 samples/sec#011loss=1.295722\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] Epoch[13] Batch[250] avg_epoch_loss=1.227820\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=250 train loss <loss>=1.2167553544\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] Epoch[13] Batch [250]#011Speed: 1708.22 samples/sec#011loss=1.216755\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] Epoch[13] Batch[255] avg_epoch_loss=1.225536\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=255 train loss <loss>=1.11089091301\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] Epoch[13] Batch [255]#011Speed: 13296.12 samples/sec#011loss=1.110891\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] Epoch[13] Batch[260] avg_epoch_loss=1.224746\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=260 train loss <loss>=1.18431043625\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] Epoch[13] Batch [260]#011Speed: 14139.34 samples/sec#011loss=1.184310\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] Epoch[13] Batch[265] avg_epoch_loss=1.221827\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=265 train loss <loss>=1.06945990324\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] Epoch[13] Batch [265]#011Speed: 1646.46 samples/sec#011loss=1.069460\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] Epoch[13] Batch[270] avg_epoch_loss=1.219414\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=270 train loss <loss>=1.09105395079\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] Epoch[13] Batch [270]#011Speed: 14109.32 samples/sec#011loss=1.091054\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] Epoch[13] Batch[275] avg_epoch_loss=1.216686\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=275 train loss <loss>=1.06883029938\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] Epoch[13] Batch [275]#011Speed: 14310.60 samples/sec#011loss=1.068830\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] Epoch[13] Batch[280] avg_epoch_loss=1.215331\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=280 train loss <loss>=1.14050006866\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] Epoch[13] Batch [280]#011Speed: 1725.95 samples/sec#011loss=1.140500\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] Epoch[13] Batch[285] avg_epoch_loss=1.213534\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=285 train loss <loss>=1.11254684925\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:43 INFO 140088046479168] Epoch[13] Batch [285]#011Speed: 14205.19 samples/sec#011loss=1.112547\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] Epoch[13] Batch[290] avg_epoch_loss=1.212133\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=290 train loss <loss>=1.13201440573\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] Epoch[13] Batch [290]#011Speed: 1762.59 samples/sec#011loss=1.132014\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] Epoch[13] Batch[295] avg_epoch_loss=1.209230\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=295 train loss <loss>=1.04026917219\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] Epoch[13] Batch [295]#011Speed: 14354.38 samples/sec#011loss=1.040269\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] Epoch[13] Batch[300] avg_epoch_loss=1.207225\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=300 train loss <loss>=1.08850121498\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] Epoch[13] Batch [300]#011Speed: 14353.76 samples/sec#011loss=1.088501\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] Epoch[13] Batch[305] avg_epoch_loss=1.201874\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=305 train loss <loss>=0.879791355133\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] Epoch[13] Batch [305]#011Speed: 1858.28 samples/sec#011loss=0.879791\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] Epoch[13] Batch[310] avg_epoch_loss=1.197111\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=310 train loss <loss>=0.905599802732\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] Epoch[13] Batch [310]#011Speed: 14198.88 samples/sec#011loss=0.905600\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] Epoch[13] Batch[315] avg_epoch_loss=1.197760\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=315 train loss <loss>=1.23812566996\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] Epoch[13] Batch [315]#011Speed: 1428.81 samples/sec#011loss=1.238126\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] Epoch[13] Batch[320] avg_epoch_loss=1.198225\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=320 train loss <loss>=1.22760950327\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] Epoch[13] Batch [320]#011Speed: 14028.95 samples/sec#011loss=1.227610\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] Epoch[13] Batch[325] avg_epoch_loss=1.196021\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=325 train loss <loss>=1.05453569889\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] Epoch[13] Batch [325]#011Speed: 14278.03 samples/sec#011loss=1.054536\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] Epoch[13] Batch[330] avg_epoch_loss=1.196527\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=330 train loss <loss>=1.22954185009\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] Epoch[13] Batch [330]#011Speed: 1864.63 samples/sec#011loss=1.229542\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] Epoch[13] Batch[335] avg_epoch_loss=1.198043\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=335 train loss <loss>=1.29837412834\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] Epoch[13] Batch [335]#011Speed: 13364.04 samples/sec#011loss=1.298374\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] Epoch[13] Batch[340] avg_epoch_loss=1.197300\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=340 train loss <loss>=1.14737844467\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] Epoch[13] Batch [340]#011Speed: 1798.28 samples/sec#011loss=1.147378\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] Epoch[13] Batch[345] avg_epoch_loss=1.198580\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=345 train loss <loss>=1.28586609364\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] Epoch[13] Batch [345]#011Speed: 13954.85 samples/sec#011loss=1.285866\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] Epoch[13] Batch[350] avg_epoch_loss=1.198115\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=350 train loss <loss>=1.16596105099\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:44 INFO 140088046479168] Epoch[13] Batch [350]#011Speed: 14317.02 samples/sec#011loss=1.165961\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] Epoch[13] Batch[355] avg_epoch_loss=1.197486\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=355 train loss <loss>=1.15329884291\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] Epoch[13] Batch [355]#011Speed: 1847.52 samples/sec#011loss=1.153299\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] Epoch[13] Batch[360] avg_epoch_loss=1.196767\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=360 train loss <loss>=1.14558483362\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] Epoch[13] Batch [360]#011Speed: 13991.65 samples/sec#011loss=1.145585\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] Epoch[13] Batch[365] avg_epoch_loss=1.195726\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=365 train loss <loss>=1.12054698467\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] Epoch[13] Batch [365]#011Speed: 1745.04 samples/sec#011loss=1.120547\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] Epoch[13] Batch[370] avg_epoch_loss=1.195201\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=370 train loss <loss>=1.15679516792\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] Epoch[13] Batch [370]#011Speed: 13217.69 samples/sec#011loss=1.156795\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] Epoch[13] Batch[375] avg_epoch_loss=1.197403\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=375 train loss <loss>=1.36080908775\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] Epoch[13] Batch [375]#011Speed: 1764.85 samples/sec#011loss=1.360809\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] Epoch[13] Batch[380] avg_epoch_loss=1.198402\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=380 train loss <loss>=1.27349307537\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] Epoch[13] Batch [380]#011Speed: 14363.90 samples/sec#011loss=1.273493\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] Epoch[13] Batch[385] avg_epoch_loss=1.198872\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=385 train loss <loss>=1.23469468355\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] Epoch[13] Batch [385]#011Speed: 14297.19 samples/sec#011loss=1.234695\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] Epoch[13] Batch[390] avg_epoch_loss=1.198076\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=390 train loss <loss>=1.13661869764\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] Epoch[13] Batch [390]#011Speed: 1788.44 samples/sec#011loss=1.136619\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] Epoch[13] Batch[395] avg_epoch_loss=1.197555\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=395 train loss <loss>=1.15681407452\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] Epoch[13] Batch [395]#011Speed: 14306.18 samples/sec#011loss=1.156814\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] Epoch[13] Batch[400] avg_epoch_loss=1.195781\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=400 train loss <loss>=1.0552631855\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] Epoch[13] Batch [400]#011Speed: 1792.23 samples/sec#011loss=1.055263\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] Epoch[13] Batch[405] avg_epoch_loss=1.193037\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=405 train loss <loss>=0.972979426384\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] Epoch[13] Batch [405]#011Speed: 13729.87 samples/sec#011loss=0.972979\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] Epoch[13] Batch[410] avg_epoch_loss=1.190628\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=410 train loss <loss>=0.995003992319\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:45 INFO 140088046479168] Epoch[13] Batch [410]#011Speed: 14362.67 samples/sec#011loss=0.995004\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] Epoch[13] Batch[415] avg_epoch_loss=1.186303\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=415 train loss <loss>=0.830832135677\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] Epoch[13] Batch [415]#011Speed: 1647.94 samples/sec#011loss=0.830832\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] Epoch[13] Batch[420] avg_epoch_loss=1.183075\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=420 train loss <loss>=0.91447905302\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] Epoch[13] Batch [420]#011Speed: 13209.50 samples/sec#011loss=0.914479\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] Epoch[13] Batch[425] avg_epoch_loss=1.180040\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=425 train loss <loss>=0.9244795084\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] Epoch[13] Batch [425]#011Speed: 1801.53 samples/sec#011loss=0.924480\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] Epoch[13] Batch[430] avg_epoch_loss=1.181088\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=430 train loss <loss>=1.27039835453\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] Epoch[13] Batch [430]#011Speed: 14269.68 samples/sec#011loss=1.270398\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] Epoch[13] Batch[435] avg_epoch_loss=1.185196\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=435 train loss <loss>=1.53933734894\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] Epoch[13] Batch [435]#011Speed: 13688.00 samples/sec#011loss=1.539337\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] Epoch[13] Batch[440] avg_epoch_loss=1.192536\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=440 train loss <loss>=1.83252871037\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] Epoch[13] Batch [440]#011Speed: 1584.16 samples/sec#011loss=1.832529\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] Epoch[13] Batch[445] avg_epoch_loss=1.201617\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=445 train loss <loss>=2.00260896683\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] Epoch[13] Batch [445]#011Speed: 12661.21 samples/sec#011loss=2.002609\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] Epoch[13] Batch[450] avg_epoch_loss=1.207458\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=450 train loss <loss>=1.72844421864\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] Epoch[13] Batch [450]#011Speed: 1465.15 samples/sec#011loss=1.728444\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] Epoch[13] Batch[455] avg_epoch_loss=1.208663\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=455 train loss <loss>=1.31734654903\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] Epoch[13] Batch [455]#011Speed: 14349.16 samples/sec#011loss=1.317347\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] Epoch[13] Batch[460] avg_epoch_loss=1.208340\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=460 train loss <loss>=1.17888176441\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:46 INFO 140088046479168] Epoch[13] Batch [460]#011Speed: 14129.97 samples/sec#011loss=1.178882\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] Epoch[13] Batch[465] avg_epoch_loss=1.209441\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=465 train loss <loss>=1.31096074581\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] Epoch[13] Batch [465]#011Speed: 1720.66 samples/sec#011loss=1.310961\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] Epoch[13] Batch[470] avg_epoch_loss=1.211731\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=470 train loss <loss>=1.42519235611\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] Epoch[13] Batch [470]#011Speed: 13573.11 samples/sec#011loss=1.425192\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] Epoch[13] Batch[475] avg_epoch_loss=1.212464\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=475 train loss <loss>=1.28147768974\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] Epoch[13] Batch [475]#011Speed: 1734.63 samples/sec#011loss=1.281478\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] Epoch[13] Batch[480] avg_epoch_loss=1.215100\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=480 train loss <loss>=1.46605341434\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] Epoch[13] Batch [480]#011Speed: 14186.27 samples/sec#011loss=1.466053\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] Epoch[13] Batch[485] avg_epoch_loss=1.214439\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=485 train loss <loss>=1.15085885525\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] Epoch[13] Batch [485]#011Speed: 14249.98 samples/sec#011loss=1.150859\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] Epoch[13] Batch[490] avg_epoch_loss=1.215350\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=490 train loss <loss>=1.30386000872\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] Epoch[13] Batch [490]#011Speed: 1702.83 samples/sec#011loss=1.303860\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] Epoch[13] Batch[495] avg_epoch_loss=1.218628\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=495 train loss <loss>=1.54052715302\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] Epoch[13] Batch [495]#011Speed: 12979.56 samples/sec#011loss=1.540527\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] Epoch[13] Batch[500] avg_epoch_loss=1.220888\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=500 train loss <loss>=1.44509906769\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] Epoch[13] Batch [500]#011Speed: 1795.60 samples/sec#011loss=1.445099\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] Epoch[13] Batch[505] avg_epoch_loss=1.224225\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=505 train loss <loss>=1.55863724947\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] Epoch[13] Batch [505]#011Speed: 14076.47 samples/sec#011loss=1.558637\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] Epoch[13] Batch[510] avg_epoch_loss=1.224144\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=510 train loss <loss>=1.21586850882\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] Epoch[13] Batch [510]#011Speed: 13538.61 samples/sec#011loss=1.215869\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] Epoch[13] Batch[515] avg_epoch_loss=1.226843\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=515 train loss <loss>=1.50274438858\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:47 INFO 140088046479168] Epoch[13] Batch [515]#011Speed: 1707.00 samples/sec#011loss=1.502744\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] Epoch[13] Batch[520] avg_epoch_loss=1.228204\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=520 train loss <loss>=1.36866250038\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] Epoch[13] Batch [520]#011Speed: 14292.01 samples/sec#011loss=1.368663\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] Epoch[13] Batch[525] avg_epoch_loss=1.231222\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=525 train loss <loss>=1.54572613239\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] Epoch[13] Batch [525]#011Speed: 14216.02 samples/sec#011loss=1.545726\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] Epoch[13] Batch[530] avg_epoch_loss=1.233029\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=530 train loss <loss>=1.42304341793\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] Epoch[13] Batch [530]#011Speed: 1753.72 samples/sec#011loss=1.423043\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] Epoch[13] Batch[535] avg_epoch_loss=1.232562\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=535 train loss <loss>=1.18302662373\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] Epoch[13] Batch [535]#011Speed: 14409.24 samples/sec#011loss=1.183027\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] Epoch[13] Batch[540] avg_epoch_loss=1.233617\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=540 train loss <loss>=1.34671863317\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] Epoch[13] Batch [540]#011Speed: 1751.93 samples/sec#011loss=1.346719\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] Epoch[13] Batch[545] avg_epoch_loss=1.233909\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=545 train loss <loss>=1.26546599865\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] Epoch[13] Batch [545]#011Speed: 14115.55 samples/sec#011loss=1.265466\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] Epoch[13] Batch[550] avg_epoch_loss=1.233191\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=550 train loss <loss>=1.15483253002\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] Epoch[13] Batch [550]#011Speed: 12081.35 samples/sec#011loss=1.154833\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] Epoch[13] Batch[555] avg_epoch_loss=1.232051\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=555 train loss <loss>=1.10633400679\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] Epoch[13] Batch [555]#011Speed: 1587.69 samples/sec#011loss=1.106334\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] Epoch[13] Batch[560] avg_epoch_loss=1.229742\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=560 train loss <loss>=0.972968935966\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] Epoch[13] Batch [560]#011Speed: 14220.99 samples/sec#011loss=0.972969\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] Epoch[13] Batch[565] avg_epoch_loss=1.229023\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=565 train loss <loss>=1.1484387815\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] Epoch[13] Batch [565]#011Speed: 1689.38 samples/sec#011loss=1.148439\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] Epoch[13] Batch[570] avg_epoch_loss=1.227594\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=570 train loss <loss>=1.06578245163\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] Epoch[13] Batch [570]#011Speed: 13287.44 samples/sec#011loss=1.065782\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] Epoch[13] Batch[575] avg_epoch_loss=1.228798\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=575 train loss <loss>=1.36631634235\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:48 INFO 140088046479168] Epoch[13] Batch [575]#011Speed: 13256.07 samples/sec#011loss=1.366316\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] Epoch[13] Batch[580] avg_epoch_loss=1.227278\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=580 train loss <loss>=1.0521600008\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] Epoch[13] Batch [580]#011Speed: 1787.34 samples/sec#011loss=1.052160\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] Epoch[13] Batch[585] avg_epoch_loss=1.226340\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=585 train loss <loss>=1.1173307538\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] Epoch[13] Batch [585]#011Speed: 13255.02 samples/sec#011loss=1.117331\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] Epoch[13] Batch[590] avg_epoch_loss=1.224412\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=590 train loss <loss>=0.998528647423\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] Epoch[13] Batch [590]#011Speed: 13170.35 samples/sec#011loss=0.998529\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] Epoch[13] Batch[595] avg_epoch_loss=1.224967\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=595 train loss <loss>=1.2905146718\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] Epoch[13] Batch [595]#011Speed: 1599.30 samples/sec#011loss=1.290515\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] Epoch[13] Batch[600] avg_epoch_loss=1.223834\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=600 train loss <loss>=1.08883097172\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] Epoch[13] Batch [600]#011Speed: 12841.59 samples/sec#011loss=1.088831\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] Epoch[13] Batch[605] avg_epoch_loss=1.222739\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=605 train loss <loss>=1.0910200119\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] Epoch[13] Batch [605]#011Speed: 1700.08 samples/sec#011loss=1.091020\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] Epoch[13] Batch[610] avg_epoch_loss=1.220496\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=610 train loss <loss>=0.948751938343\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] Epoch[13] Batch [610]#011Speed: 14524.31 samples/sec#011loss=0.948752\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] Epoch[13] Batch[615] avg_epoch_loss=1.219390\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=615 train loss <loss>=1.08416231871\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] Epoch[13] Batch [615]#011Speed: 14405.37 samples/sec#011loss=1.084162\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] Epoch[13] Batch[620] avg_epoch_loss=1.218224\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=620 train loss <loss>=1.07460452318\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] Epoch[13] Batch [620]#011Speed: 1623.90 samples/sec#011loss=1.074605\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] Epoch[13] Batch[625] avg_epoch_loss=1.218579\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=625 train loss <loss>=1.26264411211\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:49 INFO 140088046479168] Epoch[13] Batch [625]#011Speed: 14186.87 samples/sec#011loss=1.262644\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] Epoch[13] Batch[630] avg_epoch_loss=1.218375\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=630 train loss <loss>=1.19284573793\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] Epoch[13] Batch [630]#011Speed: 1732.84 samples/sec#011loss=1.192846\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] Epoch[13] Batch[635] avg_epoch_loss=1.216794\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=635 train loss <loss>=1.0172451973\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] Epoch[13] Batch [635]#011Speed: 13311.03 samples/sec#011loss=1.017245\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] Epoch[13] Batch[640] avg_epoch_loss=1.215873\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=640 train loss <loss>=1.09878107309\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] Epoch[13] Batch [640]#011Speed: 13232.42 samples/sec#011loss=1.098781\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] Epoch[13] Batch[645] avg_epoch_loss=1.214772\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=645 train loss <loss>=1.07361040115\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] Epoch[13] Batch [645]#011Speed: 1664.48 samples/sec#011loss=1.073610\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] Epoch[13] Batch[650] avg_epoch_loss=1.214516\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=650 train loss <loss>=1.18144817352\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] Epoch[13] Batch [650]#011Speed: 13567.90 samples/sec#011loss=1.181448\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] Epoch[13] Batch[655] avg_epoch_loss=1.212990\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=655 train loss <loss>=1.01421779394\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] Epoch[13] Batch [655]#011Speed: 1686.76 samples/sec#011loss=1.014218\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] Epoch[13] Batch[660] avg_epoch_loss=1.212853\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=660 train loss <loss>=1.19491894245\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] Epoch[13] Batch [660]#011Speed: 10074.59 samples/sec#011loss=1.194919\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] Epoch[13] Batch[665] avg_epoch_loss=1.212690\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=665 train loss <loss>=1.19110833406\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] Epoch[13] Batch [665]#011Speed: 14479.03 samples/sec#011loss=1.191108\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] Epoch[13] Batch[670] avg_epoch_loss=1.212634\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=670 train loss <loss>=1.20523734093\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] Epoch[13] Batch [670]#011Speed: 1645.71 samples/sec#011loss=1.205237\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] Epoch[13] Batch[675] avg_epoch_loss=1.214217\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=675 train loss <loss>=1.42667562962\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] Epoch[13] Batch [675]#011Speed: 12937.65 samples/sec#011loss=1.426676\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] Epoch[13] Batch[680] avg_epoch_loss=1.216119\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=680 train loss <loss>=1.47328908443\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] Epoch[13] Batch [680]#011Speed: 13930.52 samples/sec#011loss=1.473289\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] Epoch[13] Batch[685] avg_epoch_loss=1.217211\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=685 train loss <loss>=1.36584285498\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] Epoch[13] Batch [685]#011Speed: 1694.93 samples/sec#011loss=1.365843\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] Epoch[13] Batch[690] avg_epoch_loss=1.218871\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=690 train loss <loss>=1.44663834572\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:50 INFO 140088046479168] Epoch[13] Batch [690]#011Speed: 13203.52 samples/sec#011loss=1.446638\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] Epoch[13] Batch[695] avg_epoch_loss=1.220990\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=695 train loss <loss>=1.51393283606\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] Epoch[13] Batch [695]#011Speed: 1750.14 samples/sec#011loss=1.513933\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] Epoch[13] Batch[700] avg_epoch_loss=1.221686\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=700 train loss <loss>=1.31847116947\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] Epoch[13] Batch [700]#011Speed: 13206.77 samples/sec#011loss=1.318471\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] Epoch[13] Batch[705] avg_epoch_loss=1.221073\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=705 train loss <loss>=1.1351195097\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] Epoch[13] Batch [705]#011Speed: 13229.16 samples/sec#011loss=1.135120\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] Epoch[13] Batch[710] avg_epoch_loss=1.220074\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=710 train loss <loss>=1.07902841568\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] Epoch[13] Batch [710]#011Speed: 1740.97 samples/sec#011loss=1.079028\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] Epoch[13] Batch[715] avg_epoch_loss=1.218792\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=715 train loss <loss>=1.03648892641\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] Epoch[13] Batch [715]#011Speed: 13261.44 samples/sec#011loss=1.036489\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] Epoch[13] Batch[720] avg_epoch_loss=1.217933\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=720 train loss <loss>=1.0950152874\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] Epoch[13] Batch [720]#011Speed: 1684.77 samples/sec#011loss=1.095015\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] Epoch[13] Batch[725] avg_epoch_loss=1.215558\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=725 train loss <loss>=0.872993814945\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] Epoch[13] Batch [725]#011Speed: 14136.81 samples/sec#011loss=0.872994\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] Epoch[13] Batch[730] avg_epoch_loss=1.214433\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=730 train loss <loss>=1.05116578341\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] Epoch[13] Batch [730]#011Speed: 14610.64 samples/sec#011loss=1.051166\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] Epoch[13] Batch[735] avg_epoch_loss=1.214652\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=735 train loss <loss>=1.2465682745\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] Epoch[13] Batch [735]#011Speed: 1526.82 samples/sec#011loss=1.246568\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] Epoch[13] Batch[740] avg_epoch_loss=1.216101\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=740 train loss <loss>=1.42949154377\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:51 INFO 140088046479168] Epoch[13] Batch [740]#011Speed: 13820.49 samples/sec#011loss=1.429492\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] Epoch[13] Batch[745] avg_epoch_loss=1.217014\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=745 train loss <loss>=1.35221760273\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] Epoch[13] Batch [745]#011Speed: 1822.62 samples/sec#011loss=1.352218\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] Epoch[13] Batch[750] avg_epoch_loss=1.217253\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=750 train loss <loss>=1.25296543837\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] Epoch[13] Batch [750]#011Speed: 14238.64 samples/sec#011loss=1.252965\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] Epoch[13] Batch[755] avg_epoch_loss=1.218273\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=755 train loss <loss>=1.37141814232\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] Epoch[13] Batch [755]#011Speed: 14349.77 samples/sec#011loss=1.371418\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] Epoch[13] Batch[760] avg_epoch_loss=1.219121\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=760 train loss <loss>=1.34747052193\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] Epoch[13] Batch [760]#011Speed: 1849.69 samples/sec#011loss=1.347471\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] Epoch[13] Batch[765] avg_epoch_loss=1.220813\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=765 train loss <loss>=1.47826240063\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] Epoch[13] Batch [765]#011Speed: 13397.52 samples/sec#011loss=1.478262\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] Epoch[13] Batch[770] avg_epoch_loss=1.222526\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=770 train loss <loss>=1.48490943909\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] Epoch[13] Batch [770]#011Speed: 1438.84 samples/sec#011loss=1.484909\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] Epoch[13] Batch[775] avg_epoch_loss=1.223071\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=775 train loss <loss>=1.30717988014\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] Epoch[13] Batch [775]#011Speed: 14477.00 samples/sec#011loss=1.307180\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] Epoch[13] Batch[780] avg_epoch_loss=1.223123\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=780 train loss <loss>=1.23117274046\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] Epoch[13] Batch [780]#011Speed: 14273.02 samples/sec#011loss=1.231173\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] Epoch[13] Batch[785] avg_epoch_loss=1.225137\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=785 train loss <loss>=1.53970320225\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] Epoch[13] Batch [785]#011Speed: 1701.61 samples/sec#011loss=1.539703\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] Epoch[13] Batch[790] avg_epoch_loss=1.226527\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=790 train loss <loss>=1.44511704445\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] Epoch[13] Batch [790]#011Speed: 14300.39 samples/sec#011loss=1.445117\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] Epoch[13] Batch[795] avg_epoch_loss=1.227550\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=795 train loss <loss>=1.38925189972\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:52 INFO 140088046479168] Epoch[13] Batch [795]#011Speed: 13973.88 samples/sec#011loss=1.389252\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] Epoch[13] Batch[800] avg_epoch_loss=1.227020\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=800 train loss <loss>=1.14268015623\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] Epoch[13] Batch [800]#011Speed: 1467.84 samples/sec#011loss=1.142680\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] Epoch[13] Batch[805] avg_epoch_loss=1.226931\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=805 train loss <loss>=1.21276564598\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] Epoch[13] Batch [805]#011Speed: 14413.73 samples/sec#011loss=1.212766\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] Epoch[13] Batch[810] avg_epoch_loss=1.226369\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=810 train loss <loss>=1.13575160503\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] Epoch[13] Batch [810]#011Speed: 1783.05 samples/sec#011loss=1.135752\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] Epoch[13] Batch[815] avg_epoch_loss=1.227144\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=815 train loss <loss>=1.3527756691\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] Epoch[13] Batch [815]#011Speed: 14098.20 samples/sec#011loss=1.352776\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] Epoch[13] Batch[820] avg_epoch_loss=1.227881\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=820 train loss <loss>=1.34822378159\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] Epoch[13] Batch [820]#011Speed: 13951.37 samples/sec#011loss=1.348224\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] Epoch[13] Batch[825] avg_epoch_loss=1.227868\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=825 train loss <loss>=1.22572101355\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] Epoch[13] Batch [825]#011Speed: 1678.32 samples/sec#011loss=1.225721\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] Epoch[13] Batch[830] avg_epoch_loss=1.227054\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=830 train loss <loss>=1.09253543615\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] Epoch[13] Batch [830]#011Speed: 13298.50 samples/sec#011loss=1.092535\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] Epoch[13] Batch[835] avg_epoch_loss=1.225735\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=835 train loss <loss>=1.00648255348\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] Epoch[13] Batch [835]#011Speed: 1781.41 samples/sec#011loss=1.006483\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] Epoch[13] Batch[840] avg_epoch_loss=1.224914\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=840 train loss <loss>=1.08776857853\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] Epoch[13] Batch [840]#011Speed: 13272.06 samples/sec#011loss=1.087769\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] Epoch[13] Batch[845] avg_epoch_loss=1.224628\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=845 train loss <loss>=1.17653429508\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] Epoch[13] Batch [845]#011Speed: 13236.33 samples/sec#011loss=1.176534\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] Epoch[13] Batch[850] avg_epoch_loss=1.224531\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=850 train loss <loss>=1.20810277462\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] Epoch[13] Batch [850]#011Speed: 1699.85 samples/sec#011loss=1.208103\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] Epoch[13] Batch[855] avg_epoch_loss=1.224162\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=855 train loss <loss>=1.16127824783\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] Epoch[13] Batch [855]#011Speed: 14298.56 samples/sec#011loss=1.161278\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] Epoch[13] Batch[860] avg_epoch_loss=1.223204\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=860 train loss <loss>=1.05916275978\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:53 INFO 140088046479168] Epoch[13] Batch [860]#011Speed: 14229.28 samples/sec#011loss=1.059163\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] Epoch[13] Batch[865] avg_epoch_loss=1.221998\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=865 train loss <loss>=1.01443847418\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] Epoch[13] Batch [865]#011Speed: 1820.08 samples/sec#011loss=1.014438\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] Epoch[13] Batch[870] avg_epoch_loss=1.221526\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=870 train loss <loss>=1.13979879618\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] Epoch[13] Batch [870]#011Speed: 13416.54 samples/sec#011loss=1.139799\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] Epoch[13] Batch[875] avg_epoch_loss=1.220788\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=875 train loss <loss>=1.09207541943\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] Epoch[13] Batch [875]#011Speed: 1737.89 samples/sec#011loss=1.092075\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] Epoch[13] Batch[880] avg_epoch_loss=1.219611\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=880 train loss <loss>=1.01339335442\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] Epoch[13] Batch [880]#011Speed: 11615.25 samples/sec#011loss=1.013393\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] Epoch[13] Batch[885] avg_epoch_loss=1.218590\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=885 train loss <loss>=1.03885282278\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] Epoch[13] Batch [885]#011Speed: 14018.54 samples/sec#011loss=1.038853\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] Epoch[13] Batch[890] avg_epoch_loss=1.218739\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=890 train loss <loss>=1.24504039288\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] Epoch[13] Batch [890]#011Speed: 1642.32 samples/sec#011loss=1.245040\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] Epoch[13] Batch[895] avg_epoch_loss=1.218893\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=895 train loss <loss>=1.24629173279\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] Epoch[13] Batch [895]#011Speed: 14420.85 samples/sec#011loss=1.246292\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] Epoch[13] Batch[900] avg_epoch_loss=1.217519\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, batch=900 train loss <loss>=0.971375966072\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] Epoch[13] Batch [900]#011Speed: 7594.46 samples/sec#011loss=0.971376\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] processed a total of 57652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15886.82508468628, \"sum\": 15886.82508468628, \"min\": 15886.82508468628}}, \"EndTime\": 1604320614.651562, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320598.764192}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] #throughput_metric: host=algo-1, train throughput=3628.89473168 records/second\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=13, train loss <loss>=1.2175190588\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] Saved checkpoint to \"/opt/ml/model/state_fd47b869-40d3-4014-a147-e0e97e477204-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 5.2280426025390625, \"sum\": 5.2280426025390625, \"min\": 5.2280426025390625}}, \"EndTime\": 1604320614.657372, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320614.651624}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] Epoch[14] Batch[0] avg_epoch_loss=1.707111\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=1.70711100101\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] Epoch[14] Batch[5] avg_epoch_loss=1.309220\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=1.30922041337\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] Epoch[14] Batch [5]#011Speed: 14337.51 samples/sec#011loss=1.309220\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] Epoch[14] Batch[10] avg_epoch_loss=1.603838\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=1.95737967491\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:54 INFO 140088046479168] Epoch[14] Batch [10]#011Speed: 14340.73 samples/sec#011loss=1.957380\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] Epoch[14] Batch[15] avg_epoch_loss=1.615961\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=15 train loss <loss>=1.64262943268\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] Epoch[14] Batch [15]#011Speed: 1862.13 samples/sec#011loss=1.642629\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] Epoch[14] Batch[20] avg_epoch_loss=1.485936\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=20 train loss <loss>=1.06985887289\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] Epoch[14] Batch [20]#011Speed: 14376.21 samples/sec#011loss=1.069859\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] Epoch[14] Batch[25] avg_epoch_loss=1.413661\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=25 train loss <loss>=1.11010701656\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] Epoch[14] Batch [25]#011Speed: 1778.78 samples/sec#011loss=1.110107\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] Epoch[14] Batch[30] avg_epoch_loss=1.369310\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=30 train loss <loss>=1.13868002892\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] Epoch[14] Batch [30]#011Speed: 14480.28 samples/sec#011loss=1.138680\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] Epoch[14] Batch[35] avg_epoch_loss=1.313152\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=35 train loss <loss>=0.96497682333\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] Epoch[14] Batch [35]#011Speed: 14100.72 samples/sec#011loss=0.964977\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] Epoch[14] Batch[40] avg_epoch_loss=1.334076\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=40 train loss <loss>=1.48472337723\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] Epoch[14] Batch [40]#011Speed: 1753.81 samples/sec#011loss=1.484723\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] Epoch[14] Batch[45] avg_epoch_loss=1.350124\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=45 train loss <loss>=1.48172068596\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] Epoch[14] Batch [45]#011Speed: 13218.21 samples/sec#011loss=1.481721\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] Epoch[14] Batch[50] avg_epoch_loss=1.317229\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=50 train loss <loss>=1.01459513903\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] Epoch[14] Batch [50]#011Speed: 14122.38 samples/sec#011loss=1.014595\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] Epoch[14] Batch[55] avg_epoch_loss=1.270978\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=55 train loss <loss>=0.799216234684\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] Epoch[14] Batch [55]#011Speed: 1571.09 samples/sec#011loss=0.799216\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] Epoch[14] Batch[60] avg_epoch_loss=1.260865\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=60 train loss <loss>=1.14759608507\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] Epoch[14] Batch [60]#011Speed: 14084.59 samples/sec#011loss=1.147596\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] Epoch[14] Batch[65] avg_epoch_loss=1.260965\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=65 train loss <loss>=1.2621892333\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] Epoch[14] Batch [65]#011Speed: 1742.06 samples/sec#011loss=1.262189\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] Epoch[14] Batch[70] avg_epoch_loss=1.295863\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=70 train loss <loss>=1.75651381016\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] Epoch[14] Batch [70]#011Speed: 14359.44 samples/sec#011loss=1.756514\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] Epoch[14] Batch[75] avg_epoch_loss=1.322963\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=75 train loss <loss>=1.70778203011\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:55 INFO 140088046479168] Epoch[14] Batch [75]#011Speed: 14095.69 samples/sec#011loss=1.707782\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] Epoch[14] Batch[80] avg_epoch_loss=1.341794\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=80 train loss <loss>=1.62803527117\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] Epoch[14] Batch [80]#011Speed: 1668.57 samples/sec#011loss=1.628035\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] Epoch[14] Batch[85] avg_epoch_loss=1.354948\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=85 train loss <loss>=1.56804412603\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] Epoch[14] Batch [85]#011Speed: 14188.22 samples/sec#011loss=1.568044\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] Epoch[14] Batch[90] avg_epoch_loss=1.371581\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=90 train loss <loss>=1.65766324997\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] Epoch[14] Batch [90]#011Speed: 1661.76 samples/sec#011loss=1.657663\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] Epoch[14] Batch[95] avg_epoch_loss=1.374455\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=95 train loss <loss>=1.4267660141\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] Epoch[14] Batch [95]#011Speed: 13205.21 samples/sec#011loss=1.426766\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] Epoch[14] Batch[100] avg_epoch_loss=1.391247\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=100 train loss <loss>=1.71365761757\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] Epoch[14] Batch [100]#011Speed: 14028.80 samples/sec#011loss=1.713658\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] Epoch[14] Batch[105] avg_epoch_loss=1.385930\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=105 train loss <loss>=1.27850964069\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] Epoch[14] Batch [105]#011Speed: 1838.72 samples/sec#011loss=1.278510\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] Epoch[14] Batch[110] avg_epoch_loss=1.379834\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=110 train loss <loss>=1.25060005188\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] Epoch[14] Batch [110]#011Speed: 13750.41 samples/sec#011loss=1.250600\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] Epoch[14] Batch[115] avg_epoch_loss=1.365395\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=115 train loss <loss>=1.0448507905\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] Epoch[14] Batch [115]#011Speed: 1764.33 samples/sec#011loss=1.044851\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] Epoch[14] Batch[120] avg_epoch_loss=1.353683\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=120 train loss <loss>=1.08195869923\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] Epoch[14] Batch [120]#011Speed: 13261.44 samples/sec#011loss=1.081959\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] Epoch[14] Batch[125] avg_epoch_loss=1.348546\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=125 train loss <loss>=1.2242413044\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:56 INFO 140088046479168] Epoch[14] Batch [125]#011Speed: 13123.35 samples/sec#011loss=1.224241\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] Epoch[14] Batch[130] avg_epoch_loss=1.336389\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=130 train loss <loss>=1.03002825975\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] Epoch[14] Batch [130]#011Speed: 1764.06 samples/sec#011loss=1.030028\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] Epoch[14] Batch[135] avg_epoch_loss=1.325744\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=135 train loss <loss>=1.04684123993\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] Epoch[14] Batch [135]#011Speed: 13421.10 samples/sec#011loss=1.046841\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] Epoch[14] Batch[140] avg_epoch_loss=1.319969\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=140 train loss <loss>=1.16289505959\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] Epoch[14] Batch [140]#011Speed: 14337.51 samples/sec#011loss=1.162895\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] Epoch[14] Batch[145] avg_epoch_loss=1.310684\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=145 train loss <loss>=1.04884490967\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] Epoch[14] Batch [145]#011Speed: 1678.95 samples/sec#011loss=1.048845\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] Epoch[14] Batch[150] avg_epoch_loss=1.302827\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=150 train loss <loss>=1.07341953516\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] Epoch[14] Batch [150]#011Speed: 14487.63 samples/sec#011loss=1.073420\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] Epoch[14] Batch[155] avg_epoch_loss=1.296931\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=155 train loss <loss>=1.11885004044\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] Epoch[14] Batch [155]#011Speed: 1821.76 samples/sec#011loss=1.118850\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] Epoch[14] Batch[160] avg_epoch_loss=1.291916\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=160 train loss <loss>=1.1354665637\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] Epoch[14] Batch [160]#011Speed: 14238.79 samples/sec#011loss=1.135467\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] Epoch[14] Batch[165] avg_epoch_loss=1.286968\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=165 train loss <loss>=1.12761766911\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] Epoch[14] Batch [165]#011Speed: 13107.71 samples/sec#011loss=1.127618\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] Epoch[14] Batch[170] avg_epoch_loss=1.280805\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=170 train loss <loss>=1.07619736195\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] Epoch[14] Batch [170]#011Speed: 1666.52 samples/sec#011loss=1.076197\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] Epoch[14] Batch[175] avg_epoch_loss=1.273801\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=175 train loss <loss>=1.0342579484\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] Epoch[14] Batch [175]#011Speed: 13294.54 samples/sec#011loss=1.034258\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] Epoch[14] Batch[180] avg_epoch_loss=1.268624\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=180 train loss <loss>=1.08641765118\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] Epoch[14] Batch [180]#011Speed: 1773.52 samples/sec#011loss=1.086418\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] Epoch[14] Batch[185] avg_epoch_loss=1.262620\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=185 train loss <loss>=1.04525380135\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] Epoch[14] Batch [185]#011Speed: 13141.72 samples/sec#011loss=1.045254\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] Epoch[14] Batch[190] avg_epoch_loss=1.258778\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=190 train loss <loss>=1.11588437557\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:57 INFO 140088046479168] Epoch[14] Batch [190]#011Speed: 13121.17 samples/sec#011loss=1.115884\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] Epoch[14] Batch[195] avg_epoch_loss=1.257879\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=195 train loss <loss>=1.22353560925\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] Epoch[14] Batch [195]#011Speed: 1698.14 samples/sec#011loss=1.223536\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] Epoch[14] Batch[200] avg_epoch_loss=1.255521\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=200 train loss <loss>=1.16305658817\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] Epoch[14] Batch [200]#011Speed: 13187.17 samples/sec#011loss=1.163057\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] Epoch[14] Batch[205] avg_epoch_loss=1.254503\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=205 train loss <loss>=1.21359369755\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] Epoch[14] Batch [205]#011Speed: 1721.12 samples/sec#011loss=1.213594\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] Epoch[14] Batch[210] avg_epoch_loss=1.252633\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=210 train loss <loss>=1.17560763359\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] Epoch[14] Batch [210]#011Speed: 14164.26 samples/sec#011loss=1.175608\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] Epoch[14] Batch[215] avg_epoch_loss=1.249637\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=215 train loss <loss>=1.12319173813\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] Epoch[14] Batch [215]#011Speed: 14067.76 samples/sec#011loss=1.123192\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] Epoch[14] Batch[220] avg_epoch_loss=1.247441\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=220 train loss <loss>=1.15258233547\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] Epoch[14] Batch [220]#011Speed: 1747.16 samples/sec#011loss=1.152582\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] Epoch[14] Batch[225] avg_epoch_loss=1.246170\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=225 train loss <loss>=1.18998689651\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] Epoch[14] Batch [225]#011Speed: 11994.01 samples/sec#011loss=1.189987\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] Epoch[14] Batch[230] avg_epoch_loss=1.243107\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=230 train loss <loss>=1.10465234518\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] Epoch[14] Batch [230]#011Speed: 1755.09 samples/sec#011loss=1.104652\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] Epoch[14] Batch[235] avg_epoch_loss=1.238836\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=235 train loss <loss>=1.04154043198\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] Epoch[14] Batch [235]#011Speed: 14330.47 samples/sec#011loss=1.041540\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] Epoch[14] Batch[240] avg_epoch_loss=1.241339\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=240 train loss <loss>=1.35948050022\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:58 INFO 140088046479168] Epoch[14] Batch [240]#011Speed: 13232.94 samples/sec#011loss=1.359481\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] Epoch[14] Batch[245] avg_epoch_loss=1.238844\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=245 train loss <loss>=1.11854330301\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] Epoch[14] Batch [245]#011Speed: 1877.75 samples/sec#011loss=1.118543\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] Epoch[14] Batch[250] avg_epoch_loss=1.239181\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=250 train loss <loss>=1.25576636791\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] Epoch[14] Batch [250]#011Speed: 14625.29 samples/sec#011loss=1.255766\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] Epoch[14] Batch[255] avg_epoch_loss=1.236611\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=255 train loss <loss>=1.10760483742\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] Epoch[14] Batch [255]#011Speed: 1685.26 samples/sec#011loss=1.107605\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] Epoch[14] Batch[260] avg_epoch_loss=1.236950\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=260 train loss <loss>=1.25431406498\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] Epoch[14] Batch [260]#011Speed: 14231.10 samples/sec#011loss=1.254314\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] Epoch[14] Batch[265] avg_epoch_loss=1.237658\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=265 train loss <loss>=1.27461265326\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] Epoch[14] Batch [265]#011Speed: 14435.74 samples/sec#011loss=1.274613\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] Epoch[14] Batch[270] avg_epoch_loss=1.240303\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=270 train loss <loss>=1.38100171089\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] Epoch[14] Batch [270]#011Speed: 1734.85 samples/sec#011loss=1.381002\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] Epoch[14] Batch[275] avg_epoch_loss=1.241876\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=275 train loss <loss>=1.32713842392\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] Epoch[14] Batch [275]#011Speed: 14333.07 samples/sec#011loss=1.327138\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] Epoch[14] Batch[280] avg_epoch_loss=1.246478\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=280 train loss <loss>=1.50052945614\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] Epoch[14] Batch [280]#011Speed: 1745.43 samples/sec#011loss=1.500529\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] Epoch[14] Batch[285] avg_epoch_loss=1.250404\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=285 train loss <loss>=1.47103748322\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] Epoch[14] Batch [285]#011Speed: 13470.27 samples/sec#011loss=1.471037\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] Epoch[14] Batch[290] avg_epoch_loss=1.255523\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=290 train loss <loss>=1.54832811356\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] Epoch[14] Batch [290]#011Speed: 14209.55 samples/sec#011loss=1.548328\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] Epoch[14] Batch[295] avg_epoch_loss=1.256334\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=295 train loss <loss>=1.30354423523\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] Epoch[14] Batch [295]#011Speed: 1578.35 samples/sec#011loss=1.303544\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] Epoch[14] Batch[300] avg_epoch_loss=1.263598\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=300 train loss <loss>=1.69363808632\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:36:59 INFO 140088046479168] Epoch[14] Batch [300]#011Speed: 13275.74 samples/sec#011loss=1.693638\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] Epoch[14] Batch[305] avg_epoch_loss=1.267304\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=305 train loss <loss>=1.49035389423\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] Epoch[14] Batch [305]#011Speed: 1771.73 samples/sec#011loss=1.490354\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] Epoch[14] Batch[310] avg_epoch_loss=1.267172\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=310 train loss <loss>=1.25914455652\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] Epoch[14] Batch [310]#011Speed: 13107.20 samples/sec#011loss=1.259145\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] Epoch[14] Batch[315] avg_epoch_loss=1.268720\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=315 train loss <loss>=1.36500880718\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] Epoch[14] Batch [315]#011Speed: 13236.20 samples/sec#011loss=1.365009\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] Epoch[14] Batch[320] avg_epoch_loss=1.270462\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=320 train loss <loss>=1.38055963516\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] Epoch[14] Batch [320]#011Speed: 1423.13 samples/sec#011loss=1.380560\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] Epoch[14] Batch[325] avg_epoch_loss=1.273116\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=325 train loss <loss>=1.44350334406\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] Epoch[14] Batch [325]#011Speed: 13083.69 samples/sec#011loss=1.443503\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] Epoch[14] Batch[330] avg_epoch_loss=1.274710\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=330 train loss <loss>=1.37861161232\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] Epoch[14] Batch [330]#011Speed: 1814.36 samples/sec#011loss=1.378612\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] Epoch[14] Batch[335] avg_epoch_loss=1.274878\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=335 train loss <loss>=1.28600776196\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] Epoch[14] Batch [335]#011Speed: 14243.18 samples/sec#011loss=1.286008\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] Epoch[14] Batch[340] avg_epoch_loss=1.280295\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=340 train loss <loss>=1.64429237843\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] Epoch[14] Batch [340]#011Speed: 10851.93 samples/sec#011loss=1.644292\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] Epoch[14] Batch[345] avg_epoch_loss=1.281922\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=345 train loss <loss>=1.39287822247\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] Epoch[14] Batch [345]#011Speed: 1649.07 samples/sec#011loss=1.392878\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] Epoch[14] Batch[350] avg_epoch_loss=1.284002\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=350 train loss <loss>=1.42796425819\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] Epoch[14] Batch [350]#011Speed: 13482.17 samples/sec#011loss=1.427964\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] Epoch[14] Batch[355] avg_epoch_loss=1.283020\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=355 train loss <loss>=1.21407346725\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:00 INFO 140088046479168] Epoch[14] Batch [355]#011Speed: 14156.79 samples/sec#011loss=1.214073\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] Epoch[14] Batch[360] avg_epoch_loss=1.288050\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=360 train loss <loss>=1.64618394375\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] Epoch[14] Batch [360]#011Speed: 1777.84 samples/sec#011loss=1.646184\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] Epoch[14] Batch[365] avg_epoch_loss=1.287719\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=365 train loss <loss>=1.2638320446\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] Epoch[14] Batch [365]#011Speed: 13006.48 samples/sec#011loss=1.263832\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] Epoch[14] Batch[370] avg_epoch_loss=1.286007\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=370 train loss <loss>=1.16068582535\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] Epoch[14] Batch [370]#011Speed: 1732.19 samples/sec#011loss=1.160686\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] Epoch[14] Batch[375] avg_epoch_loss=1.282918\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=375 train loss <loss>=1.05370724201\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] Epoch[14] Batch [375]#011Speed: 14357.45 samples/sec#011loss=1.053707\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] Epoch[14] Batch[380] avg_epoch_loss=1.281521\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=380 train loss <loss>=1.17650567293\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] Epoch[14] Batch [380]#011Speed: 14251.34 samples/sec#011loss=1.176506\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] Epoch[14] Batch[385] avg_epoch_loss=1.281088\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=385 train loss <loss>=1.24807351828\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] Epoch[14] Batch [385]#011Speed: 1647.88 samples/sec#011loss=1.248074\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] Epoch[14] Batch[390] avg_epoch_loss=1.281284\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=390 train loss <loss>=1.29638929367\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] Epoch[14] Batch [390]#011Speed: 14372.21 samples/sec#011loss=1.296389\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] Epoch[14] Batch[395] avg_epoch_loss=1.280110\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=395 train loss <loss>=1.1883433342\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] Epoch[14] Batch [395]#011Speed: 14256.49 samples/sec#011loss=1.188343\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] Epoch[14] Batch[400] avg_epoch_loss=1.276133\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=400 train loss <loss>=0.961166453362\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] Epoch[14] Batch [400]#011Speed: 1724.37 samples/sec#011loss=0.961166\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] Epoch[14] Batch[405] avg_epoch_loss=1.271526\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=405 train loss <loss>=0.90203846693\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] Epoch[14] Batch [405]#011Speed: 13907.56 samples/sec#011loss=0.902038\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] Epoch[14] Batch[410] avg_epoch_loss=1.266538\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=410 train loss <loss>=0.861515796185\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:01 INFO 140088046479168] Epoch[14] Batch [410]#011Speed: 1624.79 samples/sec#011loss=0.861516\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] Epoch[14] Batch[415] avg_epoch_loss=1.262858\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=415 train loss <loss>=0.960287427902\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] Epoch[14] Batch [415]#011Speed: 13453.79 samples/sec#011loss=0.960287\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] Epoch[14] Batch[420] avg_epoch_loss=1.262647\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=420 train loss <loss>=1.24510500431\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] Epoch[14] Batch [420]#011Speed: 13369.50 samples/sec#011loss=1.245105\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] Epoch[14] Batch[425] avg_epoch_loss=1.258848\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=425 train loss <loss>=0.939007711411\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] Epoch[14] Batch [425]#011Speed: 1651.59 samples/sec#011loss=0.939008\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] Epoch[14] Batch[430] avg_epoch_loss=1.255514\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=430 train loss <loss>=0.971488785744\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] Epoch[14] Batch [430]#011Speed: 14355.60 samples/sec#011loss=0.971489\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] Epoch[14] Batch[435] avg_epoch_loss=1.259653\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=435 train loss <loss>=1.61642315388\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] Epoch[14] Batch [435]#011Speed: 1845.04 samples/sec#011loss=1.616423\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] Epoch[14] Batch[440] avg_epoch_loss=1.263258\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=440 train loss <loss>=1.5776116848\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] Epoch[14] Batch [440]#011Speed: 12737.88 samples/sec#011loss=1.577612\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] Epoch[14] Batch[445] avg_epoch_loss=1.270213\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=445 train loss <loss>=1.88359940052\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] Epoch[14] Batch [445]#011Speed: 12865.84 samples/sec#011loss=1.883599\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] Epoch[14] Batch[450] avg_epoch_loss=1.268419\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=450 train loss <loss>=1.10837968588\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] Epoch[14] Batch [450]#011Speed: 1684.04 samples/sec#011loss=1.108380\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] Epoch[14] Batch[455] avg_epoch_loss=1.267480\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=455 train loss <loss>=1.1828061223\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] Epoch[14] Batch [455]#011Speed: 12207.16 samples/sec#011loss=1.182806\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] Epoch[14] Batch[460] avg_epoch_loss=1.272526\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=460 train loss <loss>=1.73270099163\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] Epoch[14] Batch [460]#011Speed: 1642.74 samples/sec#011loss=1.732701\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] Epoch[14] Batch[465] avg_epoch_loss=1.277203\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=465 train loss <loss>=1.70840511322\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] Epoch[14] Batch [465]#011Speed: 14027.19 samples/sec#011loss=1.708405\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] Epoch[14] Batch[470] avg_epoch_loss=1.277722\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=470 train loss <loss>=1.32617679834\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:02 INFO 140088046479168] Epoch[14] Batch [470]#011Speed: 12959.13 samples/sec#011loss=1.326177\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] Epoch[14] Batch[475] avg_epoch_loss=1.275247\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=475 train loss <loss>=1.0420355916\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] Epoch[14] Batch [475]#011Speed: 1836.65 samples/sec#011loss=1.042036\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] Epoch[14] Batch[480] avg_epoch_loss=1.273829\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=480 train loss <loss>=1.13890507221\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] Epoch[14] Batch [480]#011Speed: 13248.35 samples/sec#011loss=1.138905\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] Epoch[14] Batch[485] avg_epoch_loss=1.274678\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=485 train loss <loss>=1.35633015633\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] Epoch[14] Batch [485]#011Speed: 1802.18 samples/sec#011loss=1.356330\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] Epoch[14] Batch[490] avg_epoch_loss=1.275808\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=490 train loss <loss>=1.38563725948\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] Epoch[14] Batch [490]#011Speed: 14370.98 samples/sec#011loss=1.385637\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] Epoch[14] Batch[495] avg_epoch_loss=1.277003\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=495 train loss <loss>=1.39432939291\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] Epoch[14] Batch [495]#011Speed: 14365.90 samples/sec#011loss=1.394329\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] Epoch[14] Batch[500] avg_epoch_loss=1.277017\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=500 train loss <loss>=1.2784353137\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] Epoch[14] Batch [500]#011Speed: 1772.48 samples/sec#011loss=1.278435\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] Epoch[14] Batch[505] avg_epoch_loss=1.275126\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=505 train loss <loss>=1.08567203283\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] Epoch[14] Batch [505]#011Speed: 14575.89 samples/sec#011loss=1.085672\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] Epoch[14] Batch[510] avg_epoch_loss=1.272952\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=510 train loss <loss>=1.05284655094\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] Epoch[14] Batch [510]#011Speed: 13368.43 samples/sec#011loss=1.052847\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] Epoch[14] Batch[515] avg_epoch_loss=1.270601\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=515 train loss <loss>=1.03038005829\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] Epoch[14] Batch [515]#011Speed: 1759.72 samples/sec#011loss=1.030380\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] Epoch[14] Batch[520] avg_epoch_loss=1.268098\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=520 train loss <loss>=1.00983183384\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] Epoch[14] Batch [520]#011Speed: 14328.63 samples/sec#011loss=1.009832\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] Epoch[14] Batch[525] avg_epoch_loss=1.266609\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=525 train loss <loss>=1.11144434214\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] Epoch[14] Batch [525]#011Speed: 1763.57 samples/sec#011loss=1.111444\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] Epoch[14] Batch[530] avg_epoch_loss=1.264098\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=530 train loss <loss>=0.99986140728\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:03 INFO 140088046479168] Epoch[14] Batch [530]#011Speed: 13419.49 samples/sec#011loss=0.999861\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] Epoch[14] Batch[535] avg_epoch_loss=1.262782\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=535 train loss <loss>=1.12309037447\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] Epoch[14] Batch [535]#011Speed: 13615.80 samples/sec#011loss=1.123090\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] Epoch[14] Batch[540] avg_epoch_loss=1.260100\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=540 train loss <loss>=0.972603261471\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] Epoch[14] Batch [540]#011Speed: 1736.40 samples/sec#011loss=0.972603\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] Epoch[14] Batch[545] avg_epoch_loss=1.258273\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=545 train loss <loss>=1.06054161787\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] Epoch[14] Batch [545]#011Speed: 14234.26 samples/sec#011loss=1.060542\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] Epoch[14] Batch[550] avg_epoch_loss=1.257910\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=550 train loss <loss>=1.21826989651\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] Epoch[14] Batch [550]#011Speed: 1740.08 samples/sec#011loss=1.218270\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] Epoch[14] Batch[555] avg_epoch_loss=1.254861\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=555 train loss <loss>=0.918910372257\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] Epoch[14] Batch [555]#011Speed: 13307.86 samples/sec#011loss=0.918910\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] Epoch[14] Batch[560] avg_epoch_loss=1.254267\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=560 train loss <loss>=1.18814367056\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] Epoch[14] Batch [560]#011Speed: 13254.37 samples/sec#011loss=1.188144\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] Epoch[14] Batch[565] avg_epoch_loss=1.253159\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=565 train loss <loss>=1.12884975672\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] Epoch[14] Batch [565]#011Speed: 1792.04 samples/sec#011loss=1.128850\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] Epoch[14] Batch[570] avg_epoch_loss=1.250452\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=570 train loss <loss>=0.944046401978\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] Epoch[14] Batch [570]#011Speed: 14410.63 samples/sec#011loss=0.944046\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] Epoch[14] Batch[575] avg_epoch_loss=1.250126\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=575 train loss <loss>=1.21292427778\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] Epoch[14] Batch [575]#011Speed: 14212.11 samples/sec#011loss=1.212924\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] Epoch[14] Batch[580] avg_epoch_loss=1.249234\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=580 train loss <loss>=1.14650093317\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] Epoch[14] Batch [580]#011Speed: 1631.10 samples/sec#011loss=1.146501\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] Epoch[14] Batch[585] avg_epoch_loss=1.251011\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=585 train loss <loss>=1.45739277601\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:04 INFO 140088046479168] Epoch[14] Batch [585]#011Speed: 14290.80 samples/sec#011loss=1.457393\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] Epoch[14] Batch[590] avg_epoch_loss=1.249771\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=590 train loss <loss>=1.1044647336\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] Epoch[14] Batch [590]#011Speed: 1731.97 samples/sec#011loss=1.104465\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] Epoch[14] Batch[595] avg_epoch_loss=1.248102\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=595 train loss <loss>=1.05088434219\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] Epoch[14] Batch [595]#011Speed: 14362.06 samples/sec#011loss=1.050884\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] Epoch[14] Batch[600] avg_epoch_loss=1.247613\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=600 train loss <loss>=1.18928896189\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] Epoch[14] Batch [600]#011Speed: 13758.72 samples/sec#011loss=1.189289\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] Epoch[14] Batch[605] avg_epoch_loss=1.246577\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=605 train loss <loss>=1.1221111536\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] Epoch[14] Batch [605]#011Speed: 1635.16 samples/sec#011loss=1.122111\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] Epoch[14] Batch[610] avg_epoch_loss=1.246637\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=610 train loss <loss>=1.2538393259\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] Epoch[14] Batch [610]#011Speed: 13414.39 samples/sec#011loss=1.253839\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] Epoch[14] Batch[615] avg_epoch_loss=1.245630\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=615 train loss <loss>=1.12255040407\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] Epoch[14] Batch [615]#011Speed: 1807.35 samples/sec#011loss=1.122550\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] Epoch[14] Batch[620] avg_epoch_loss=1.245186\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=620 train loss <loss>=1.19055936337\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] Epoch[14] Batch [620]#011Speed: 13394.72 samples/sec#011loss=1.190559\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] Epoch[14] Batch[625] avg_epoch_loss=1.244848\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=625 train loss <loss>=1.20283887386\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] Epoch[14] Batch [625]#011Speed: 13382.30 samples/sec#011loss=1.202839\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] Epoch[14] Batch[630] avg_epoch_loss=1.244646\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=630 train loss <loss>=1.21932566166\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] Epoch[14] Batch [630]#011Speed: 1778.54 samples/sec#011loss=1.219326\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] Epoch[14] Batch[635] avg_epoch_loss=1.244028\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=635 train loss <loss>=1.1660089016\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] Epoch[14] Batch [635]#011Speed: 13318.42 samples/sec#011loss=1.166009\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] Epoch[14] Batch[640] avg_epoch_loss=1.243490\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=640 train loss <loss>=1.1751321435\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] Epoch[14] Batch [640]#011Speed: 1743.80 samples/sec#011loss=1.175132\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] Epoch[14] Batch[645] avg_epoch_loss=1.244771\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=645 train loss <loss>=1.4090080142\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:05 INFO 140088046479168] Epoch[14] Batch [645]#011Speed: 14198.13 samples/sec#011loss=1.409008\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] Epoch[14] Batch[650] avg_epoch_loss=1.247577\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=650 train loss <loss>=1.61010098457\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] Epoch[14] Batch [650]#011Speed: 14116.15 samples/sec#011loss=1.610101\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] Epoch[14] Batch[655] avg_epoch_loss=1.247124\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=655 train loss <loss>=1.18814575672\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] Epoch[14] Batch [655]#011Speed: 1805.69 samples/sec#011loss=1.188146\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] Epoch[14] Batch[660] avg_epoch_loss=1.245057\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=660 train loss <loss>=0.973853266239\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] Epoch[14] Batch [660]#011Speed: 14331.08 samples/sec#011loss=0.973853\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] Epoch[14] Batch[665] avg_epoch_loss=1.243526\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=665 train loss <loss>=1.04106010199\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] Epoch[14] Batch [665]#011Speed: 14315.03 samples/sec#011loss=1.041060\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] Epoch[14] Batch[670] avg_epoch_loss=1.242889\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=670 train loss <loss>=1.15812287331\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] Epoch[14] Batch [670]#011Speed: 1650.34 samples/sec#011loss=1.158123\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] Epoch[14] Batch[675] avg_epoch_loss=1.241626\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=675 train loss <loss>=1.07204316854\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] Epoch[14] Batch [675]#011Speed: 14146.05 samples/sec#011loss=1.072043\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] Epoch[14] Batch[680] avg_epoch_loss=1.241717\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=680 train loss <loss>=1.25408024788\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] Epoch[14] Batch [680]#011Speed: 1560.72 samples/sec#011loss=1.254080\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] Epoch[14] Batch[685] avg_epoch_loss=1.243622\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=685 train loss <loss>=1.50306181908\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] Epoch[14] Batch [685]#011Speed: 14359.44 samples/sec#011loss=1.503062\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] Epoch[14] Batch[690] avg_epoch_loss=1.247602\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=690 train loss <loss>=1.79368309975\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] Epoch[14] Batch [690]#011Speed: 14294.60 samples/sec#011loss=1.793683\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] Epoch[14] Batch[695] avg_epoch_loss=1.250631\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=695 train loss <loss>=1.66925649643\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] Epoch[14] Batch [695]#011Speed: 1561.84 samples/sec#011loss=1.669256\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] Epoch[14] Batch[700] avg_epoch_loss=1.254551\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=700 train loss <loss>=1.80024154186\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] Epoch[14] Batch [700]#011Speed: 13320.54 samples/sec#011loss=1.800242\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] Epoch[14] Batch[705] avg_epoch_loss=1.256511\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=705 train loss <loss>=1.53127563\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:06 INFO 140088046479168] Epoch[14] Batch [705]#011Speed: 13192.10 samples/sec#011loss=1.531276\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] Epoch[14] Batch[710] avg_epoch_loss=1.257824\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=710 train loss <loss>=1.44323401451\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] Epoch[14] Batch [710]#011Speed: 1880.82 samples/sec#011loss=1.443234\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] Epoch[14] Batch[715] avg_epoch_loss=1.260256\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=715 train loss <loss>=1.6060708046\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] Epoch[14] Batch [715]#011Speed: 14149.93 samples/sec#011loss=1.606071\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] Epoch[14] Batch[720] avg_epoch_loss=1.260688\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=720 train loss <loss>=1.322504282\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] Epoch[14] Batch [720]#011Speed: 1818.72 samples/sec#011loss=1.322504\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] Epoch[14] Batch[725] avg_epoch_loss=1.262792\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=725 train loss <loss>=1.56620817184\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] Epoch[14] Batch [725]#011Speed: 14096.87 samples/sec#011loss=1.566208\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] Epoch[14] Batch[730] avg_epoch_loss=1.263875\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=730 train loss <loss>=1.4211217165\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] Epoch[14] Batch [730]#011Speed: 1833.02 samples/sec#011loss=1.421122\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] Epoch[14] Batch[735] avg_epoch_loss=1.264827\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=735 train loss <loss>=1.40400094986\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] Epoch[14] Batch [735]#011Speed: 13737.46 samples/sec#011loss=1.404001\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] Epoch[14] Batch[740] avg_epoch_loss=1.266403\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=740 train loss <loss>=1.49838700294\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] Epoch[14] Batch [740]#011Speed: 12779.60 samples/sec#011loss=1.498387\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] Epoch[14] Batch[745] avg_epoch_loss=1.266929\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=745 train loss <loss>=1.34493551254\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] Epoch[14] Batch [745]#011Speed: 1587.35 samples/sec#011loss=1.344936\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] Epoch[14] Batch[750] avg_epoch_loss=1.268163\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=750 train loss <loss>=1.45229687691\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] Epoch[14] Batch [750]#011Speed: 14551.40 samples/sec#011loss=1.452297\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] Epoch[14] Batch[755] avg_epoch_loss=1.269365\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=755 train loss <loss>=1.44992778301\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:07 INFO 140088046479168] Epoch[14] Batch [755]#011Speed: 13381.76 samples/sec#011loss=1.449928\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] Epoch[14] Batch[760] avg_epoch_loss=1.269289\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=760 train loss <loss>=1.25777778625\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] Epoch[14] Batch [760]#011Speed: 1643.14 samples/sec#011loss=1.257778\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] Epoch[14] Batch[765] avg_epoch_loss=1.270343\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=765 train loss <loss>=1.43071570396\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] Epoch[14] Batch [765]#011Speed: 12905.92 samples/sec#011loss=1.430716\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] Epoch[14] Batch[770] avg_epoch_loss=1.271345\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=770 train loss <loss>=1.42477009296\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] Epoch[14] Batch [770]#011Speed: 1725.82 samples/sec#011loss=1.424770\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] Epoch[14] Batch[775] avg_epoch_loss=1.272431\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=775 train loss <loss>=1.43997762203\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] Epoch[14] Batch [775]#011Speed: 14310.60 samples/sec#011loss=1.439978\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] Epoch[14] Batch[780] avg_epoch_loss=1.273483\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=780 train loss <loss>=1.43680582047\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] Epoch[14] Batch [780]#011Speed: 13957.31 samples/sec#011loss=1.436806\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] Epoch[14] Batch[785] avg_epoch_loss=1.273373\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=785 train loss <loss>=1.25613684654\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] Epoch[14] Batch [785]#011Speed: 1721.57 samples/sec#011loss=1.256137\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] Epoch[14] Batch[790] avg_epoch_loss=1.274109\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=790 train loss <loss>=1.389782691\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] Epoch[14] Batch [790]#011Speed: 14402.13 samples/sec#011loss=1.389783\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] Epoch[14] Batch[795] avg_epoch_loss=1.274689\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=795 train loss <loss>=1.36641755104\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] Epoch[14] Batch [795]#011Speed: 1769.93 samples/sec#011loss=1.366418\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] Epoch[14] Batch[800] avg_epoch_loss=1.274635\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=800 train loss <loss>=1.26616220474\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] Epoch[14] Batch [800]#011Speed: 14252.10 samples/sec#011loss=1.266162\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] Epoch[14] Batch[805] avg_epoch_loss=1.274580\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=805 train loss <loss>=1.26561944485\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] Epoch[14] Batch [805]#011Speed: 14309.99 samples/sec#011loss=1.265619\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] Epoch[14] Batch[810] avg_epoch_loss=1.272665\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=810 train loss <loss>=0.964116895199\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] Epoch[14] Batch [810]#011Speed: 1680.78 samples/sec#011loss=0.964117\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] Epoch[14] Batch[815] avg_epoch_loss=1.273013\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=815 train loss <loss>=1.32932281494\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:08 INFO 140088046479168] Epoch[14] Batch [815]#011Speed: 13610.14 samples/sec#011loss=1.329323\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] Epoch[14] Batch[820] avg_epoch_loss=1.273293\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=820 train loss <loss>=1.31901681423\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] Epoch[14] Batch [820]#011Speed: 1675.63 samples/sec#011loss=1.319017\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] Epoch[14] Batch[825] avg_epoch_loss=1.273474\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=825 train loss <loss>=1.3032959938\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] Epoch[14] Batch [825]#011Speed: 13569.68 samples/sec#011loss=1.303296\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] Epoch[14] Batch[830] avg_epoch_loss=1.272724\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=830 train loss <loss>=1.14876556396\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] Epoch[14] Batch [830]#011Speed: 14570.51 samples/sec#011loss=1.148766\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] Epoch[14] Batch[835] avg_epoch_loss=1.271450\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=835 train loss <loss>=1.05976345539\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] Epoch[14] Batch [835]#011Speed: 1707.78 samples/sec#011loss=1.059763\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] Epoch[14] Batch[840] avg_epoch_loss=1.270965\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=840 train loss <loss>=1.1898111701\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] Epoch[14] Batch [840]#011Speed: 14635.18 samples/sec#011loss=1.189811\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] Epoch[14] Batch[845] avg_epoch_loss=1.270105\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=845 train loss <loss>=1.12536777258\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] Epoch[14] Batch [845]#011Speed: 1809.94 samples/sec#011loss=1.125368\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] Epoch[14] Batch[850] avg_epoch_loss=1.269294\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=850 train loss <loss>=1.13213092089\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] Epoch[14] Batch [850]#011Speed: 14347.93 samples/sec#011loss=1.132131\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] Epoch[14] Batch[855] avg_epoch_loss=1.267959\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=855 train loss <loss>=1.04081673622\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] Epoch[14] Batch [855]#011Speed: 14152.32 samples/sec#011loss=1.040817\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] Epoch[14] Batch[860] avg_epoch_loss=1.267561\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=860 train loss <loss>=1.19937163591\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] Epoch[14] Batch [860]#011Speed: 1775.99 samples/sec#011loss=1.199372\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] Epoch[14] Batch[865] avg_epoch_loss=1.267423\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=865 train loss <loss>=1.2436965704\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] Epoch[14] Batch [865]#011Speed: 12806.67 samples/sec#011loss=1.243697\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] Epoch[14] Batch[870] avg_epoch_loss=1.265796\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=870 train loss <loss>=0.983887088299\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] Epoch[14] Batch [870]#011Speed: 1611.76 samples/sec#011loss=0.983887\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] Epoch[14] Batch[875] avg_epoch_loss=1.265482\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=875 train loss <loss>=1.21079989672\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:09 INFO 140088046479168] Epoch[14] Batch [875]#011Speed: 14462.65 samples/sec#011loss=1.210800\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] Epoch[14] Batch[880] avg_epoch_loss=1.265789\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=880 train loss <loss>=1.3196295023\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] Epoch[14] Batch [880]#011Speed: 13743.93 samples/sec#011loss=1.319630\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] Epoch[14] Batch[885] avg_epoch_loss=1.264287\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=885 train loss <loss>=0.999593389034\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] Epoch[14] Batch [885]#011Speed: 1802.12 samples/sec#011loss=0.999593\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] Epoch[14] Batch[890] avg_epoch_loss=1.263813\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=890 train loss <loss>=1.17978136539\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] Epoch[14] Batch [890]#011Speed: 14064.67 samples/sec#011loss=1.179781\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] Epoch[14] Batch[895] avg_epoch_loss=1.263659\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=895 train loss <loss>=1.23621852398\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] Epoch[14] Batch [895]#011Speed: 2118.99 samples/sec#011loss=1.236219\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] Epoch[14] Batch[900] avg_epoch_loss=1.262276\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, batch=900 train loss <loss>=1.01449961662\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] Epoch[14] Batch [900]#011Speed: 13328.87 samples/sec#011loss=1.014500\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] processed a total of 57914 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15761.471033096313, \"sum\": 15761.471033096313, \"min\": 15761.471033096313}}, \"EndTime\": 1604320630.418968, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320614.657435}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] #throughput_metric: host=algo-1, train throughput=3674.37454551 records/second\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] #progress_metric: host=algo-1, completed 75 % of epochs\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=14, train loss <loss>=1.26013331499\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] Epoch[15] Batch[0] avg_epoch_loss=1.412483\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=1.41248261929\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] Epoch[15] Batch[5] avg_epoch_loss=1.176968\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=1.17696752151\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] Epoch[15] Batch [5]#011Speed: 13774.11 samples/sec#011loss=1.176968\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] Epoch[15] Batch[10] avg_epoch_loss=1.284253\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=1.41299551725\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] Epoch[15] Batch [10]#011Speed: 13310.10 samples/sec#011loss=1.412996\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] Epoch[15] Batch[15] avg_epoch_loss=1.345275\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=15 train loss <loss>=1.47952455282\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] Epoch[15] Batch [15]#011Speed: 1851.15 samples/sec#011loss=1.479525\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] Epoch[15] Batch[20] avg_epoch_loss=1.343346\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=20 train loss <loss>=1.33717403412\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:10 INFO 140088046479168] Epoch[15] Batch [20]#011Speed: 12748.04 samples/sec#011loss=1.337174\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] Epoch[15] Batch[25] avg_epoch_loss=1.347098\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=25 train loss <loss>=1.36285223961\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] Epoch[15] Batch [25]#011Speed: 1704.87 samples/sec#011loss=1.362852\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] Epoch[15] Batch[30] avg_epoch_loss=1.362325\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=30 train loss <loss>=1.44151002169\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] Epoch[15] Batch [30]#011Speed: 13879.23 samples/sec#011loss=1.441510\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] Epoch[15] Batch[35] avg_epoch_loss=1.344759\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=35 train loss <loss>=1.23585064411\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] Epoch[15] Batch [35]#011Speed: 13995.15 samples/sec#011loss=1.235851\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] Epoch[15] Batch[40] avg_epoch_loss=1.341017\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=40 train loss <loss>=1.31407305002\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] Epoch[15] Batch [40]#011Speed: 1764.97 samples/sec#011loss=1.314073\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] Epoch[15] Batch[45] avg_epoch_loss=1.363160\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=45 train loss <loss>=1.54472818375\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] Epoch[15] Batch [45]#011Speed: 14418.22 samples/sec#011loss=1.544728\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] Epoch[15] Batch[50] avg_epoch_loss=1.355997\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=50 train loss <loss>=1.29010190964\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] Epoch[15] Batch [50]#011Speed: 1718.75 samples/sec#011loss=1.290102\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] Epoch[15] Batch[55] avg_epoch_loss=1.347865\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=55 train loss <loss>=1.2649135232\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] Epoch[15] Batch [55]#011Speed: 14240.46 samples/sec#011loss=1.264914\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] Epoch[15] Batch[60] avg_epoch_loss=1.313860\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=60 train loss <loss>=0.933005535603\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] Epoch[15] Batch [60]#011Speed: 13828.33 samples/sec#011loss=0.933006\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] Epoch[15] Batch[65] avg_epoch_loss=1.291161\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=65 train loss <loss>=1.01423606873\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] Epoch[15] Batch [65]#011Speed: 1807.97 samples/sec#011loss=1.014236\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] Epoch[15] Batch[70] avg_epoch_loss=1.272661\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=70 train loss <loss>=1.02845703363\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] Epoch[15] Batch [70]#011Speed: 13327.81 samples/sec#011loss=1.028457\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] Epoch[15] Batch[75] avg_epoch_loss=1.271567\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=75 train loss <loss>=1.25603165627\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] Epoch[15] Batch [75]#011Speed: 1788.44 samples/sec#011loss=1.256032\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] Epoch[15] Batch[80] avg_epoch_loss=1.264279\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=80 train loss <loss>=1.15349932909\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] Epoch[15] Batch [80]#011Speed: 13371.76 samples/sec#011loss=1.153499\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] Epoch[15] Batch[85] avg_epoch_loss=1.269280\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=85 train loss <loss>=1.35030550957\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:11 INFO 140088046479168] Epoch[15] Batch [85]#011Speed: 13399.13 samples/sec#011loss=1.350306\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] Epoch[15] Batch[90] avg_epoch_loss=1.252605\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=90 train loss <loss>=0.965797793865\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] Epoch[15] Batch [90]#011Speed: 1848.15 samples/sec#011loss=0.965798\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] Epoch[15] Batch[95] avg_epoch_loss=1.246839\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=95 train loss <loss>=1.14189935923\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] Epoch[15] Batch [95]#011Speed: 13970.24 samples/sec#011loss=1.141899\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] Epoch[15] Batch[100] avg_epoch_loss=1.226273\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=100 train loss <loss>=0.831405484676\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] Epoch[15] Batch [100]#011Speed: 1537.89 samples/sec#011loss=0.831405\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] Epoch[15] Batch[105] avg_epoch_loss=1.217171\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=105 train loss <loss>=1.03330715895\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] Epoch[15] Batch [105]#011Speed: 14345.78 samples/sec#011loss=1.033307\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] Epoch[15] Batch[110] avg_epoch_loss=1.211286\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=110 train loss <loss>=1.08650917411\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] Epoch[15] Batch [110]#011Speed: 14264.67 samples/sec#011loss=1.086509\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] Epoch[15] Batch[115] avg_epoch_loss=1.206165\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=115 train loss <loss>=1.09248787165\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] Epoch[15] Batch [115]#011Speed: 1712.44 samples/sec#011loss=1.092488\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] Epoch[15] Batch[120] avg_epoch_loss=1.211717\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=120 train loss <loss>=1.34051826\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] Epoch[15] Batch [120]#011Speed: 14388.38 samples/sec#011loss=1.340518\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] Epoch[15] Batch[125] avg_epoch_loss=1.200311\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=125 train loss <loss>=0.924302351475\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] Epoch[15] Batch [125]#011Speed: 14191.97 samples/sec#011loss=0.924302\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] Epoch[15] Batch[130] avg_epoch_loss=1.192374\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=130 train loss <loss>=0.992357373238\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] Epoch[15] Batch [130]#011Speed: 1685.03 samples/sec#011loss=0.992357\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] Epoch[15] Batch[135] avg_epoch_loss=1.191477\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=135 train loss <loss>=1.16797692776\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:12 INFO 140088046479168] Epoch[15] Batch [135]#011Speed: 13535.74 samples/sec#011loss=1.167977\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] Epoch[15] Batch[140] avg_epoch_loss=1.184784\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=140 train loss <loss>=1.00274102688\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] Epoch[15] Batch [140]#011Speed: 1748.30 samples/sec#011loss=1.002741\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] Epoch[15] Batch[145] avg_epoch_loss=1.182287\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=145 train loss <loss>=1.11184772253\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] Epoch[15] Batch [145]#011Speed: 14361.90 samples/sec#011loss=1.111848\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] Epoch[15] Batch[150] avg_epoch_loss=1.176672\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=150 train loss <loss>=1.01271508932\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] Epoch[15] Batch [150]#011Speed: 14334.91 samples/sec#011loss=1.012715\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] Epoch[15] Batch[155] avg_epoch_loss=1.176830\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=155 train loss <loss>=1.18160755634\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] Epoch[15] Batch [155]#011Speed: 1744.12 samples/sec#011loss=1.181608\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] Epoch[15] Batch[160] avg_epoch_loss=1.194695\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=160 train loss <loss>=1.75208568573\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] Epoch[15] Batch [160]#011Speed: 14340.88 samples/sec#011loss=1.752086\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] Epoch[15] Batch[165] avg_epoch_loss=1.190607\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=165 train loss <loss>=1.05896039009\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] Epoch[15] Batch [165]#011Speed: 1539.32 samples/sec#011loss=1.058960\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] Epoch[15] Batch[170] avg_epoch_loss=1.185639\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=170 train loss <loss>=1.02072315216\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] Epoch[15] Batch [170]#011Speed: 14168.00 samples/sec#011loss=1.020723\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] Epoch[15] Batch[175] avg_epoch_loss=1.182494\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=175 train loss <loss>=1.07493561506\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] Epoch[15] Batch [175]#011Speed: 14225.97 samples/sec#011loss=1.074936\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] Epoch[15] Batch[180] avg_epoch_loss=1.178787\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=180 train loss <loss>=1.0483068943\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] Epoch[15] Batch [180]#011Speed: 1724.82 samples/sec#011loss=1.048307\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] Epoch[15] Batch[185] avg_epoch_loss=1.182305\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=185 train loss <loss>=1.30963630676\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] Epoch[15] Batch [185]#011Speed: 14005.08 samples/sec#011loss=1.309636\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] Epoch[15] Batch[190] avg_epoch_loss=1.182074\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=190 train loss <loss>=1.17348983288\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] Epoch[15] Batch [190]#011Speed: 1681.64 samples/sec#011loss=1.173490\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] Epoch[15] Batch[195] avg_epoch_loss=1.185792\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=195 train loss <loss>=1.32782449722\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] Epoch[15] Batch [195]#011Speed: 14280.61 samples/sec#011loss=1.327824\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] Epoch[15] Batch[200] avg_epoch_loss=1.188519\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=200 train loss <loss>=1.29539167881\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:13 INFO 140088046479168] Epoch[15] Batch [200]#011Speed: 14321.60 samples/sec#011loss=1.295392\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] Epoch[15] Batch[205] avg_epoch_loss=1.189737\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=205 train loss <loss>=1.23871059418\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] Epoch[15] Batch [205]#011Speed: 1784.05 samples/sec#011loss=1.238711\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] Epoch[15] Batch[210] avg_epoch_loss=1.182643\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=210 train loss <loss>=0.890365576744\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] Epoch[15] Batch [210]#011Speed: 14058.48 samples/sec#011loss=0.890366\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] Epoch[15] Batch[215] avg_epoch_loss=1.182638\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=215 train loss <loss>=1.18243473768\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] Epoch[15] Batch [215]#011Speed: 1810.61 samples/sec#011loss=1.182435\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] Epoch[15] Batch[220] avg_epoch_loss=1.182223\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=220 train loss <loss>=1.16431478262\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] Epoch[15] Batch [220]#011Speed: 13720.89 samples/sec#011loss=1.164315\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] Epoch[15] Batch[225] avg_epoch_loss=1.182658\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=225 train loss <loss>=1.20186864138\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] Epoch[15] Batch [225]#011Speed: 12924.56 samples/sec#011loss=1.201869\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] Epoch[15] Batch[230] avg_epoch_loss=1.181185\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=230 train loss <loss>=1.11461793184\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] Epoch[15] Batch [230]#011Speed: 1798.49 samples/sec#011loss=1.114618\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] Epoch[15] Batch[235] avg_epoch_loss=1.183479\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=235 train loss <loss>=1.2894453764\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] Epoch[15] Batch [235]#011Speed: 14047.30 samples/sec#011loss=1.289445\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] Epoch[15] Batch[240] avg_epoch_loss=1.180085\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=240 train loss <loss>=1.01986968517\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] Epoch[15] Batch [240]#011Speed: 1874.82 samples/sec#011loss=1.019870\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] Epoch[15] Batch[245] avg_epoch_loss=1.186831\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=245 train loss <loss>=1.51199202538\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] Epoch[15] Batch [245]#011Speed: 13381.89 samples/sec#011loss=1.511992\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] Epoch[15] Batch[250] avg_epoch_loss=1.186898\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=250 train loss <loss>=1.19022264481\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:14 INFO 140088046479168] Epoch[15] Batch [250]#011Speed: 14028.95 samples/sec#011loss=1.190223\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] Epoch[15] Batch[255] avg_epoch_loss=1.185649\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=255 train loss <loss>=1.12291424274\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] Epoch[15] Batch [255]#011Speed: 1411.74 samples/sec#011loss=1.122914\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] Epoch[15] Batch[260] avg_epoch_loss=1.187753\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=260 train loss <loss>=1.29548084736\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] Epoch[15] Batch [260]#011Speed: 14389.77 samples/sec#011loss=1.295481\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] Epoch[15] Batch[265] avg_epoch_loss=1.184450\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=265 train loss <loss>=1.01207304001\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] Epoch[15] Batch [265]#011Speed: 1767.95 samples/sec#011loss=1.012073\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] Epoch[15] Batch[270] avg_epoch_loss=1.187798\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=270 train loss <loss>=1.36590583324\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] Epoch[15] Batch [270]#011Speed: 14324.81 samples/sec#011loss=1.365906\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] Epoch[15] Batch[275] avg_epoch_loss=1.186289\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=275 train loss <loss>=1.10450726748\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] Epoch[15] Batch [275]#011Speed: 13817.51 samples/sec#011loss=1.104507\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] Epoch[15] Batch[280] avg_epoch_loss=1.192237\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=280 train loss <loss>=1.52054023743\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] Epoch[15] Batch [280]#011Speed: 1727.00 samples/sec#011loss=1.520540\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] Epoch[15] Batch[285] avg_epoch_loss=1.192734\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=285 train loss <loss>=1.2206579566\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] Epoch[15] Batch [285]#011Speed: 13916.65 samples/sec#011loss=1.220658\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] Epoch[15] Batch[290] avg_epoch_loss=1.193416\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=290 train loss <loss>=1.2324668169\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] Epoch[15] Batch [290]#011Speed: 1730.37 samples/sec#011loss=1.232467\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] Epoch[15] Batch[295] avg_epoch_loss=1.198885\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=295 train loss <loss>=1.51716861725\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] Epoch[15] Batch [295]#011Speed: 14309.38 samples/sec#011loss=1.517169\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] Epoch[15] Batch[300] avg_epoch_loss=1.198003\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=300 train loss <loss>=1.14576961994\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] Epoch[15] Batch [300]#011Speed: 14398.11 samples/sec#011loss=1.145770\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] Epoch[15] Batch[305] avg_epoch_loss=1.195294\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=305 train loss <loss>=1.03219276667\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] Epoch[15] Batch [305]#011Speed: 1694.03 samples/sec#011loss=1.032193\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] Epoch[15] Batch[310] avg_epoch_loss=1.193402\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=310 train loss <loss>=1.07765675783\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] Epoch[15] Batch [310]#011Speed: 14258.31 samples/sec#011loss=1.077657\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] Epoch[15] Batch[315] avg_epoch_loss=1.193747\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=315 train loss <loss>=1.21516544819\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:15 INFO 140088046479168] Epoch[15] Batch [315]#011Speed: 14188.22 samples/sec#011loss=1.215165\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] Epoch[15] Batch[320] avg_epoch_loss=1.191835\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=320 train loss <loss>=1.07104005814\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] Epoch[15] Batch [320]#011Speed: 1721.78 samples/sec#011loss=1.071040\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] Epoch[15] Batch[325] avg_epoch_loss=1.188888\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=325 train loss <loss>=0.999700677395\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] Epoch[15] Batch [325]#011Speed: 13325.03 samples/sec#011loss=0.999701\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] Epoch[15] Batch[330] avg_epoch_loss=1.187871\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=330 train loss <loss>=1.1215076685\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] Epoch[15] Batch [330]#011Speed: 1917.78 samples/sec#011loss=1.121508\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] Epoch[15] Batch[335] avg_epoch_loss=1.188196\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=335 train loss <loss>=1.20976523161\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] Epoch[15] Batch [335]#011Speed: 14115.55 samples/sec#011loss=1.209765\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] Epoch[15] Batch[340] avg_epoch_loss=1.186433\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=340 train loss <loss>=1.06794784069\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] Epoch[15] Batch [340]#011Speed: 1731.83 samples/sec#011loss=1.067948\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] Epoch[15] Batch[345] avg_epoch_loss=1.185903\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=345 train loss <loss>=1.1497559309\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] Epoch[15] Batch [345]#011Speed: 13904.54 samples/sec#011loss=1.149756\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] Epoch[15] Batch[350] avg_epoch_loss=1.185886\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=350 train loss <loss>=1.18466061354\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] Epoch[15] Batch [350]#011Speed: 14118.67 samples/sec#011loss=1.184661\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] Epoch[15] Batch[355] avg_epoch_loss=1.184554\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=355 train loss <loss>=1.09108705521\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] Epoch[15] Batch [355]#011Speed: 1699.83 samples/sec#011loss=1.091087\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] Epoch[15] Batch[360] avg_epoch_loss=1.186516\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=360 train loss <loss>=1.32618318796\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] Epoch[15] Batch [360]#011Speed: 14231.70 samples/sec#011loss=1.326183\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] Epoch[15] Batch[365] avg_epoch_loss=1.186107\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=365 train loss <loss>=1.15659656525\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:16 INFO 140088046479168] Epoch[15] Batch [365]#011Speed: 14256.49 samples/sec#011loss=1.156597\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] Epoch[15] Batch[370] avg_epoch_loss=1.183578\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=370 train loss <loss>=0.998459255695\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] Epoch[15] Batch [370]#011Speed: 1398.47 samples/sec#011loss=0.998459\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] Epoch[15] Batch[375] avg_epoch_loss=1.183459\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=375 train loss <loss>=1.17464314699\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] Epoch[15] Batch [375]#011Speed: 14276.05 samples/sec#011loss=1.174643\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] Epoch[15] Batch[380] avg_epoch_loss=1.182428\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=380 train loss <loss>=1.10484937429\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] Epoch[15] Batch [380]#011Speed: 1745.49 samples/sec#011loss=1.104849\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] Epoch[15] Batch[385] avg_epoch_loss=1.182226\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=385 train loss <loss>=1.16683959961\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] Epoch[15] Batch [385]#011Speed: 13141.72 samples/sec#011loss=1.166840\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] Epoch[15] Batch[390] avg_epoch_loss=1.184090\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=390 train loss <loss>=1.3279907465\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] Epoch[15] Batch [390]#011Speed: 13466.35 samples/sec#011loss=1.327991\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] Epoch[15] Batch[395] avg_epoch_loss=1.182732\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=395 train loss <loss>=1.076580441\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] Epoch[15] Batch [395]#011Speed: 1680.84 samples/sec#011loss=1.076580\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] Epoch[15] Batch[400] avg_epoch_loss=1.181090\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=400 train loss <loss>=1.05105775595\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] Epoch[15] Batch [400]#011Speed: 13333.90 samples/sec#011loss=1.051058\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] Epoch[15] Batch[405] avg_epoch_loss=1.178304\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=405 train loss <loss>=0.954825019836\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] Epoch[15] Batch [405]#011Speed: 1764.70 samples/sec#011loss=0.954825\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] Epoch[15] Batch[410] avg_epoch_loss=1.175944\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=410 train loss <loss>=0.984352242947\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] Epoch[15] Batch [410]#011Speed: 13364.57 samples/sec#011loss=0.984352\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] Epoch[15] Batch[415] avg_epoch_loss=1.175998\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=415 train loss <loss>=1.18040215969\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] Epoch[15] Batch [415]#011Speed: 14227.93 samples/sec#011loss=1.180402\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] Epoch[15] Batch[420] avg_epoch_loss=1.175791\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=420 train loss <loss>=1.15854709148\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] Epoch[15] Batch [420]#011Speed: 1842.57 samples/sec#011loss=1.158547\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] Epoch[15] Batch[425] avg_epoch_loss=1.173544\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=425 train loss <loss>=0.984389925003\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:17 INFO 140088046479168] Epoch[15] Batch [425]#011Speed: 13063.44 samples/sec#011loss=0.984390\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] Epoch[15] Batch[430] avg_epoch_loss=1.173735\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=430 train loss <loss>=1.18998041153\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] Epoch[15] Batch [430]#011Speed: 1710.95 samples/sec#011loss=1.189980\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] Epoch[15] Batch[435] avg_epoch_loss=1.172701\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=435 train loss <loss>=1.08353514671\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] Epoch[15] Batch [435]#011Speed: 14267.86 samples/sec#011loss=1.083535\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] Epoch[15] Batch[440] avg_epoch_loss=1.169898\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=440 train loss <loss>=0.925523066521\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] Epoch[15] Batch [440]#011Speed: 14248.77 samples/sec#011loss=0.925523\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] Epoch[15] Batch[445] avg_epoch_loss=1.167266\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=445 train loss <loss>=0.935082858801\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] Epoch[15] Batch [445]#011Speed: 1720.48 samples/sec#011loss=0.935083\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] Epoch[15] Batch[450] avg_epoch_loss=1.167937\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=450 train loss <loss>=1.2278435111\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] Epoch[15] Batch [450]#011Speed: 14511.28 samples/sec#011loss=1.227844\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] Epoch[15] Batch[455] avg_epoch_loss=1.168779\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=455 train loss <loss>=1.24469451904\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] Epoch[15] Batch [455]#011Speed: 1786.77 samples/sec#011loss=1.244695\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] Epoch[15] Batch[460] avg_epoch_loss=1.171224\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=460 train loss <loss>=1.394188416\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] Epoch[15] Batch [460]#011Speed: 14229.13 samples/sec#011loss=1.394188\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] Epoch[15] Batch[465] avg_epoch_loss=1.175306\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=465 train loss <loss>=1.55166406631\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] Epoch[15] Batch [465]#011Speed: 14108.73 samples/sec#011loss=1.551664\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] Epoch[15] Batch[470] avg_epoch_loss=1.183942\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=470 train loss <loss>=1.98884036541\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] Epoch[15] Batch [470]#011Speed: 1708.02 samples/sec#011loss=1.988840\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] Epoch[15] Batch[475] avg_epoch_loss=1.191593\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=475 train loss <loss>=1.91228485107\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] Epoch[15] Batch [475]#011Speed: 14244.39 samples/sec#011loss=1.912285\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] Epoch[15] Batch[480] avg_epoch_loss=1.197234\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=480 train loss <loss>=1.73428449631\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:18 INFO 140088046479168] Epoch[15] Batch [480]#011Speed: 13233.07 samples/sec#011loss=1.734284\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] Epoch[15] Batch[485] avg_epoch_loss=1.202313\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=485 train loss <loss>=1.69089715481\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] Epoch[15] Batch [485]#011Speed: 1791.69 samples/sec#011loss=1.690897\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] Epoch[15] Batch[490] avg_epoch_loss=1.202559\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=490 train loss <loss>=1.22653889656\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] Epoch[15] Batch [490]#011Speed: 14306.18 samples/sec#011loss=1.226539\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] Epoch[15] Batch[495] avg_epoch_loss=1.200571\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=495 train loss <loss>=1.00530906916\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] Epoch[15] Batch [495]#011Speed: 1838.01 samples/sec#011loss=1.005309\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] Epoch[15] Batch[500] avg_epoch_loss=1.201000\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=500 train loss <loss>=1.24352771044\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] Epoch[15] Batch [500]#011Speed: 14384.07 samples/sec#011loss=1.243528\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] Epoch[15] Batch[505] avg_epoch_loss=1.200760\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=505 train loss <loss>=1.17674645185\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] Epoch[15] Batch [505]#011Speed: 1904.92 samples/sec#011loss=1.176746\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] Epoch[15] Batch[510] avg_epoch_loss=1.199389\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=510 train loss <loss>=1.06064119339\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] Epoch[15] Batch [510]#011Speed: 12753.13 samples/sec#011loss=1.060641\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] Epoch[15] Batch[515] avg_epoch_loss=1.198040\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=515 train loss <loss>=1.06017782688\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] Epoch[15] Batch [515]#011Speed: 14314.42 samples/sec#011loss=1.060178\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] Epoch[15] Batch[520] avg_epoch_loss=1.197516\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=520 train loss <loss>=1.14341398478\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] Epoch[15] Batch [520]#011Speed: 1758.84 samples/sec#011loss=1.143414\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] Epoch[15] Batch[525] avg_epoch_loss=1.196809\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=525 train loss <loss>=1.12319564819\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] Epoch[15] Batch [525]#011Speed: 14398.88 samples/sec#011loss=1.123196\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] Epoch[15] Batch[530] avg_epoch_loss=1.194814\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=530 train loss <loss>=0.984916186333\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] Epoch[15] Batch [530]#011Speed: 1785.60 samples/sec#011loss=0.984916\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] Epoch[15] Batch[535] avg_epoch_loss=1.193109\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=535 train loss <loss>=1.01205968857\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] Epoch[15] Batch [535]#011Speed: 14057.30 samples/sec#011loss=1.012060\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] Epoch[15] Batch[540] avg_epoch_loss=1.190369\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=540 train loss <loss>=0.896635997295\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:19 INFO 140088046479168] Epoch[15] Batch [540]#011Speed: 14195.72 samples/sec#011loss=0.896636\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] Epoch[15] Batch[545] avg_epoch_loss=1.188945\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=545 train loss <loss>=1.03484796286\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] Epoch[15] Batch [545]#011Speed: 1788.96 samples/sec#011loss=1.034848\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] Epoch[15] Batch[550] avg_epoch_loss=1.188312\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=550 train loss <loss>=1.11922395229\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] Epoch[15] Batch [550]#011Speed: 14545.41 samples/sec#011loss=1.119224\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] Epoch[15] Batch[555] avg_epoch_loss=1.186953\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=555 train loss <loss>=1.03712978363\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] Epoch[15] Batch [555]#011Speed: 1602.87 samples/sec#011loss=1.037130\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] Epoch[15] Batch[560] avg_epoch_loss=1.183946\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=560 train loss <loss>=0.849586129189\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] Epoch[15] Batch [560]#011Speed: 14048.62 samples/sec#011loss=0.849586\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] Epoch[15] Batch[565] avg_epoch_loss=1.180196\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=565 train loss <loss>=0.7594191432\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] Epoch[15] Batch [565]#011Speed: 14353.00 samples/sec#011loss=0.759419\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] Epoch[15] Batch[570] avg_epoch_loss=1.178496\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=570 train loss <loss>=0.986107909679\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] Epoch[15] Batch [570]#011Speed: 1868.85 samples/sec#011loss=0.986108\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] Epoch[15] Batch[575] avg_epoch_loss=1.176610\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=575 train loss <loss>=0.961245727539\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] Epoch[15] Batch [575]#011Speed: 14276.81 samples/sec#011loss=0.961246\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] Epoch[15] Batch[580] avg_epoch_loss=1.174527\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=580 train loss <loss>=0.934575021267\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] Epoch[15] Batch [580]#011Speed: 1846.38 samples/sec#011loss=0.934575\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] Epoch[15] Batch[585] avg_epoch_loss=1.171241\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=585 train loss <loss>=0.78940089941\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] Epoch[15] Batch [585]#011Speed: 13392.58 samples/sec#011loss=0.789401\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] Epoch[15] Batch[590] avg_epoch_loss=1.168979\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=590 train loss <loss>=0.903855067492\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] Epoch[15] Batch [590]#011Speed: 13253.32 samples/sec#011loss=0.903855\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] Epoch[15] Batch[595] avg_epoch_loss=1.168205\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=595 train loss <loss>=1.07664792538\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] Epoch[15] Batch [595]#011Speed: 1798.97 samples/sec#011loss=1.076648\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] Epoch[15] Batch[600] avg_epoch_loss=1.166655\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=600 train loss <loss>=0.98189111948\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:20 INFO 140088046479168] Epoch[15] Batch [600]#011Speed: 13167.64 samples/sec#011loss=0.981891\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] Epoch[15] Batch[605] avg_epoch_loss=1.166321\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=605 train loss <loss>=1.12617069483\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] Epoch[15] Batch [605]#011Speed: 1796.80 samples/sec#011loss=1.126171\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] Epoch[15] Batch[610] avg_epoch_loss=1.164598\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=610 train loss <loss>=0.955780351162\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] Epoch[15] Batch [610]#011Speed: 13195.34 samples/sec#011loss=0.955780\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] Epoch[15] Batch[615] avg_epoch_loss=1.163494\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=615 train loss <loss>=1.02859646082\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] Epoch[15] Batch [615]#011Speed: 13848.01 samples/sec#011loss=1.028596\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] Epoch[15] Batch[620] avg_epoch_loss=1.164541\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=620 train loss <loss>=1.29351209402\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] Epoch[15] Batch [620]#011Speed: 1860.65 samples/sec#011loss=1.293512\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] Epoch[15] Batch[625] avg_epoch_loss=1.168057\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=625 train loss <loss>=1.6047401309\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] Epoch[15] Batch [625]#011Speed: 13413.86 samples/sec#011loss=1.604740\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] Epoch[15] Batch[630] avg_epoch_loss=1.167107\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=630 train loss <loss>=1.04825018644\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] Epoch[15] Batch [630]#011Speed: 1812.32 samples/sec#011loss=1.048250\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] Epoch[15] Batch[635] avg_epoch_loss=1.172076\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=635 train loss <loss>=1.79918296337\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] Epoch[15] Batch [635]#011Speed: 14191.97 samples/sec#011loss=1.799183\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] Epoch[15] Batch[640] avg_epoch_loss=1.177681\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=640 train loss <loss>=1.89053275585\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] Epoch[15] Batch [640]#011Speed: 14316.40 samples/sec#011loss=1.890533\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] Epoch[15] Batch[645] avg_epoch_loss=1.180982\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=645 train loss <loss>=1.60417106152\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] Epoch[15] Batch [645]#011Speed: 1678.21 samples/sec#011loss=1.604171\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] Epoch[15] Batch[650] avg_epoch_loss=1.180167\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=650 train loss <loss>=1.07490111589\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] Epoch[15] Batch [650]#011Speed: 13350.08 samples/sec#011loss=1.074901\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] Epoch[15] Batch[655] avg_epoch_loss=1.179003\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=655 train loss <loss>=1.02747404575\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:21 INFO 140088046479168] Epoch[15] Batch [655]#011Speed: 1785.10 samples/sec#011loss=1.027474\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] Epoch[15] Batch[660] avg_epoch_loss=1.178719\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=660 train loss <loss>=1.14146533012\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] Epoch[15] Batch [660]#011Speed: 14285.02 samples/sec#011loss=1.141465\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] Epoch[15] Batch[665] avg_epoch_loss=1.177026\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=665 train loss <loss>=0.953237509727\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] Epoch[15] Batch [665]#011Speed: 14462.49 samples/sec#011loss=0.953238\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] Epoch[15] Batch[670] avg_epoch_loss=1.176440\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=670 train loss <loss>=1.0983002305\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] Epoch[15] Batch [670]#011Speed: 1732.88 samples/sec#011loss=1.098300\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] Epoch[15] Batch[675] avg_epoch_loss=1.175910\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=675 train loss <loss>=1.10487341881\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] Epoch[15] Batch [675]#011Speed: 13834.88 samples/sec#011loss=1.104873\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] Epoch[15] Batch[680] avg_epoch_loss=1.174550\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=680 train loss <loss>=0.990682518482\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] Epoch[15] Batch [680]#011Speed: 13096.58 samples/sec#011loss=0.990683\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] Epoch[15] Batch[685] avg_epoch_loss=1.172546\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=685 train loss <loss>=0.899574786425\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] Epoch[15] Batch [685]#011Speed: 1283.41 samples/sec#011loss=0.899575\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] Epoch[15] Batch[690] avg_epoch_loss=1.171070\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=690 train loss <loss>=0.96854736805\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] Epoch[15] Batch [690]#011Speed: 14952.62 samples/sec#011loss=0.968547\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] Epoch[15] Batch[695] avg_epoch_loss=1.171565\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=695 train loss <loss>=1.23993490934\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] Epoch[15] Batch [695]#011Speed: 1681.54 samples/sec#011loss=1.239935\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] Epoch[15] Batch[700] avg_epoch_loss=1.177709\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=700 train loss <loss>=2.0329480052\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] Epoch[15] Batch [700]#011Speed: 14286.38 samples/sec#011loss=2.032948\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] Epoch[15] Batch[705] avg_epoch_loss=1.179601\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=705 train loss <loss>=1.44492306709\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] Epoch[15] Batch [705]#011Speed: 14065.26 samples/sec#011loss=1.444923\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] Epoch[15] Batch[710] avg_epoch_loss=1.184316\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=710 train loss <loss>=1.85011994839\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] Epoch[15] Batch [710]#011Speed: 1759.51 samples/sec#011loss=1.850120\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] Epoch[15] Batch[715] avg_epoch_loss=1.188657\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=715 train loss <loss>=1.80591073036\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:22 INFO 140088046479168] Epoch[15] Batch [715]#011Speed: 12408.84 samples/sec#011loss=1.805911\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] Epoch[15] Batch[720] avg_epoch_loss=1.194709\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=720 train loss <loss>=2.06125674248\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] Epoch[15] Batch [720]#011Speed: 1702.83 samples/sec#011loss=2.061257\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] Epoch[15] Batch[725] avg_epoch_loss=1.199968\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=725 train loss <loss>=1.95842671394\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] Epoch[15] Batch [725]#011Speed: 14106.80 samples/sec#011loss=1.958427\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] Epoch[15] Batch[730] avg_epoch_loss=1.204499\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=730 train loss <loss>=1.86229155064\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] Epoch[15] Batch [730]#011Speed: 1755.01 samples/sec#011loss=1.862292\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] Epoch[15] Batch[735] avg_epoch_loss=1.211197\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=735 train loss <loss>=2.19055116177\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] Epoch[15] Batch [735]#011Speed: 13940.93 samples/sec#011loss=2.190551\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] Epoch[15] Batch[740] avg_epoch_loss=1.215731\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=740 train loss <loss>=1.88305675983\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] Epoch[15] Batch [740]#011Speed: 13507.82 samples/sec#011loss=1.883057\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] Epoch[15] Batch[745] avg_epoch_loss=1.219535\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=745 train loss <loss>=1.78330135345\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] Epoch[15] Batch [745]#011Speed: 1677.30 samples/sec#011loss=1.783301\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] Epoch[15] Batch[750] avg_epoch_loss=1.222675\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=750 train loss <loss>=1.69114403725\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] Epoch[15] Batch [750]#011Speed: 14344.56 samples/sec#011loss=1.691144\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] Epoch[15] Batch[755] avg_epoch_loss=1.226108\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=755 train loss <loss>=1.74179050922\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] Epoch[15] Batch [755]#011Speed: 1861.68 samples/sec#011loss=1.741791\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] Epoch[15] Batch[760] avg_epoch_loss=1.229095\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=760 train loss <loss>=1.68069647551\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] Epoch[15] Batch [760]#011Speed: 14199.48 samples/sec#011loss=1.680696\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] Epoch[15] Batch[765] avg_epoch_loss=1.229676\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=765 train loss <loss>=1.31818537712\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:23 INFO 140088046479168] Epoch[15] Batch [765]#011Speed: 14631.82 samples/sec#011loss=1.318185\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] Epoch[15] Batch[770] avg_epoch_loss=1.229502\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=770 train loss <loss>=1.20281875134\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] Epoch[15] Batch [770]#011Speed: 1698.51 samples/sec#011loss=1.202819\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] Epoch[15] Batch[775] avg_epoch_loss=1.229258\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=775 train loss <loss>=1.19156616926\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] Epoch[15] Batch [775]#011Speed: 14378.06 samples/sec#011loss=1.191566\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] Epoch[15] Batch[780] avg_epoch_loss=1.227940\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=780 train loss <loss>=1.02338858843\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] Epoch[15] Batch [780]#011Speed: 1791.36 samples/sec#011loss=1.023389\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] Epoch[15] Batch[785] avg_epoch_loss=1.227813\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=785 train loss <loss>=1.20797901154\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] Epoch[15] Batch [785]#011Speed: 14314.42 samples/sec#011loss=1.207979\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] Epoch[15] Batch[790] avg_epoch_loss=1.227682\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=790 train loss <loss>=1.20705633163\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] Epoch[15] Batch [790]#011Speed: 14599.20 samples/sec#011loss=1.207056\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] Epoch[15] Batch[795] avg_epoch_loss=1.227431\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=795 train loss <loss>=1.18777077198\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] Epoch[15] Batch [795]#011Speed: 1714.25 samples/sec#011loss=1.187771\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] Epoch[15] Batch[800] avg_epoch_loss=1.226773\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=800 train loss <loss>=1.12202291489\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] Epoch[15] Batch [800]#011Speed: 14251.95 samples/sec#011loss=1.122023\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] Epoch[15] Batch[805] avg_epoch_loss=1.226013\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=805 train loss <loss>=1.10422625542\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] Epoch[15] Batch [805]#011Speed: 1806.44 samples/sec#011loss=1.104226\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] Epoch[15] Batch[810] avg_epoch_loss=1.224203\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=810 train loss <loss>=0.932460808754\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] Epoch[15] Batch [810]#011Speed: 13187.69 samples/sec#011loss=0.932461\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] Epoch[15] Batch[815] avg_epoch_loss=1.224431\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=815 train loss <loss>=1.26148247719\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] Epoch[15] Batch [815]#011Speed: 14900.33 samples/sec#011loss=1.261482\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] Epoch[15] Batch[820] avg_epoch_loss=1.223387\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=820 train loss <loss>=1.05293475389\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] Epoch[15] Batch [820]#011Speed: 1654.45 samples/sec#011loss=1.052935\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] Epoch[15] Batch[825] avg_epoch_loss=1.222224\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=825 train loss <loss>=1.03133839369\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:24 INFO 140088046479168] Epoch[15] Batch [825]#011Speed: 14411.87 samples/sec#011loss=1.031338\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] Epoch[15] Batch[830] avg_epoch_loss=1.222099\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=830 train loss <loss>=1.20132827759\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] Epoch[15] Batch [830]#011Speed: 1611.64 samples/sec#011loss=1.201328\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] Epoch[15] Batch[835] avg_epoch_loss=1.221248\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=835 train loss <loss>=1.07986787558\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] Epoch[15] Batch [835]#011Speed: 14160.53 samples/sec#011loss=1.079868\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] Epoch[15] Batch[840] avg_epoch_loss=1.220694\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=840 train loss <loss>=1.12814990282\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] Epoch[15] Batch [840]#011Speed: 14229.89 samples/sec#011loss=1.128150\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] Epoch[15] Batch[845] avg_epoch_loss=1.219211\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=845 train loss <loss>=0.96963031292\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] Epoch[15] Batch [845]#011Speed: 1725.26 samples/sec#011loss=0.969630\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] Epoch[15] Batch[850] avg_epoch_loss=1.220115\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=850 train loss <loss>=1.37316665649\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] Epoch[15] Batch [850]#011Speed: 14292.77 samples/sec#011loss=1.373167\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] Epoch[15] Batch[855] avg_epoch_loss=1.219458\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=855 train loss <loss>=1.10757074356\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] Epoch[15] Batch [855]#011Speed: 1801.06 samples/sec#011loss=1.107571\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] Epoch[15] Batch[860] avg_epoch_loss=1.219166\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=860 train loss <loss>=1.16919791698\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] Epoch[15] Batch [860]#011Speed: 14041.27 samples/sec#011loss=1.169198\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] Epoch[15] Batch[865] avg_epoch_loss=1.218695\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=865 train loss <loss>=1.13765798807\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] Epoch[15] Batch [865]#011Speed: 14694.46 samples/sec#011loss=1.137658\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] Epoch[15] Batch[870] avg_epoch_loss=1.218192\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=870 train loss <loss>=1.1310479641\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] Epoch[15] Batch [870]#011Speed: 1871.51 samples/sec#011loss=1.131048\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] Epoch[15] Batch[875] avg_epoch_loss=1.216651\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=875 train loss <loss>=0.948223054409\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] Epoch[15] Batch [875]#011Speed: 14381.29 samples/sec#011loss=0.948223\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] Epoch[15] Batch[880] avg_epoch_loss=1.216210\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=880 train loss <loss>=1.13895608187\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:25 INFO 140088046479168] Epoch[15] Batch [880]#011Speed: 1752.25 samples/sec#011loss=1.138956\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] Epoch[15] Batch[885] avg_epoch_loss=1.216496\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=885 train loss <loss>=1.2668513298\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] Epoch[15] Batch [885]#011Speed: 13744.49 samples/sec#011loss=1.266851\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] Epoch[15] Batch[890] avg_epoch_loss=1.215672\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=890 train loss <loss>=1.06957967281\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] Epoch[15] Batch [890]#011Speed: 11002.17 samples/sec#011loss=1.069580\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] Epoch[15] Batch[895] avg_epoch_loss=1.213026\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, batch=895 train loss <loss>=0.741499590874\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] Epoch[15] Batch [895]#011Speed: 2489.22 samples/sec#011loss=0.741500\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] processed a total of 57410 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15757.354974746704, \"sum\": 15757.354974746704, \"min\": 15757.354974746704}}, \"EndTime\": 1604320646.176912, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320630.41905}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] #throughput_metric: host=algo-1, train throughput=3643.35018766 records/second\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=15, train loss <loss>=1.21062315884\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] Saved checkpoint to \"/opt/ml/model/state_bd4bc855-2879-49e1-ae46-bb14610c63fc-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 4.755973815917969, \"sum\": 4.755973815917969, \"min\": 4.755973815917969}}, \"EndTime\": 1604320646.182129, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320646.176989}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] Epoch[16] Batch[0] avg_epoch_loss=0.843616\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=0.843615531921\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] Epoch[16] Batch[5] avg_epoch_loss=0.967661\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=0.967660744985\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] Epoch[16] Batch [5]#011Speed: 14241.21 samples/sec#011loss=0.967661\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] Epoch[16] Batch[10] avg_epoch_loss=1.042396\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=1.13207815886\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] Epoch[16] Batch [10]#011Speed: 14184.47 samples/sec#011loss=1.132078\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] Epoch[16] Batch[15] avg_epoch_loss=1.164728\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=15 train loss <loss>=1.43385784626\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] Epoch[16] Batch [15]#011Speed: 1597.01 samples/sec#011loss=1.433858\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] Epoch[16] Batch[20] avg_epoch_loss=1.287283\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=20 train loss <loss>=1.67946050167\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] Epoch[16] Batch [20]#011Speed: 14293.38 samples/sec#011loss=1.679461\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] Epoch[16] Batch[25] avg_epoch_loss=1.407039\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=25 train loss <loss>=1.91001298428\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] Epoch[16] Batch [25]#011Speed: 13931.82 samples/sec#011loss=1.910013\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] Epoch[16] Batch[30] avg_epoch_loss=1.496011\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=30 train loss <loss>=1.95866701603\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] Epoch[16] Batch [30]#011Speed: 1650.69 samples/sec#011loss=1.958667\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] Epoch[16] Batch[35] avg_epoch_loss=1.504942\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=35 train loss <loss>=1.56031066179\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:26 INFO 140088046479168] Epoch[16] Batch [35]#011Speed: 14807.29 samples/sec#011loss=1.560311\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] Epoch[16] Batch[40] avg_epoch_loss=1.503240\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=40 train loss <loss>=1.49099142551\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] Epoch[16] Batch [40]#011Speed: 1560.63 samples/sec#011loss=1.490991\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] Epoch[16] Batch[45] avg_epoch_loss=1.506541\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=45 train loss <loss>=1.53360345364\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] Epoch[16] Batch [45]#011Speed: 13119.63 samples/sec#011loss=1.533603\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] Epoch[16] Batch[50] avg_epoch_loss=1.519324\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=50 train loss <loss>=1.63693101406\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] Epoch[16] Batch [50]#011Speed: 13707.44 samples/sec#011loss=1.636931\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] Epoch[16] Batch[55] avg_epoch_loss=1.512417\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=55 train loss <loss>=1.44196144342\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] Epoch[16] Batch [55]#011Speed: 1636.42 samples/sec#011loss=1.441961\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] Epoch[16] Batch[60] avg_epoch_loss=1.507930\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=60 train loss <loss>=1.45767863989\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] Epoch[16] Batch [60]#011Speed: 12904.31 samples/sec#011loss=1.457679\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] Epoch[16] Batch[65] avg_epoch_loss=1.496333\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=65 train loss <loss>=1.35485434532\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] Epoch[16] Batch [65]#011Speed: 1684.62 samples/sec#011loss=1.354854\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] Epoch[16] Batch[70] avg_epoch_loss=1.489966\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=70 train loss <loss>=1.40591650009\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] Epoch[16] Batch [70]#011Speed: 14301.61 samples/sec#011loss=1.405917\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] Epoch[16] Batch[75] avg_epoch_loss=1.488988\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=75 train loss <loss>=1.47509887218\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] Epoch[16] Batch [75]#011Speed: 14344.10 samples/sec#011loss=1.475099\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] Epoch[16] Batch[80] avg_epoch_loss=1.487831\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=80 train loss <loss>=1.47024737597\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] Epoch[16] Batch [80]#011Speed: 1721.88 samples/sec#011loss=1.470247\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] Epoch[16] Batch[85] avg_epoch_loss=1.472455\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=85 train loss <loss>=1.22337130308\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] Epoch[16] Batch [85]#011Speed: 14315.64 samples/sec#011loss=1.223371\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] Epoch[16] Batch[90] avg_epoch_loss=1.468589\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=90 train loss <loss>=1.40207753181\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] Epoch[16] Batch [90]#011Speed: 13100.29 samples/sec#011loss=1.402078\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] Epoch[16] Batch[95] avg_epoch_loss=1.472535\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=95 train loss <loss>=1.54436552525\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:27 INFO 140088046479168] Epoch[16] Batch [95]#011Speed: 1730.92 samples/sec#011loss=1.544366\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] Epoch[16] Batch[100] avg_epoch_loss=1.463120\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=100 train loss <loss>=1.28233659267\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] Epoch[16] Batch [100]#011Speed: 13243.38 samples/sec#011loss=1.282337\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] Epoch[16] Batch[105] avg_epoch_loss=1.446766\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=105 train loss <loss>=1.11642611027\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] Epoch[16] Batch [105]#011Speed: 1685.53 samples/sec#011loss=1.116426\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] Epoch[16] Batch[110] avg_epoch_loss=1.447180\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=110 train loss <loss>=1.45594975948\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] Epoch[16] Batch [110]#011Speed: 12853.52 samples/sec#011loss=1.455950\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] Epoch[16] Batch[115] avg_epoch_loss=1.436247\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=115 train loss <loss>=1.19353654385\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] Epoch[16] Batch [115]#011Speed: 14693.82 samples/sec#011loss=1.193537\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] Epoch[16] Batch[120] avg_epoch_loss=1.428409\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=120 train loss <loss>=1.24656970501\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] Epoch[16] Batch [120]#011Speed: 1444.06 samples/sec#011loss=1.246570\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] Epoch[16] Batch[125] avg_epoch_loss=1.421289\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=125 train loss <loss>=1.24897487164\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] Epoch[16] Batch [125]#011Speed: 14321.45 samples/sec#011loss=1.248975\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] Epoch[16] Batch[130] avg_epoch_loss=1.416623\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=130 train loss <loss>=1.29905440807\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] Epoch[16] Batch [130]#011Speed: 1781.56 samples/sec#011loss=1.299054\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] Epoch[16] Batch[135] avg_epoch_loss=1.400664\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=135 train loss <loss>=0.982537269592\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] Epoch[16] Batch [135]#011Speed: 14486.22 samples/sec#011loss=0.982537\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] Epoch[16] Batch[140] avg_epoch_loss=1.395371\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=140 train loss <loss>=1.25139132738\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] Epoch[16] Batch [140]#011Speed: 14251.95 samples/sec#011loss=1.251391\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] Epoch[16] Batch[145] avg_epoch_loss=1.393663\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=145 train loss <loss>=1.34549322128\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] Epoch[16] Batch [145]#011Speed: 1765.59 samples/sec#011loss=1.345493\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] Epoch[16] Batch[150] avg_epoch_loss=1.392734\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=150 train loss <loss>=1.36562407017\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:28 INFO 140088046479168] Epoch[16] Batch [150]#011Speed: 14660.75 samples/sec#011loss=1.365624\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] Epoch[16] Batch[155] avg_epoch_loss=1.383065\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=155 train loss <loss>=1.09106776714\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] Epoch[16] Batch [155]#011Speed: 1542.20 samples/sec#011loss=1.091068\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] Epoch[16] Batch[160] avg_epoch_loss=1.376892\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=160 train loss <loss>=1.18428405523\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] Epoch[16] Batch [160]#011Speed: 14294.60 samples/sec#011loss=1.184284\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] Epoch[16] Batch[165] avg_epoch_loss=1.373036\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=165 train loss <loss>=1.24887382984\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] Epoch[16] Batch [165]#011Speed: 13942.82 samples/sec#011loss=1.248874\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] Epoch[16] Batch[170] avg_epoch_loss=1.369939\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=170 train loss <loss>=1.2671251297\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] Epoch[16] Batch [170]#011Speed: 1738.37 samples/sec#011loss=1.267125\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] Epoch[16] Batch[175] avg_epoch_loss=1.363993\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=175 train loss <loss>=1.16061691046\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] Epoch[16] Batch [175]#011Speed: 13963.99 samples/sec#011loss=1.160617\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] Epoch[16] Batch[180] avg_epoch_loss=1.358222\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=180 train loss <loss>=1.15510232449\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] Epoch[16] Batch [180]#011Speed: 14469.82 samples/sec#011loss=1.155102\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] Epoch[16] Batch[185] avg_epoch_loss=1.356127\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=185 train loss <loss>=1.28027763367\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] Epoch[16] Batch [185]#011Speed: 1589.00 samples/sec#011loss=1.280278\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] Epoch[16] Batch[190] avg_epoch_loss=1.350424\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=190 train loss <loss>=1.13827155828\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] Epoch[16] Batch [190]#011Speed: 14219.64 samples/sec#011loss=1.138272\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] Epoch[16] Batch[195] avg_epoch_loss=1.351700\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=195 train loss <loss>=1.40044071674\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] Epoch[16] Batch [195]#011Speed: 1814.36 samples/sec#011loss=1.400441\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] Epoch[16] Batch[200] avg_epoch_loss=1.357303\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=200 train loss <loss>=1.57695219517\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] Epoch[16] Batch [200]#011Speed: 14369.13 samples/sec#011loss=1.576952\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] Epoch[16] Batch[205] avg_epoch_loss=1.357106\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=205 train loss <loss>=1.34918899536\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:29 INFO 140088046479168] Epoch[16] Batch [205]#011Speed: 14591.10 samples/sec#011loss=1.349189\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] Epoch[16] Batch[210] avg_epoch_loss=1.355342\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=210 train loss <loss>=1.28265554905\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] Epoch[16] Batch [210]#011Speed: 1630.32 samples/sec#011loss=1.282656\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] Epoch[16] Batch[215] avg_epoch_loss=1.350171\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=215 train loss <loss>=1.13194702864\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] Epoch[16] Batch [215]#011Speed: 14308.16 samples/sec#011loss=1.131947\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] Epoch[16] Batch[220] avg_epoch_loss=1.341088\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=220 train loss <loss>=0.948720562458\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] Epoch[16] Batch [220]#011Speed: 1747.82 samples/sec#011loss=0.948721\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] Epoch[16] Batch[225] avg_epoch_loss=1.336418\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=225 train loss <loss>=1.13000990152\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] Epoch[16] Batch [225]#011Speed: 13009.75 samples/sec#011loss=1.130010\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] Epoch[16] Batch[230] avg_epoch_loss=1.339821\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=230 train loss <loss>=1.49361054897\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] Epoch[16] Batch [230]#011Speed: 13125.02 samples/sec#011loss=1.493611\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] Epoch[16] Batch[235] avg_epoch_loss=1.335810\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=235 train loss <loss>=1.15052746534\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] Epoch[16] Batch [235]#011Speed: 1849.01 samples/sec#011loss=1.150527\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] Epoch[16] Batch[240] avg_epoch_loss=1.328973\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=240 train loss <loss>=1.00626293421\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] Epoch[16] Batch [240]#011Speed: 13658.75 samples/sec#011loss=1.006263\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] Epoch[16] Batch[245] avg_epoch_loss=1.326738\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=245 train loss <loss>=1.21901779175\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] Epoch[16] Batch [245]#011Speed: 1639.06 samples/sec#011loss=1.219018\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] Epoch[16] Batch[250] avg_epoch_loss=1.328671\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=250 train loss <loss>=1.42374138832\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] Epoch[16] Batch [250]#011Speed: 14236.23 samples/sec#011loss=1.423741\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] Epoch[16] Batch[255] avg_epoch_loss=1.331390\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=255 train loss <loss>=1.4679166317\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] Epoch[16] Batch [255]#011Speed: 1877.32 samples/sec#011loss=1.467917\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] Epoch[16] Batch[260] avg_epoch_loss=1.326420\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=260 train loss <loss>=1.0719645381\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] Epoch[16] Batch [260]#011Speed: 14559.92 samples/sec#011loss=1.071965\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] Epoch[16] Batch[265] avg_epoch_loss=1.320835\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=265 train loss <loss>=1.02928099632\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:30 INFO 140088046479168] Epoch[16] Batch [265]#011Speed: 14562.77 samples/sec#011loss=1.029281\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] Epoch[16] Batch[270] avg_epoch_loss=1.318214\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=270 train loss <loss>=1.17876801491\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] Epoch[16] Batch [270]#011Speed: 1881.57 samples/sec#011loss=1.178768\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] Epoch[16] Batch[275] avg_epoch_loss=1.312367\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=275 train loss <loss>=0.995490026474\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] Epoch[16] Batch [275]#011Speed: 11668.98 samples/sec#011loss=0.995490\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] Epoch[16] Batch[280] avg_epoch_loss=1.306990\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=280 train loss <loss>=1.01015161276\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] Epoch[16] Batch [280]#011Speed: 1561.74 samples/sec#011loss=1.010152\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] Epoch[16] Batch[285] avg_epoch_loss=1.302186\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=285 train loss <loss>=1.03219143152\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] Epoch[16] Batch [285]#011Speed: 13182.90 samples/sec#011loss=1.032191\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] Epoch[16] Batch[290] avg_epoch_loss=1.297400\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=290 train loss <loss>=1.02366957664\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] Epoch[16] Batch [290]#011Speed: 14517.72 samples/sec#011loss=1.023670\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] Epoch[16] Batch[295] avg_epoch_loss=1.291150\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=295 train loss <loss>=0.927386188507\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] Epoch[16] Batch [295]#011Speed: 1666.28 samples/sec#011loss=0.927386\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] Epoch[16] Batch[300] avg_epoch_loss=1.288935\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=300 train loss <loss>=1.15781862736\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] Epoch[16] Batch [300]#011Speed: 12823.68 samples/sec#011loss=1.157819\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] Epoch[16] Batch[305] avg_epoch_loss=1.285398\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=305 train loss <loss>=1.07248010635\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] Epoch[16] Batch [305]#011Speed: 1760.50 samples/sec#011loss=1.072480\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] Epoch[16] Batch[310] avg_epoch_loss=1.281019\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=310 train loss <loss>=1.01300998926\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] Epoch[16] Batch [310]#011Speed: 14031.29 samples/sec#011loss=1.013010\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] Epoch[16] Batch[315] avg_epoch_loss=1.276564\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=315 train loss <loss>=0.999423885345\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] Epoch[16] Batch [315]#011Speed: 12968.52 samples/sec#011loss=0.999424\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] Epoch[16] Batch[320] avg_epoch_loss=1.276494\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=320 train loss <loss>=1.27212548256\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:31 INFO 140088046479168] Epoch[16] Batch [320]#011Speed: 1854.73 samples/sec#011loss=1.272125\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] Epoch[16] Batch[325] avg_epoch_loss=1.275427\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=325 train loss <loss>=1.20687830448\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] Epoch[16] Batch [325]#011Speed: 14292.01 samples/sec#011loss=1.206878\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] Epoch[16] Batch[330] avg_epoch_loss=1.272241\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=330 train loss <loss>=1.06453903913\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] Epoch[16] Batch [330]#011Speed: 1746.68 samples/sec#011loss=1.064539\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] Epoch[16] Batch[335] avg_epoch_loss=1.271350\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=335 train loss <loss>=1.21238992214\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] Epoch[16] Batch [335]#011Speed: 14322.21 samples/sec#011loss=1.212390\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] Epoch[16] Batch[340] avg_epoch_loss=1.269249\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=340 train loss <loss>=1.12802720666\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] Epoch[16] Batch [340]#011Speed: 13337.88 samples/sec#011loss=1.128027\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] Epoch[16] Batch[345] avg_epoch_loss=1.270646\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=345 train loss <loss>=1.36593191624\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] Epoch[16] Batch [345]#011Speed: 1761.67 samples/sec#011loss=1.365932\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] Epoch[16] Batch[350] avg_epoch_loss=1.274163\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=350 train loss <loss>=1.51752533913\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] Epoch[16] Batch [350]#011Speed: 14413.11 samples/sec#011loss=1.517525\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] Epoch[16] Batch[355] avg_epoch_loss=1.279569\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=355 train loss <loss>=1.65908586979\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] Epoch[16] Batch [355]#011Speed: 1620.69 samples/sec#011loss=1.659086\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] Epoch[16] Batch[360] avg_epoch_loss=1.287027\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=360 train loss <loss>=1.81799457073\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] Epoch[16] Batch [360]#011Speed: 14286.38 samples/sec#011loss=1.817995\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] Epoch[16] Batch[365] avg_epoch_loss=1.286645\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=365 train loss <loss>=1.25910415649\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] Epoch[16] Batch [365]#011Speed: 14272.26 samples/sec#011loss=1.259104\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] Epoch[16] Batch[370] avg_epoch_loss=1.284716\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=370 train loss <loss>=1.14349931479\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] Epoch[16] Batch [370]#011Speed: 1669.13 samples/sec#011loss=1.143499\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] Epoch[16] Batch[375] avg_epoch_loss=1.283632\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=375 train loss <loss>=1.20318877697\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] Epoch[16] Batch [375]#011Speed: 14403.98 samples/sec#011loss=1.203189\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] Epoch[16] Batch[380] avg_epoch_loss=1.282703\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=380 train loss <loss>=1.21287031174\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:32 INFO 140088046479168] Epoch[16] Batch [380]#011Speed: 14263.46 samples/sec#011loss=1.212870\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] Epoch[16] Batch[385] avg_epoch_loss=1.282290\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=385 train loss <loss>=1.25082607269\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] Epoch[16] Batch [385]#011Speed: 1688.79 samples/sec#011loss=1.250826\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] Epoch[16] Batch[390] avg_epoch_loss=1.281660\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=390 train loss <loss>=1.23302590847\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] Epoch[16] Batch [390]#011Speed: 11767.29 samples/sec#011loss=1.233026\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] Epoch[16] Batch[395] avg_epoch_loss=1.279566\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=395 train loss <loss>=1.11577533484\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] Epoch[16] Batch [395]#011Speed: 13317.23 samples/sec#011loss=1.115775\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] Epoch[16] Batch[400] avg_epoch_loss=1.276612\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=400 train loss <loss>=1.042692101\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] Epoch[16] Batch [400]#011Speed: 1691.88 samples/sec#011loss=1.042692\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] Epoch[16] Batch[405] avg_epoch_loss=1.274325\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=405 train loss <loss>=1.09089615345\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] Epoch[16] Batch [405]#011Speed: 13954.41 samples/sec#011loss=1.090896\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] Epoch[16] Batch[410] avg_epoch_loss=1.271290\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=410 train loss <loss>=1.0248821795\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] Epoch[16] Batch [410]#011Speed: 1789.99 samples/sec#011loss=1.024882\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] Epoch[16] Batch[415] avg_epoch_loss=1.268966\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=415 train loss <loss>=1.07793328762\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] Epoch[16] Batch [415]#011Speed: 14297.95 samples/sec#011loss=1.077933\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] Epoch[16] Batch[420] avg_epoch_loss=1.266788\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=420 train loss <loss>=1.08555961847\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] Epoch[16] Batch [420]#011Speed: 14165.46 samples/sec#011loss=1.085560\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] Epoch[16] Batch[425] avg_epoch_loss=1.263000\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=425 train loss <loss>=0.944037234783\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] Epoch[16] Batch [425]#011Speed: 1735.41 samples/sec#011loss=0.944037\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] Epoch[16] Batch[430] avg_epoch_loss=1.261955\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=430 train loss <loss>=1.17287728786\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:33 INFO 140088046479168] Epoch[16] Batch [430]#011Speed: 14201.88 samples/sec#011loss=1.172877\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] Epoch[16] Batch[435] avg_epoch_loss=1.259244\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=435 train loss <loss>=1.02560226917\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] Epoch[16] Batch [435]#011Speed: 1754.27 samples/sec#011loss=1.025602\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] Epoch[16] Batch[440] avg_epoch_loss=1.258188\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=440 train loss <loss>=1.16609712839\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] Epoch[16] Batch [440]#011Speed: 13167.64 samples/sec#011loss=1.166097\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] Epoch[16] Batch[445] avg_epoch_loss=1.256698\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=445 train loss <loss>=1.12531881332\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] Epoch[16] Batch [445]#011Speed: 13104.64 samples/sec#011loss=1.125319\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] Epoch[16] Batch[450] avg_epoch_loss=1.255355\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=450 train loss <loss>=1.13549721241\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] Epoch[16] Batch [450]#011Speed: 1733.48 samples/sec#011loss=1.135497\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] Epoch[16] Batch[455] avg_epoch_loss=1.254084\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=455 train loss <loss>=1.13947887421\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] Epoch[16] Batch [455]#011Speed: 12886.59 samples/sec#011loss=1.139479\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] Epoch[16] Batch[460] avg_epoch_loss=1.252748\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=460 train loss <loss>=1.13084573746\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] Epoch[16] Batch [460]#011Speed: 1739.57 samples/sec#011loss=1.130846\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] Epoch[16] Batch[465] avg_epoch_loss=1.251121\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=465 train loss <loss>=1.10112535954\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] Epoch[16] Batch [465]#011Speed: 14273.02 samples/sec#011loss=1.101125\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] Epoch[16] Batch[470] avg_epoch_loss=1.249427\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=470 train loss <loss>=1.09157276154\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] Epoch[16] Batch [470]#011Speed: 14311.98 samples/sec#011loss=1.091573\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] Epoch[16] Batch[475] avg_epoch_loss=1.247106\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=475 train loss <loss>=1.02842737436\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] Epoch[16] Batch [475]#011Speed: 1763.24 samples/sec#011loss=1.028427\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] Epoch[16] Batch[480] avg_epoch_loss=1.247567\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=480 train loss <loss>=1.29147036076\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] Epoch[16] Batch [480]#011Speed: 14351.00 samples/sec#011loss=1.291470\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] Epoch[16] Batch[485] avg_epoch_loss=1.246564\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=485 train loss <loss>=1.15008295774\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] Epoch[16] Batch [485]#011Speed: 1624.23 samples/sec#011loss=1.150083\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] Epoch[16] Batch[490] avg_epoch_loss=1.245240\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=490 train loss <loss>=1.11655164957\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] Epoch[16] Batch [490]#011Speed: 14418.22 samples/sec#011loss=1.116552\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] Epoch[16] Batch[495] avg_epoch_loss=1.241641\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=495 train loss <loss>=0.88825930357\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:34 INFO 140088046479168] Epoch[16] Batch [495]#011Speed: 13142.75 samples/sec#011loss=0.888259\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] Epoch[16] Batch[500] avg_epoch_loss=1.240823\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=500 train loss <loss>=1.15968775749\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] Epoch[16] Batch [500]#011Speed: 1793.90 samples/sec#011loss=1.159688\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] Epoch[16] Batch[505] avg_epoch_loss=1.238302\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=505 train loss <loss>=0.985637414455\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] Epoch[16] Batch [505]#011Speed: 13183.42 samples/sec#011loss=0.985637\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] Epoch[16] Batch[510] avg_epoch_loss=1.237780\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=510 train loss <loss>=1.18500862122\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] Epoch[16] Batch [510]#011Speed: 13228.11 samples/sec#011loss=1.185009\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] Epoch[16] Batch[515] avg_epoch_loss=1.234060\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=515 train loss <loss>=0.853803831339\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] Epoch[16] Batch [515]#011Speed: 1407.30 samples/sec#011loss=0.853804\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] Epoch[16] Batch[520] avg_epoch_loss=1.232416\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=520 train loss <loss>=1.06281703711\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] Epoch[16] Batch [520]#011Speed: 12376.23 samples/sec#011loss=1.062817\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] Epoch[16] Batch[525] avg_epoch_loss=1.231713\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=525 train loss <loss>=1.1584887743\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] Epoch[16] Batch [525]#011Speed: 1614.07 samples/sec#011loss=1.158489\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] Epoch[16] Batch[530] avg_epoch_loss=1.233809\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=530 train loss <loss>=1.45421311855\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] Epoch[16] Batch [530]#011Speed: 14355.60 samples/sec#011loss=1.454213\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] Epoch[16] Batch[535] avg_epoch_loss=1.234278\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=535 train loss <loss>=1.28410712481\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] Epoch[16] Batch [535]#011Speed: 14203.23 samples/sec#011loss=1.284107\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] Epoch[16] Batch[540] avg_epoch_loss=1.237240\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=540 train loss <loss>=1.55482559204\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] Epoch[16] Batch [540]#011Speed: 1771.09 samples/sec#011loss=1.554826\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] Epoch[16] Batch[545] avg_epoch_loss=1.239033\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=545 train loss <loss>=1.43303163052\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:35 INFO 140088046479168] Epoch[16] Batch [545]#011Speed: 13214.96 samples/sec#011loss=1.433032\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] Epoch[16] Batch[550] avg_epoch_loss=1.237038\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=550 train loss <loss>=1.01911019087\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] Epoch[16] Batch [550]#011Speed: 1862.52 samples/sec#011loss=1.019110\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] Epoch[16] Batch[555] avg_epoch_loss=1.234974\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=555 train loss <loss>=1.00753819942\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] Epoch[16] Batch [555]#011Speed: 14647.31 samples/sec#011loss=1.007538\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] Epoch[16] Batch[560] avg_epoch_loss=1.232785\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=560 train loss <loss>=0.989366960526\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] Epoch[16] Batch [560]#011Speed: 14631.98 samples/sec#011loss=0.989367\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] Epoch[16] Batch[565] avg_epoch_loss=1.230972\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=565 train loss <loss>=1.0276073575\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] Epoch[16] Batch [565]#011Speed: 1680.04 samples/sec#011loss=1.027607\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] Epoch[16] Batch[570] avg_epoch_loss=1.228865\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=570 train loss <loss>=0.990335118771\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] Epoch[16] Batch [570]#011Speed: 14008.59 samples/sec#011loss=0.990335\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] Epoch[16] Batch[575] avg_epoch_loss=1.228064\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=575 train loss <loss>=1.13661817312\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] Epoch[16] Batch [575]#011Speed: 1819.45 samples/sec#011loss=1.136618\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] Epoch[16] Batch[580] avg_epoch_loss=1.226088\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=580 train loss <loss>=0.998402154446\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] Epoch[16] Batch [580]#011Speed: 13231.37 samples/sec#011loss=0.998402\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] Epoch[16] Batch[585] avg_epoch_loss=1.225289\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=585 train loss <loss>=1.13249058127\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] Epoch[16] Batch [585]#011Speed: 13015.56 samples/sec#011loss=1.132491\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] Epoch[16] Batch[590] avg_epoch_loss=1.223457\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=590 train loss <loss>=1.00874205828\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] Epoch[16] Batch [590]#011Speed: 1714.52 samples/sec#011loss=1.008742\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] Epoch[16] Batch[595] avg_epoch_loss=1.222862\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=595 train loss <loss>=1.15250235796\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] Epoch[16] Batch [595]#011Speed: 13939.63 samples/sec#011loss=1.152502\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] Epoch[16] Batch[600] avg_epoch_loss=1.220990\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=600 train loss <loss>=0.997800767422\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] Epoch[16] Batch [600]#011Speed: 1793.96 samples/sec#011loss=0.997801\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] Epoch[16] Batch[605] avg_epoch_loss=1.220818\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=605 train loss <loss>=1.20023566484\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] Epoch[16] Batch [605]#011Speed: 14048.62 samples/sec#011loss=1.200236\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] Epoch[16] Batch[610] avg_epoch_loss=1.220673\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=610 train loss <loss>=1.20303758383\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:36 INFO 140088046479168] Epoch[16] Batch [610]#011Speed: 14216.47 samples/sec#011loss=1.203038\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] Epoch[16] Batch[615] avg_epoch_loss=1.219859\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=615 train loss <loss>=1.12041605711\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] Epoch[16] Batch [615]#011Speed: 1828.84 samples/sec#011loss=1.120416\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] Epoch[16] Batch[620] avg_epoch_loss=1.221434\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=620 train loss <loss>=1.41543560028\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] Epoch[16] Batch [620]#011Speed: 14322.82 samples/sec#011loss=1.415436\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] Epoch[16] Batch[625] avg_epoch_loss=1.224179\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=625 train loss <loss>=1.56516895294\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] Epoch[16] Batch [625]#011Speed: 1489.18 samples/sec#011loss=1.565169\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] Epoch[16] Batch[630] avg_epoch_loss=1.227989\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=630 train loss <loss>=1.70499157906\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] Epoch[16] Batch [630]#011Speed: 14507.20 samples/sec#011loss=1.704992\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] Epoch[16] Batch[635] avg_epoch_loss=1.231995\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=635 train loss <loss>=1.73756546974\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] Epoch[16] Batch [635]#011Speed: 14365.90 samples/sec#011loss=1.737565\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] Epoch[16] Batch[640] avg_epoch_loss=1.234305\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=640 train loss <loss>=1.52805321217\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] Epoch[16] Batch [640]#011Speed: 1474.61 samples/sec#011loss=1.528053\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] Epoch[16] Batch[645] avg_epoch_loss=1.237045\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=645 train loss <loss>=1.58841643333\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] Epoch[16] Batch [645]#011Speed: 14309.99 samples/sec#011loss=1.588416\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] Epoch[16] Batch[650] avg_epoch_loss=1.239465\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=650 train loss <loss>=1.55203199387\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] Epoch[16] Batch [650]#011Speed: 1671.53 samples/sec#011loss=1.552032\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] Epoch[16] Batch[655] avg_epoch_loss=1.240433\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=655 train loss <loss>=1.36650121212\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] Epoch[16] Batch [655]#011Speed: 13356.73 samples/sec#011loss=1.366501\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] Epoch[16] Batch[660] avg_epoch_loss=1.241600\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=660 train loss <loss>=1.39468803406\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:37 INFO 140088046479168] Epoch[16] Batch [660]#011Speed: 13207.81 samples/sec#011loss=1.394688\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] Epoch[16] Batch[665] avg_epoch_loss=1.243429\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=665 train loss <loss>=1.4852694273\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] Epoch[16] Batch [665]#011Speed: 1753.55 samples/sec#011loss=1.485269\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] Epoch[16] Batch[670] avg_epoch_loss=1.245458\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=670 train loss <loss>=1.5156424284\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] Epoch[16] Batch [670]#011Speed: 14274.23 samples/sec#011loss=1.515642\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] Epoch[16] Batch[675] avg_epoch_loss=1.247546\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=675 train loss <loss>=1.52784729004\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] Epoch[16] Batch [675]#011Speed: 14287.60 samples/sec#011loss=1.527847\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] Epoch[16] Batch[680] avg_epoch_loss=1.249778\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=680 train loss <loss>=1.55145447254\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] Epoch[16] Batch [680]#011Speed: 1720.96 samples/sec#011loss=1.551454\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] Epoch[16] Batch[685] avg_epoch_loss=1.250671\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=685 train loss <loss>=1.37229242325\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] Epoch[16] Batch [685]#011Speed: 14080.16 samples/sec#011loss=1.372292\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] Epoch[16] Batch[690] avg_epoch_loss=1.250005\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=690 train loss <loss>=1.15868223906\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] Epoch[16] Batch [690]#011Speed: 1735.84 samples/sec#011loss=1.158682\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] Epoch[16] Batch[695] avg_epoch_loss=1.249497\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=695 train loss <loss>=1.17936013937\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] Epoch[16] Batch [695]#011Speed: 14443.66 samples/sec#011loss=1.179360\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] Epoch[16] Batch[700] avg_epoch_loss=1.248273\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=700 train loss <loss>=1.07783830166\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] Epoch[16] Batch [700]#011Speed: 14699.13 samples/sec#011loss=1.077838\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] Epoch[16] Batch[705] avg_epoch_loss=1.248431\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=705 train loss <loss>=1.27063641548\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] Epoch[16] Batch [705]#011Speed: 1642.01 samples/sec#011loss=1.270636\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] Epoch[16] Batch[710] avg_epoch_loss=1.248124\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=710 train loss <loss>=1.20466352701\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] Epoch[16] Batch [710]#011Speed: 14333.07 samples/sec#011loss=1.204664\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] Epoch[16] Batch[715] avg_epoch_loss=1.247333\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=715 train loss <loss>=1.13487702608\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] Epoch[16] Batch [715]#011Speed: 14368.36 samples/sec#011loss=1.134877\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] Epoch[16] Batch[720] avg_epoch_loss=1.245436\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=720 train loss <loss>=0.973806297779\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:38 INFO 140088046479168] Epoch[16] Batch [720]#011Speed: 1696.96 samples/sec#011loss=0.973806\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] Epoch[16] Batch[725] avg_epoch_loss=1.244680\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=725 train loss <loss>=1.13568258286\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] Epoch[16] Batch [725]#011Speed: 14382.06 samples/sec#011loss=1.135683\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] Epoch[16] Batch[730] avg_epoch_loss=1.243900\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=730 train loss <loss>=1.13059973717\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] Epoch[16] Batch [730]#011Speed: 1739.80 samples/sec#011loss=1.130600\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] Epoch[16] Batch[735] avg_epoch_loss=1.241813\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=735 train loss <loss>=0.936686646938\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] Epoch[16] Batch [735]#011Speed: 14475.13 samples/sec#011loss=0.936687\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] Epoch[16] Batch[740] avg_epoch_loss=1.239840\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=740 train loss <loss>=0.949457740784\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] Epoch[16] Batch [740]#011Speed: 12305.31 samples/sec#011loss=0.949458\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] Epoch[16] Batch[745] avg_epoch_loss=1.238502\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=745 train loss <loss>=1.04016674757\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] Epoch[16] Batch [745]#011Speed: 1511.08 samples/sec#011loss=1.040167\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] Epoch[16] Batch[750] avg_epoch_loss=1.238949\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=750 train loss <loss>=1.30565462112\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] Epoch[16] Batch [750]#011Speed: 14366.51 samples/sec#011loss=1.305655\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] Epoch[16] Batch[755] avg_epoch_loss=1.238405\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=755 train loss <loss>=1.15676478148\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] Epoch[16] Batch [755]#011Speed: 1789.64 samples/sec#011loss=1.156765\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] Epoch[16] Batch[760] avg_epoch_loss=1.237697\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=760 train loss <loss>=1.13060045242\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] Epoch[16] Batch [760]#011Speed: 14119.41 samples/sec#011loss=1.130600\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] Epoch[16] Batch[765] avg_epoch_loss=1.237027\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=765 train loss <loss>=1.13505787849\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] Epoch[16] Batch [765]#011Speed: 14217.83 samples/sec#011loss=1.135058\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] Epoch[16] Batch[770] avg_epoch_loss=1.237246\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=770 train loss <loss>=1.27085773945\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] Epoch[16] Batch [770]#011Speed: 1751.12 samples/sec#011loss=1.270858\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] Epoch[16] Batch[775] avg_epoch_loss=1.237664\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=775 train loss <loss>=1.3020252943\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:39 INFO 140088046479168] Epoch[16] Batch [775]#011Speed: 14401.35 samples/sec#011loss=1.302025\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] Epoch[16] Batch[780] avg_epoch_loss=1.236413\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=780 train loss <loss>=1.04224662781\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] Epoch[16] Batch [780]#011Speed: 1684.71 samples/sec#011loss=1.042247\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] Epoch[16] Batch[785] avg_epoch_loss=1.236391\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=785 train loss <loss>=1.2330545783\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] Epoch[16] Batch [785]#011Speed: 14236.83 samples/sec#011loss=1.233055\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] Epoch[16] Batch[790] avg_epoch_loss=1.235904\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=790 train loss <loss>=1.15923678875\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] Epoch[16] Batch [790]#011Speed: 14332.46 samples/sec#011loss=1.159237\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] Epoch[16] Batch[795] avg_epoch_loss=1.234682\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=795 train loss <loss>=1.0413599968\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] Epoch[16] Batch [795]#011Speed: 1652.83 samples/sec#011loss=1.041360\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] Epoch[16] Batch[800] avg_epoch_loss=1.235077\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=800 train loss <loss>=1.2979626894\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] Epoch[16] Batch [800]#011Speed: 12973.79 samples/sec#011loss=1.297963\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] Epoch[16] Batch[805] avg_epoch_loss=1.235020\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=805 train loss <loss>=1.22593846321\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] Epoch[16] Batch [805]#011Speed: 1798.12 samples/sec#011loss=1.225938\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] Epoch[16] Batch[810] avg_epoch_loss=1.234870\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=810 train loss <loss>=1.21077692509\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] Epoch[16] Batch [810]#011Speed: 14137.41 samples/sec#011loss=1.210777\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] Epoch[16] Batch[815] avg_epoch_loss=1.235670\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=815 train loss <loss>=1.36534459591\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] Epoch[16] Batch [815]#011Speed: 14449.57 samples/sec#011loss=1.365345\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] Epoch[16] Batch[820] avg_epoch_loss=1.235272\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=820 train loss <loss>=1.17025823593\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] Epoch[16] Batch [820]#011Speed: 1727.81 samples/sec#011loss=1.170258\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] Epoch[16] Batch[825] avg_epoch_loss=1.233453\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=825 train loss <loss>=0.93481991291\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] Epoch[16] Batch [825]#011Speed: 13578.88 samples/sec#011loss=0.934820\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] Epoch[16] Batch[830] avg_epoch_loss=1.233177\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=830 train loss <loss>=1.18767557144\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] Epoch[16] Batch [830]#011Speed: 1737.01 samples/sec#011loss=1.187676\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] Epoch[16] Batch[835] avg_epoch_loss=1.231369\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=835 train loss <loss>=0.930797064304\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:40 INFO 140088046479168] Epoch[16] Batch [835]#011Speed: 13256.60 samples/sec#011loss=0.930797\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] Epoch[16] Batch[840] avg_epoch_loss=1.230375\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=840 train loss <loss>=1.06424021721\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] Epoch[16] Batch [840]#011Speed: 13230.72 samples/sec#011loss=1.064240\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] Epoch[16] Batch[845] avg_epoch_loss=1.228545\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=845 train loss <loss>=0.920763528347\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] Epoch[16] Batch [845]#011Speed: 1791.56 samples/sec#011loss=0.920764\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] Epoch[16] Batch[850] avg_epoch_loss=1.227209\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=850 train loss <loss>=1.00101252794\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] Epoch[16] Batch [850]#011Speed: 14021.47 samples/sec#011loss=1.001013\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] Epoch[16] Batch[855] avg_epoch_loss=1.226364\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=855 train loss <loss>=1.08254796267\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] Epoch[16] Batch [855]#011Speed: 14363.90 samples/sec#011loss=1.082548\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] Epoch[16] Batch[860] avg_epoch_loss=1.227032\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=860 train loss <loss>=1.34145195484\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] Epoch[16] Batch [860]#011Speed: 1443.98 samples/sec#011loss=1.341452\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] Epoch[16] Batch[865] avg_epoch_loss=1.229779\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=865 train loss <loss>=1.70280855894\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] Epoch[16] Batch [865]#011Speed: 14532.96 samples/sec#011loss=1.702809\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] Epoch[16] Batch[870] avg_epoch_loss=1.234903\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=870 train loss <loss>=2.12234890461\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] Epoch[16] Batch [870]#011Speed: 1733.06 samples/sec#011loss=2.122349\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] Epoch[16] Batch[875] avg_epoch_loss=1.236663\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=875 train loss <loss>=1.5432117939\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] Epoch[16] Batch [875]#011Speed: 14341.49 samples/sec#011loss=1.543212\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] Epoch[16] Batch[880] avg_epoch_loss=1.238660\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=880 train loss <loss>=1.58863830566\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] Epoch[16] Batch [880]#011Speed: 14347.32 samples/sec#011loss=1.588638\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] Epoch[16] Batch[885] avg_epoch_loss=1.241553\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=885 train loss <loss>=1.75127551556\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] Epoch[16] Batch [885]#011Speed: 1666.46 samples/sec#011loss=1.751276\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] Epoch[16] Batch[890] avg_epoch_loss=1.242317\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=890 train loss <loss>=1.37774288654\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:41 INFO 140088046479168] Epoch[16] Batch [890]#011Speed: 14468.42 samples/sec#011loss=1.377743\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] Epoch[16] Batch[895] avg_epoch_loss=1.242257\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=895 train loss <loss>=1.23147172928\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] Epoch[16] Batch [895]#011Speed: 2129.97 samples/sec#011loss=1.231472\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] Epoch[16] Batch[900] avg_epoch_loss=1.243263\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=900 train loss <loss>=1.42351603508\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] Epoch[16] Batch [900]#011Speed: 13287.44 samples/sec#011loss=1.423516\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] Epoch[16] Batch[905] avg_epoch_loss=1.242245\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, batch=905 train loss <loss>=1.05881133676\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] Epoch[16] Batch [905]#011Speed: 12140.03 samples/sec#011loss=1.058811\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] processed a total of 57934 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15953.553199768066, \"sum\": 15953.553199768066, \"min\": 15953.553199768066}}, \"EndTime\": 1604320662.135766, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320646.182165}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] #throughput_metric: host=algo-1, train throughput=3631.39127808 records/second\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] #progress_metric: host=algo-1, completed 85 % of epochs\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=16, train loss <loss>=1.24224462477\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] Epoch[17] Batch[0] avg_epoch_loss=1.623640\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=1.62364029884\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] Epoch[17] Batch[5] avg_epoch_loss=1.484196\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=1.48419640462\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] Epoch[17] Batch [5]#011Speed: 14377.60 samples/sec#011loss=1.484196\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] Epoch[17] Batch[10] avg_epoch_loss=1.365842\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=1.22381694317\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] Epoch[17] Batch [10]#011Speed: 14302.98 samples/sec#011loss=1.223817\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] Epoch[17] Batch[15] avg_epoch_loss=1.313225\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=15 train loss <loss>=1.19746842384\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] Epoch[17] Batch [15]#011Speed: 1736.77 samples/sec#011loss=1.197468\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] Epoch[17] Batch[20] avg_epoch_loss=1.286442\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=20 train loss <loss>=1.20073466301\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] Epoch[17] Batch [20]#011Speed: 12894.39 samples/sec#011loss=1.200735\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] Epoch[17] Batch[25] avg_epoch_loss=1.292004\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=25 train loss <loss>=1.3153660059\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] Epoch[17] Batch [25]#011Speed: 13512.99 samples/sec#011loss=1.315366\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] Epoch[17] Batch[30] avg_epoch_loss=1.274470\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=30 train loss <loss>=1.18329377174\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] Epoch[17] Batch [30]#011Speed: 1471.58 samples/sec#011loss=1.183294\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] Epoch[17] Batch[35] avg_epoch_loss=1.287039\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=35 train loss <loss>=1.36496862173\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:42 INFO 140088046479168] Epoch[17] Batch [35]#011Speed: 14284.41 samples/sec#011loss=1.364969\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] Epoch[17] Batch[40] avg_epoch_loss=1.275754\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=40 train loss <loss>=1.19449715614\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] Epoch[17] Batch [40]#011Speed: 1785.29 samples/sec#011loss=1.194497\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] Epoch[17] Batch[45] avg_epoch_loss=1.281029\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=45 train loss <loss>=1.32428228855\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] Epoch[17] Batch [45]#011Speed: 13241.82 samples/sec#011loss=1.324282\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] Epoch[17] Batch[50] avg_epoch_loss=1.266561\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=50 train loss <loss>=1.13345789909\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] Epoch[17] Batch [50]#011Speed: 13401.00 samples/sec#011loss=1.133458\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] Epoch[17] Batch[55] avg_epoch_loss=1.257337\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=55 train loss <loss>=1.16325042248\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] Epoch[17] Batch [55]#011Speed: 1585.91 samples/sec#011loss=1.163250\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] Epoch[17] Batch[60] avg_epoch_loss=1.258857\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=60 train loss <loss>=1.27588088512\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] Epoch[17] Batch [60]#011Speed: 11247.80 samples/sec#011loss=1.275881\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] Epoch[17] Batch[65] avg_epoch_loss=1.249999\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=65 train loss <loss>=1.14193229675\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] Epoch[17] Batch [65]#011Speed: 1828.27 samples/sec#011loss=1.141932\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] Epoch[17] Batch[70] avg_epoch_loss=1.247318\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=70 train loss <loss>=1.21193119287\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] Epoch[17] Batch [70]#011Speed: 14309.99 samples/sec#011loss=1.211931\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] Epoch[17] Batch[75] avg_epoch_loss=1.252326\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=75 train loss <loss>=1.32343697548\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] Epoch[17] Batch [75]#011Speed: 14308.77 samples/sec#011loss=1.323437\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] Epoch[17] Batch[80] avg_epoch_loss=1.251394\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=80 train loss <loss>=1.23722180128\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] Epoch[17] Batch [80]#011Speed: 1807.37 samples/sec#011loss=1.237222\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] Epoch[17] Batch[85] avg_epoch_loss=1.246409\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=85 train loss <loss>=1.16565375328\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] Epoch[17] Batch [85]#011Speed: 13503.20 samples/sec#011loss=1.165654\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] Epoch[17] Batch[90] avg_epoch_loss=1.241425\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=90 train loss <loss>=1.15570209026\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] Epoch[17] Batch [90]#011Speed: 1673.54 samples/sec#011loss=1.155702\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] Epoch[17] Batch[95] avg_epoch_loss=1.239405\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=95 train loss <loss>=1.20264284611\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] Epoch[17] Batch [95]#011Speed: 13819.92 samples/sec#011loss=1.202643\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] Epoch[17] Batch[100] avg_epoch_loss=1.237763\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=100 train loss <loss>=1.20624434948\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:43 INFO 140088046479168] Epoch[17] Batch [100]#011Speed: 14122.98 samples/sec#011loss=1.206244\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] Epoch[17] Batch[105] avg_epoch_loss=1.230561\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=105 train loss <loss>=1.08508411646\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] Epoch[17] Batch [105]#011Speed: 1562.51 samples/sec#011loss=1.085084\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] Epoch[17] Batch[110] avg_epoch_loss=1.228705\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=110 train loss <loss>=1.18935828209\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] Epoch[17] Batch [110]#011Speed: 14308.01 samples/sec#011loss=1.189358\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] Epoch[17] Batch[115] avg_epoch_loss=1.229043\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=115 train loss <loss>=1.23654134274\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] Epoch[17] Batch [115]#011Speed: 1767.83 samples/sec#011loss=1.236541\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] Epoch[17] Batch[120] avg_epoch_loss=1.222333\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=120 train loss <loss>=1.06664640903\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] Epoch[17] Batch [120]#011Speed: 14260.88 samples/sec#011loss=1.066646\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] Epoch[17] Batch[125] avg_epoch_loss=1.219806\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=125 train loss <loss>=1.15867555141\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] Epoch[17] Batch [125]#011Speed: 14131.75 samples/sec#011loss=1.158676\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] Epoch[17] Batch[130] avg_epoch_loss=1.205396\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=130 train loss <loss>=0.842259216309\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] Epoch[17] Batch [130]#011Speed: 1666.00 samples/sec#011loss=0.842259\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] Epoch[17] Batch[135] avg_epoch_loss=1.196452\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=135 train loss <loss>=0.962115287781\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] Epoch[17] Batch [135]#011Speed: 13176.95 samples/sec#011loss=0.962115\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] Epoch[17] Batch[140] avg_epoch_loss=1.198737\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=140 train loss <loss>=1.26089408398\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] Epoch[17] Batch [140]#011Speed: 1708.72 samples/sec#011loss=1.260894\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] Epoch[17] Batch[145] avg_epoch_loss=1.197156\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=145 train loss <loss>=1.15256382227\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] Epoch[17] Batch [145]#011Speed: 13586.99 samples/sec#011loss=1.152564\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] Epoch[17] Batch[150] avg_epoch_loss=1.193347\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=150 train loss <loss>=1.08210812807\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:44 INFO 140088046479168] Epoch[17] Batch [150]#011Speed: 14578.58 samples/sec#011loss=1.082108\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] Epoch[17] Batch[155] avg_epoch_loss=1.182181\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=155 train loss <loss>=0.844991397858\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] Epoch[17] Batch [155]#011Speed: 1542.84 samples/sec#011loss=0.844991\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] Epoch[17] Batch[160] avg_epoch_loss=1.180002\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=160 train loss <loss>=1.11201943159\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] Epoch[17] Batch [160]#011Speed: 14412.49 samples/sec#011loss=1.112019\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] Epoch[17] Batch[165] avg_epoch_loss=1.180826\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=165 train loss <loss>=1.20734580755\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] Epoch[17] Batch [165]#011Speed: 14285.02 samples/sec#011loss=1.207346\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] Epoch[17] Batch[170] avg_epoch_loss=1.173751\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=170 train loss <loss>=0.938861739635\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] Epoch[17] Batch [170]#011Speed: 1702.67 samples/sec#011loss=0.938862\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] Epoch[17] Batch[175] avg_epoch_loss=1.171136\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=175 train loss <loss>=1.08170171976\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] Epoch[17] Batch [175]#011Speed: 11946.07 samples/sec#011loss=1.081702\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] Epoch[17] Batch[180] avg_epoch_loss=1.170574\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=180 train loss <loss>=1.15077834129\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] Epoch[17] Batch [180]#011Speed: 1676.99 samples/sec#011loss=1.150778\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] Epoch[17] Batch[185] avg_epoch_loss=1.168663\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=185 train loss <loss>=1.09950884581\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] Epoch[17] Batch [185]#011Speed: 14448.79 samples/sec#011loss=1.099509\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] Epoch[17] Batch[190] avg_epoch_loss=1.166584\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=190 train loss <loss>=1.0892560482\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] Epoch[17] Batch [190]#011Speed: 13186.14 samples/sec#011loss=1.089256\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] Epoch[17] Batch[195] avg_epoch_loss=1.165819\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=195 train loss <loss>=1.13656357527\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] Epoch[17] Batch [195]#011Speed: 1720.61 samples/sec#011loss=1.136564\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] Epoch[17] Batch[200] avg_epoch_loss=1.168295\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=200 train loss <loss>=1.26537241936\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] Epoch[17] Batch [200]#011Speed: 13275.87 samples/sec#011loss=1.265372\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] Epoch[17] Batch[205] avg_epoch_loss=1.171480\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=205 train loss <loss>=1.29953217506\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] Epoch[17] Batch [205]#011Speed: 1767.06 samples/sec#011loss=1.299532\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] Epoch[17] Batch[210] avg_epoch_loss=1.172085\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=210 train loss <loss>=1.19697268009\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:45 INFO 140088046479168] Epoch[17] Batch [210]#011Speed: 14122.98 samples/sec#011loss=1.196973\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] Epoch[17] Batch[215] avg_epoch_loss=1.171740\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=215 train loss <loss>=1.15718054771\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] Epoch[17] Batch [215]#011Speed: 14161.13 samples/sec#011loss=1.157181\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] Epoch[17] Batch[220] avg_epoch_loss=1.169353\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=220 train loss <loss>=1.06624263525\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] Epoch[17] Batch [220]#011Speed: 1782.99 samples/sec#011loss=1.066243\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] Epoch[17] Batch[225] avg_epoch_loss=1.168676\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=225 train loss <loss>=1.13876094818\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] Epoch[17] Batch [225]#011Speed: 13891.30 samples/sec#011loss=1.138761\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] Epoch[17] Batch[230] avg_epoch_loss=1.172148\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=230 train loss <loss>=1.32907278538\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] Epoch[17] Batch [230]#011Speed: 1717.41 samples/sec#011loss=1.329073\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] Epoch[17] Batch[235] avg_epoch_loss=1.171946\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=235 train loss <loss>=1.16264740229\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] Epoch[17] Batch [235]#011Speed: 14198.13 samples/sec#011loss=1.162647\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] Epoch[17] Batch[240] avg_epoch_loss=1.171181\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=240 train loss <loss>=1.13503257036\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] Epoch[17] Batch [240]#011Speed: 14103.09 samples/sec#011loss=1.135033\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] Epoch[17] Batch[245] avg_epoch_loss=1.166144\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=245 train loss <loss>=0.923371803761\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] Epoch[17] Batch [245]#011Speed: 1716.26 samples/sec#011loss=0.923372\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] Epoch[17] Batch[250] avg_epoch_loss=1.166224\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=250 train loss <loss>=1.17016158104\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] Epoch[17] Batch [250]#011Speed: 13189.38 samples/sec#011loss=1.170162\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] Epoch[17] Batch[255] avg_epoch_loss=1.164561\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=255 train loss <loss>=1.08107753992\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] Epoch[17] Batch [255]#011Speed: 13661.25 samples/sec#011loss=1.081078\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] Epoch[17] Batch[260] avg_epoch_loss=1.161421\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=260 train loss <loss>=1.00066611767\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] Epoch[17] Batch [260]#011Speed: 1656.44 samples/sec#011loss=1.000666\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] Epoch[17] Batch[265] avg_epoch_loss=1.159535\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=265 train loss <loss>=1.0610787034\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:46 INFO 140088046479168] Epoch[17] Batch [265]#011Speed: 14397.65 samples/sec#011loss=1.061079\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] Epoch[17] Batch[270] avg_epoch_loss=1.155202\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=270 train loss <loss>=0.924687063694\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] Epoch[17] Batch [270]#011Speed: 1699.76 samples/sec#011loss=0.924687\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] Epoch[17] Batch[275] avg_epoch_loss=1.151775\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=275 train loss <loss>=0.966040444374\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] Epoch[17] Batch [275]#011Speed: 12629.76 samples/sec#011loss=0.966040\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] Epoch[17] Batch[280] avg_epoch_loss=1.145582\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=280 train loss <loss>=0.803736996651\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] Epoch[17] Batch [280]#011Speed: 1583.10 samples/sec#011loss=0.803737\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] Epoch[17] Batch[285] avg_epoch_loss=1.141776\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=285 train loss <loss>=0.927870559692\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] Epoch[17] Batch [285]#011Speed: 14318.39 samples/sec#011loss=0.927871\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] Epoch[17] Batch[290] avg_epoch_loss=1.134446\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=290 train loss <loss>=0.715137404203\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] Epoch[17] Batch [290]#011Speed: 12128.07 samples/sec#011loss=0.715137\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] Epoch[17] Batch[295] avg_epoch_loss=1.129935\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=295 train loss <loss>=0.867402839661\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] Epoch[17] Batch [295]#011Speed: 1553.91 samples/sec#011loss=0.867403\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] Epoch[17] Batch[300] avg_epoch_loss=1.125555\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=300 train loss <loss>=0.866274166107\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] Epoch[17] Batch [300]#011Speed: 14283.19 samples/sec#011loss=0.866274\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] Epoch[17] Batch[305] avg_epoch_loss=1.124303\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=305 train loss <loss>=1.04893790483\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] Epoch[17] Batch [305]#011Speed: 1883.88 samples/sec#011loss=1.048938\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] Epoch[17] Batch[310] avg_epoch_loss=1.132773\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=310 train loss <loss>=1.65116074085\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] Epoch[17] Batch [310]#011Speed: 14503.28 samples/sec#011loss=1.651161\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] Epoch[17] Batch[315] avg_epoch_loss=1.135773\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=315 train loss <loss>=1.32232816219\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] Epoch[17] Batch [315]#011Speed: 14584.60 samples/sec#011loss=1.322328\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] Epoch[17] Batch[320] avg_epoch_loss=1.135453\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=320 train loss <loss>=1.11523702145\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:47 INFO 140088046479168] Epoch[17] Batch [320]#011Speed: 1821.37 samples/sec#011loss=1.115237\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] Epoch[17] Batch[325] avg_epoch_loss=1.136821\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=325 train loss <loss>=1.2246519208\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] Epoch[17] Batch [325]#011Speed: 14445.68 samples/sec#011loss=1.224652\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] Epoch[17] Batch[330] avg_epoch_loss=1.141215\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=330 train loss <loss>=1.42773270607\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] Epoch[17] Batch [330]#011Speed: 1754.07 samples/sec#011loss=1.427733\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] Epoch[17] Batch[335] avg_epoch_loss=1.142505\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=335 train loss <loss>=1.22784500122\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] Epoch[17] Batch [335]#011Speed: 12866.33 samples/sec#011loss=1.227845\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] Epoch[17] Batch[340] avg_epoch_loss=1.144079\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=340 train loss <loss>=1.2498626709\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] Epoch[17] Batch [340]#011Speed: 13265.37 samples/sec#011loss=1.249863\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] Epoch[17] Batch[345] avg_epoch_loss=1.143595\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=345 train loss <loss>=1.11063889265\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] Epoch[17] Batch [345]#011Speed: 1694.66 samples/sec#011loss=1.110639\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] Epoch[17] Batch[350] avg_epoch_loss=1.143934\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=350 train loss <loss>=1.16735979319\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] Epoch[17] Batch [350]#011Speed: 14276.20 samples/sec#011loss=1.167360\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] Epoch[17] Batch[355] avg_epoch_loss=1.150448\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=355 train loss <loss>=1.60773346424\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] Epoch[17] Batch [355]#011Speed: 1772.12 samples/sec#011loss=1.607733\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] Epoch[17] Batch[360] avg_epoch_loss=1.154865\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=360 train loss <loss>=1.46932829618\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] Epoch[17] Batch [360]#011Speed: 14621.94 samples/sec#011loss=1.469328\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] Epoch[17] Batch[365] avg_epoch_loss=1.155322\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=365 train loss <loss>=1.18837538958\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] Epoch[17] Batch [365]#011Speed: 14735.76 samples/sec#011loss=1.188375\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] Epoch[17] Batch[370] avg_epoch_loss=1.158934\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=370 train loss <loss>=1.42328329086\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] Epoch[17] Batch [370]#011Speed: 1646.37 samples/sec#011loss=1.423283\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] Epoch[17] Batch[375] avg_epoch_loss=1.160179\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=375 train loss <loss>=1.25259913206\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:48 INFO 140088046479168] Epoch[17] Batch [375]#011Speed: 14310.60 samples/sec#011loss=1.252599\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] Epoch[17] Batch[380] avg_epoch_loss=1.167006\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=380 train loss <loss>=1.6804101944\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] Epoch[17] Batch [380]#011Speed: 1733.51 samples/sec#011loss=1.680410\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] Epoch[17] Batch[385] avg_epoch_loss=1.171833\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=385 train loss <loss>=1.53961336613\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] Epoch[17] Batch [385]#011Speed: 13324.50 samples/sec#011loss=1.539613\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] Epoch[17] Batch[390] avg_epoch_loss=1.174032\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=390 train loss <loss>=1.34376363754\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] Epoch[17] Batch [390]#011Speed: 14648.59 samples/sec#011loss=1.343764\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] Epoch[17] Batch[395] avg_epoch_loss=1.175375\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=395 train loss <loss>=1.28043656349\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] Epoch[17] Batch [395]#011Speed: 1607.56 samples/sec#011loss=1.280437\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] Epoch[17] Batch[400] avg_epoch_loss=1.173186\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=400 train loss <loss>=0.999831163883\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] Epoch[17] Batch [400]#011Speed: 12822.08 samples/sec#011loss=0.999831\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] Epoch[17] Batch[405] avg_epoch_loss=1.171739\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=405 train loss <loss>=1.05565882921\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] Epoch[17] Batch [405]#011Speed: 1760.19 samples/sec#011loss=1.055659\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] Epoch[17] Batch[410] avg_epoch_loss=1.168518\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=410 train loss <loss>=0.90695977211\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] Epoch[17] Batch [410]#011Speed: 13777.65 samples/sec#011loss=0.906960\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] Epoch[17] Batch[415] avg_epoch_loss=1.167419\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=415 train loss <loss>=1.07706130743\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] Epoch[17] Batch [415]#011Speed: 13195.34 samples/sec#011loss=1.077061\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] Epoch[17] Batch[420] avg_epoch_loss=1.169212\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=420 train loss <loss>=1.31839843988\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] Epoch[17] Batch [420]#011Speed: 1696.06 samples/sec#011loss=1.318398\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] Epoch[17] Batch[425] avg_epoch_loss=1.167663\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=425 train loss <loss>=1.03726826906\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] Epoch[17] Batch [425]#011Speed: 13235.68 samples/sec#011loss=1.037268\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] Epoch[17] Batch[430] avg_epoch_loss=1.166416\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=430 train loss <loss>=1.06018413305\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:49 INFO 140088046479168] Epoch[17] Batch [430]#011Speed: 13167.12 samples/sec#011loss=1.060184\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] Epoch[17] Batch[435] avg_epoch_loss=1.166523\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=435 train loss <loss>=1.17575521469\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] Epoch[17] Batch [435]#011Speed: 1648.07 samples/sec#011loss=1.175755\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] Epoch[17] Batch[440] avg_epoch_loss=1.168810\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=440 train loss <loss>=1.36823700666\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] Epoch[17] Batch [440]#011Speed: 14167.55 samples/sec#011loss=1.368237\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] Epoch[17] Batch[445] avg_epoch_loss=1.171223\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=445 train loss <loss>=1.3840116024\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] Epoch[17] Batch [445]#011Speed: 1799.67 samples/sec#011loss=1.384012\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] Epoch[17] Batch[450] avg_epoch_loss=1.174169\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=450 train loss <loss>=1.43693053722\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] Epoch[17] Batch [450]#011Speed: 13242.34 samples/sec#011loss=1.436931\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] Epoch[17] Batch[455] avg_epoch_loss=1.175790\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=455 train loss <loss>=1.32201037407\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] Epoch[17] Batch [455]#011Speed: 13234.64 samples/sec#011loss=1.322010\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] Epoch[17] Batch[460] avg_epoch_loss=1.177118\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=460 train loss <loss>=1.29825394154\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] Epoch[17] Batch [460]#011Speed: 1689.38 samples/sec#011loss=1.298254\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] Epoch[17] Batch[465] avg_epoch_loss=1.179596\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=465 train loss <loss>=1.40808119774\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] Epoch[17] Batch [465]#011Speed: 13218.73 samples/sec#011loss=1.408081\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] Epoch[17] Batch[470] avg_epoch_loss=1.180050\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=470 train loss <loss>=1.2223451972\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] Epoch[17] Batch [470]#011Speed: 1789.07 samples/sec#011loss=1.222345\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] Epoch[17] Batch[475] avg_epoch_loss=1.179610\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=475 train loss <loss>=1.13815076351\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] Epoch[17] Batch [475]#011Speed: 13224.20 samples/sec#011loss=1.138151\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] Epoch[17] Batch[480] avg_epoch_loss=1.181854\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=480 train loss <loss>=1.39554538727\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] Epoch[17] Batch [480]#011Speed: 13176.30 samples/sec#011loss=1.395545\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] Epoch[17] Batch[485] avg_epoch_loss=1.186311\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=485 train loss <loss>=1.61501047611\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] Epoch[17] Batch [485]#011Speed: 1762.16 samples/sec#011loss=1.615010\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] Epoch[17] Batch[490] avg_epoch_loss=1.189439\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=490 train loss <loss>=1.49351644516\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:50 INFO 140088046479168] Epoch[17] Batch [490]#011Speed: 13619.80 samples/sec#011loss=1.493516\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] Epoch[17] Batch[495] avg_epoch_loss=1.192703\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=495 train loss <loss>=1.51325531006\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] Epoch[17] Batch [495]#011Speed: 1743.93 samples/sec#011loss=1.513255\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] Epoch[17] Batch[500] avg_epoch_loss=1.194231\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=500 train loss <loss>=1.34573905468\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] Epoch[17] Batch [500]#011Speed: 13720.33 samples/sec#011loss=1.345739\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] Epoch[17] Batch[505] avg_epoch_loss=1.194845\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=505 train loss <loss>=1.2564261198\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] Epoch[17] Batch [505]#011Speed: 14603.17 samples/sec#011loss=1.256426\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] Epoch[17] Batch[510] avg_epoch_loss=1.196621\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=510 train loss <loss>=1.37632293701\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] Epoch[17] Batch [510]#011Speed: 1811.53 samples/sec#011loss=1.376323\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] Epoch[17] Batch[515] avg_epoch_loss=1.196077\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=515 train loss <loss>=1.14047088623\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] Epoch[17] Batch [515]#011Speed: 14291.56 samples/sec#011loss=1.140471\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] Epoch[17] Batch[520] avg_epoch_loss=1.196015\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=520 train loss <loss>=1.18962218761\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] Epoch[17] Batch [520]#011Speed: 1777.85 samples/sec#011loss=1.189622\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] Epoch[17] Batch[525] avg_epoch_loss=1.195889\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=525 train loss <loss>=1.18272140026\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] Epoch[17] Batch [525]#011Speed: 13544.49 samples/sec#011loss=1.182721\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] Epoch[17] Batch[530] avg_epoch_loss=1.194296\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=530 train loss <loss>=1.02672592402\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] Epoch[17] Batch [530]#011Speed: 1688.32 samples/sec#011loss=1.026726\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] Epoch[17] Batch[535] avg_epoch_loss=1.195043\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=535 train loss <loss>=1.27436548471\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] Epoch[17] Batch [535]#011Speed: 13235.81 samples/sec#011loss=1.274365\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] Epoch[17] Batch[540] avg_epoch_loss=1.193334\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=540 train loss <loss>=1.01014649868\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] Epoch[17] Batch [540]#011Speed: 13154.73 samples/sec#011loss=1.010146\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] Epoch[17] Batch[545] avg_epoch_loss=1.192163\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=545 train loss <loss>=1.06549376249\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] Epoch[17] Batch [545]#011Speed: 1687.14 samples/sec#011loss=1.065494\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] Epoch[17] Batch[550] avg_epoch_loss=1.190280\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=550 train loss <loss>=0.98460470438\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:51 INFO 140088046479168] Epoch[17] Batch [550]#011Speed: 13195.34 samples/sec#011loss=0.984605\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] Epoch[17] Batch[555] avg_epoch_loss=1.189507\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=555 train loss <loss>=1.10433000326\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] Epoch[17] Batch [555]#011Speed: 13157.96 samples/sec#011loss=1.104330\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] Epoch[17] Batch[560] avg_epoch_loss=1.187512\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=560 train loss <loss>=0.965733885765\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] Epoch[17] Batch [560]#011Speed: 1766.15 samples/sec#011loss=0.965734\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] Epoch[17] Batch[565] avg_epoch_loss=1.186782\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=565 train loss <loss>=1.10483514071\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] Epoch[17] Batch [565]#011Speed: 13807.41 samples/sec#011loss=1.104835\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] Epoch[17] Batch[570] avg_epoch_loss=1.184303\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=570 train loss <loss>=0.903639543056\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] Epoch[17] Batch [570]#011Speed: 1640.84 samples/sec#011loss=0.903640\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] Epoch[17] Batch[575] avg_epoch_loss=1.182572\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=575 train loss <loss>=0.984892833233\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] Epoch[17] Batch [575]#011Speed: 11873.79 samples/sec#011loss=0.984893\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] Epoch[17] Batch[580] avg_epoch_loss=1.180769\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=580 train loss <loss>=0.973088109493\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] Epoch[17] Batch [580]#011Speed: 14027.63 samples/sec#011loss=0.973088\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] Epoch[17] Batch[585] avg_epoch_loss=1.177967\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=585 train loss <loss>=0.852433025837\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] Epoch[17] Batch [585]#011Speed: 1731.84 samples/sec#011loss=0.852433\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] Epoch[17] Batch[590] avg_epoch_loss=1.176004\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=590 train loss <loss>=0.945956587791\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] Epoch[17] Batch [590]#011Speed: 14043.77 samples/sec#011loss=0.945957\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] Epoch[17] Batch[595] avg_epoch_loss=1.174269\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=595 train loss <loss>=0.969190406799\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] Epoch[17] Batch [595]#011Speed: 1661.67 samples/sec#011loss=0.969190\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] Epoch[17] Batch[600] avg_epoch_loss=1.173726\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=600 train loss <loss>=1.10895510912\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] Epoch[17] Batch [600]#011Speed: 12834.96 samples/sec#011loss=1.108955\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] Epoch[17] Batch[605] avg_epoch_loss=1.172716\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=605 train loss <loss>=1.05128444433\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:52 INFO 140088046479168] Epoch[17] Batch [605]#011Speed: 13013.92 samples/sec#011loss=1.051284\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] Epoch[17] Batch[610] avg_epoch_loss=1.171881\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=610 train loss <loss>=1.07067614794\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] Epoch[17] Batch [610]#011Speed: 1849.11 samples/sec#011loss=1.070676\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] Epoch[17] Batch[615] avg_epoch_loss=1.174501\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=615 train loss <loss>=1.49474767447\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] Epoch[17] Batch [615]#011Speed: 14374.82 samples/sec#011loss=1.494748\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] Epoch[17] Batch[620] avg_epoch_loss=1.179281\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=620 train loss <loss>=1.76806511879\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] Epoch[17] Batch [620]#011Speed: 1767.04 samples/sec#011loss=1.768065\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] Epoch[17] Batch[625] avg_epoch_loss=1.180682\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=625 train loss <loss>=1.35470409393\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] Epoch[17] Batch [625]#011Speed: 14008.59 samples/sec#011loss=1.354704\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] Epoch[17] Batch[630] avg_epoch_loss=1.178426\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=630 train loss <loss>=0.895995402336\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] Epoch[17] Batch [630]#011Speed: 14266.64 samples/sec#011loss=0.895995\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] Epoch[17] Batch[635] avg_epoch_loss=1.177640\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=635 train loss <loss>=1.07849714756\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] Epoch[17] Batch [635]#011Speed: 1640.96 samples/sec#011loss=1.078497\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] Epoch[17] Batch[640] avg_epoch_loss=1.175924\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=640 train loss <loss>=0.957586109638\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] Epoch[17] Batch [640]#011Speed: 13724.96 samples/sec#011loss=0.957586\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] Epoch[17] Batch[645] avg_epoch_loss=1.174010\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=645 train loss <loss>=0.928686141968\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] Epoch[17] Batch [645]#011Speed: 1611.69 samples/sec#011loss=0.928686\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] Epoch[17] Batch[650] avg_epoch_loss=1.172120\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=650 train loss <loss>=0.927866971493\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] Epoch[17] Batch [650]#011Speed: 12946.63 samples/sec#011loss=0.927867\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] Epoch[17] Batch[655] avg_epoch_loss=1.169683\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=655 train loss <loss>=0.852476215363\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] Epoch[17] Batch [655]#011Speed: 12930.79 samples/sec#011loss=0.852476\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] Epoch[17] Batch[660] avg_epoch_loss=1.166886\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=660 train loss <loss>=0.799931633472\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:53 INFO 140088046479168] Epoch[17] Batch [660]#011Speed: 1734.56 samples/sec#011loss=0.799932\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] Epoch[17] Batch[665] avg_epoch_loss=1.165771\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=665 train loss <loss>=1.01827658415\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] Epoch[17] Batch [665]#011Speed: 14669.41 samples/sec#011loss=1.018277\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] Epoch[17] Batch[670] avg_epoch_loss=1.167502\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=670 train loss <loss>=1.39813270569\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] Epoch[17] Batch [670]#011Speed: 14602.53 samples/sec#011loss=1.398133\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] Epoch[17] Batch[675] avg_epoch_loss=1.167637\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=675 train loss <loss>=1.18570491076\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] Epoch[17] Batch [675]#011Speed: 1681.68 samples/sec#011loss=1.185705\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] Epoch[17] Batch[680] avg_epoch_loss=1.168124\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=680 train loss <loss>=1.23398376703\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] Epoch[17] Batch [680]#011Speed: 13176.82 samples/sec#011loss=1.233984\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] Epoch[17] Batch[685] avg_epoch_loss=1.169384\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=685 train loss <loss>=1.34101655483\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] Epoch[17] Batch [685]#011Speed: 1729.85 samples/sec#011loss=1.341017\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] Epoch[17] Batch[690] avg_epoch_loss=1.173547\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=690 train loss <loss>=1.74467966557\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] Epoch[17] Batch [690]#011Speed: 12543.60 samples/sec#011loss=1.744680\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] Epoch[17] Batch[695] avg_epoch_loss=1.179026\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=695 train loss <loss>=1.93626909256\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] Epoch[17] Batch [695]#011Speed: 12606.39 samples/sec#011loss=1.936269\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] Epoch[17] Batch[700] avg_epoch_loss=1.184602\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=700 train loss <loss>=1.96075085402\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] Epoch[17] Batch [700]#011Speed: 1701.32 samples/sec#011loss=1.960751\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] Epoch[17] Batch[705] avg_epoch_loss=1.188587\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=705 train loss <loss>=1.74726932049\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] Epoch[17] Batch [705]#011Speed: 14319.00 samples/sec#011loss=1.747269\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] Epoch[17] Batch[710] avg_epoch_loss=1.191852\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=710 train loss <loss>=1.65288193226\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] Epoch[17] Batch [710]#011Speed: 1687.83 samples/sec#011loss=1.652882\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] Epoch[17] Batch[715] avg_epoch_loss=1.194517\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=715 train loss <loss>=1.57346994877\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] Epoch[17] Batch [715]#011Speed: 13148.16 samples/sec#011loss=1.573470\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] Epoch[17] Batch[720] avg_epoch_loss=1.199410\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=720 train loss <loss>=1.90011763573\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:54 INFO 140088046479168] Epoch[17] Batch [720]#011Speed: 13214.96 samples/sec#011loss=1.900118\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] Epoch[17] Batch[725] avg_epoch_loss=1.201341\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=725 train loss <loss>=1.47981259823\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] Epoch[17] Batch [725]#011Speed: 1751.56 samples/sec#011loss=1.479813\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] Epoch[17] Batch[730] avg_epoch_loss=1.202284\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=730 train loss <loss>=1.33916739225\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] Epoch[17] Batch [730]#011Speed: 13817.51 samples/sec#011loss=1.339167\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] Epoch[17] Batch[735] avg_epoch_loss=1.203255\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=735 train loss <loss>=1.34521279335\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] Epoch[17] Batch [735]#011Speed: 13659.45 samples/sec#011loss=1.345213\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] Epoch[17] Batch[740] avg_epoch_loss=1.203693\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=740 train loss <loss>=1.26810204983\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] Epoch[17] Batch [740]#011Speed: 1720.92 samples/sec#011loss=1.268102\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] Epoch[17] Batch[745] avg_epoch_loss=1.201750\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=745 train loss <loss>=0.91387283802\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] Epoch[17] Batch [745]#011Speed: 14267.25 samples/sec#011loss=0.913873\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] Epoch[17] Batch[750] avg_epoch_loss=1.200653\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=750 train loss <loss>=1.03704504967\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] Epoch[17] Batch [750]#011Speed: 1744.01 samples/sec#011loss=1.037045\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] Epoch[17] Batch[755] avg_epoch_loss=1.199967\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=755 train loss <loss>=1.09681557417\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] Epoch[17] Batch [755]#011Speed: 14297.19 samples/sec#011loss=1.096816\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] Epoch[17] Batch[760] avg_epoch_loss=1.198886\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=760 train loss <loss>=1.03542090654\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] Epoch[17] Batch [760]#011Speed: 1888.64 samples/sec#011loss=1.035421\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] Epoch[17] Batch[765] avg_epoch_loss=1.197728\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=765 train loss <loss>=1.02159574032\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] Epoch[17] Batch [765]#011Speed: 14411.87 samples/sec#011loss=1.021596\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] Epoch[17] Batch[770] avg_epoch_loss=1.198227\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=770 train loss <loss>=1.27456681728\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] Epoch[17] Batch [770]#011Speed: 14547.45 samples/sec#011loss=1.274567\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] Epoch[17] Batch[775] avg_epoch_loss=1.197559\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=775 train loss <loss>=1.09459398985\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] Epoch[17] Batch [775]#011Speed: 1811.15 samples/sec#011loss=1.094594\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] Epoch[17] Batch[780] avg_epoch_loss=1.197154\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=780 train loss <loss>=1.13437182903\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:55 INFO 140088046479168] Epoch[17] Batch [780]#011Speed: 13230.33 samples/sec#011loss=1.134372\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] Epoch[17] Batch[785] avg_epoch_loss=1.196081\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=785 train loss <loss>=1.02836828232\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] Epoch[17] Batch [785]#011Speed: 1819.11 samples/sec#011loss=1.028368\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] Epoch[17] Batch[790] avg_epoch_loss=1.197111\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=790 train loss <loss>=1.35914142132\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] Epoch[17] Batch [790]#011Speed: 13246.65 samples/sec#011loss=1.359141\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] Epoch[17] Batch[795] avg_epoch_loss=1.196928\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=795 train loss <loss>=1.16785048246\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] Epoch[17] Batch [795]#011Speed: 13840.16 samples/sec#011loss=1.167850\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] Epoch[17] Batch[800] avg_epoch_loss=1.198393\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=800 train loss <loss>=1.43163738251\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] Epoch[17] Batch [800]#011Speed: 1550.85 samples/sec#011loss=1.431637\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] Epoch[17] Batch[805] avg_epoch_loss=1.198753\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=805 train loss <loss>=1.25642819405\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] Epoch[17] Batch [805]#011Speed: 12929.30 samples/sec#011loss=1.256428\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] Epoch[17] Batch[810] avg_epoch_loss=1.198239\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=810 train loss <loss>=1.11536204815\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] Epoch[17] Batch [810]#011Speed: 1594.86 samples/sec#011loss=1.115362\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] Epoch[17] Batch[815] avg_epoch_loss=1.198450\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=815 train loss <loss>=1.23274388313\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] Epoch[17] Batch [815]#011Speed: 14250.13 samples/sec#011loss=1.232744\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] Epoch[17] Batch[820] avg_epoch_loss=1.198891\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=820 train loss <loss>=1.27088592052\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] Epoch[17] Batch [820]#011Speed: 1790.67 samples/sec#011loss=1.270886\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] Epoch[17] Batch[825] avg_epoch_loss=1.198397\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=825 train loss <loss>=1.11720354557\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] Epoch[17] Batch [825]#011Speed: 14168.75 samples/sec#011loss=1.117204\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] Epoch[17] Batch[830] avg_epoch_loss=1.196835\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=830 train loss <loss>=0.938818341494\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:56 INFO 140088046479168] Epoch[17] Batch [830]#011Speed: 14583.18 samples/sec#011loss=0.938818\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] Epoch[17] Batch[835] avg_epoch_loss=1.196470\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=835 train loss <loss>=1.13575210571\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] Epoch[17] Batch [835]#011Speed: 1769.05 samples/sec#011loss=1.135752\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] Epoch[17] Batch[840] avg_epoch_loss=1.195527\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=840 train loss <loss>=1.03785310984\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] Epoch[17] Batch [840]#011Speed: 13844.44 samples/sec#011loss=1.037853\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] Epoch[17] Batch[845] avg_epoch_loss=1.195313\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=845 train loss <loss>=1.15932538509\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] Epoch[17] Batch [845]#011Speed: 14302.37 samples/sec#011loss=1.159325\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] Epoch[17] Batch[850] avg_epoch_loss=1.195862\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=850 train loss <loss>=1.28886562586\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] Epoch[17] Batch [850]#011Speed: 1722.23 samples/sec#011loss=1.288866\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] Epoch[17] Batch[855] avg_epoch_loss=1.199124\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=855 train loss <loss>=1.75429552794\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] Epoch[17] Batch [855]#011Speed: 13209.50 samples/sec#011loss=1.754296\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] Epoch[17] Batch[860] avg_epoch_loss=1.198994\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=860 train loss <loss>=1.17666243315\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] Epoch[17] Batch [860]#011Speed: 1694.42 samples/sec#011loss=1.176662\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] Epoch[17] Batch[865] avg_epoch_loss=1.199111\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=865 train loss <loss>=1.21937408447\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] Epoch[17] Batch [865]#011Speed: 13365.64 samples/sec#011loss=1.219374\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] Epoch[17] Batch[870] avg_epoch_loss=1.196365\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=870 train loss <loss>=0.720614981651\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] Epoch[17] Batch [870]#011Speed: 13184.97 samples/sec#011loss=0.720615\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] Epoch[17] Batch[875] avg_epoch_loss=1.194321\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=875 train loss <loss>=0.838406908512\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] Epoch[17] Batch [875]#011Speed: 1720.33 samples/sec#011loss=0.838407\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] Epoch[17] Batch[880] avg_epoch_loss=1.194051\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=880 train loss <loss>=1.14676035643\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] Epoch[17] Batch [880]#011Speed: 14470.45 samples/sec#011loss=1.146760\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] Epoch[17] Batch[885] avg_epoch_loss=1.194020\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=885 train loss <loss>=1.18847929239\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] Epoch[17] Batch [885]#011Speed: 1590.31 samples/sec#011loss=1.188479\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] Epoch[17] Batch[890] avg_epoch_loss=1.193870\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=890 train loss <loss>=1.16729915142\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:57 INFO 140088046479168] Epoch[17] Batch [890]#011Speed: 14229.13 samples/sec#011loss=1.167299\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] Epoch[17] Batch[895] avg_epoch_loss=1.194624\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=895 train loss <loss>=1.32902641296\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] Epoch[17] Batch [895]#011Speed: 14236.83 samples/sec#011loss=1.329026\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] Epoch[17] Batch[900] avg_epoch_loss=1.194553\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, batch=900 train loss <loss>=1.18177351952\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] Epoch[17] Batch [900]#011Speed: 6541.81 samples/sec#011loss=1.181774\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] processed a total of 57671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15937.122106552124, \"sum\": 15937.122106552124, \"min\": 15937.122106552124}}, \"EndTime\": 1604320678.073406, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320662.135842}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] #throughput_metric: host=algo-1, train throughput=3618.63068814 records/second\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=17, train loss <loss>=1.19390961931\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] Saved checkpoint to \"/opt/ml/model/state_936e7a5f-b5f6-45e6-827c-d057c37849ce-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 6.904125213623047, \"sum\": 6.904125213623047, \"min\": 6.904125213623047}}, \"EndTime\": 1604320678.080895, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320678.073488}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] Epoch[18] Batch[0] avg_epoch_loss=1.729288\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=1.72928774357\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] Epoch[18] Batch[5] avg_epoch_loss=1.844809\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=1.84480917454\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] Epoch[18] Batch [5]#011Speed: 14369.74 samples/sec#011loss=1.844809\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] Epoch[18] Batch[10] avg_epoch_loss=1.735227\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=1.6037273407\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] Epoch[18] Batch [10]#011Speed: 14433.26 samples/sec#011loss=1.603727\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] Epoch[18] Batch[15] avg_epoch_loss=1.624617\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=15 train loss <loss>=1.3812766552\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] Epoch[18] Batch [15]#011Speed: 1877.30 samples/sec#011loss=1.381277\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] Epoch[18] Batch[20] avg_epoch_loss=1.546587\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=20 train loss <loss>=1.29688926935\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] Epoch[18] Batch [20]#011Speed: 12338.12 samples/sec#011loss=1.296889\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] Epoch[18] Batch[25] avg_epoch_loss=1.485747\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=25 train loss <loss>=1.23021994829\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] Epoch[18] Batch [25]#011Speed: 1780.87 samples/sec#011loss=1.230220\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] Epoch[18] Batch[30] avg_epoch_loss=1.438081\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=30 train loss <loss>=1.19021708965\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] Epoch[18] Batch [30]#011Speed: 13940.93 samples/sec#011loss=1.190217\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] Epoch[18] Batch[35] avg_epoch_loss=1.386589\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=35 train loss <loss>=1.0673417449\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] Epoch[18] Batch [35]#011Speed: 14238.04 samples/sec#011loss=1.067342\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] Epoch[18] Batch[40] avg_epoch_loss=1.340591\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=40 train loss <loss>=1.00940191746\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] Epoch[18] Batch [40]#011Speed: 1584.35 samples/sec#011loss=1.009402\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] Epoch[18] Batch[45] avg_epoch_loss=1.321390\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=45 train loss <loss>=1.16393992901\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:58 INFO 140088046479168] Epoch[18] Batch [45]#011Speed: 14083.85 samples/sec#011loss=1.163940\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] Epoch[18] Batch[50] avg_epoch_loss=1.292216\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=50 train loss <loss>=1.0238224268\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] Epoch[18] Batch [50]#011Speed: 1873.38 samples/sec#011loss=1.023822\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] Epoch[18] Batch[55] avg_epoch_loss=1.270827\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=55 train loss <loss>=1.05265089273\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] Epoch[18] Batch [55]#011Speed: 14391.16 samples/sec#011loss=1.052651\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] Epoch[18] Batch[60] avg_epoch_loss=1.246440\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=60 train loss <loss>=0.973306870461\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] Epoch[18] Batch [60]#011Speed: 14200.23 samples/sec#011loss=0.973307\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] Epoch[18] Batch[65] avg_epoch_loss=1.232692\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=65 train loss <loss>=1.06497513056\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] Epoch[18] Batch [65]#011Speed: 1892.17 samples/sec#011loss=1.064975\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] Epoch[18] Batch[70] avg_epoch_loss=1.223851\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=70 train loss <loss>=1.10714771748\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] Epoch[18] Batch [70]#011Speed: 13891.87 samples/sec#011loss=1.107148\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] Epoch[18] Batch[75] avg_epoch_loss=1.219963\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=75 train loss <loss>=1.16475511789\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] Epoch[18] Batch [75]#011Speed: 1736.75 samples/sec#011loss=1.164755\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] Epoch[18] Batch[80] avg_epoch_loss=1.219665\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=80 train loss <loss>=1.21513215303\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] Epoch[18] Batch [80]#011Speed: 14649.23 samples/sec#011loss=1.215132\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] Epoch[18] Batch[85] avg_epoch_loss=1.225611\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=85 train loss <loss>=1.32194061279\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] Epoch[18] Batch [85]#011Speed: 12817.43 samples/sec#011loss=1.321941\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] Epoch[18] Batch[90] avg_epoch_loss=1.243209\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=90 train loss <loss>=1.5458864212\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] Epoch[18] Batch [90]#011Speed: 1807.21 samples/sec#011loss=1.545886\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] Epoch[18] Batch[95] avg_epoch_loss=1.235929\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=95 train loss <loss>=1.10343334675\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] Epoch[18] Batch [95]#011Speed: 14467.17 samples/sec#011loss=1.103433\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] Epoch[18] Batch[100] avg_epoch_loss=1.226420\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=100 train loss <loss>=1.04383984804\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:37:59 INFO 140088046479168] Epoch[18] Batch [100]#011Speed: 1765.78 samples/sec#011loss=1.043840\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] Epoch[18] Batch[105] avg_epoch_loss=1.209181\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=105 train loss <loss>=0.860966801643\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] Epoch[18] Batch [105]#011Speed: 14247.41 samples/sec#011loss=0.860967\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] Epoch[18] Batch[110] avg_epoch_loss=1.203289\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=110 train loss <loss>=1.07837722301\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] Epoch[18] Batch [110]#011Speed: 14121.05 samples/sec#011loss=1.078377\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] Epoch[18] Batch[115] avg_epoch_loss=1.202563\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=115 train loss <loss>=1.18643410206\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] Epoch[18] Batch [115]#011Speed: 1653.93 samples/sec#011loss=1.186434\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] Epoch[18] Batch[120] avg_epoch_loss=1.197472\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=120 train loss <loss>=1.07935932875\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] Epoch[18] Batch [120]#011Speed: 13278.63 samples/sec#011loss=1.079359\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] Epoch[18] Batch[125] avg_epoch_loss=1.199953\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=125 train loss <loss>=1.2599950552\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] Epoch[18] Batch [125]#011Speed: 1809.08 samples/sec#011loss=1.259995\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] Epoch[18] Batch[130] avg_epoch_loss=1.192904\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=130 train loss <loss>=1.01528052092\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] Epoch[18] Batch [130]#011Speed: 14552.66 samples/sec#011loss=1.015281\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] Epoch[18] Batch[135] avg_epoch_loss=1.189959\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=135 train loss <loss>=1.11278779507\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] Epoch[18] Batch [135]#011Speed: 14542.10 samples/sec#011loss=1.112788\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] Epoch[18] Batch[140] avg_epoch_loss=1.183743\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=140 train loss <loss>=1.01467376947\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] Epoch[18] Batch [140]#011Speed: 1813.00 samples/sec#011loss=1.014674\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] Epoch[18] Batch[145] avg_epoch_loss=1.181969\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=145 train loss <loss>=1.13194508553\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] Epoch[18] Batch [145]#011Speed: 14398.11 samples/sec#011loss=1.131945\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] Epoch[18] Batch[150] avg_epoch_loss=1.182083\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=150 train loss <loss>=1.18542324305\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] Epoch[18] Batch [150]#011Speed: 1652.64 samples/sec#011loss=1.185423\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] Epoch[18] Batch[155] avg_epoch_loss=1.178901\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=155 train loss <loss>=1.08280371428\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] Epoch[18] Batch [155]#011Speed: 14453.46 samples/sec#011loss=1.082804\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] Epoch[18] Batch[160] avg_epoch_loss=1.180932\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=160 train loss <loss>=1.24429820776\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:00 INFO 140088046479168] Epoch[18] Batch [160]#011Speed: 14408.00 samples/sec#011loss=1.244298\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] Epoch[18] Batch[165] avg_epoch_loss=1.173923\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=165 train loss <loss>=0.948234033585\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] Epoch[18] Batch [165]#011Speed: 1674.72 samples/sec#011loss=0.948234\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] Epoch[18] Batch[170] avg_epoch_loss=1.175114\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=170 train loss <loss>=1.21463512182\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] Epoch[18] Batch [170]#011Speed: 13592.77 samples/sec#011loss=1.214635\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] Epoch[18] Batch[175] avg_epoch_loss=1.190525\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=175 train loss <loss>=1.71757748127\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] Epoch[18] Batch [175]#011Speed: 1614.72 samples/sec#011loss=1.717577\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] Epoch[18] Batch[180] avg_epoch_loss=1.199507\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=180 train loss <loss>=1.51568162441\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] Epoch[18] Batch [180]#011Speed: 16638.91 samples/sec#011loss=1.515682\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] Epoch[18] Batch[185] avg_epoch_loss=1.205572\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=185 train loss <loss>=1.42514806986\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] Epoch[18] Batch [185]#011Speed: 15039.75 samples/sec#011loss=1.425148\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] Epoch[18] Batch[190] avg_epoch_loss=1.209096\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=190 train loss <loss>=1.34017636776\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] Epoch[18] Batch [190]#011Speed: 1711.67 samples/sec#011loss=1.340176\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] Epoch[18] Batch[195] avg_epoch_loss=1.222860\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=195 train loss <loss>=1.7486335516\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] Epoch[18] Batch [195]#011Speed: 11641.45 samples/sec#011loss=1.748634\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] Epoch[18] Batch[200] avg_epoch_loss=1.234243\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=200 train loss <loss>=1.68048138618\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] Epoch[18] Batch [200]#011Speed: 12660.14 samples/sec#011loss=1.680481\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] Epoch[18] Batch[205] avg_epoch_loss=1.241507\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=205 train loss <loss>=1.53351831436\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] Epoch[18] Batch [205]#011Speed: 1706.77 samples/sec#011loss=1.533518\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] Epoch[18] Batch[210] avg_epoch_loss=1.244237\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=210 train loss <loss>=1.35668783188\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] Epoch[18] Batch [210]#011Speed: 14105.02 samples/sec#011loss=1.356688\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] Epoch[18] Batch[215] avg_epoch_loss=1.251211\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=215 train loss <loss>=1.54554111958\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:01 INFO 140088046479168] Epoch[18] Batch [215]#011Speed: 1776.43 samples/sec#011loss=1.545541\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] Epoch[18] Batch[220] avg_epoch_loss=1.257826\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=220 train loss <loss>=1.5435603857\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] Epoch[18] Batch [220]#011Speed: 14311.98 samples/sec#011loss=1.543560\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] Epoch[18] Batch[225] avg_epoch_loss=1.258894\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=225 train loss <loss>=1.30613458157\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] Epoch[18] Batch [225]#011Speed: 14414.96 samples/sec#011loss=1.306135\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] Epoch[18] Batch[230] avg_epoch_loss=1.267319\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=230 train loss <loss>=1.64812483788\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] Epoch[18] Batch [230]#011Speed: 1558.46 samples/sec#011loss=1.648125\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] Epoch[18] Batch[235] avg_epoch_loss=1.274663\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=235 train loss <loss>=1.61393656731\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] Epoch[18] Batch [235]#011Speed: 13408.77 samples/sec#011loss=1.613937\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] Epoch[18] Batch[240] avg_epoch_loss=1.279922\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=240 train loss <loss>=1.52816333771\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] Epoch[18] Batch [240]#011Speed: 1727.98 samples/sec#011loss=1.528163\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] Epoch[18] Batch[245] avg_epoch_loss=1.281739\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=245 train loss <loss>=1.36932160854\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] Epoch[18] Batch [245]#011Speed: 14208.95 samples/sec#011loss=1.369322\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] Epoch[18] Batch[250] avg_epoch_loss=1.282414\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=250 train loss <loss>=1.31558654308\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] Epoch[18] Batch [250]#011Speed: 14405.37 samples/sec#011loss=1.315587\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] Epoch[18] Batch[255] avg_epoch_loss=1.282555\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=255 train loss <loss>=1.28966078758\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] Epoch[18] Batch [255]#011Speed: 1692.55 samples/sec#011loss=1.289661\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] Epoch[18] Batch[260] avg_epoch_loss=1.286188\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=260 train loss <loss>=1.47216989994\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] Epoch[18] Batch [260]#011Speed: 14310.76 samples/sec#011loss=1.472170\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] Epoch[18] Batch[265] avg_epoch_loss=1.287253\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=265 train loss <loss>=1.34286627769\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] Epoch[18] Batch [265]#011Speed: 1795.12 samples/sec#011loss=1.342866\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] Epoch[18] Batch[270] avg_epoch_loss=1.285056\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=270 train loss <loss>=1.16818722486\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] Epoch[18] Batch [270]#011Speed: 13280.73 samples/sec#011loss=1.168187\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] Epoch[18] Batch[275] avg_epoch_loss=1.283425\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=275 train loss <loss>=1.19501538277\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:02 INFO 140088046479168] Epoch[18] Batch [275]#011Speed: 13276.92 samples/sec#011loss=1.195015\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] Epoch[18] Batch[280] avg_epoch_loss=1.279031\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=280 train loss <loss>=1.03645350933\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] Epoch[18] Batch [280]#011Speed: 1767.41 samples/sec#011loss=1.036454\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] Epoch[18] Batch[285] avg_epoch_loss=1.275615\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=285 train loss <loss>=1.08364344835\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] Epoch[18] Batch [285]#011Speed: 13231.37 samples/sec#011loss=1.083643\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] Epoch[18] Batch[290] avg_epoch_loss=1.271789\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=290 train loss <loss>=1.05296013355\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] Epoch[18] Batch [290]#011Speed: 1817.63 samples/sec#011loss=1.052960\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] Epoch[18] Batch[295] avg_epoch_loss=1.265559\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=295 train loss <loss>=0.90295766592\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] Epoch[18] Batch [295]#011Speed: 12812.78 samples/sec#011loss=0.902958\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] Epoch[18] Batch[300] avg_epoch_loss=1.263675\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=300 train loss <loss>=1.15215579271\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] Epoch[18] Batch [300]#011Speed: 14130.56 samples/sec#011loss=1.152156\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] Epoch[18] Batch[305] avg_epoch_loss=1.259102\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=305 train loss <loss>=0.98379817009\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] Epoch[18] Batch [305]#011Speed: 1656.48 samples/sec#011loss=0.983798\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] Epoch[18] Batch[310] avg_epoch_loss=1.252329\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=310 train loss <loss>=0.83783929348\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] Epoch[18] Batch [310]#011Speed: 11543.92 samples/sec#011loss=0.837839\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] Epoch[18] Batch[315] avg_epoch_loss=1.247914\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=315 train loss <loss>=0.97329928875\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] Epoch[18] Batch [315]#011Speed: 1859.98 samples/sec#011loss=0.973299\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] Epoch[18] Batch[320] avg_epoch_loss=1.244511\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=320 train loss <loss>=1.02942863703\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] Epoch[18] Batch [320]#011Speed: 14214.06 samples/sec#011loss=1.029429\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] Epoch[18] Batch[325] avg_epoch_loss=1.240511\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=325 train loss <loss>=0.983732163906\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] Epoch[18] Batch [325]#011Speed: 14268.62 samples/sec#011loss=0.983732\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] Epoch[18] Batch[330] avg_epoch_loss=1.237383\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=330 train loss <loss>=1.03342891932\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:03 INFO 140088046479168] Epoch[18] Batch [330]#011Speed: 1837.31 samples/sec#011loss=1.033429\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] Epoch[18] Batch[335] avg_epoch_loss=1.234959\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=335 train loss <loss>=1.07450467348\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] Epoch[18] Batch [335]#011Speed: 13267.47 samples/sec#011loss=1.074505\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] Epoch[18] Batch[340] avg_epoch_loss=1.234106\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=340 train loss <loss>=1.1767464757\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] Epoch[18] Batch [340]#011Speed: 1641.72 samples/sec#011loss=1.176746\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] Epoch[18] Batch[345] avg_epoch_loss=1.232355\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=345 train loss <loss>=1.11292461157\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] Epoch[18] Batch [345]#011Speed: 13773.55 samples/sec#011loss=1.112925\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] Epoch[18] Batch[350] avg_epoch_loss=1.229012\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=350 train loss <loss>=0.997691130638\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] Epoch[18] Batch [350]#011Speed: 14384.07 samples/sec#011loss=0.997691\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] Epoch[18] Batch[355] avg_epoch_loss=1.224831\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=355 train loss <loss>=0.931325399876\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] Epoch[18] Batch [355]#011Speed: 1649.49 samples/sec#011loss=0.931325\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] Epoch[18] Batch[360] avg_epoch_loss=1.222073\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=360 train loss <loss>=1.02573013306\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] Epoch[18] Batch [360]#011Speed: 14256.49 samples/sec#011loss=1.025730\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] Epoch[18] Batch[365] avg_epoch_loss=1.218420\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=365 train loss <loss>=0.954661440849\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] Epoch[18] Batch [365]#011Speed: 14144.26 samples/sec#011loss=0.954661\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] Epoch[18] Batch[370] avg_epoch_loss=1.214624\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=370 train loss <loss>=0.936758482456\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] Epoch[18] Batch [370]#011Speed: 1787.97 samples/sec#011loss=0.936758\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] Epoch[18] Batch[375] avg_epoch_loss=1.213984\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=375 train loss <loss>=1.16646723747\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] Epoch[18] Batch [375]#011Speed: 14466.55 samples/sec#011loss=1.166467\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] Epoch[18] Batch[380] avg_epoch_loss=1.215365\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=380 train loss <loss>=1.31927249432\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] Epoch[18] Batch [380]#011Speed: 1662.83 samples/sec#011loss=1.319272\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] Epoch[18] Batch[385] avg_epoch_loss=1.224427\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=385 train loss <loss>=1.91489195824\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] Epoch[18] Batch [385]#011Speed: 14333.07 samples/sec#011loss=1.914892\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] Epoch[18] Batch[390] avg_epoch_loss=1.225052\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=390 train loss <loss>=1.27330043316\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:04 INFO 140088046479168] Epoch[18] Batch [390]#011Speed: 14027.77 samples/sec#011loss=1.273300\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] Epoch[18] Batch[395] avg_epoch_loss=1.231700\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=395 train loss <loss>=1.75161325932\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] Epoch[18] Batch [395]#011Speed: 1656.24 samples/sec#011loss=1.751613\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] Epoch[18] Batch[400] avg_epoch_loss=1.231713\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=400 train loss <loss>=1.2327136755\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] Epoch[18] Batch [400]#011Speed: 13584.65 samples/sec#011loss=1.232714\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] Epoch[18] Batch[405] avg_epoch_loss=1.233591\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=405 train loss <loss>=1.384230268\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] Epoch[18] Batch [405]#011Speed: 1802.49 samples/sec#011loss=1.384230\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] Epoch[18] Batch[410] avg_epoch_loss=1.237420\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=410 train loss <loss>=1.54833698273\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] Epoch[18] Batch [410]#011Speed: 14460.78 samples/sec#011loss=1.548337\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] Epoch[18] Batch[415] avg_epoch_loss=1.242684\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=415 train loss <loss>=1.67538352013\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] Epoch[18] Batch [415]#011Speed: 14482.31 samples/sec#011loss=1.675384\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] Epoch[18] Batch[420] avg_epoch_loss=1.240330\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=420 train loss <loss>=1.04446280003\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] Epoch[18] Batch [420]#011Speed: 1647.50 samples/sec#011loss=1.044463\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] Epoch[18] Batch[425] avg_epoch_loss=1.237095\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=425 train loss <loss>=0.964749336243\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] Epoch[18] Batch [425]#011Speed: 13934.85 samples/sec#011loss=0.964749\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] Epoch[18] Batch[430] avg_epoch_loss=1.237733\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=430 train loss <loss>=1.29206790924\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] Epoch[18] Batch [430]#011Speed: 1707.80 samples/sec#011loss=1.292068\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] Epoch[18] Batch[435] avg_epoch_loss=1.238988\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=435 train loss <loss>=1.34719219208\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] Epoch[18] Batch [435]#011Speed: 14465.30 samples/sec#011loss=1.347192\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] Epoch[18] Batch[440] avg_epoch_loss=1.238919\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=440 train loss <loss>=1.23283131123\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] Epoch[18] Batch [440]#011Speed: 14422.86 samples/sec#011loss=1.232831\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] Epoch[18] Batch[445] avg_epoch_loss=1.239972\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=445 train loss <loss>=1.33289928436\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:05 INFO 140088046479168] Epoch[18] Batch [445]#011Speed: 1750.75 samples/sec#011loss=1.332899\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] Epoch[18] Batch[450] avg_epoch_loss=1.240045\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=450 train loss <loss>=1.24658321142\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] Epoch[18] Batch [450]#011Speed: 14244.39 samples/sec#011loss=1.246583\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] Epoch[18] Batch[455] avg_epoch_loss=1.240415\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=455 train loss <loss>=1.27377003431\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] Epoch[18] Batch [455]#011Speed: 1674.47 samples/sec#011loss=1.273770\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] Epoch[18] Batch[460] avg_epoch_loss=1.241105\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=460 train loss <loss>=1.30405777693\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] Epoch[18] Batch [460]#011Speed: 14358.83 samples/sec#011loss=1.304058\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] Epoch[18] Batch[465] avg_epoch_loss=1.242100\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=465 train loss <loss>=1.33383386135\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] Epoch[18] Batch [465]#011Speed: 14086.37 samples/sec#011loss=1.333834\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] Epoch[18] Batch[470] avg_epoch_loss=1.241117\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=470 train loss <loss>=1.14946721792\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] Epoch[18] Batch [470]#011Speed: 1692.32 samples/sec#011loss=1.149467\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] Epoch[18] Batch[475] avg_epoch_loss=1.240440\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=475 train loss <loss>=1.17663135529\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] Epoch[18] Batch [475]#011Speed: 14411.09 samples/sec#011loss=1.176631\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] Epoch[18] Batch[480] avg_epoch_loss=1.241082\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=480 train loss <loss>=1.30220274925\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] Epoch[18] Batch [480]#011Speed: 14176.83 samples/sec#011loss=1.302203\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] Epoch[18] Batch[485] avg_epoch_loss=1.241456\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=485 train loss <loss>=1.27750182152\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] Epoch[18] Batch [485]#011Speed: 1703.72 samples/sec#011loss=1.277502\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] Epoch[18] Batch[490] avg_epoch_loss=1.240745\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=490 train loss <loss>=1.17160387039\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] Epoch[18] Batch [490]#011Speed: 13137.86 samples/sec#011loss=1.171604\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] Epoch[18] Batch[495] avg_epoch_loss=1.240940\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=495 train loss <loss>=1.26005897522\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] Epoch[18] Batch [495]#011Speed: 1828.22 samples/sec#011loss=1.260059\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] Epoch[18] Batch[500] avg_epoch_loss=1.238727\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=500 train loss <loss>=1.01917870045\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] Epoch[18] Batch [500]#011Speed: 13254.37 samples/sec#011loss=1.019179\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] Epoch[18] Batch[505] avg_epoch_loss=1.238823\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=505 train loss <loss>=1.24849942923\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:06 INFO 140088046479168] Epoch[18] Batch [505]#011Speed: 13144.43 samples/sec#011loss=1.248499\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] Epoch[18] Batch[510] avg_epoch_loss=1.236731\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=510 train loss <loss>=1.02502926588\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] Epoch[18] Batch [510]#011Speed: 1812.85 samples/sec#011loss=1.025029\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] Epoch[18] Batch[515] avg_epoch_loss=1.236552\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=515 train loss <loss>=1.21820516586\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] Epoch[18] Batch [515]#011Speed: 13212.75 samples/sec#011loss=1.218205\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] Epoch[18] Batch[520] avg_epoch_loss=1.235925\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=520 train loss <loss>=1.17119545937\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] Epoch[18] Batch [520]#011Speed: 1756.85 samples/sec#011loss=1.171195\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] Epoch[18] Batch[525] avg_epoch_loss=1.235910\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=525 train loss <loss>=1.23436388969\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] Epoch[18] Batch [525]#011Speed: 13088.54 samples/sec#011loss=1.234364\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] Epoch[18] Batch[530] avg_epoch_loss=1.234539\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=530 train loss <loss>=1.09034680128\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] Epoch[18] Batch [530]#011Speed: 13326.62 samples/sec#011loss=1.090347\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] Epoch[18] Batch[535] avg_epoch_loss=1.234601\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=535 train loss <loss>=1.2412113905\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] Epoch[18] Batch [535]#011Speed: 1694.91 samples/sec#011loss=1.241211\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] Epoch[18] Batch[540] avg_epoch_loss=1.233590\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=540 train loss <loss>=1.125202775\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] Epoch[18] Batch [540]#011Speed: 14257.70 samples/sec#011loss=1.125203\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] Epoch[18] Batch[545] avg_epoch_loss=1.233236\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=545 train loss <loss>=1.19492417574\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] Epoch[18] Batch [545]#011Speed: 1751.97 samples/sec#011loss=1.194924\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] Epoch[18] Batch[550] avg_epoch_loss=1.233620\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=550 train loss <loss>=1.27556631565\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] Epoch[18] Batch [550]#011Speed: 13668.77 samples/sec#011loss=1.275566\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] Epoch[18] Batch[555] avg_epoch_loss=1.233157\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=555 train loss <loss>=1.18210333586\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] Epoch[18] Batch [555]#011Speed: 14446.30 samples/sec#011loss=1.182103\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] Epoch[18] Batch[560] avg_epoch_loss=1.231798\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=560 train loss <loss>=1.08071630001\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:07 INFO 140088046479168] Epoch[18] Batch [560]#011Speed: 1702.34 samples/sec#011loss=1.080716\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] Epoch[18] Batch[565] avg_epoch_loss=1.230862\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=565 train loss <loss>=1.1257617712\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] Epoch[18] Batch [565]#011Speed: 14267.25 samples/sec#011loss=1.125762\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] Epoch[18] Batch[570] avg_epoch_loss=1.230817\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=570 train loss <loss>=1.22573599815\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] Epoch[18] Batch [570]#011Speed: 1732.04 samples/sec#011loss=1.225736\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] Epoch[18] Batch[575] avg_epoch_loss=1.231493\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=575 train loss <loss>=1.30869009495\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] Epoch[18] Batch [575]#011Speed: 14362.06 samples/sec#011loss=1.308690\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] Epoch[18] Batch[580] avg_epoch_loss=1.230055\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=580 train loss <loss>=1.06443637609\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] Epoch[18] Batch [580]#011Speed: 14343.33 samples/sec#011loss=1.064436\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] Epoch[18] Batch[585] avg_epoch_loss=1.232357\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=585 train loss <loss>=1.499832654\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] Epoch[18] Batch [585]#011Speed: 1762.08 samples/sec#011loss=1.499833\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] Epoch[18] Batch[590] avg_epoch_loss=1.232651\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=590 train loss <loss>=1.26707880497\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] Epoch[18] Batch [590]#011Speed: 14420.23 samples/sec#011loss=1.267079\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] Epoch[18] Batch[595] avg_epoch_loss=1.233477\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=595 train loss <loss>=1.33118844032\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] Epoch[18] Batch [595]#011Speed: 1671.34 samples/sec#011loss=1.331188\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] Epoch[18] Batch[600] avg_epoch_loss=1.233558\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=600 train loss <loss>=1.24317715168\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] Epoch[18] Batch [600]#011Speed: 12950.25 samples/sec#011loss=1.243177\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] Epoch[18] Batch[605] avg_epoch_loss=1.232807\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=605 train loss <loss>=1.14256579876\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] Epoch[18] Batch [605]#011Speed: 12706.40 samples/sec#011loss=1.142566\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] Epoch[18] Batch[610] avg_epoch_loss=1.231714\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=610 train loss <loss>=1.0992382884\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] Epoch[18] Batch [610]#011Speed: 1586.24 samples/sec#011loss=1.099238\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] Epoch[18] Batch[615] avg_epoch_loss=1.230566\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=615 train loss <loss>=1.09028222561\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] Epoch[18] Batch [615]#011Speed: 13301.13 samples/sec#011loss=1.090282\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] Epoch[18] Batch[620] avg_epoch_loss=1.230353\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=620 train loss <loss>=1.20402570963\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:08 INFO 140088046479168] Epoch[18] Batch [620]#011Speed: 13208.46 samples/sec#011loss=1.204026\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] Epoch[18] Batch[625] avg_epoch_loss=1.231348\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=625 train loss <loss>=1.35503185987\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] Epoch[18] Batch [625]#011Speed: 1788.88 samples/sec#011loss=1.355032\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] Epoch[18] Batch[630] avg_epoch_loss=1.232012\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=630 train loss <loss>=1.3150883317\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] Epoch[18] Batch [630]#011Speed: 14229.89 samples/sec#011loss=1.315088\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] Epoch[18] Batch[635] avg_epoch_loss=1.232798\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=635 train loss <loss>=1.33196775913\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] Epoch[18] Batch [635]#011Speed: 1792.34 samples/sec#011loss=1.331968\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] Epoch[18] Batch[640] avg_epoch_loss=1.233389\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=640 train loss <loss>=1.30864882469\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] Epoch[18] Batch [640]#011Speed: 14314.42 samples/sec#011loss=1.308649\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] Epoch[18] Batch[645] avg_epoch_loss=1.235784\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=645 train loss <loss>=1.5427806139\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] Epoch[18] Batch [645]#011Speed: 14246.96 samples/sec#011loss=1.542781\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] Epoch[18] Batch[650] avg_epoch_loss=1.234973\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=650 train loss <loss>=1.13023480177\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] Epoch[18] Batch [650]#011Speed: 1872.83 samples/sec#011loss=1.130235\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] Epoch[18] Batch[655] avg_epoch_loss=1.235303\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=655 train loss <loss>=1.27828247547\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] Epoch[18] Batch [655]#011Speed: 14483.56 samples/sec#011loss=1.278282\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] Epoch[18] Batch[660] avg_epoch_loss=1.236152\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=660 train loss <loss>=1.34748226404\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] Epoch[18] Batch [660]#011Speed: 1595.75 samples/sec#011loss=1.347482\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] Epoch[18] Batch[665] avg_epoch_loss=1.237371\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=665 train loss <loss>=1.39845348597\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] Epoch[18] Batch [665]#011Speed: 12574.15 samples/sec#011loss=1.398453\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] Epoch[18] Batch[670] avg_epoch_loss=1.237680\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=670 train loss <loss>=1.27896840572\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] Epoch[18] Batch [670]#011Speed: 9980.05 samples/sec#011loss=1.278968\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] Epoch[18] Batch[675] avg_epoch_loss=1.238174\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=675 train loss <loss>=1.30441424847\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:09 INFO 140088046479168] Epoch[18] Batch [675]#011Speed: 1809.98 samples/sec#011loss=1.304414\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] Epoch[18] Batch[680] avg_epoch_loss=1.237515\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=680 train loss <loss>=1.14844284058\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] Epoch[18] Batch [680]#011Speed: 13504.96 samples/sec#011loss=1.148443\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] Epoch[18] Batch[685] avg_epoch_loss=1.238818\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=685 train loss <loss>=1.41625277996\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] Epoch[18] Batch [685]#011Speed: 1673.03 samples/sec#011loss=1.416253\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] Epoch[18] Batch[690] avg_epoch_loss=1.239762\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=690 train loss <loss>=1.36926064491\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] Epoch[18] Batch [690]#011Speed: 13283.49 samples/sec#011loss=1.369261\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] Epoch[18] Batch[695] avg_epoch_loss=1.240266\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=695 train loss <loss>=1.30989599228\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] Epoch[18] Batch [695]#011Speed: 13300.08 samples/sec#011loss=1.309896\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] Epoch[18] Batch[700] avg_epoch_loss=1.240725\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=700 train loss <loss>=1.30469615459\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] Epoch[18] Batch [700]#011Speed: 1773.12 samples/sec#011loss=1.304696\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] Epoch[18] Batch[705] avg_epoch_loss=1.242659\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=705 train loss <loss>=1.51377630234\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] Epoch[18] Batch [705]#011Speed: 13932.40 samples/sec#011loss=1.513776\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] Epoch[18] Batch[710] avg_epoch_loss=1.242565\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=710 train loss <loss>=1.22932264805\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] Epoch[18] Batch [710]#011Speed: 1706.58 samples/sec#011loss=1.229323\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] Epoch[18] Batch[715] avg_epoch_loss=1.242335\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=715 train loss <loss>=1.20962543488\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] Epoch[18] Batch [715]#011Speed: 13258.17 samples/sec#011loss=1.209625\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] Epoch[18] Batch[720] avg_epoch_loss=1.241175\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=720 train loss <loss>=1.07506127357\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] Epoch[18] Batch [720]#011Speed: 11352.74 samples/sec#011loss=1.075061\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] Epoch[18] Batch[725] avg_epoch_loss=1.240138\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=725 train loss <loss>=1.09061378241\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] Epoch[18] Batch [725]#011Speed: 1650.45 samples/sec#011loss=1.090614\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] Epoch[18] Batch[730] avg_epoch_loss=1.239373\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=730 train loss <loss>=1.12818940878\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:10 INFO 140088046479168] Epoch[18] Batch [730]#011Speed: 14179.38 samples/sec#011loss=1.128189\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] Epoch[18] Batch[735] avg_epoch_loss=1.239086\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=735 train loss <loss>=1.19722213745\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] Epoch[18] Batch [735]#011Speed: 1680.04 samples/sec#011loss=1.197222\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] Epoch[18] Batch[740] avg_epoch_loss=1.239327\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=740 train loss <loss>=1.27470595837\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] Epoch[18] Batch [740]#011Speed: 14277.42 samples/sec#011loss=1.274706\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] Epoch[18] Batch[745] avg_epoch_loss=1.240352\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=745 train loss <loss>=1.39230384827\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] Epoch[18] Batch [745]#011Speed: 14203.99 samples/sec#011loss=1.392304\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] Epoch[18] Batch[750] avg_epoch_loss=1.240603\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=750 train loss <loss>=1.27799991369\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] Epoch[18] Batch [750]#011Speed: 1704.02 samples/sec#011loss=1.278000\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] Epoch[18] Batch[755] avg_epoch_loss=1.240909\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=755 train loss <loss>=1.28686999083\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] Epoch[18] Batch [755]#011Speed: 13156.15 samples/sec#011loss=1.286870\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] Epoch[18] Batch[760] avg_epoch_loss=1.239851\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=760 train loss <loss>=1.07999593019\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] Epoch[18] Batch [760]#011Speed: 1854.41 samples/sec#011loss=1.079996\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] Epoch[18] Batch[765] avg_epoch_loss=1.239337\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=765 train loss <loss>=1.16101336479\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] Epoch[18] Batch [765]#011Speed: 13126.56 samples/sec#011loss=1.161013\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] Epoch[18] Batch[770] avg_epoch_loss=1.239143\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=770 train loss <loss>=1.20951333046\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] Epoch[18] Batch [770]#011Speed: 14264.67 samples/sec#011loss=1.209513\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] Epoch[18] Batch[775] avg_epoch_loss=1.240136\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=775 train loss <loss>=1.39328151941\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] Epoch[18] Batch [775]#011Speed: 1605.19 samples/sec#011loss=1.393282\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] Epoch[18] Batch[780] avg_epoch_loss=1.240250\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=780 train loss <loss>=1.25792682171\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] Epoch[18] Batch [780]#011Speed: 14242.42 samples/sec#011loss=1.257927\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] Epoch[18] Batch[785] avg_epoch_loss=1.239838\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=785 train loss <loss>=1.17541142702\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:11 INFO 140088046479168] Epoch[18] Batch [785]#011Speed: 14171.89 samples/sec#011loss=1.175411\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] Epoch[18] Batch[790] avg_epoch_loss=1.241103\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=790 train loss <loss>=1.44003493786\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] Epoch[18] Batch [790]#011Speed: 1719.80 samples/sec#011loss=1.440035\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] Epoch[18] Batch[795] avg_epoch_loss=1.242043\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=795 train loss <loss>=1.39068682194\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] Epoch[18] Batch [795]#011Speed: 14336.28 samples/sec#011loss=1.390687\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] Epoch[18] Batch[800] avg_epoch_loss=1.242415\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=800 train loss <loss>=1.30171682835\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] Epoch[18] Batch [800]#011Speed: 1807.88 samples/sec#011loss=1.301717\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] Epoch[18] Batch[805] avg_epoch_loss=1.242673\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=805 train loss <loss>=1.28397111893\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] Epoch[18] Batch [805]#011Speed: 13874.35 samples/sec#011loss=1.283971\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] Epoch[18] Batch[810] avg_epoch_loss=1.243533\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=810 train loss <loss>=1.38211810589\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] Epoch[18] Batch [810]#011Speed: 14420.23 samples/sec#011loss=1.382118\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] Epoch[18] Batch[815] avg_epoch_loss=1.242851\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=815 train loss <loss>=1.1322551012\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] Epoch[18] Batch [815]#011Speed: 1618.06 samples/sec#011loss=1.132255\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] Epoch[18] Batch[820] avg_epoch_loss=1.243112\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=820 train loss <loss>=1.28562203646\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] Epoch[18] Batch [820]#011Speed: 14216.62 samples/sec#011loss=1.285622\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] Epoch[18] Batch[825] avg_epoch_loss=1.243413\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=825 train loss <loss>=1.29292763472\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] Epoch[18] Batch [825]#011Speed: 1892.48 samples/sec#011loss=1.292928\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] Epoch[18] Batch[830] avg_epoch_loss=1.243425\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=830 train loss <loss>=1.24544616938\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] Epoch[18] Batch [830]#011Speed: 13163.38 samples/sec#011loss=1.245446\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] Epoch[18] Batch[835] avg_epoch_loss=1.242461\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=835 train loss <loss>=1.08211450577\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] Epoch[18] Batch [835]#011Speed: 13605.45 samples/sec#011loss=1.082115\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] Epoch[18] Batch[840] avg_epoch_loss=1.242888\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=840 train loss <loss>=1.31435718536\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] Epoch[18] Batch [840]#011Speed: 1534.34 samples/sec#011loss=1.314357\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] Epoch[18] Batch[845] avg_epoch_loss=1.242322\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=845 train loss <loss>=1.1470864296\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:12 INFO 140088046479168] Epoch[18] Batch [845]#011Speed: 14288.21 samples/sec#011loss=1.147086\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] Epoch[18] Batch[850] avg_epoch_loss=1.244006\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=850 train loss <loss>=1.52897307873\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] Epoch[18] Batch [850]#011Speed: 1793.11 samples/sec#011loss=1.528973\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] Epoch[18] Batch[855] avg_epoch_loss=1.243843\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=855 train loss <loss>=1.21611686945\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] Epoch[18] Batch [855]#011Speed: 13316.04 samples/sec#011loss=1.216117\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] Epoch[18] Batch[860] avg_epoch_loss=1.242425\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=860 train loss <loss>=0.999599957466\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] Epoch[18] Batch [860]#011Speed: 14464.68 samples/sec#011loss=0.999600\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] Epoch[18] Batch[865] avg_epoch_loss=1.241054\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=865 train loss <loss>=1.00495005846\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] Epoch[18] Batch [865]#011Speed: 1876.43 samples/sec#011loss=1.004950\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] Epoch[18] Batch[870] avg_epoch_loss=1.239713\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=870 train loss <loss>=1.00755161047\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] Epoch[18] Batch [870]#011Speed: 13316.70 samples/sec#011loss=1.007552\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] Epoch[18] Batch[875] avg_epoch_loss=1.238505\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=875 train loss <loss>=1.02801555395\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] Epoch[18] Batch [875]#011Speed: 1698.59 samples/sec#011loss=1.028016\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] Epoch[18] Batch[880] avg_epoch_loss=1.237880\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=880 train loss <loss>=1.12832087278\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] Epoch[18] Batch [880]#011Speed: 14293.38 samples/sec#011loss=1.128321\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] Epoch[18] Batch[885] avg_epoch_loss=1.236117\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=885 train loss <loss>=0.925583779812\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] Epoch[18] Batch [885]#011Speed: 13405.95 samples/sec#011loss=0.925584\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] Epoch[18] Batch[890] avg_epoch_loss=1.236638\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=890 train loss <loss>=1.32885813713\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] Epoch[18] Batch [890]#011Speed: 1681.31 samples/sec#011loss=1.328858\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] Epoch[18] Batch[895] avg_epoch_loss=1.236813\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=895 train loss <loss>=1.26812032461\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] Epoch[18] Batch [895]#011Speed: 13213.92 samples/sec#011loss=1.268120\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] Epoch[18] Batch[900] avg_epoch_loss=1.235221\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, batch=900 train loss <loss>=0.949821591377\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] Epoch[18] Batch [900]#011Speed: 7175.04 samples/sec#011loss=0.949822\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] processed a total of 57661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15758.157968521118, \"sum\": 15758.157968521118, \"min\": 15758.157968521118}}, \"EndTime\": 1604320693.839169, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320678.080954}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] #throughput_metric: host=algo-1, train throughput=3659.09266983 records/second\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] #progress_metric: host=algo-1, completed 95 % of epochs\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] #quality_metric: host=algo-1, epoch=18, train loss <loss>=1.23522067222\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:13 INFO 140088046479168] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] Epoch[19] Batch[0] avg_epoch_loss=1.391486\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=1.39148616791\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] Epoch[19] Batch[5] avg_epoch_loss=1.202064\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=1.20206384857\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] Epoch[19] Batch [5]#011Speed: 14611.91 samples/sec#011loss=1.202064\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] Epoch[19] Batch[10] avg_epoch_loss=1.169019\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=1.12936577797\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] Epoch[19] Batch [10]#011Speed: 14420.85 samples/sec#011loss=1.129366\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] Epoch[19] Batch[15] avg_epoch_loss=1.109650\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=15 train loss <loss>=0.979037296772\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] Epoch[19] Batch [15]#011Speed: 1554.55 samples/sec#011loss=0.979037\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] Epoch[19] Batch[20] avg_epoch_loss=1.126029\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=20 train loss <loss>=1.17844173908\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] Epoch[19] Batch [20]#011Speed: 14178.78 samples/sec#011loss=1.178442\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] Epoch[19] Batch[25] avg_epoch_loss=1.119658\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=25 train loss <loss>=1.09290242195\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] Epoch[19] Batch [25]#011Speed: 14259.67 samples/sec#011loss=1.092902\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] Epoch[19] Batch[30] avg_epoch_loss=1.119875\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=30 train loss <loss>=1.12099957466\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] Epoch[19] Batch [30]#011Speed: 1798.43 samples/sec#011loss=1.121000\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] Epoch[19] Batch[35] avg_epoch_loss=1.133372\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=35 train loss <loss>=1.21705547571\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] Epoch[19] Batch [35]#011Speed: 13283.49 samples/sec#011loss=1.217055\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] Epoch[19] Batch[40] avg_epoch_loss=1.126495\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=40 train loss <loss>=1.07698235512\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] Epoch[19] Batch [40]#011Speed: 1859.99 samples/sec#011loss=1.076982\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] Epoch[19] Batch[45] avg_epoch_loss=1.133824\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=45 train loss <loss>=1.19391965866\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] Epoch[19] Batch [45]#011Speed: 13232.42 samples/sec#011loss=1.193920\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] Epoch[19] Batch[50] avg_epoch_loss=1.119054\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=50 train loss <loss>=0.983174610138\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] Epoch[19] Batch [50]#011Speed: 1655.27 samples/sec#011loss=0.983175\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] Epoch[19] Batch[55] avg_epoch_loss=1.109889\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=55 train loss <loss>=1.01640547514\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] Epoch[19] Batch [55]#011Speed: 14090.66 samples/sec#011loss=1.016405\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] Epoch[19] Batch[60] avg_epoch_loss=1.094424\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=60 train loss <loss>=0.921216082573\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:14 INFO 140088046479168] Epoch[19] Batch [60]#011Speed: 14393.63 samples/sec#011loss=0.921216\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] Epoch[19] Batch[65] avg_epoch_loss=1.110894\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=65 train loss <loss>=1.31182268262\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] Epoch[19] Batch [65]#011Speed: 1640.75 samples/sec#011loss=1.311823\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] Epoch[19] Batch[70] avg_epoch_loss=1.139427\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=70 train loss <loss>=1.51606278419\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] Epoch[19] Batch [70]#011Speed: 14555.97 samples/sec#011loss=1.516063\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] Epoch[19] Batch[75] avg_epoch_loss=1.190734\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=75 train loss <loss>=1.91928799152\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] Epoch[19] Batch [75]#011Speed: 14310.60 samples/sec#011loss=1.919288\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] Epoch[19] Batch[80] avg_epoch_loss=1.238124\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=80 train loss <loss>=1.95845656395\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] Epoch[19] Batch [80]#011Speed: 1812.80 samples/sec#011loss=1.958457\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] Epoch[19] Batch[85] avg_epoch_loss=1.251016\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=85 train loss <loss>=1.45986344814\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] Epoch[19] Batch [85]#011Speed: 14053.48 samples/sec#011loss=1.459863\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] Epoch[19] Batch[90] avg_epoch_loss=1.257692\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=90 train loss <loss>=1.37251722813\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] Epoch[19] Batch [90]#011Speed: 1662.46 samples/sec#011loss=1.372517\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] Epoch[19] Batch[95] avg_epoch_loss=1.260308\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=95 train loss <loss>=1.30792531967\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] Epoch[19] Batch [95]#011Speed: 14310.60 samples/sec#011loss=1.307925\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] Epoch[19] Batch[100] avg_epoch_loss=1.250823\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=100 train loss <loss>=1.06872001886\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] Epoch[19] Batch [100]#011Speed: 14229.74 samples/sec#011loss=1.068720\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] Epoch[19] Batch[105] avg_epoch_loss=1.253515\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=105 train loss <loss>=1.30788142681\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] Epoch[19] Batch [105]#011Speed: 1750.72 samples/sec#011loss=1.307881\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] Epoch[19] Batch[110] avg_epoch_loss=1.251970\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=110 train loss <loss>=1.21922059059\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:15 INFO 140088046479168] Epoch[19] Batch [110]#011Speed: 14220.99 samples/sec#011loss=1.219221\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] Epoch[19] Batch[115] avg_epoch_loss=1.258552\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=115 train loss <loss>=1.40467329025\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] Epoch[19] Batch [115]#011Speed: 1684.35 samples/sec#011loss=1.404673\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] Epoch[19] Batch[120] avg_epoch_loss=1.253537\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=120 train loss <loss>=1.1371966958\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] Epoch[19] Batch [120]#011Speed: 13183.29 samples/sec#011loss=1.137197\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] Epoch[19] Batch[125] avg_epoch_loss=1.256925\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=125 train loss <loss>=1.33891203403\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] Epoch[19] Batch [125]#011Speed: 14376.21 samples/sec#011loss=1.338912\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] Epoch[19] Batch[130] avg_epoch_loss=1.266667\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=130 train loss <loss>=1.51216986179\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] Epoch[19] Batch [130]#011Speed: 1626.47 samples/sec#011loss=1.512170\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] Epoch[19] Batch[135] avg_epoch_loss=1.261119\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=135 train loss <loss>=1.11574174166\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] Epoch[19] Batch [135]#011Speed: 14293.38 samples/sec#011loss=1.115742\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] Epoch[19] Batch[140] avg_epoch_loss=1.260940\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=140 train loss <loss>=1.25606946945\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] Epoch[19] Batch [140]#011Speed: 1859.55 samples/sec#011loss=1.256069\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] Epoch[19] Batch[145] avg_epoch_loss=1.261903\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=145 train loss <loss>=1.28906655312\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] Epoch[19] Batch [145]#011Speed: 14238.04 samples/sec#011loss=1.289067\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] Epoch[19] Batch[150] avg_epoch_loss=1.261341\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=150 train loss <loss>=1.2449468255\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] Epoch[19] Batch [150]#011Speed: 14166.81 samples/sec#011loss=1.244947\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] Epoch[19] Batch[155] avg_epoch_loss=1.262016\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=155 train loss <loss>=1.28238537312\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] Epoch[19] Batch [155]#011Speed: 1808.41 samples/sec#011loss=1.282385\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] Epoch[19] Batch[160] avg_epoch_loss=1.269459\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=160 train loss <loss>=1.50169277191\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] Epoch[19] Batch [160]#011Speed: 14392.40 samples/sec#011loss=1.501693\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] Epoch[19] Batch[165] avg_epoch_loss=1.264448\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=165 train loss <loss>=1.1030761838\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] Epoch[19] Batch [165]#011Speed: 1707.02 samples/sec#011loss=1.103076\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] Epoch[19] Batch[170] avg_epoch_loss=1.267375\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=170 train loss <loss>=1.36454885006\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] Epoch[19] Batch [170]#011Speed: 14238.04 samples/sec#011loss=1.364549\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] Epoch[19] Batch[175] avg_epoch_loss=1.267046\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=175 train loss <loss>=1.25580945015\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:16 INFO 140088046479168] Epoch[19] Batch [175]#011Speed: 14394.40 samples/sec#011loss=1.255809\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] Epoch[19] Batch[180] avg_epoch_loss=1.266007\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=180 train loss <loss>=1.22942218781\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] Epoch[19] Batch [180]#011Speed: 1604.04 samples/sec#011loss=1.229422\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] Epoch[19] Batch[185] avg_epoch_loss=1.264624\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=185 train loss <loss>=1.21456537247\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] Epoch[19] Batch [185]#011Speed: 14088.29 samples/sec#011loss=1.214565\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] Epoch[19] Batch[190] avg_epoch_loss=1.258317\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=190 train loss <loss>=1.02368197441\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] Epoch[19] Batch [190]#011Speed: 1628.06 samples/sec#011loss=1.023682\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] Epoch[19] Batch[195] avg_epoch_loss=1.267228\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=195 train loss <loss>=1.60766074657\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] Epoch[19] Batch [195]#011Speed: 14203.23 samples/sec#011loss=1.607661\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] Epoch[19] Batch[200] avg_epoch_loss=1.262157\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=200 train loss <loss>=1.06335513592\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] Epoch[19] Batch [200]#011Speed: 14403.98 samples/sec#011loss=1.063355\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] Epoch[19] Batch[205] avg_epoch_loss=1.263472\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=205 train loss <loss>=1.31631777287\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] Epoch[19] Batch [205]#011Speed: 1681.77 samples/sec#011loss=1.316318\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] Epoch[19] Batch[210] avg_epoch_loss=1.266997\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=210 train loss <loss>=1.41225454807\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] Epoch[19] Batch [210]#011Speed: 14295.97 samples/sec#011loss=1.412255\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] Epoch[19] Batch[215] avg_epoch_loss=1.265700\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=215 train loss <loss>=1.21093921661\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] Epoch[19] Batch [215]#011Speed: 14311.83 samples/sec#011loss=1.210939\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] Epoch[19] Batch[220] avg_epoch_loss=1.264598\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=220 train loss <loss>=1.21700819731\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] Epoch[19] Batch [220]#011Speed: 1789.82 samples/sec#011loss=1.217008\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] Epoch[19] Batch[225] avg_epoch_loss=1.265321\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=225 train loss <loss>=1.29726178646\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:17 INFO 140088046479168] Epoch[19] Batch [225]#011Speed: 14639.96 samples/sec#011loss=1.297262\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] Epoch[19] Batch[230] avg_epoch_loss=1.267955\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=230 train loss <loss>=1.38701664209\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] Epoch[19] Batch [230]#011Speed: 1700.76 samples/sec#011loss=1.387017\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] Epoch[19] Batch[235] avg_epoch_loss=1.267381\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=235 train loss <loss>=1.2408621788\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] Epoch[19] Batch [235]#011Speed: 14283.19 samples/sec#011loss=1.240862\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] Epoch[19] Batch[240] avg_epoch_loss=1.269145\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=240 train loss <loss>=1.35242643356\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] Epoch[19] Batch [240]#011Speed: 13837.88 samples/sec#011loss=1.352426\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] Epoch[19] Batch[245] avg_epoch_loss=1.271217\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=245 train loss <loss>=1.37107658386\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] Epoch[19] Batch [245]#011Speed: 1596.30 samples/sec#011loss=1.371077\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] Epoch[19] Batch[250] avg_epoch_loss=1.275033\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=250 train loss <loss>=1.46278035641\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] Epoch[19] Batch [250]#011Speed: 13286.91 samples/sec#011loss=1.462780\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] Epoch[19] Batch[255] avg_epoch_loss=1.275254\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=255 train loss <loss>=1.28635681868\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] Epoch[19] Batch [255]#011Speed: 1795.88 samples/sec#011loss=1.286357\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] Epoch[19] Batch[260] avg_epoch_loss=1.274679\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=260 train loss <loss>=1.24525635242\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] Epoch[19] Batch [260]#011Speed: 13192.10 samples/sec#011loss=1.245256\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] Epoch[19] Batch[265] avg_epoch_loss=1.274450\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=265 train loss <loss>=1.26247695684\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] Epoch[19] Batch [265]#011Speed: 13311.16 samples/sec#011loss=1.262477\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] Epoch[19] Batch[270] avg_epoch_loss=1.270752\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=270 train loss <loss>=1.07401866913\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] Epoch[19] Batch [270]#011Speed: 1791.12 samples/sec#011loss=1.074019\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] Epoch[19] Batch[275] avg_epoch_loss=1.267983\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=275 train loss <loss>=1.11791585684\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] Epoch[19] Batch [275]#011Speed: 14330.47 samples/sec#011loss=1.117916\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] Epoch[19] Batch[280] avg_epoch_loss=1.265276\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=280 train loss <loss>=1.11580761671\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] Epoch[19] Batch [280]#011Speed: 1735.08 samples/sec#011loss=1.115808\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] Epoch[19] Batch[285] avg_epoch_loss=1.265336\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=285 train loss <loss>=1.26873941422\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] Epoch[19] Batch [285]#011Speed: 14216.47 samples/sec#011loss=1.268739\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] Epoch[19] Batch[290] avg_epoch_loss=1.264362\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=290 train loss <loss>=1.20862305164\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:18 INFO 140088046479168] Epoch[19] Batch [290]#011Speed: 14354.99 samples/sec#011loss=1.208623\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] Epoch[19] Batch[295] avg_epoch_loss=1.261494\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=295 train loss <loss>=1.09459410906\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] Epoch[19] Batch [295]#011Speed: 1813.99 samples/sec#011loss=1.094594\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] Epoch[19] Batch[300] avg_epoch_loss=1.265605\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=300 train loss <loss>=1.50899353027\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] Epoch[19] Batch [300]#011Speed: 13882.25 samples/sec#011loss=1.508994\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] Epoch[19] Batch[305] avg_epoch_loss=1.261575\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=305 train loss <loss>=1.0189399004\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] Epoch[19] Batch [305]#011Speed: 1616.23 samples/sec#011loss=1.018940\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] Epoch[19] Batch[310] avg_epoch_loss=1.258518\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=310 train loss <loss>=1.0714392066\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] Epoch[19] Batch [310]#011Speed: 13349.55 samples/sec#011loss=1.071439\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] Epoch[19] Batch[315] avg_epoch_loss=1.256174\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=315 train loss <loss>=1.11039793491\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] Epoch[19] Batch [315]#011Speed: 14406.61 samples/sec#011loss=1.110398\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] Epoch[19] Batch[320] avg_epoch_loss=1.257403\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=320 train loss <loss>=1.33505110741\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] Epoch[19] Batch [320]#011Speed: 1809.82 samples/sec#011loss=1.335051\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] Epoch[19] Batch[325] avg_epoch_loss=1.256652\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=325 train loss <loss>=1.20847239494\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] Epoch[19] Batch [325]#011Speed: 14294.60 samples/sec#011loss=1.208472\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] Epoch[19] Batch[330] avg_epoch_loss=1.257740\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=330 train loss <loss>=1.32866201401\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] Epoch[19] Batch [330]#011Speed: 1737.17 samples/sec#011loss=1.328662\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] Epoch[19] Batch[335] avg_epoch_loss=1.259383\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=335 train loss <loss>=1.36812002659\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] Epoch[19] Batch [335]#011Speed: 13222.64 samples/sec#011loss=1.368120\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] Epoch[19] Batch[340] avg_epoch_loss=1.257929\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=340 train loss <loss>=1.16025042534\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:19 INFO 140088046479168] Epoch[19] Batch [340]#011Speed: 12408.84 samples/sec#011loss=1.160250\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] Epoch[19] Batch[345] avg_epoch_loss=1.259588\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=345 train loss <loss>=1.37270927429\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] Epoch[19] Batch [345]#011Speed: 1663.76 samples/sec#011loss=1.372709\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] Epoch[19] Batch[350] avg_epoch_loss=1.259846\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=350 train loss <loss>=1.27768218517\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] Epoch[19] Batch [350]#011Speed: 14300.39 samples/sec#011loss=1.277682\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] Epoch[19] Batch[355] avg_epoch_loss=1.259942\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=355 train loss <loss>=1.26671134233\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] Epoch[19] Batch [355]#011Speed: 1838.22 samples/sec#011loss=1.266711\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] Epoch[19] Batch[360] avg_epoch_loss=1.264124\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=360 train loss <loss>=1.56186556816\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] Epoch[19] Batch [360]#011Speed: 13800.74 samples/sec#011loss=1.561866\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] Epoch[19] Batch[365] avg_epoch_loss=1.266247\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=365 train loss <loss>=1.41956746578\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] Epoch[19] Batch [365]#011Speed: 14257.10 samples/sec#011loss=1.419567\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] Epoch[19] Batch[370] avg_epoch_loss=1.265960\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=370 train loss <loss>=1.24495267868\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] Epoch[19] Batch [370]#011Speed: 1812.18 samples/sec#011loss=1.244953\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] Epoch[19] Batch[375] avg_epoch_loss=1.263249\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=375 train loss <loss>=1.06207836866\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] Epoch[19] Batch [375]#011Speed: 13601.31 samples/sec#011loss=1.062078\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] Epoch[19] Batch[380] avg_epoch_loss=1.263285\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=380 train loss <loss>=1.2659715414\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] Epoch[19] Batch [380]#011Speed: 1621.47 samples/sec#011loss=1.265972\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] Epoch[19] Batch[385] avg_epoch_loss=1.263568\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=385 train loss <loss>=1.28514246941\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] Epoch[19] Batch [385]#011Speed: 13245.48 samples/sec#011loss=1.285142\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] Epoch[19] Batch[390] avg_epoch_loss=1.265016\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=390 train loss <loss>=1.37683953047\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] Epoch[19] Batch [390]#011Speed: 13259.21 samples/sec#011loss=1.376840\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] Epoch[19] Batch[395] avg_epoch_loss=1.265466\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=395 train loss <loss>=1.30061607361\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] Epoch[19] Batch [395]#011Speed: 1631.02 samples/sec#011loss=1.300616\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] Epoch[19] Batch[400] avg_epoch_loss=1.266710\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=400 train loss <loss>=1.36525431871\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:20 INFO 140088046479168] Epoch[19] Batch [400]#011Speed: 13563.92 samples/sec#011loss=1.365254\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] Epoch[19] Batch[405] avg_epoch_loss=1.264814\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=405 train loss <loss>=1.11274447441\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] Epoch[19] Batch [405]#011Speed: 1834.33 samples/sec#011loss=1.112744\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] Epoch[19] Batch[410] avg_epoch_loss=1.263523\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=410 train loss <loss>=1.15869898796\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] Epoch[19] Batch [410]#011Speed: 13286.78 samples/sec#011loss=1.158699\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] Epoch[19] Batch[415] avg_epoch_loss=1.265180\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=415 train loss <loss>=1.40139937401\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] Epoch[19] Batch [415]#011Speed: 13179.53 samples/sec#011loss=1.401399\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] Epoch[19] Batch[420] avg_epoch_loss=1.262441\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=420 train loss <loss>=1.03448861837\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] Epoch[19] Batch [420]#011Speed: 1688.00 samples/sec#011loss=1.034489\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] Epoch[19] Batch[425] avg_epoch_loss=1.261279\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=425 train loss <loss>=1.1634834528\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] Epoch[19] Batch [425]#011Speed: 13084.20 samples/sec#011loss=1.163483\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] Epoch[19] Batch[430] avg_epoch_loss=1.260049\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=430 train loss <loss>=1.15529201031\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] Epoch[19] Batch [430]#011Speed: 12866.83 samples/sec#011loss=1.155292\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] Epoch[19] Batch[435] avg_epoch_loss=1.259032\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=435 train loss <loss>=1.17128195763\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] Epoch[19] Batch [435]#011Speed: 1599.67 samples/sec#011loss=1.171282\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] Epoch[19] Batch[440] avg_epoch_loss=1.260022\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=440 train loss <loss>=1.34639045\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] Epoch[19] Batch [440]#011Speed: 14517.09 samples/sec#011loss=1.346390\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] Epoch[19] Batch[445] avg_epoch_loss=1.259378\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=445 train loss <loss>=1.20254089832\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] Epoch[19] Batch [445]#011Speed: 1835.33 samples/sec#011loss=1.202541\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] Epoch[19] Batch[450] avg_epoch_loss=1.259546\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=450 train loss <loss>=1.2745636344\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] Epoch[19] Batch [450]#011Speed: 14251.34 samples/sec#011loss=1.274564\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] Epoch[19] Batch[455] avg_epoch_loss=1.258068\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=455 train loss <loss>=1.12471898794\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:21 INFO 140088046479168] Epoch[19] Batch [455]#011Speed: 13182.25 samples/sec#011loss=1.124719\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] Epoch[19] Batch[460] avg_epoch_loss=1.256293\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=460 train loss <loss>=1.09441201687\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] Epoch[19] Batch [460]#011Speed: 1666.73 samples/sec#011loss=1.094412\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] Epoch[19] Batch[465] avg_epoch_loss=1.255999\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=465 train loss <loss>=1.22895880938\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] Epoch[19] Batch [465]#011Speed: 14393.01 samples/sec#011loss=1.228959\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] Epoch[19] Batch[470] avg_epoch_loss=1.254900\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=470 train loss <loss>=1.15248447657\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] Epoch[19] Batch [470]#011Speed: 14335.06 samples/sec#011loss=1.152484\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] Epoch[19] Batch[475] avg_epoch_loss=1.251268\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=475 train loss <loss>=0.909139752388\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] Epoch[19] Batch [475]#011Speed: 1519.43 samples/sec#011loss=0.909140\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] Epoch[19] Batch[480] avg_epoch_loss=1.249718\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=480 train loss <loss>=1.10208774805\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] Epoch[19] Batch [480]#011Speed: 13275.87 samples/sec#011loss=1.102088\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] Epoch[19] Batch[485] avg_epoch_loss=1.251927\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=485 train loss <loss>=1.46442770958\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] Epoch[19] Batch [485]#011Speed: 1899.65 samples/sec#011loss=1.464428\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] Epoch[19] Batch[490] avg_epoch_loss=1.251473\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=490 train loss <loss>=1.20734434128\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] Epoch[19] Batch [490]#011Speed: 13777.65 samples/sec#011loss=1.207344\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] Epoch[19] Batch[495] avg_epoch_loss=1.251037\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=495 train loss <loss>=1.20827127695\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] Epoch[19] Batch [495]#011Speed: 1763.10 samples/sec#011loss=1.208271\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] Epoch[19] Batch[500] avg_epoch_loss=1.250434\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=500 train loss <loss>=1.19056218863\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] Epoch[19] Batch [500]#011Speed: 13090.71 samples/sec#011loss=1.190562\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] Epoch[19] Batch[505] avg_epoch_loss=1.247454\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=505 train loss <loss>=0.948858177662\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] Epoch[19] Batch [505]#011Speed: 13472.02 samples/sec#011loss=0.948858\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] Epoch[19] Batch[510] avg_epoch_loss=1.243863\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=510 train loss <loss>=0.880525434017\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] Epoch[19] Batch [510]#011Speed: 1846.18 samples/sec#011loss=0.880525\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] Epoch[19] Batch[515] avg_epoch_loss=1.240022\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=515 train loss <loss>=0.847428882122\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:22 INFO 140088046479168] Epoch[19] Batch [515]#011Speed: 14408.00 samples/sec#011loss=0.847429\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] Epoch[19] Batch[520] avg_epoch_loss=1.236459\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=520 train loss <loss>=0.868791103363\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] Epoch[19] Batch [520]#011Speed: 1875.34 samples/sec#011loss=0.868791\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] Epoch[19] Batch[525] avg_epoch_loss=1.233359\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=525 train loss <loss>=0.910261666775\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] Epoch[19] Batch [525]#011Speed: 14302.98 samples/sec#011loss=0.910262\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] Epoch[19] Batch[530] avg_epoch_loss=1.230900\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=530 train loss <loss>=0.972285449505\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] Epoch[19] Batch [530]#011Speed: 14281.22 samples/sec#011loss=0.972285\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] Epoch[19] Batch[535] avg_epoch_loss=1.226571\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=535 train loss <loss>=0.766780185699\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] Epoch[19] Batch [535]#011Speed: 1806.95 samples/sec#011loss=0.766780\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] Epoch[19] Batch[540] avg_epoch_loss=1.223184\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=540 train loss <loss>=0.860143303871\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] Epoch[19] Batch [540]#011Speed: 13358.85 samples/sec#011loss=0.860143\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] Epoch[19] Batch[545] avg_epoch_loss=1.220424\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=545 train loss <loss>=0.921828508377\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] Epoch[19] Batch [545]#011Speed: 1719.11 samples/sec#011loss=0.921829\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] Epoch[19] Batch[550] avg_epoch_loss=1.218350\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=550 train loss <loss>=0.991853404045\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] Epoch[19] Batch [550]#011Speed: 13209.50 samples/sec#011loss=0.991853\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] Epoch[19] Batch[555] avg_epoch_loss=1.217344\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=555 train loss <loss>=1.10641932487\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] Epoch[19] Batch [555]#011Speed: 13060.14 samples/sec#011loss=1.106419\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] Epoch[19] Batch[560] avg_epoch_loss=1.215823\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=560 train loss <loss>=1.04667317867\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] Epoch[19] Batch [560]#011Speed: 1758.75 samples/sec#011loss=1.046673\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] Epoch[19] Batch[565] avg_epoch_loss=1.215412\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=565 train loss <loss>=1.1693505466\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] Epoch[19] Batch [565]#011Speed: 14261.49 samples/sec#011loss=1.169351\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] Epoch[19] Batch[570] avg_epoch_loss=1.221576\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=570 train loss <loss>=1.91937849522\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] Epoch[19] Batch [570]#011Speed: 1745.49 samples/sec#011loss=1.919378\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] Epoch[19] Batch[575] avg_epoch_loss=1.229124\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=575 train loss <loss>=2.09103631973\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:23 INFO 140088046479168] Epoch[19] Batch [575]#011Speed: 13849.16 samples/sec#011loss=2.091036\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] Epoch[19] Batch[580] avg_epoch_loss=1.243051\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=580 train loss <loss>=2.84746017456\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] Epoch[19] Batch [580]#011Speed: 1694.55 samples/sec#011loss=2.847460\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] Epoch[19] Batch[585] avg_epoch_loss=1.252399\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=585 train loss <loss>=2.33867228031\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] Epoch[19] Batch [585]#011Speed: 13254.37 samples/sec#011loss=2.338672\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] Epoch[19] Batch[590] avg_epoch_loss=1.257858\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=590 train loss <loss>=1.89756524563\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] Epoch[19] Batch [590]#011Speed: 13309.44 samples/sec#011loss=1.897565\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] Epoch[19] Batch[595] avg_epoch_loss=1.259796\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=595 train loss <loss>=1.48895995617\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] Epoch[19] Batch [595]#011Speed: 1776.88 samples/sec#011loss=1.488960\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] Epoch[19] Batch[600] avg_epoch_loss=1.261010\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=600 train loss <loss>=1.40563359261\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] Epoch[19] Batch [600]#011Speed: 14239.85 samples/sec#011loss=1.405634\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] Epoch[19] Batch[605] avg_epoch_loss=1.261161\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=605 train loss <loss>=1.27932221889\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] Epoch[19] Batch [605]#011Speed: 1797.21 samples/sec#011loss=1.279322\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] Epoch[19] Batch[610] avg_epoch_loss=1.260653\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=610 train loss <loss>=1.19913915396\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] Epoch[19] Batch [610]#011Speed: 14237.44 samples/sec#011loss=1.199139\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] Epoch[19] Batch[615] avg_epoch_loss=1.259638\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=615 train loss <loss>=1.13556549549\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] Epoch[19] Batch [615]#011Speed: 14363.90 samples/sec#011loss=1.135565\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] Epoch[19] Batch[620] avg_epoch_loss=1.260319\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=620 train loss <loss>=1.34425275326\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] Epoch[19] Batch [620]#011Speed: 1679.42 samples/sec#011loss=1.344253\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] Epoch[19] Batch[625] avg_epoch_loss=1.260666\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=625 train loss <loss>=1.3037091732\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:24 INFO 140088046479168] Epoch[19] Batch [625]#011Speed: 14323.43 samples/sec#011loss=1.303709\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] Epoch[19] Batch[630] avg_epoch_loss=1.258168\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=630 train loss <loss>=0.945475292206\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] Epoch[19] Batch [630]#011Speed: 1265.97 samples/sec#011loss=0.945475\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] Epoch[19] Batch[635] avg_epoch_loss=1.257823\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=635 train loss <loss>=1.21423633099\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] Epoch[19] Batch [635]#011Speed: 12752.04 samples/sec#011loss=1.214236\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] Epoch[19] Batch[640] avg_epoch_loss=1.254317\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=640 train loss <loss>=0.808378267288\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] Epoch[19] Batch [640]#011Speed: 12619.79 samples/sec#011loss=0.808378\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] Epoch[19] Batch[645] avg_epoch_loss=1.251201\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=645 train loss <loss>=0.851787793636\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] Epoch[19] Batch [645]#011Speed: 1613.50 samples/sec#011loss=0.851788\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] Epoch[19] Batch[650] avg_epoch_loss=1.249263\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=650 train loss <loss>=0.998831856251\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] Epoch[19] Batch [650]#011Speed: 12933.03 samples/sec#011loss=0.998832\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] Epoch[19] Batch[655] avg_epoch_loss=1.248050\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=655 train loss <loss>=1.09013426304\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] Epoch[19] Batch [655]#011Speed: 12763.31 samples/sec#011loss=1.090134\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] Epoch[19] Batch[660] avg_epoch_loss=1.246571\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=660 train loss <loss>=1.05251643658\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] Epoch[19] Batch [660]#011Speed: 1527.88 samples/sec#011loss=1.052516\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] Epoch[19] Batch[665] avg_epoch_loss=1.245471\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=665 train loss <loss>=1.10003151894\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] Epoch[19] Batch [665]#011Speed: 14028.36 samples/sec#011loss=1.100032\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] Epoch[19] Batch[670] avg_epoch_loss=1.244770\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=670 train loss <loss>=1.15134751797\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] Epoch[19] Batch [670]#011Speed: 1917.45 samples/sec#011loss=1.151348\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] Epoch[19] Batch[675] avg_epoch_loss=1.244140\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=675 train loss <loss>=1.15969895124\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:25 INFO 140088046479168] Epoch[19] Batch [675]#011Speed: 14487.47 samples/sec#011loss=1.159699\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] Epoch[19] Batch[680] avg_epoch_loss=1.244221\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=680 train loss <loss>=1.25514212847\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] Epoch[19] Batch [680]#011Speed: 1857.20 samples/sec#011loss=1.255142\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] Epoch[19] Batch[685] avg_epoch_loss=1.243513\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=685 train loss <loss>=1.14703472853\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] Epoch[19] Batch [685]#011Speed: 14264.67 samples/sec#011loss=1.147035\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] Epoch[19] Batch[690] avg_epoch_loss=1.243848\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=690 train loss <loss>=1.28980426788\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] Epoch[19] Batch [690]#011Speed: 14462.65 samples/sec#011loss=1.289804\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] Epoch[19] Batch[695] avg_epoch_loss=1.244763\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=695 train loss <loss>=1.37126123905\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] Epoch[19] Batch [695]#011Speed: 1762.88 samples/sec#011loss=1.371261\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] Epoch[19] Batch[700] avg_epoch_loss=1.243720\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=700 train loss <loss>=1.09853841066\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] Epoch[19] Batch [700]#011Speed: 14299.78 samples/sec#011loss=1.098538\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] Epoch[19] Batch[705] avg_epoch_loss=1.243998\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=705 train loss <loss>=1.28290491104\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] Epoch[19] Batch [705]#011Speed: 1771.45 samples/sec#011loss=1.282905\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] Epoch[19] Batch[710] avg_epoch_loss=1.242862\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=710 train loss <loss>=1.08244270086\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] Epoch[19] Batch [710]#011Speed: 13901.08 samples/sec#011loss=1.082443\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] Epoch[19] Batch[715] avg_epoch_loss=1.241966\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=715 train loss <loss>=1.1146222353\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] Epoch[19] Batch [715]#011Speed: 13299.02 samples/sec#011loss=1.114622\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] Epoch[19] Batch[720] avg_epoch_loss=1.241177\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=720 train loss <loss>=1.12822532654\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] Epoch[19] Batch [720]#011Speed: 1844.73 samples/sec#011loss=1.128225\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] Epoch[19] Batch[725] avg_epoch_loss=1.239961\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=725 train loss <loss>=1.06454440355\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] Epoch[19] Batch [725]#011Speed: 13356.73 samples/sec#011loss=1.064544\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] Epoch[19] Batch[730] avg_epoch_loss=1.238702\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=730 train loss <loss>=1.05591782331\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] Epoch[19] Batch [730]#011Speed: 1834.26 samples/sec#011loss=1.055918\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] Epoch[19] Batch[735] avg_epoch_loss=1.236310\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=735 train loss <loss>=0.886613881588\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] Epoch[19] Batch [735]#011Speed: 13363.37 samples/sec#011loss=0.886614\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] Epoch[19] Batch[740] avg_epoch_loss=1.236900\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=740 train loss <loss>=1.32373791933\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:26 INFO 140088046479168] Epoch[19] Batch [740]#011Speed: 13352.34 samples/sec#011loss=1.323738\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] Epoch[19] Batch[745] avg_epoch_loss=1.238230\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=745 train loss <loss>=1.43530054092\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] Epoch[19] Batch [745]#011Speed: 1689.29 samples/sec#011loss=1.435301\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] Epoch[19] Batch[750] avg_epoch_loss=1.238611\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=750 train loss <loss>=1.2955602169\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] Epoch[19] Batch [750]#011Speed: 13268.65 samples/sec#011loss=1.295560\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] Epoch[19] Batch[755] avg_epoch_loss=1.240074\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=755 train loss <loss>=1.45978159904\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] Epoch[19] Batch [755]#011Speed: 1760.90 samples/sec#011loss=1.459782\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] Epoch[19] Batch[760] avg_epoch_loss=1.241583\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=760 train loss <loss>=1.46970593929\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] Epoch[19] Batch [760]#011Speed: 13567.35 samples/sec#011loss=1.469706\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] Epoch[19] Batch[765] avg_epoch_loss=1.240986\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=765 train loss <loss>=1.15011171103\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] Epoch[19] Batch [765]#011Speed: 13670.44 samples/sec#011loss=1.150112\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] Epoch[19] Batch[770] avg_epoch_loss=1.242678\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=770 train loss <loss>=1.50195088387\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] Epoch[19] Batch [770]#011Speed: 1733.22 samples/sec#011loss=1.501951\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] Epoch[19] Batch[775] avg_epoch_loss=1.243937\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=775 train loss <loss>=1.43804146051\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] Epoch[19] Batch [775]#011Speed: 14287.60 samples/sec#011loss=1.438041\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] Epoch[19] Batch[780] avg_epoch_loss=1.244303\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=780 train loss <loss>=1.3010668993\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] Epoch[19] Batch [780]#011Speed: 13269.70 samples/sec#011loss=1.301067\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] Epoch[19] Batch[785] avg_epoch_loss=1.243644\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=785 train loss <loss>=1.14074244499\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] Epoch[19] Batch [785]#011Speed: 1753.44 samples/sec#011loss=1.140742\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] Epoch[19] Batch[790] avg_epoch_loss=1.243327\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=790 train loss <loss>=1.19346470833\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] Epoch[19] Batch [790]#011Speed: 13338.41 samples/sec#011loss=1.193465\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] Epoch[19] Batch[795] avg_epoch_loss=1.241608\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=795 train loss <loss>=0.969655144215\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:27 INFO 140088046479168] Epoch[19] Batch [795]#011Speed: 1669.58 samples/sec#011loss=0.969655\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] Epoch[19] Batch[800] avg_epoch_loss=1.239936\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=800 train loss <loss>=0.973768079281\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] Epoch[19] Batch [800]#011Speed: 13311.03 samples/sec#011loss=0.973768\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] Epoch[19] Batch[805] avg_epoch_loss=1.239339\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=805 train loss <loss>=1.14370808601\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] Epoch[19] Batch [805]#011Speed: 13358.85 samples/sec#011loss=1.143708\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] Epoch[19] Batch[810] avg_epoch_loss=1.238551\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=810 train loss <loss>=1.11160025597\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] Epoch[19] Batch [810]#011Speed: 1767.00 samples/sec#011loss=1.111600\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] Epoch[19] Batch[815] avg_epoch_loss=1.237820\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=815 train loss <loss>=1.11923775673\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] Epoch[19] Batch [815]#011Speed: 13327.28 samples/sec#011loss=1.119238\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] Epoch[19] Batch[820] avg_epoch_loss=1.237511\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=820 train loss <loss>=1.18705765009\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] Epoch[19] Batch [820]#011Speed: 1773.42 samples/sec#011loss=1.187058\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] Epoch[19] Batch[825] avg_epoch_loss=1.236805\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=825 train loss <loss>=1.12087627649\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] Epoch[19] Batch [825]#011Speed: 13348.36 samples/sec#011loss=1.120876\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] Epoch[19] Batch[830] avg_epoch_loss=1.236196\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=830 train loss <loss>=1.13552681208\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] Epoch[19] Batch [830]#011Speed: 13356.19 samples/sec#011loss=1.135527\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] Epoch[19] Batch[835] avg_epoch_loss=1.236117\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=835 train loss <loss>=1.22305727005\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] Epoch[19] Batch [835]#011Speed: 1542.59 samples/sec#011loss=1.223057\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] Epoch[19] Batch[840] avg_epoch_loss=1.234476\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=840 train loss <loss>=0.960098075867\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] Epoch[19] Batch [840]#011Speed: 13309.05 samples/sec#011loss=0.960098\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] Epoch[19] Batch[845] avg_epoch_loss=1.233622\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=845 train loss <loss>=1.08988534212\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] Epoch[19] Batch [845]#011Speed: 13290.07 samples/sec#011loss=1.089885\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] Epoch[19] Batch[850] avg_epoch_loss=1.233519\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=850 train loss <loss>=1.21610382795\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] Epoch[19] Batch [850]#011Speed: 1796.40 samples/sec#011loss=1.216104\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] Epoch[19] Batch[855] avg_epoch_loss=1.232888\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=855 train loss <loss>=1.12560092211\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:28 INFO 140088046479168] Epoch[19] Batch [855]#011Speed: 14357.45 samples/sec#011loss=1.125601\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] Epoch[19] Batch[860] avg_epoch_loss=1.232826\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=860 train loss <loss>=1.22219831944\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] Epoch[19] Batch [860]#011Speed: 1787.45 samples/sec#011loss=1.222198\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] Epoch[19] Batch[865] avg_epoch_loss=1.232384\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=865 train loss <loss>=1.15623884201\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] Epoch[19] Batch [865]#011Speed: 14183.27 samples/sec#011loss=1.156239\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] Epoch[19] Batch[870] avg_epoch_loss=1.231229\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=870 train loss <loss>=1.03125329018\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] Epoch[19] Batch [870]#011Speed: 14256.49 samples/sec#011loss=1.031253\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] Epoch[19] Batch[875] avg_epoch_loss=1.230325\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=875 train loss <loss>=1.07272547483\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] Epoch[19] Batch [875]#011Speed: 1712.22 samples/sec#011loss=1.072725\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] Epoch[19] Batch[880] avg_epoch_loss=1.229186\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=880 train loss <loss>=1.02968269587\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] Epoch[19] Batch [880]#011Speed: 13197.55 samples/sec#011loss=1.029683\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] Epoch[19] Batch[885] avg_epoch_loss=1.228110\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=885 train loss <loss>=1.03852446079\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] Epoch[19] Batch [885]#011Speed: 1780.68 samples/sec#011loss=1.038524\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] Epoch[19] Batch[890] avg_epoch_loss=1.227144\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=890 train loss <loss>=1.05590544939\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] Epoch[19] Batch [890]#011Speed: 14437.14 samples/sec#011loss=1.055905\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] Epoch[19] Batch[895] avg_epoch_loss=1.226798\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, batch=895 train loss <loss>=1.16523325443\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] Epoch[19] Batch [895]#011Speed: 14347.16 samples/sec#011loss=1.165233\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] processed a total of 57502 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 15783.482074737549, \"sum\": 15783.482074737549, \"min\": 15783.482074737549}}, \"EndTime\": 1604320709.623193, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320693.839249}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] #throughput_metric: host=algo-1, train throughput=3643.14812314 records/second\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] #quality_metric: host=algo-1, epoch=19, train loss <loss>=1.22616301389\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] loss did not improve\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] Final loss: 1.19390961931 (occurred at epoch 17)\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] #quality_metric: host=algo-1, train final_loss <loss>=1.19390961931\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 WARNING 140088046479168] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 13.148069381713867, \"sum\": 13.148069381713867, \"min\": 13.148069381713867}}, \"EndTime\": 1604320709.637291, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320709.623273}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 27.58312225341797, \"sum\": 27.58312225341797, \"min\": 27.58312225341797}}, \"EndTime\": 1604320709.651685, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320709.637353}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 2.1209716796875, \"sum\": 2.1209716796875, \"min\": 2.1209716796875}}, \"EndTime\": 1604320709.653903, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320709.651742}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:29 INFO 140088046479168] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 0.03600120544433594, \"sum\": 0.03600120544433594, \"min\": 0.03600120544433594}}, \"EndTime\": 1604320709.654752, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320709.653962}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:31 INFO 140088046479168] Number of test batches scored: 10\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:33 INFO 140088046479168] Number of test batches scored: 20\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:36 INFO 140088046479168] Number of test batches scored: 30\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:38 INFO 140088046479168] Number of test batches scored: 40\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:40 INFO 140088046479168] Number of test batches scored: 50\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:42 INFO 140088046479168] Number of test batches scored: 60\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:44 INFO 140088046479168] Number of test batches scored: 70\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:46 INFO 140088046479168] Number of test batches scored: 80\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:48 INFO 140088046479168] Number of test batches scored: 90\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:51 INFO 140088046479168] Number of test batches scored: 100\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:53 INFO 140088046479168] Number of test batches scored: 110\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:55 INFO 140088046479168] Number of test batches scored: 120\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:57 INFO 140088046479168] Number of test batches scored: 130\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:38:59 INFO 140088046479168] Number of test batches scored: 140\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:39:01 INFO 140088046479168] Number of test batches scored: 150\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:39:03 INFO 140088046479168] Number of test batches scored: 160\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:39:05 INFO 140088046479168] Number of test batches scored: 170\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:39:08 INFO 140088046479168] Number of test batches scored: 180\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:39:10 INFO 140088046479168] Number of test batches scored: 190\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:39:12 INFO 140088046479168] Number of test batches scored: 200\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:39:14 INFO 140088046479168] Number of test batches scored: 210\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:39:16 INFO 140088046479168] Number of test batches scored: 220\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.score.time\": {\"count\": 1, \"max\": 48161.67497634888, \"sum\": 48161.67497634888, \"min\": 48161.67497634888}}, \"EndTime\": 1604320757.816392, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320709.65481}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:39:17 INFO 140088046479168] #test_score (algo-1, RMSE): 16.8754029515\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:39:17 INFO 140088046479168] #test_score (algo-1, mean_absolute_QuantileLoss): 60574.684532786385\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:39:17 INFO 140088046479168] #test_score (algo-1, mean_wQuantileLoss): 0.1540396933247289\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:39:17 INFO 140088046479168] #test_score (algo-1, wQuantileLoss[0.1]): 0.07976232072396439\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:39:17 INFO 140088046479168] #test_score (algo-1, wQuantileLoss[0.2]): 0.10796913953305218\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:39:17 INFO 140088046479168] #test_score (algo-1, wQuantileLoss[0.3]): 0.13862330638014275\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:39:17 INFO 140088046479168] #test_score (algo-1, wQuantileLoss[0.4]): 0.17781723776227468\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:39:17 INFO 140088046479168] #test_score (algo-1, wQuantileLoss[0.5]): 0.2051216400297568\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:39:17 INFO 140088046479168] #test_score (algo-1, wQuantileLoss[0.6]): 0.21210524992413568\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:39:17 INFO 140088046479168] #test_score (algo-1, wQuantileLoss[0.7]): 0.19891939700470312\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:39:17 INFO 140088046479168] #test_score (algo-1, wQuantileLoss[0.8]): 0.1616839935743462\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:39:17 INFO 140088046479168] #test_score (algo-1, wQuantileLoss[0.9]): 0.10435495499018416\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:39:17 INFO 140088046479168] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.154039693325\u001b[0m\n",
      "\u001b[34m[11/02/2020 12:39:17 INFO 140088046479168] #quality_metric: host=algo-1, test RMSE <loss>=16.8754029515\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 372359.3330383301, \"sum\": 372359.3330383301, \"min\": 372359.3330383301}, \"setuptime\": {\"count\": 1, \"max\": 11.68513298034668, \"sum\": 11.68513298034668, \"min\": 11.68513298034668}}, \"EndTime\": 1604320757.819769, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1604320757.816461}\n",
      "\u001b[0m\n",
      "\n",
      "2020-11-02 12:39:27 Uploading - Uploading generated training model\n",
      "2020-11-02 12:39:27 Completed - Training job completed\n",
      "Training seconds: 416\n",
      "Billable seconds: 416\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_name=image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.2xlarge',\n",
    "   # base_job_name='deepar-electricity-demo',\n",
    "    output_path=s3_output_path,\n",
    "    image_uri=image_name\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "hyperparameters = {\n",
    "    \"time_freq\": '1H',\n",
    "    \"epochs\": \"20\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"mini_batch_size\": \"64\",\n",
    "    \"learning_rate\": \"5E-4\",\n",
    "    \"context_length\": 1,\n",
    "    \"prediction_length\": 1\n",
    "}\n",
    "\n",
    "estimator.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "\n",
    "data_channels = {\n",
    "    \"train\": \"{}/train/\".format(s3_data_path),\n",
    "    \"test\": \"{}/test/\".format(s3_data_path)\n",
    "}\n",
    "\n",
    "estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
