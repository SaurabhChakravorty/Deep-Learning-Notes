{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Electricity price modeling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djl8VtwmApoz"
      },
      "source": [
        "**Notebook to demonstrate the reading and splitting of the hourly electricity data.**<br>\n",
        "\n",
        "Comments about data structure, the splitting on the data into train, validation, and test sets, etc., are given below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMOcSo6eAk5V",
        "outputId": "eefa65f6-641f-4413-e645-6de93c7e0b13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Use wget to download the data stored in csv format.\n",
        "!wget \"https://frankfurt-school-dataset.s3.eu-central-1.amazonaws.com/Electricity_data_hourly_products.csv\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-30 14:42:44--  https://frankfurt-school-dataset.s3.eu-central-1.amazonaws.com/Electricity_data_hourly_products.csv\n",
            "Resolving frankfurt-school-dataset.s3.eu-central-1.amazonaws.com (frankfurt-school-dataset.s3.eu-central-1.amazonaws.com)... 52.219.72.112\n",
            "Connecting to frankfurt-school-dataset.s3.eu-central-1.amazonaws.com (frankfurt-school-dataset.s3.eu-central-1.amazonaws.com)|52.219.72.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 350029849 (334M) [text/csv]\n",
            "Saving to: ‘Electricity_data_hourly_products.csv.1’\n",
            "\n",
            "Electricity_data_ho 100%[===================>] 333.81M  28.0MB/s    in 13s     \n",
            "\n",
            "2020-09-30 14:42:57 (26.0 MB/s) - ‘Electricity_data_hourly_products.csv.1’ saved [350029849/350029849]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cdXNg2oN9i1",
        "outputId": "efc058ae-18f9-4359-a81f-4b78d76e9896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# List the directory; the downloaded file should be there. \n",
        "!ls -lh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 668M\n",
            "-rw-r--r-- 1 root root 334M Sep 30 08:49 Electricity_data_hourly_products.csv\n",
            "-rw-r--r-- 1 root root 334M Sep 30 08:49 Electricity_data_hourly_products.csv.1\n",
            "drwxr-xr-x 1 root root 4.0K Sep 28 16:35 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qRgVE-BOHV1",
        "outputId": "27981828-024f-4694-d0d5-14bc1bccad1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "source": [
        "# Load the data using the pandas library. Use the 1st (0th) column as index\n",
        "import pandas as pd\n",
        "df = pd.read_csv('Electricity_data_hourly_products.csv', index_col=0)\n",
        "\n",
        "# Display the first 5 rows of the data; for a description of the content, see the text below this cell\n",
        "display(df.head())\n",
        "\n",
        "# Display basic dataframe info\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>contractId</th>\n",
              "      <th>qty</th>\n",
              "      <th>px</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-03-01 11:59:13.229</th>\n",
              "      <td>11629792</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-01 11:59:13.243</th>\n",
              "      <td>11629792</td>\n",
              "      <td>0.5</td>\n",
              "      <td>-0.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-01 11:59:13.243</th>\n",
              "      <td>11629792</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-01 11:59:46.669</th>\n",
              "      <td>11629792</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-0.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-01 11:59:55.065</th>\n",
              "      <td>11629792</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-0.99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         contractId  qty    px\n",
              "Datetime                                      \n",
              "2020-03-01 11:59:13.229    11629792  0.5 -0.99\n",
              "2020-03-01 11:59:13.243    11629792  0.5 -0.99\n",
              "2020-03-01 11:59:13.243    11629792  0.1 -1.00\n",
              "2020-03-01 11:59:46.669    11629792  3.0 -0.99\n",
              "2020-03-01 11:59:55.065    11629792  3.0 -0.99"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 8219996 entries, 2020-03-01 11:59:13.229 to 2020-08-24 20:42:39.432\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Dtype  \n",
            "---  ------      -----  \n",
            " 0   contractId  int64  \n",
            " 1   qty         float64\n",
            " 2   px          float64\n",
            "dtypes: float64(2), int64(1)\n",
            "memory usage: 250.9+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CdrrhQ4DvBb"
      },
      "source": [
        "**The content of the dataframe is the following:**<br>\n",
        "Each row corresponds to a single electricity trade; the information given are all related to that.\n",
        "* *Datetime*: the time that the electricity trade takes place. This is not the delivery time of the electricity, it is simply the time of the trade itself. This column is the index of the dataframe.<br>\n",
        "* *contractId*: the id of the contract. The contractId identifies a given time window in which the electricity is to be provided (the \"sell\" leg) and used up (the \"buy\" leg). In this exercise, only hourly contracts, that is contracts which are about 1-hour-long time windows, are considered. There can be many trades under a given contractId. Trades, naturally, predate the time for which the electricity is to be actually delivered.\n",
        "* *qty*: the quantity of the electricty being traded, given in MWH units.\n",
        "* *px*: the price of 1 MWH of electricity, given in EUR.\n",
        "\n",
        "Given all the above, it is clear that our data contains historical information about the price changes of electricity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jS-_SjcJFqg"
      },
      "source": [
        "As each contractId in our data belongs to similar (hourly) contracts, all of them can be considered, there is no need to discard any of them. Each contract can be considered a time series of its own, pulled / sampled from the same population of price evolution over time. Data from different contracts, however, should not be mixed with each other; even if trades are happening at the same time for two different contracts, the prices can and will be different.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRNum_21P_Ne"
      },
      "source": [
        "The prediction scneario is as follows. We are at the very beginning of an hour and we would like to know the price of electricity at the end of the current hour. We know all the trades that have just taken place the previous hour, while there are no trades yet in the current one. Can we then predict what the price will be by the end of the hour?\n",
        "\n",
        "**Exercise steps:**\n",
        "* Separately for all contracts, compute the OHLCV (Open, High, Low, Close, Volume) values with hourly binning for all trades. The volumes from the trades should be summed. Such OHCLV values will be your features.\n",
        "  * A possible SOLUTION is something along the following lines:<br>\n",
        "```\n",
        "    def bin_ohlcv(df, contractId, binning_size='H'):\n",
        "        df_cid = df[df.contractId == contractId]\n",
        "        # resample for a binsize and the ohlc the result; and volume too.\n",
        "        data = df_cid[['px']].resample(binning_size).ohlc().px\n",
        "        data['volsum'] = df_cid[['qty']].resample(binning_size).sum()\n",
        "        return data\n",
        "```\n",
        "* If no trades took place during a given hour, use the close price of the last hour to replace the nano OHLC values and use 0 for the nan volume.\n",
        "  * A possible SOLUTION is something along the following lines:<br>\n",
        "```\n",
        "    def fillna_close(df):\n",
        "        for i in df.iterrows():\n",
        "            if not np.isnan(i[1]['close']):\n",
        "                close = i[1]['close']\n",
        "            else:\n",
        "                i[1]['open'] = close\n",
        "                i[1]['high'] = close\n",
        "                i[1]['low'] = close\n",
        "                i[1]['close'] = close\n",
        "        return df\n",
        "```\n",
        "\n",
        "* Define how many hours of the immediate past should be considered as predictors for the next hour. Treating the contracts separately, prepare the OHLCV values of the past hours as features. Use a Segmenter for this.\n",
        "  * A possible SOLUTION is something along the following lines (note: the code below sits within a contractId loop; X_train is already for a given contractId!):<br>\n",
        "```\n",
        "    # forecast defines how far in the future one predicts\n",
        "    segmenter = SegmentXYForecast(width=window_size, step=1, y_func=last, forecast=1)\n",
        "\n",
        "    if X_train.shape[0] < window_size+forecast_distance:\n",
        "        error_cids[cid] = X_train.shape[0]\n",
        "    else:\n",
        "        # Selecting the y colum\n",
        "        predict_column='close'\n",
        "        y_train = X_train[predict_column]\n",
        "        # Making a windowed version of the data with seglearn segmenter\n",
        "        X_train_rolled, y_train_rolled, _= segmenter.fit_transform([X_train.values],[y_train.values.flatten()])\n",
        "        # getting the segmented indices, aka dates\n",
        "        X_train_index_rolled, _, _ = segmenter.fit_transform([X_train.index.values],[y_train.values.flatten()])\n",
        "        count = 0\n",
        "        # Iterating through the seglearn output windows (3D arrays)\n",
        "        for i in X_train_rolled:\n",
        "            # Flattening X_train_rolled to append as a row to the return df of df_windowing function\n",
        "            data = pd.Series(i.flatten())\n",
        "            # Appending flattened data\n",
        "            train_df = train_df.append(data, ignore_index=True)\n",
        "            # If getContractId is True append its value to the return df of df_windowing function\n",
        "            if getContractId:\n",
        "                train_df['contractId'].iloc[-1] = str(cid)\n",
        "            # Appending y values from the y_train_rolled to the last added window row\n",
        "            train_df['y'].iloc[-1] = y_train_rolled[count]\n",
        "            count = count+1\n",
        "```\n",
        "At the end, for contract id 116330300 the data should look like this one (numerical values might be different for volume):\n",
        "```\n",
        "contractId,y,0,1,2,3,4,5,6,7,8,9\n",
        "11630300,24.51,29.99,30.0,29.99,30.0,10.399999999999999,30.02,30.8,28.82,28.82,199.8\n",
        "11630300,31.4,30.02,30.8,28.82,28.82,199.8,20.51,28.82,20.51,24.51,559.0000000000002\n",
        "11630300,30.09,20.51,28.82,20.51,24.51,559.0000000000002,25.99,31.4,25.9,31.4,939.5999999999999\n",
        "11630300,26.91,25.99,31.4,25.9,31.4,939.5999999999999,30.4,31.19,27.2,30.09,902.8000000000005\n",
        "11630300,23.7,30.4,31.19,27.2,30.09,902.8000000000005,30.09,30.99,26.54,26.91,763.2\n",
        "11630300,23.69,30.09,30.99,26.54,26.91,763.2,26.6,28.4,18.57,23.7,2491.800000000002\n",
        "11630300,21.0,26.6,28.4,18.57,23.7,2491.800000000002,23.7,26.71,21.01,23.69,1894.0000000000005\n",
        "11630300,23.41,23.7,26.71,21.01,23.69,1894.0000000000005,23.0,25.6,19.9,21.0,2427.2\n",
        "```\n",
        "Here one can see the contractId, the target y (the close price of the next hour), and the 2*5 OHLCV values (for a history length of 2 hours). It is clearly visible how the y values are indeed the close values of the next hour.\n",
        "* Define your predictors (X) and the target (y). Don't use the contractId as a predictor! It was needed for the OHLCV computation and the segmentation, but it can be dropped now. Split the data into Train, Validation, and Test sets using train_test_split from sklearn. In order to make the results reproduceable, make sure that the \"shuffle\" parameter of the function is False. Look up the documentation and understand why this is needed. As the train_test_split returns only two data sets instead of the three we need, it is to be applied twice. Use 95% for Train and 5% for Test set during the first split. Then, for the second call, split off 5% from the just created Train set as Validation set.\n",
        "  * A possible SOLUTION is something along the following lines:<br>\n",
        "```\n",
        "    X = train_df.drop(columns=['y','contractId'])\n",
        "    y = train_df['y']\n",
        "\n",
        "    # Creating train and test splits\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split_size, shuffle=False)\n",
        "    # Creating by splitting from remaning data of train\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=split_size, shuffle=False)\n",
        "```\n",
        "* Define models! Use the Train data to fit, and the Validation data to evaluate your models!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbw-F0BpS95F"
      },
      "source": [
        ""
      ]
    }
  ]
}