{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Saurabh_POS_tagging_with_classical_models_handout.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"cells":[{"cell_type":"markdown","metadata":{"id":"no_k76e0NZHI"},"source":["# Task: Part of speech tagging\n","\n","In this task we try to recreate a very rudimentary POS tagger \"from scratch\" using SpaCy and CRF models. \n","\n","(We disregard the fact, that SpaCy has a built in POS tagger for the moment for demonstration purposes.)\n","\n","The input is a tokenized English sentence. The task is to label each word with a part of speech (POS) tag. The tag set, which is identical the [Universal Dependencies project's](https://universaldependencies.org/) basic tag set is the following:\n","\n","- NOUN: noun\n","- VERB: verb\n","- DET: determiner\n","- ADJ: adjective\n","- ADP: adposition (e.g., prepositions)\n","- ADV: adverb\n","- CONJ: conjunction\n","- NUM: numeral\n","- PART: particle (function word that cannot be inflected, has no meaning in\n","  itself and doesn't fit elsewhere, e.g., \"to\")\n","- PRON: pronoun\n","- .: punctuation\n","- X: other\n","\n","The code in this task is an adaptation of the NER code in the sklearn-crfsuite documentation.\n","\n","# The data set\n","\n","__Brown__ corpus: \"The Brown University Standard Corpus of Present-Day American English (or just Brown Corpus) was compiled in the 1960s by Henry Kučera and W. Nelson Francis at Brown University, Providence, Rhode Island as a general corpus (text collection) in the field of corpus linguistics. It contains 500 samples of English-language text, totaling roughly one million words, compiled from works published in the United States in 1961\" (Wikpedia: Brown Corpus)\n","\n","Let's download and inspect the data!"]},{"cell_type":"code","metadata":{"id":"fc4CZfSvL2lO","executionInfo":{"status":"ok","timestamp":1605834361994,"user_tz":-60,"elapsed":4147,"user":{"displayName":"Saurabh Chakravorty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4i8aVesE-zqnMJttjboEDqonbdcW85GPg1Yfj5g=s64","userId":"01575942328847603880"}}},"source":["%%capture\n","!pip install nltk"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-12T09:32:20.712982Z","start_time":"2019-11-12T09:32:16.093693Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"KAPwh8mmNZHM","executionInfo":{"status":"ok","timestamp":1605834363709,"user_tz":-60,"elapsed":5782,"user":{"displayName":"Saurabh Chakravorty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4i8aVesE-zqnMJttjboEDqonbdcW85GPg1Yfj5g=s64","userId":"01575942328847603880"}},"outputId":"3871c17b-9660-43e9-b6be-1b6b3d97b9cd"},"source":["import nltk\n","\n","from nltk.corpus import brown\n","nltk.download('brown')\n","\n","brown.words()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/brown.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-12T09:32:21.291370Z","start_time":"2019-11-12T09:32:20.723897Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"3kSgq4e0NZHi","executionInfo":{"status":"ok","timestamp":1605834363718,"user_tz":-60,"elapsed":5770,"user":{"displayName":"Saurabh Chakravorty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4i8aVesE-zqnMJttjboEDqonbdcW85GPg1Yfj5g=s64","userId":"01575942328847603880"}},"outputId":"53c9385f-4502-4250-fd86-4ab8bb891e5c"},"source":["nltk.download('universal_tagset')\n","brown.tagged_words(tagset='universal')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n","[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[('The', 'DET'), ('Fulton', 'NOUN'), ...]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-12T09:32:21.352042Z","start_time":"2019-11-12T09:32:21.297210Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"9tT1DBTtNZHu","executionInfo":{"status":"ok","timestamp":1605834363720,"user_tz":-60,"elapsed":5754,"user":{"displayName":"Saurabh Chakravorty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4i8aVesE-zqnMJttjboEDqonbdcW85GPg1Yfj5g=s64","userId":"01575942328847603880"}},"outputId":"fe861981-978b-40d9-9b04-be5e188a4936"},"source":["brown.sents()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-12T09:32:25.131849Z","start_time":"2019-11-12T09:32:21.365202Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"UuwBB-XRNZH6","executionInfo":{"status":"ok","timestamp":1605834366074,"user_tz":-60,"elapsed":8089,"user":{"displayName":"Saurabh Chakravorty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4i8aVesE-zqnMJttjboEDqonbdcW85GPg1Yfj5g=s64","userId":"01575942328847603880"}},"outputId":"91fb90bb-ff64-4bc0-e89e-46a3b4a01ffc"},"source":["len(brown.words())"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1161192"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"m8VYZmFCsNTa"},"source":["From the brown the object provided by NLTK we will work with the tagged sentence list:"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-12T09:32:25.163453Z","start_time":"2019-11-12T09:32:25.136038Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"bh0wAJkWNnlV","executionInfo":{"status":"ok","timestamp":1605834366076,"user_tz":-60,"elapsed":8073,"user":{"displayName":"Saurabh Chakravorty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4i8aVesE-zqnMJttjboEDqonbdcW85GPg1Yfj5g=s64","userId":"01575942328847603880"}},"outputId":"8fd2df82-66d6-45f9-cf88-f15a090b2e4c"},"source":["sents = brown.tagged_sents(tagset=\"universal\")\n","\n","sents[:2]"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[('The', 'DET'),\n","  ('Fulton', 'NOUN'),\n","  ('County', 'NOUN'),\n","  ('Grand', 'ADJ'),\n","  ('Jury', 'NOUN'),\n","  ('said', 'VERB'),\n","  ('Friday', 'NOUN'),\n","  ('an', 'DET'),\n","  ('investigation', 'NOUN'),\n","  ('of', 'ADP'),\n","  (\"Atlanta's\", 'NOUN'),\n","  ('recent', 'ADJ'),\n","  ('primary', 'NOUN'),\n","  ('election', 'NOUN'),\n","  ('produced', 'VERB'),\n","  ('``', '.'),\n","  ('no', 'DET'),\n","  ('evidence', 'NOUN'),\n","  (\"''\", '.'),\n","  ('that', 'ADP'),\n","  ('any', 'DET'),\n","  ('irregularities', 'NOUN'),\n","  ('took', 'VERB'),\n","  ('place', 'NOUN'),\n","  ('.', '.')],\n"," [('The', 'DET'),\n","  ('jury', 'NOUN'),\n","  ('further', 'ADV'),\n","  ('said', 'VERB'),\n","  ('in', 'ADP'),\n","  ('term-end', 'NOUN'),\n","  ('presentments', 'NOUN'),\n","  ('that', 'ADP'),\n","  ('the', 'DET'),\n","  ('City', 'NOUN'),\n","  ('Executive', 'ADJ'),\n","  ('Committee', 'NOUN'),\n","  (',', '.'),\n","  ('which', 'DET'),\n","  ('had', 'VERB'),\n","  ('over-all', 'ADJ'),\n","  ('charge', 'NOUN'),\n","  ('of', 'ADP'),\n","  ('the', 'DET'),\n","  ('election', 'NOUN'),\n","  (',', '.'),\n","  ('``', '.'),\n","  ('deserves', 'VERB'),\n","  ('the', 'DET'),\n","  ('praise', 'NOUN'),\n","  ('and', 'CONJ'),\n","  ('thanks', 'NOUN'),\n","  ('of', 'ADP'),\n","  ('the', 'DET'),\n","  ('City', 'NOUN'),\n","  ('of', 'ADP'),\n","  ('Atlanta', 'NOUN'),\n","  (\"''\", '.'),\n","  ('for', 'ADP'),\n","  ('the', 'DET'),\n","  ('manner', 'NOUN'),\n","  ('in', 'ADP'),\n","  ('which', 'DET'),\n","  ('the', 'DET'),\n","  ('election', 'NOUN'),\n","  ('was', 'VERB'),\n","  ('conducted', 'VERB'),\n","  ('.', '.')]]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-12T09:32:28.899336Z","start_time":"2019-11-12T09:32:25.166107Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"L2oUMrTpasZY","executionInfo":{"status":"ok","timestamp":1605834369191,"user_tz":-60,"elapsed":11168,"user":{"displayName":"Saurabh Chakravorty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4i8aVesE-zqnMJttjboEDqonbdcW85GPg1Yfj5g=s64","userId":"01575942328847603880"}},"outputId":"ef1bbda8-f53d-4659-f000-b2263af03bc4"},"source":["len(sents)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["57340"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"tgvacV45sNTz"},"source":["We divide our data set into a train and a valid part:"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-12T09:32:28.905030Z","start_time":"2019-11-12T09:32:28.901963Z"},"id":"jPvFic-atE6S","executionInfo":{"status":"ok","timestamp":1605834369192,"user_tz":-60,"elapsed":11166,"user":{"displayName":"Saurabh Chakravorty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4i8aVesE-zqnMJttjboEDqonbdcW85GPg1Yfj5g=s64","userId":"01575942328847603880"}}},"source":["valid_sents = sents[:5734]\n","train_sents = sents[5734:]"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zO8hXBHHPR4f"},"source":["# Feature template\n","\n","Since the plan is to build a CRF model, we need a __feature template__, which generates features for a word in a sentence (our sequence in the sequence tagging task). We use spaCy for feature extraction."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-12T09:32:36.258620Z","start_time":"2019-11-12T09:32:28.906793Z"},"id":"rd504nqAL2lS","executionInfo":{"status":"ok","timestamp":1605834372090,"user_tz":-60,"elapsed":14057,"user":{"displayName":"Saurabh Chakravorty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4i8aVesE-zqnMJttjboEDqonbdcW85GPg1Yfj5g=s64","userId":"01575942328847603880"}}},"source":["#!python -m spacy download en_core_web_sm\n","#Spacy install, load and such stuff\n","\n","#Import\n","import spacy\n","\n","#By model load, please deactivate unnecessary pipeline elements!\n","en = spacy.load(\"en_core_web_sm\" , disable=[\"passer\",\"ner\"])\n"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TC4f13w9sNUJ"},"source":["We write a function which generates features for a token in a sentence, which is already a spaCy document. The feature vector is represented as a `dict` mapping feature names to their values.\n","\n","The desired **feature set for a token is**:\n","\n","- `bias`: A constant value of 1 as an input\n","- `token.lower`: the lowercased textual form of the token\n","- `token.suffix`: the textual form of the token's suffix as defined by SpaCy,\n","- `token.prefix`: the textual form of the token's prefix as defined by SpaCy,\n","- `token.is_upper`: boolean value indicating if the token is uppercase,\n","- `token.is_title`: boolean value indicating if the token is a title,\n","- `token.is_digit`: boolean value indicating if the token consists of numbers.\n","\n","These are only the `Token`'s own properties, but they represent no context.\n","\n","We would like to include information about  the previous and next words, as well as indicating if the `Token` is the beginning or the end of sentence.\n","\n","The **contextual features** should be:\n"," \n","- `-1:token.lower`: What is the lowercase textual form of the previous token?,\n","- `-1:token.is_title`: Is the previous token a title?,\n","- `-1:token.is_upper`: Is the previous token uppercase?,\n","- `+1:token.lower`: What is the lowercase textual form of the next token?,\n","- `+1:token.is_title`: Is the next token a title?,\n","- `+1:token.is_upper`: Is the next token uppercase?,\n","- `BOS`: Boolean value indicating if the token is the beginning of a sentence,\n","- `EOS`: Boolean value indicating if the token is the end of a sentence"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-12T09:32:37.930451Z","start_time":"2019-11-12T09:32:37.909065Z"},"id":"SKz9zT8bsNUL","executionInfo":{"status":"ok","timestamp":1605835822977,"user_tz":-60,"elapsed":515,"user":{"displayName":"Saurabh Chakravorty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4i8aVesE-zqnMJttjboEDqonbdcW85GPg1Yfj5g=s64","userId":"01575942328847603880"}}},"source":["def token2features(sent, i):\n","    \"\"\"Return a feature dict for a token. \n","    sent is a spaCy Doc containing a sentence, i is the token's index in it.\n","    \"\"\"\n","    features = {}\n","    # For the word\n","    features['bias'] = 1.0\n","    features['token.lower']  = sent[i].lower_\n","    features['token.suffix'] = sent[i].suffix_\n","    features['token.prefix'] =  sent[i].prefix_\n","    features['token.is_upper'] = sent[i].is_upper\n","    features['token.is_title'] =  sent[i].is_title\n","    features['token.is_digit'] =  sent[i].is_digit\n","\n","    # If token is previous\n","    if i > 0:\n","            features['-1:token.lower'] =  sent[i-1].lower_ \n","            features['-1:token.is_title'] = sent[i-1].is_title\n","            features['-1:token.is_upper']=  sent[i-1].is_upper\n","    else:\n","        features['BOS'] =  True\n","\n","    # If token is next\n","    if i < len(sent) - 1:\n","            features['+1:token.lower'] =  sent[i+1].lower_\n","            features['+1:token.is_title'] = sent[i+1].is_title\n","            features['+1:token.is_upper'] =  sent[i+1].is_upper\n","    else:\n","        features['EOS'] = True\n","\n","\n","    return features"],"execution_count":60,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VvwL0hF3sNUS"},"source":["For training, we will also need functions to generate feature dict and label lists for sentences in our training corpus:"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-12T09:32:37.958184Z","start_time":"2019-11-12T09:32:37.936592Z"},"id":"ZLW80wtksNUU","executionInfo":{"status":"ok","timestamp":1605835825374,"user_tz":-60,"elapsed":541,"user":{"displayName":"Saurabh Chakravorty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4i8aVesE-zqnMJttjboEDqonbdcW85GPg1Yfj5g=s64","userId":"01575942328847603880"}}},"source":["from spacy.tokens import Doc\n","def sent2features(sent):\n","    \"Return a list of feature dicts for a sentence in the data set.\"\n","    # Create a doc by instantiating a Doc class and iterating through the sentence token by token.\n","    # Please bear in mind, that Brown has token-POS pairs, latter one we don't need here...\n","    #....\n","    doc = [token[0] for token in sent]\n","    text = Doc(en.vocab, words=doc)\n","    \n","    # Plese use the above defined token2features function on each token to generate the features\n","    # For the whole sentence!\n","    sent_features = []\n","    for i in range(len(text)):\n","         sent_features.append(token2features(text, i))\n","    \n","    return sent_features\n","\n","def sent2labels(sent):\n","    \n","    #Please create / filter only the labels for given sentence!\n","    labels = [token[1] for token in sent]\n","    \n","    return labels"],"execution_count":61,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pBoPuzeMsNUa"},"source":["Sanity check: let's see the values for the first 2 tokens in the corpus:"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-12T09:32:37.997140Z","start_time":"2019-11-12T09:32:37.966347Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"UcqvDIJofccv","executionInfo":{"status":"ok","timestamp":1605835827403,"user_tz":-60,"elapsed":539,"user":{"displayName":"Saurabh Chakravorty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4i8aVesE-zqnMJttjboEDqonbdcW85GPg1Yfj5g=s64","userId":"01575942328847603880"}},"outputId":"e5f40256-3e88-4112-a857-eb5636e37da6"},"source":["print(sent2features(sents[0])[:2])\n","print(sent2labels(sents[0])[:2])"],"execution_count":62,"outputs":[{"output_type":"stream","text":["[{'bias': 1.0, 'token.lower': 'the', 'token.suffix': 'The', 'token.prefix': 'T', 'token.is_upper': False, 'token.is_title': True, 'token.is_digit': False, 'BOS': True, '+1:token.lower': 'fulton', '+1:token.is_title': True, '+1:token.is_upper': False}, {'bias': 1.0, 'token.lower': 'fulton', 'token.suffix': 'ton', 'token.prefix': 'F', 'token.is_upper': False, 'token.is_title': True, 'token.is_digit': False, '-1:token.lower': 'the', '-1:token.is_title': True, '-1:token.is_upper': False, '+1:token.lower': 'county', '+1:token.is_title': True, '+1:token.is_upper': False}]\n","['DET', 'NOUN']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KsoK0-GNfzt5"},"source":["# Putting the data into final form"]},{"cell_type":"markdown","metadata":{"id":"Ylfst7VGsNUl"},"source":["Everything is ready to generate the training data in the form which is usable for the CRFsuite. Note that our inputs and labels will be  2-level representations, lists of lists, because we deal with token sequences (sentences)."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-12T09:33:02.066506Z","start_time":"2019-11-12T09:32:38.005545Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"Wfqa0feYgspT","executionInfo":{"status":"ok","timestamp":1605835849477,"user_tz":-60,"elapsed":18937,"user":{"displayName":"Saurabh Chakravorty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4i8aVesE-zqnMJttjboEDqonbdcW85GPg1Yfj5g=s64","userId":"01575942328847603880"}},"outputId":"b0cc6ee6-97e2-4b82-a6ce-2374e7c912cd"},"source":["%%time\n","X_train = [sent2features(s) for s in train_sents]\n","y_train = [sent2labels(s) for s in train_sents]\n","\n","X_valid = [sent2features(s) for s in valid_sents]\n","y_valid = [sent2labels(s) for s in valid_sents]"],"execution_count":63,"outputs":[{"output_type":"stream","text":["CPU times: user 18.2 s, sys: 199 ms, total: 18.4 s\n","Wall time: 18.4 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-12T09:33:02.072026Z","start_time":"2019-11-12T09:33:02.068258Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"XNFvu0UosNUt","executionInfo":{"status":"ok","timestamp":1605835849479,"user_tz":-60,"elapsed":16761,"user":{"displayName":"Saurabh Chakravorty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4i8aVesE-zqnMJttjboEDqonbdcW85GPg1Yfj5g=s64","userId":"01575942328847603880"}},"outputId":"0a9632ce-dbae-4161-89f7-e62a0e719c20"},"source":["print(\"Feature dict for the first token in the first validation sentence:\")\n","print(X_valid[0][0])\n","print(\"Its label:\")\n","print(y_valid[0][0])"],"execution_count":64,"outputs":[{"output_type":"stream","text":["Feature dict for the first token in the first validation sentence:\n","{'bias': 1.0, 'token.lower': 'the', 'token.suffix': 'The', 'token.prefix': 'T', 'token.is_upper': False, 'token.is_title': True, 'token.is_digit': False, 'BOS': True, '+1:token.lower': 'fulton', '+1:token.is_title': True, '+1:token.is_upper': False}\n","Its label:\n","DET\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"f2siQxe9k4ql"},"source":["# Training and evaluation"]},{"cell_type":"markdown","metadata":{"id":"xwyn356ysNU2"},"source":["We use the super-optimized [CRFsuite](http://www.chokkan.org/software/crfsuite/) via the scikit-learn compatible [sklearn-crfsuite](https://sklearn-crfsuite.readthedocs.io) wrapper to train a CRF model on the data."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-12T09:33:04.830327Z","start_time":"2019-11-12T09:33:02.073675Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"15POzt86sNSe","executionInfo":{"status":"ok","timestamp":1605834401751,"user_tz":-60,"elapsed":3536,"user":{"displayName":"Saurabh Chakravorty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4i8aVesE-zqnMJttjboEDqonbdcW85GPg1Yfj5g=s64","userId":"01575942328847603880"}},"outputId":"94824d79-924e-4216-e170-7abe06962d61"},"source":["#%%capture # only to avoid ugly printouts during install\n","!pip install sklearn_crfsuite"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Collecting sklearn_crfsuite\n","  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n","Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.41.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (1.15.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.7)\n","Collecting python-crfsuite>=0.8.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n","\u001b[K     |████████████████████████████████| 747kB 18.2MB/s \n","\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite\n","Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-12T09:33:04.883741Z","start_time":"2019-11-12T09:33:04.836395Z"},"id":"WkX57BFDklEL","executionInfo":{"status":"ok","timestamp":1605835860757,"user_tz":-60,"elapsed":567,"user":{"displayName":"Saurabh Chakravorty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4i8aVesE-zqnMJttjboEDqonbdcW85GPg1Yfj5g=s64","userId":"01575942328847603880"}}},"source":["# Please import and train an averaged perceptron model from CRFsuite and use it's custom metrics,\n","import sklearn_crfsuite\n","from sklearn_crfsuite import scorers\n","from sklearn_crfsuite import metrics\n","\n","# especially the multiple forms of accuracy score to evaluate the model!\n","crf = sklearn_crfsuite.CRF(\n","    algorithm='lbfgs',\n","    c1=0.2,\n","    c2=0.1,\n","    max_iterations=100,\n","    all_possible_transitions=True)"],"execution_count":65,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jLnq8AgxL2lT","executionInfo":{"status":"ok","timestamp":1605836026008,"user_tz":-60,"elapsed":159397,"user":{"displayName":"Saurabh Chakravorty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4i8aVesE-zqnMJttjboEDqonbdcW85GPg1Yfj5g=s64","userId":"01575942328847603880"}},"outputId":"5817fa07-a4e8-4973-fcd9-948fcb98d9c8"},"source":["%%time\n","crf.fit(X_train, y_train)"],"execution_count":67,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n","  FutureWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n","    averaging=None, c=None, c1=0.2, c2=0.1, calibration_candidates=None,\n","    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n","    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n","    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n","    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n","    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"]},"metadata":{"tags":[]},"execution_count":67}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"swXCV8BSL2lU","executionInfo":{"status":"ok","timestamp":1605836282031,"user_tz":-60,"elapsed":2549,"user":{"displayName":"Saurabh Chakravorty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4i8aVesE-zqnMJttjboEDqonbdcW85GPg1Yfj5g=s64","userId":"01575942328847603880"}},"outputId":"7a0c4c28-3177-48c7-e5f5-6665a943d4a3"},"source":["# Please draw some conclusion if this model is \"good enough\" \n","# in your view if you take token level and sentence level metrics into account!\n","labels = list(crf.classes_)\n","y_pred = crf.predict(X_valid)\n","metrics.flat_f1_score(y_valid, y_pred, \n","                      average='weighted', labels=labels)"],"execution_count":69,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9764343387570985"]},"metadata":{"tags":[]},"execution_count":69}]},{"cell_type":"markdown","metadata":{"id":"pcATVMrxTZgW"},"source":["- The model is one of the best with high accuracy score\n","\n","- If we take token level features and sentence level metrics, it gives us more features to train our model which has more coorelation with target variable"]},{"cell_type":"markdown","metadata":{"id":"63p9RtDhsNU_"},"source":["Let's instantiate and fit our model. CRFsuite implements several learning methods, here we use \"ap\", i.e., averaged perceptron."]},{"cell_type":"markdown","metadata":{"id":"li8CXg67sNVc"},"source":["# Demonstration\n","\n","Just for the fun, we can try out the model."]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-12T09:35:17.983727Z","start_time":"2019-11-12T09:35:17.965723Z"},"id":"JHoYAGHFsNVe","executionInfo":{"status":"ok","timestamp":1605836483093,"user_tz":-60,"elapsed":509,"user":{"displayName":"Saurabh Chakravorty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4i8aVesE-zqnMJttjboEDqonbdcW85GPg1Yfj5g=s64","userId":"01575942328847603880"}}},"source":["def predict_tags(sent):\n","    \"\"\"Predict tags for a sentence.\n","    sent is a string.\n","    \"\"\"\n","    doc = en(sent)\n","    return crf.predict([[token2features(doc, i) for i in range(len(doc))]])"],"execution_count":70,"outputs":[]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2019-11-12T09:35:37.676093Z","start_time":"2019-11-12T09:35:17.986500Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"Ya59xso_z7uj","executionInfo":{"status":"ok","timestamp":1605836510150,"user_tz":-60,"elapsed":6474,"user":{"displayName":"Saurabh Chakravorty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4i8aVesE-zqnMJttjboEDqonbdcW85GPg1Yfj5g=s64","userId":"01575942328847603880"}},"outputId":"2d3bef38-9a91-40fa-b29d-df52aba1bba4"},"source":[" while True:\n","        sent = input(\"\\nEnter a sentence to tag or press return to quit:\\n\")\n","        if sent:\n","            print(predict_tags(sent))\n","        else:\n","            print(\"\\nEmpty input received -- bye!\")\n","            break"],"execution_count":72,"outputs":[{"output_type":"stream","text":["\n","Enter a sentence to tag or press return to quit:\n","This is an Englsh sentence.\n","[['DET', 'VERB', 'DET', 'ADJ', 'NOUN', '.']]\n","\n","Enter a sentence to tag or press return to quit:\n","\n","\n","Empty input received -- bye!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gE_93ADDUCyE"},"source":[""],"execution_count":null,"outputs":[]}]}