{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to access WordNet?\n",
    "\n",
    "[WordNet](https://wordnet.princeton.edu/) is a huge free lexical resource provided by Princeton University.\n",
    "\n",
    "More about WordNet can be found [here](https://en.wikipedia.org/wiki/WordNet)\n",
    "\n",
    "## Main concepts\n",
    "\n",
    "[Source](https://github.com/wordnet/wordnet)\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/wordnet/wordnet/master/doc/class_diagram.png\" width=55%>\n",
    "\n",
    "As a relational database the following attributes describe WordNet entities:\n",
    "\n",
    "### senses\n",
    "\n",
    "* `id`: The UUID identifier\n",
    "* `synset_id`:  The UUID of connected Synset\n",
    "* `external_id`:  The ID from external database, used for importing\n",
    "* `lemma`: The lemma of Lexeme that Sense belongs to (e.g. car)\n",
    "* `sense_index`: The index of sense in context of its Synset (e.g. 1)\n",
    "* `comment`: The short comment, used in UI (e.g. transporting machine)\n",
    "* `language`: Currently can be `en_GB` or `pl_PL`\n",
    "* `part_of_speech`: The part of speech of Sense (noun etc.)\n",
    "* `domain_id`: The ID of the Domain of Sense (not used yet)\n",
    "\n",
    "### synsets\n",
    "\n",
    "* `id`: The UUID identifier\n",
    "* `external_id`:  The ID from external database, used for importing\n",
    "* `comment`: The short comment by Słowosieć, used in UI\n",
    "* `definition`: The short comment by Princeton Wordnet, used in UI\n",
    "* `examples`: The examples of usage of synset from Princeton Wordnet\n",
    "\n",
    "### relation_types\n",
    "\n",
    "* `name`: Name of the relation\n",
    "* `reverse_relation`: Name of reverse relation (see: normalisation)\n",
    "* `parent_id`: Name of parent RelationType (inheritance-like)\n",
    "* `priority`: It is used for sorting relation types in UI (lower-better)\n",
    "* `description`: Description of the relation (not used yet)\n",
    "\n",
    "### sense\\_relations and synset\\_relations\n",
    "\n",
    "* `parent_id`: UUID of base sense (or synset)\n",
    "* `child_id`: UUID of of related sense (or synset)\n",
    "* `relation_id`: UUID of relation in which child is toward parent (e.g. UUID hyponymy relation means child is hyponym of parent)\n",
    "\n",
    "\n",
    "### Illustration\n",
    "\n",
    "<img src=\"https://www.w3.org/2001/sw/BestPractices/WNET/wordnet-sw-20040713-fig01.png\" width=60%>\n",
    "\n",
    "\n",
    "## WordNet on the web\n",
    "\n",
    "Princeton is providing a nice web based interface whereby one can easily query the lexical graph containing the `synsets` and the individual entries in them.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b8/WordNet.PNG/600px-WordNet.PNG\" width=65%>\n",
    "\n",
    "This is the [\"WordNet Search\" interface\"](http://wordnetweb.princeton.edu/perl/webwn)\n",
    "\n",
    "\n",
    "## Via NLTK\n",
    "\n",
    "<img src=\"https://i0.wp.com/clay-atlas.com/wp-content/uploads/2019/08/python_nltk.png?resize=592%2C644&ssl=1\" width=20%>\n",
    "\n",
    "[NLTK](https://www.nltk.org/) is a research / study focused NLP library with a very low barrier of entry, so it can be considered a \"go-to\" tool for students of NLP since it's [release in 2001](https://en.wikipedia.org/wiki/Natural_Language_Toolkit).\n",
    "\n",
    "As well as being a pipeline itself, it provides interfaces for famous (mostly \"practice sized\") default corpora and linguistic resources. (Recurring way to demonstrate NLP problems is to load the corpus with NLTK.)\n",
    "\n",
    "I this frame it has an interface exposing WordNet - detailed below.\n",
    "\n",
    "There are numerous introductions to NLTK. [this](https://www.nltk.org/book/ch01.html) is one amongst them.\n",
    "\n",
    "## Integration with SpaCy\n",
    "\n",
    "Luckily enough, there is an integration library, that exposes the NLTK based WordNet interface to SpaCy, integrating it to the pipeline.\n",
    "\n",
    "This is `spacy-wordnet`, and can be found [here](https://pypi.org/project/spacy-wordnet/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
    "<!-- saved from url=(0038)http://www.nltk.org/howto/wordnet.html -->\n",
    "<html xmlns=\"http://www.w3.org/1999/xhtml\" xml:lang=\"en\" lang=\"en\"><head><meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n",
    "\n",
    "<meta name=\"generator\" content=\"Docutils 0.12: http://docutils.sourceforge.net/\">\n",
    "<title>WordNet Interface</title>\n",
    "<style type=\"text/css\">\n",
    "\n",
    "/*\n",
    ":Author: David Goodger (goodger@python.org)\n",
    ":Id: $Id: html4css1.css 7614 2013-02-21 15:55:51Z milde $\n",
    ":Copyright: This stylesheet has been placed in the public domain.\n",
    "\n",
    "Default cascading style sheet for the HTML output of Docutils.\n",
    "\n",
    "See http://docutils.sf.net/docs/howto/html-stylesheets.html for how to\n",
    "customize this style sheet.\n",
    "*/\n",
    "\n",
    "/* used to remove borders from tables and images */\n",
    ".borderless, table.borderless td, table.borderless th {\n",
    "  border: 0 }\n",
    "\n",
    "table.borderless td, table.borderless th {\n",
    "  /* Override padding for \"table.docutils td\" with \"! important\".\n",
    "     The right padding separates the table cells. */\n",
    "  padding: 0 0.5em 0 0 ! important }\n",
    "\n",
    ".first {\n",
    "  /* Override more specific margin styles with \"! important\". */\n",
    "  margin-top: 0 ! important }\n",
    "\n",
    ".last, .with-subtitle {\n",
    "  margin-bottom: 0 ! important }\n",
    "\n",
    ".hidden {\n",
    "  display: none }\n",
    "\n",
    "a.toc-backref {\n",
    "  text-decoration: none ;\n",
    "  color: black }\n",
    "\n",
    "blockquote.epigraph {\n",
    "  margin: 2em 5em ; }\n",
    "\n",
    "dl.docutils dd {\n",
    "  margin-bottom: 0.5em }\n",
    "\n",
    "object[type=\"image/svg+xml\"], object[type=\"application/x-shockwave-flash\"] {\n",
    "  overflow: hidden;\n",
    "}\n",
    "\n",
    "/* Uncomment (and remove this text!) to get bold-faced definition list terms\n",
    "dl.docutils dt {\n",
    "  font-weight: bold }\n",
    "*/\n",
    "\n",
    "div.abstract {\n",
    "  margin: 2em 5em }\n",
    "\n",
    "div.abstract p.topic-title {\n",
    "  font-weight: bold ;\n",
    "  text-align: center }\n",
    "\n",
    "div.admonition, div.attention, div.caution, div.danger, div.error,\n",
    "div.hint, div.important, div.note, div.tip, div.warning {\n",
    "  margin: 2em ;\n",
    "  border: medium outset ;\n",
    "  padding: 1em }\n",
    "\n",
    "div.admonition p.admonition-title, div.hint p.admonition-title,\n",
    "div.important p.admonition-title, div.note p.admonition-title,\n",
    "div.tip p.admonition-title {\n",
    "  font-weight: bold ;\n",
    "  font-family: sans-serif }\n",
    "\n",
    "div.attention p.admonition-title, div.caution p.admonition-title,\n",
    "div.danger p.admonition-title, div.error p.admonition-title,\n",
    "div.warning p.admonition-title, .code .error {\n",
    "  color: red ;\n",
    "  font-weight: bold ;\n",
    "  font-family: sans-serif }\n",
    "\n",
    "/* Uncomment (and remove this text!) to get reduced vertical space in\n",
    "   compound paragraphs.\n",
    "div.compound .compound-first, div.compound .compound-middle {\n",
    "  margin-bottom: 0.5em }\n",
    "\n",
    "div.compound .compound-last, div.compound .compound-middle {\n",
    "  margin-top: 0.5em }\n",
    "*/\n",
    "\n",
    "div.dedication {\n",
    "  margin: 2em 5em ;\n",
    "  text-align: center ;\n",
    "  font-style: italic }\n",
    "\n",
    "div.dedication p.topic-title {\n",
    "  font-weight: bold ;\n",
    "  font-style: normal }\n",
    "\n",
    "div.figure {\n",
    "  margin-left: 2em ;\n",
    "  margin-right: 2em }\n",
    "\n",
    "div.footer, div.header {\n",
    "  clear: both;\n",
    "  font-size: smaller }\n",
    "\n",
    "div.line-block {\n",
    "  display: block ;\n",
    "  margin-top: 1em ;\n",
    "  margin-bottom: 1em }\n",
    "\n",
    "div.line-block div.line-block {\n",
    "  margin-top: 0 ;\n",
    "  margin-bottom: 0 ;\n",
    "  margin-left: 1.5em }\n",
    "\n",
    "div.sidebar {\n",
    "  margin: 0 0 0.5em 1em ;\n",
    "  border: medium outset ;\n",
    "  padding: 1em ;\n",
    "  background-color: #ffffee ;\n",
    "  width: 40% ;\n",
    "  float: right ;\n",
    "  clear: right }\n",
    "\n",
    "div.sidebar p.rubric {\n",
    "  font-family: sans-serif ;\n",
    "  font-size: medium }\n",
    "\n",
    "div.system-messages {\n",
    "  margin: 5em }\n",
    "\n",
    "div.system-messages h1 {\n",
    "  color: red }\n",
    "\n",
    "div.system-message {\n",
    "  border: medium outset ;\n",
    "  padding: 1em }\n",
    "\n",
    "div.system-message p.system-message-title {\n",
    "  color: red ;\n",
    "  font-weight: bold }\n",
    "\n",
    "div.topic {\n",
    "  margin: 2em }\n",
    "\n",
    "h1.section-subtitle, h2.section-subtitle, h3.section-subtitle,\n",
    "h4.section-subtitle, h5.section-subtitle, h6.section-subtitle {\n",
    "  margin-top: 0.4em }\n",
    "\n",
    "h1.title {\n",
    "  text-align: center }\n",
    "\n",
    "h2.subtitle {\n",
    "  text-align: center }\n",
    "\n",
    "hr.docutils {\n",
    "  width: 75% }\n",
    "\n",
    "img.align-left, .figure.align-left, object.align-left {\n",
    "  clear: left ;\n",
    "  float: left ;\n",
    "  margin-right: 1em }\n",
    "\n",
    "img.align-right, .figure.align-right, object.align-right {\n",
    "  clear: right ;\n",
    "  float: right ;\n",
    "  margin-left: 1em }\n",
    "\n",
    "img.align-center, .figure.align-center, object.align-center {\n",
    "  display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "}\n",
    "\n",
    ".align-left {\n",
    "  text-align: left }\n",
    "\n",
    ".align-center {\n",
    "  clear: both ;\n",
    "  text-align: center }\n",
    "\n",
    ".align-right {\n",
    "  text-align: right }\n",
    "\n",
    "/* reset inner alignment in figures */\n",
    "div.align-right {\n",
    "  text-align: inherit }\n",
    "\n",
    "/* div.align-center * { */\n",
    "/*   text-align: left } */\n",
    "\n",
    "ol.simple, ul.simple {\n",
    "  margin-bottom: 1em }\n",
    "\n",
    "ol.arabic {\n",
    "  list-style: decimal }\n",
    "\n",
    "ol.loweralpha {\n",
    "  list-style: lower-alpha }\n",
    "\n",
    "ol.upperalpha {\n",
    "  list-style: upper-alpha }\n",
    "\n",
    "ol.lowerroman {\n",
    "  list-style: lower-roman }\n",
    "\n",
    "ol.upperroman {\n",
    "  list-style: upper-roman }\n",
    "\n",
    "p.attribution {\n",
    "  text-align: right ;\n",
    "  margin-left: 50% }\n",
    "\n",
    "p.caption {\n",
    "  font-style: italic }\n",
    "\n",
    "p.credits {\n",
    "  font-style: italic ;\n",
    "  font-size: smaller }\n",
    "\n",
    "p.label {\n",
    "  white-space: nowrap }\n",
    "\n",
    "p.rubric {\n",
    "  font-weight: bold ;\n",
    "  font-size: larger ;\n",
    "  color: maroon ;\n",
    "  text-align: center }\n",
    "\n",
    "p.sidebar-title {\n",
    "  font-family: sans-serif ;\n",
    "  font-weight: bold ;\n",
    "  font-size: larger }\n",
    "\n",
    "p.sidebar-subtitle {\n",
    "  font-family: sans-serif ;\n",
    "  font-weight: bold }\n",
    "\n",
    "p.topic-title {\n",
    "  font-weight: bold }\n",
    "\n",
    "pre.address {\n",
    "  margin-bottom: 0 ;\n",
    "  margin-top: 0 ;\n",
    "  font: inherit }\n",
    "\n",
    "pre.literal-block, pre.doctest-block, pre.math, pre.code {\n",
    "  margin-left: 2em ;\n",
    "  margin-right: 2em }\n",
    "\n",
    "pre.code .ln { color: grey; } /* line numbers */\n",
    "pre.code, code { background-color: #eeeeee }\n",
    "pre.code .comment, code .comment { color: #5C6576 }\n",
    "pre.code .keyword, code .keyword { color: #3B0D06; font-weight: bold }\n",
    "pre.code .literal.string, code .literal.string { color: #0C5404 }\n",
    "pre.code .name.builtin, code .name.builtin { color: #352B84 }\n",
    "pre.code .deleted, code .deleted { background-color: #DEB0A1}\n",
    "pre.code .inserted, code .inserted { background-color: #A3D289}\n",
    "\n",
    "span.classifier {\n",
    "  font-family: sans-serif ;\n",
    "  font-style: oblique }\n",
    "\n",
    "span.classifier-delimiter {\n",
    "  font-family: sans-serif ;\n",
    "  font-weight: bold }\n",
    "\n",
    "span.interpreted {\n",
    "  font-family: sans-serif }\n",
    "\n",
    "span.option {\n",
    "  white-space: nowrap }\n",
    "\n",
    "span.pre {\n",
    "  white-space: pre }\n",
    "\n",
    "span.problematic {\n",
    "  color: red }\n",
    "\n",
    "span.section-subtitle {\n",
    "  /* font-size relative to parent (h1..h6 element) */\n",
    "  font-size: 80% }\n",
    "\n",
    "table.citation {\n",
    "  border-left: solid 1px gray;\n",
    "  margin-left: 1px }\n",
    "\n",
    "table.docinfo {\n",
    "  margin: 2em 4em }\n",
    "\n",
    "table.docutils {\n",
    "  margin-top: 0.5em ;\n",
    "  margin-bottom: 0.5em }\n",
    "\n",
    "table.footnote {\n",
    "  border-left: solid 1px black;\n",
    "  margin-left: 1px }\n",
    "\n",
    "table.docutils td, table.docutils th,\n",
    "table.docinfo td, table.docinfo th {\n",
    "  padding-left: 0.5em ;\n",
    "  padding-right: 0.5em ;\n",
    "  vertical-align: top }\n",
    "\n",
    "table.docutils th.field-name, table.docinfo th.docinfo-name {\n",
    "  font-weight: bold ;\n",
    "  text-align: left ;\n",
    "  white-space: nowrap ;\n",
    "  padding-left: 0 }\n",
    "\n",
    "/* \"booktabs\" style (no vertical lines) */\n",
    "table.docutils.booktabs {\n",
    "  border: 0px;\n",
    "  border-top: 2px solid;\n",
    "  border-bottom: 2px solid;\n",
    "  border-collapse: collapse;\n",
    "}\n",
    "table.docutils.booktabs * {\n",
    "  border: 0px;\n",
    "}\n",
    "table.docutils.booktabs th {\n",
    "  border-bottom: thin solid;\n",
    "  text-align: left;\n",
    "}\n",
    "\n",
    "h1 tt.docutils, h2 tt.docutils, h3 tt.docutils,\n",
    "h4 tt.docutils, h5 tt.docutils, h6 tt.docutils {\n",
    "  font-size: 100% }\n",
    "\n",
    "ul.auto-toc {\n",
    "  list-style-type: none }\n",
    "\n",
    "</style>\n",
    "<style>@media print {#ghostery-purple-box {display:none !important}}</style></head>\n",
    "<body>\n",
    "<div class=\"document\" id=\"wordnet-interface\">\n",
    "<h1 class=\"title\">WordNet Interface</h1>\n",
    "\n",
    "<!-- Copyright (C) 2001-2015 NLTK Project -->\n",
    "<!-- For license information, see LICENSE.TXT -->\n",
    "<p>WordNet is just another NLTK corpus reader, and can be imported like this:</p>\n",
    "<blockquote>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; from nltk.corpus import wordnet\n",
    "</pre>\n",
    "</blockquote>\n",
    "<p>For more compact code, we recommend:</p>\n",
    "<blockquote>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; from nltk.corpus import wordnet as wn\n",
    "</pre>\n",
    "</blockquote>\n",
    "<div class=\"section\" id=\"words\">\n",
    "<h1>Words</h1>\n",
    "<p>Look up a word using <tt class=\"docutils literal\">synsets()</tt>; this function has an optional <tt class=\"docutils literal\">pos</tt> argument\n",
    "which lets you constrain the part of speech of the word:</p>\n",
    "<blockquote>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; wn.synsets('dog') # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n",
    "[Synset('dog.n.01'), Synset('frump.n.01'), Synset('dog.n.03'), Synset('cad.n.01'),\n",
    "Synset('frank.n.02'), Synset('pawl.n.01'), Synset('andiron.n.01'), Synset('chase.v.01')]\n",
    "&gt;&gt;&gt; wn.synsets('dog', pos=wn.VERB)\n",
    "[Synset('chase.v.01')]\n",
    "</pre>\n",
    "</blockquote>\n",
    "<p>The other parts of speech are <tt class=\"docutils literal\">NOUN</tt>, <tt class=\"docutils literal\">ADJ</tt> and <tt class=\"docutils literal\">ADV</tt>.\n",
    "A synset is identified with a 3-part name of the form: word.pos.nn:</p>\n",
    "<blockquote>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; wn.synset('dog.n.01')\n",
    "Synset('dog.n.01')\n",
    "&gt;&gt;&gt; print(wn.synset('dog.n.01').definition())\n",
    "a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n",
    "&gt;&gt;&gt; len(wn.synset('dog.n.01').examples())\n",
    "1\n",
    "&gt;&gt;&gt; print(wn.synset('dog.n.01').examples()[0])\n",
    "the dog barked all night\n",
    "&gt;&gt;&gt; wn.synset('dog.n.01').lemmas()\n",
    "[Lemma('dog.n.01.dog'), Lemma('dog.n.01.domestic_dog'), Lemma('dog.n.01.Canis_familiaris')]\n",
    "&gt;&gt;&gt; [str(lemma.name()) for lemma in wn.synset('dog.n.01').lemmas()]\n",
    "['dog', 'domestic_dog', 'Canis_familiaris']\n",
    "&gt;&gt;&gt; wn.lemma('dog.n.01.dog').synset()\n",
    "Synset('dog.n.01')\n",
    "</pre>\n",
    "</blockquote>\n",
    "<p>The WordNet corpus reader gives access to the Open Multilingual\n",
    "WordNet, using ISO-639 language codes.</p>\n",
    "<blockquote>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; sorted(wn.langs())\n",
    "['als', 'arb', 'cat', 'cmn', 'dan', 'eng', 'eus', 'fas',\n",
    "'fin', 'fra', 'fre', 'glg', 'heb', 'ind', 'ita', 'jpn', 'nno',\n",
    "'nob', 'pol', 'por', 'spa', 'tha', 'zsm']\n",
    "&gt;&gt;&gt; wn.synsets(b'\\xe7\\x8a\\xac'.decode('utf-8'), lang='jpn')\n",
    "[Synset('dog.n.01'), Synset('spy.n.01')]\n",
    "&gt;&gt;&gt; wn.synset('spy.n.01').lemma_names('jpn')\n",
    "['\\u3044\\u306c', '\\u307e\\u308f\\u3057\\u8005', '\\u30b9\\u30d1\\u30a4', '\\u56de\\u3057\\u8005',\n",
    "'\\u56de\\u8005', '\\u5bc6\\u5075', '\\u5de5\\u4f5c\\u54e1', '\\u5efb\\u3057\\u8005',\n",
    "'\\u5efb\\u8005', '\\u63a2', '\\u63a2\\u308a', '\\u72ac', '\\u79d8\\u5bc6\\u635c\\u67fb\\u54e1',\n",
    "'\\u8adc\\u5831\\u54e1', '\\u8adc\\u8005', '\\u9593\\u8005', '\\u9593\\u8adc', '\\u96a0\\u5bc6']\n",
    "&gt;&gt;&gt; wn.synset('dog.n.01').lemma_names('ita')\n",
    "['cane', 'Canis_familiaris']\n",
    "&gt;&gt;&gt; wn.lemmas('cane', lang='ita')\n",
    "[Lemma('dog.n.01.cane'), Lemma('hammer.n.01.cane'), Lemma('cramp.n.02.cane'),\n",
    "Lemma('bad_person.n.01.cane'), Lemma('incompetent.n.01.cane')]\n",
    "&gt;&gt;&gt; sorted(wn.synset('dog.n.01').lemmas('dan'))\n",
    "[Lemma('dog.n.01.hund'), Lemma('dog.n.01.k\\xf8ter'),\n",
    "Lemma('dog.n.01.vovhund'), Lemma('dog.n.01.vovse')]\n",
    "&gt;&gt;&gt; sorted(wn.synset('dog.n.01').lemmas('por'))\n",
    "[Lemma('dog.n.01.cachorro'), Lemma('dog.n.01.c\\xe3es'),\n",
    "Lemma('dog.n.01.c\\xe3o'), Lemma('dog.n.01.c\\xe3o')]\n",
    "&gt;&gt;&gt; dog_lemma = wn.lemma(b'dog.n.01.c\\xc3\\xa3o'.decode('utf-8'), lang='por')\n",
    "&gt;&gt;&gt; dog_lemma\n",
    "Lemma('dog.n.01.c\\xe3o')\n",
    "&gt;&gt;&gt; dog_lemma.lang()\n",
    "'por'\n",
    "&gt;&gt;&gt; len(wordnet.all_lemma_names(pos='n', lang='jpn'))\n",
    "66027\n",
    "</pre>\n",
    "</blockquote>\n",
    "</div>\n",
    "<div class=\"section\" id=\"synsets\">\n",
    "<h1>Synsets</h1>\n",
    "<p><cite>Synset</cite>: a set of synonyms that share a common meaning.</p>\n",
    "<blockquote>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; dog = wn.synset('dog.n.01')\n",
    "&gt;&gt;&gt; dog.hypernyms()\n",
    "[Synset('canine.n.02'), Synset('domestic_animal.n.01')]\n",
    "&gt;&gt;&gt; dog.hyponyms()  # doctest: +ELLIPSIS\n",
    "[Synset('basenji.n.01'), Synset('corgi.n.01'), Synset('cur.n.01'), Synset('dalmatian.n.02'), ...]\n",
    "&gt;&gt;&gt; dog.member_holonyms()\n",
    "[Synset('canis.n.01'), Synset('pack.n.06')]\n",
    "&gt;&gt;&gt; dog.root_hypernyms()\n",
    "[Synset('entity.n.01')]\n",
    "&gt;&gt;&gt; wn.synset('dog.n.01').lowest_common_hypernyms(wn.synset('cat.n.01'))\n",
    "[Synset('carnivore.n.01')]\n",
    "</pre>\n",
    "</blockquote>\n",
    "<p>Each synset contains one or more lemmas, which represent a specific\n",
    "sense of a specific word.</p>\n",
    "<p>Note that some relations are defined by WordNet only over Lemmas:</p>\n",
    "<blockquote>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; good = wn.synset('good.a.01')\n",
    "&gt;&gt;&gt; good.antonyms()\n",
    "Traceback (most recent call last):\n",
    "  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n",
    "AttributeError: 'Synset' object has no attribute 'antonyms'\n",
    "&gt;&gt;&gt; good.lemmas()[0].antonyms()\n",
    "[Lemma('bad.a.01.bad')]\n",
    "</pre>\n",
    "</blockquote>\n",
    "<p>The relations that are currently defined in this way are <cite>antonyms</cite>,\n",
    "<cite>derivationally_related_forms</cite> and <cite>pertainyms</cite>.</p>\n",
    "</div>\n",
    "<div class=\"section\" id=\"lemmas\">\n",
    "<h1>Lemmas</h1>\n",
    "<blockquote>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; eat = wn.lemma('eat.v.03.eat')\n",
    "&gt;&gt;&gt; eat\n",
    "Lemma('feed.v.06.eat')\n",
    "&gt;&gt;&gt; print(eat.key())\n",
    "eat%2:34:02::\n",
    "&gt;&gt;&gt; eat.count()\n",
    "4\n",
    "&gt;&gt;&gt; wn.lemma_from_key(eat.key())\n",
    "Lemma('feed.v.06.eat')\n",
    "&gt;&gt;&gt; wn.lemma_from_key(eat.key()).synset()\n",
    "Synset('feed.v.06')\n",
    "&gt;&gt;&gt; wn.lemma_from_key('feebleminded%5:00:00:retarded:00')\n",
    "Lemma('backward.s.03.feebleminded')\n",
    "&gt;&gt;&gt; for lemma in wn.synset('eat.v.03').lemmas():\n",
    "...     print(lemma, lemma.count())\n",
    "...\n",
    "Lemma('feed.v.06.feed') 3\n",
    "Lemma('feed.v.06.eat') 4\n",
    "&gt;&gt;&gt; for lemma in wn.lemmas('eat', 'v'):\n",
    "...     print(lemma, lemma.count())\n",
    "...\n",
    "Lemma('eat.v.01.eat') 61\n",
    "Lemma('eat.v.02.eat') 13\n",
    "Lemma('feed.v.06.eat') 4\n",
    "Lemma('eat.v.04.eat') 0\n",
    "Lemma('consume.v.05.eat') 0\n",
    "Lemma('corrode.v.01.eat') 0\n",
    "</pre>\n",
    "</blockquote>\n",
    "<p>Lemmas can also have relations between them:</p>\n",
    "<blockquote>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; vocal = wn.lemma('vocal.a.01.vocal')\n",
    "&gt;&gt;&gt; vocal.derivationally_related_forms()\n",
    "[Lemma('vocalize.v.02.vocalize')]\n",
    "&gt;&gt;&gt; vocal.pertainyms()\n",
    "[Lemma('voice.n.02.voice')]\n",
    "&gt;&gt;&gt; vocal.antonyms()\n",
    "[Lemma('instrumental.a.01.instrumental')]\n",
    "</pre>\n",
    "</blockquote>\n",
    "<p>The three relations above exist only on lemmas, not on synsets.</p>\n",
    "</div>\n",
    "<div class=\"section\" id=\"verb-frames\">\n",
    "<h1>Verb Frames</h1>\n",
    "<blockquote>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; wn.synset('think.v.01').frame_ids()\n",
    "[5, 9]\n",
    "&gt;&gt;&gt; for lemma in wn.synset('think.v.01').lemmas():\n",
    "...     print(lemma, lemma.frame_ids())\n",
    "...     print(\" | \".join(lemma.frame_strings()))\n",
    "...\n",
    "Lemma('think.v.01.think') [5, 9]\n",
    "Something think something Adjective/Noun | Somebody think somebody\n",
    "Lemma('think.v.01.believe') [5, 9]\n",
    "Something believe something Adjective/Noun | Somebody believe somebody\n",
    "Lemma('think.v.01.consider') [5, 9]\n",
    "Something consider something Adjective/Noun | Somebody consider somebody\n",
    "Lemma('think.v.01.conceive') [5, 9]\n",
    "Something conceive something Adjective/Noun | Somebody conceive somebody\n",
    "&gt;&gt;&gt; wn.synset('stretch.v.02').frame_ids()\n",
    "[8]\n",
    "&gt;&gt;&gt; for lemma in wn.synset('stretch.v.02').lemmas():\n",
    "...     print(lemma, lemma.frame_ids())\n",
    "...     print(\" | \".join(lemma.frame_strings()))\n",
    "...\n",
    "Lemma('stretch.v.02.stretch') [8, 2]\n",
    "Somebody stretch something | Somebody stretch\n",
    "Lemma('stretch.v.02.extend') [8]\n",
    "Somebody extend something\n",
    "</pre>\n",
    "</blockquote>\n",
    "</div>\n",
    "<div class=\"section\" id=\"similarity\">\n",
    "<h1>Similarity</h1>\n",
    "<blockquote>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; dog = wn.synset('dog.n.01')\n",
    "&gt;&gt;&gt; cat = wn.synset('cat.n.01')\n",
    "</pre>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; hit = wn.synset('hit.v.01')\n",
    "&gt;&gt;&gt; slap = wn.synset('slap.v.01')\n",
    "</pre>\n",
    "</blockquote>\n",
    "<p><tt class=\"docutils literal\">synset1.path_similarity(synset2):</tt>\n",
    "Return a score denoting how similar two word senses are, based on the\n",
    "shortest path that connects the senses in the is-a (hypernym/hypnoym)\n",
    "taxonomy. The score is in the range 0 to 1. By default, there is now\n",
    "a fake root node added to verbs so for cases where previously a path\n",
    "could not be found---and None was returned---it should return a value.\n",
    "The old behavior can be achieved by setting simulate_root to be False.\n",
    "A score of 1 represents identity i.e. comparing a sense with itself\n",
    "will return 1.</p>\n",
    "<blockquote>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; dog.path_similarity(cat)  # doctest: +ELLIPSIS\n",
    "0.2...\n",
    "</pre>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; hit.path_similarity(slap)  # doctest: +ELLIPSIS\n",
    "0.142...\n",
    "</pre>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; wn.path_similarity(hit, slap)  # doctest: +ELLIPSIS\n",
    "0.142...\n",
    "</pre>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; print(hit.path_similarity(slap, simulate_root=False))\n",
    "None\n",
    "</pre>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; print(wn.path_similarity(hit, slap, simulate_root=False))\n",
    "None\n",
    "</pre>\n",
    "</blockquote>\n",
    "<p><tt class=\"docutils literal\">synset1.lch_similarity(synset2):</tt>\n",
    "Leacock-Chodorow Similarity:\n",
    "Return a score denoting how similar two word senses are, based on the\n",
    "shortest path that connects the senses (as above) and the maximum depth\n",
    "of the taxonomy in which the senses occur. The relationship is given\n",
    "as -log(p/2d) where p is the shortest path length and d the taxonomy\n",
    "depth.</p>\n",
    "<blockquote>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; dog.lch_similarity(cat)  # doctest: +ELLIPSIS\n",
    "2.028...\n",
    "</pre>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; hit.lch_similarity(slap)  # doctest: +ELLIPSIS\n",
    "1.312...\n",
    "</pre>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; wn.lch_similarity(hit, slap)  # doctest: +ELLIPSIS\n",
    "1.312...\n",
    "</pre>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; print(hit.lch_similarity(slap, simulate_root=False))\n",
    "None\n",
    "</pre>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; print(wn.lch_similarity(hit, slap, simulate_root=False))\n",
    "None\n",
    "</pre>\n",
    "</blockquote>\n",
    "<p><tt class=\"docutils literal\">synset1.wup_similarity(synset2):</tt>\n",
    "Wu-Palmer Similarity:\n",
    "Return a score denoting how similar two word senses are, based on the\n",
    "depth of the two senses in the taxonomy and that of their Least Common\n",
    "Subsumer (most specific ancestor node). Note that at this time the\n",
    "scores given do _not_ always agree with those given by Pedersen's Perl\n",
    "implementation of Wordnet Similarity.</p>\n",
    "<p>The LCS does not necessarily feature in the shortest path connecting the\n",
    "two senses, as it is by definition the common ancestor deepest in the\n",
    "taxonomy, not closest to the two senses. Typically, however, it will so\n",
    "feature. Where multiple candidates for the LCS exist, that whose\n",
    "shortest path to the root node is the longest will be selected. Where\n",
    "the LCS has multiple paths to the root, the longer path is used for\n",
    "the purposes of the calculation.</p>\n",
    "<blockquote>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; dog.wup_similarity(cat)  # doctest: +ELLIPSIS\n",
    "0.857...\n",
    "</pre>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; hit.wup_similarity(slap)\n",
    "0.25\n",
    "</pre>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; wn.wup_similarity(hit, slap)\n",
    "0.25\n",
    "</pre>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; print(hit.wup_similarity(slap, simulate_root=False))\n",
    "None\n",
    "</pre>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; print(wn.wup_similarity(hit, slap, simulate_root=False))\n",
    "None\n",
    "</pre>\n",
    "</blockquote>\n",
    "<p><tt class=\"docutils literal\">wordnet_ic</tt>\n",
    "Information Content:\n",
    "Load an information content file from the wordnet_ic corpus.</p>\n",
    "<blockquote>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; from nltk.corpus import wordnet_ic\n",
    "&gt;&gt;&gt; brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "&gt;&gt;&gt; semcor_ic = wordnet_ic.ic('ic-semcor.dat')\n",
    "</pre>\n",
    "</blockquote>\n",
    "<p>Or you can create an information content dictionary from a corpus (or\n",
    "anything that has a words() method).</p>\n",
    "<blockquote>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; from nltk.corpus import genesis\n",
    "&gt;&gt;&gt; genesis_ic = wn.ic(genesis, False, 0.0)\n",
    "</pre>\n",
    "</blockquote>\n",
    "<p><tt class=\"docutils literal\">synset1.res_similarity(synset2, ic):</tt>\n",
    "Resnik Similarity:\n",
    "Return a score denoting how similar two word senses are, based on the\n",
    "Information Content (IC) of the Least Common Subsumer (most specific\n",
    "ancestor node).  Note that for any similarity measure that uses\n",
    "information content, the result is dependent on the corpus used to\n",
    "generate the information content and the specifics of how the\n",
    "information content was created.</p>\n",
    "<blockquote>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; dog.res_similarity(cat, brown_ic)  # doctest: +ELLIPSIS\n",
    "7.911...\n",
    "&gt;&gt;&gt; dog.res_similarity(cat, genesis_ic)  # doctest: +ELLIPSIS\n",
    "7.204...\n",
    "</pre>\n",
    "</blockquote>\n",
    "<p><tt class=\"docutils literal\">synset1.jcn_similarity(synset2, ic):</tt>\n",
    "Jiang-Conrath Similarity\n",
    "Return a score denoting how similar two word senses are, based on the\n",
    "Information Content (IC) of the Least Common Subsumer (most specific\n",
    "ancestor node) and that of the two input Synsets. The relationship is\n",
    "given by the equation 1 / (IC(s1) + IC(s2) - 2 * IC(lcs)).</p>\n",
    "<blockquote>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; dog.jcn_similarity(cat, brown_ic)  # doctest: +ELLIPSIS\n",
    "0.449...\n",
    "&gt;&gt;&gt; dog.jcn_similarity(cat, genesis_ic)  # doctest: +ELLIPSIS\n",
    "0.285...\n",
    "</pre>\n",
    "</blockquote>\n",
    "<p><tt class=\"docutils literal\">synset1.lin_similarity(synset2, ic):</tt>\n",
    "Lin Similarity:\n",
    "Return a score denoting how similar two word senses are, based on the\n",
    "Information Content (IC) of the Least Common Subsumer (most specific\n",
    "ancestor node) and that of the two input Synsets. The relationship is\n",
    "given by the equation 2 * IC(lcs) / (IC(s1) + IC(s2)).</p>\n",
    "<blockquote>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; dog.lin_similarity(cat, semcor_ic)  # doctest: +ELLIPSIS\n",
    "0.886...\n",
    "</pre>\n",
    "</blockquote>\n",
    "</div>\n",
    "<div class=\"section\" id=\"access-to-all-synsets\">\n",
    "<h1>Access to all Synsets</h1>\n",
    "<p>Iterate over all the noun synsets:</p>\n",
    "<blockquote>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; for synset in list(wn.all_synsets('n'))[:10]:\n",
    "...     print(synset)\n",
    "...\n",
    "Synset('entity.n.01')\n",
    "Synset('physical_entity.n.01')\n",
    "Synset('abstraction.n.06')\n",
    "Synset('thing.n.12')\n",
    "Synset('object.n.01')\n",
    "Synset('whole.n.02')\n",
    "Synset('congener.n.03')\n",
    "Synset('living_thing.n.01')\n",
    "Synset('organism.n.01')\n",
    "Synset('benthos.n.02')\n",
    "</pre>\n",
    "</blockquote>\n",
    "<p>Get all synsets for this word, possibly restricted by POS:</p>\n",
    "<blockquote>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; wn.synsets('dog') # doctest: +ELLIPSIS\n",
    "[Synset('dog.n.01'), Synset('frump.n.01'), Synset('dog.n.03'), Synset('cad.n.01'), ...]\n",
    "&gt;&gt;&gt; wn.synsets('dog', pos='v')\n",
    "[Synset('chase.v.01')]\n",
    "</pre>\n",
    "</blockquote>\n",
    "<p>Walk through the noun synsets looking at their hypernyms:</p>\n",
    "<blockquote>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; from itertools import islice\n",
    "&gt;&gt;&gt; for synset in islice(wn.all_synsets('n'), 5):\n",
    "...     print(synset, synset.hypernyms())\n",
    "...\n",
    "Synset('entity.n.01') []\n",
    "Synset('physical_entity.n.01') [Synset('entity.n.01')]\n",
    "Synset('abstraction.n.06') [Synset('entity.n.01')]\n",
    "Synset('thing.n.12') [Synset('physical_entity.n.01')]\n",
    "Synset('object.n.01') [Synset('physical_entity.n.01')]\n",
    "</pre>\n",
    "</blockquote>\n",
    "</div>\n",
    "<div class=\"section\" id=\"morphy\">\n",
    "<h1>Morphy</h1>\n",
    "<p>Look up forms not in WordNet, with the help of Morphy:</p>\n",
    "<blockquote>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; wn.morphy('denied', wn.NOUN)\n",
    "&gt;&gt;&gt; print(wn.morphy('denied', wn.VERB))\n",
    "deny\n",
    "&gt;&gt;&gt; wn.synsets('denied', wn.NOUN)\n",
    "[]\n",
    "&gt;&gt;&gt; wn.synsets('denied', wn.VERB) # doctest: +NORMALIZE_WHITESPACE\n",
    "[Synset('deny.v.01'), Synset('deny.v.02'), Synset('deny.v.03'), Synset('deny.v.04'),\n",
    "Synset('deny.v.05'), Synset('traverse.v.03'), Synset('deny.v.07')]\n",
    "</pre>\n",
    "</blockquote>\n",
    "<p>Morphy uses a combination of inflectional ending rules and exception\n",
    "lists to handle a variety of different possibilities:</p>\n",
    "<blockquote>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; print(wn.morphy('dogs'))\n",
    "dog\n",
    "&gt;&gt;&gt; print(wn.morphy('churches'))\n",
    "church\n",
    "&gt;&gt;&gt; print(wn.morphy('aardwolves'))\n",
    "aardwolf\n",
    "&gt;&gt;&gt; print(wn.morphy('abaci'))\n",
    "abacus\n",
    "&gt;&gt;&gt; print(wn.morphy('book', wn.NOUN))\n",
    "book\n",
    "&gt;&gt;&gt; wn.morphy('hardrock', wn.ADV)\n",
    "&gt;&gt;&gt; wn.morphy('book', wn.ADJ)\n",
    "&gt;&gt;&gt; wn.morphy('his', wn.NOUN)\n",
    "&gt;&gt;&gt;\n",
    "</pre>\n",
    "</blockquote>\n",
    "</div>\n",
    "<div class=\"section\" id=\"synset-closures\">\n",
    "<h1>Synset Closures</h1>\n",
    "<p>Compute transitive closures of synsets</p>\n",
    "<blockquote>\n",
    "<pre class=\"doctest-block\">&gt;&gt;&gt; dog = wn.synset('dog.n.01')\n",
    "&gt;&gt;&gt; hypo = lambda s: s.hyponyms()\n",
    "&gt;&gt;&gt; hyper = lambda s: s.hypernyms()\n",
    "&gt;&gt;&gt; list(dog.closure(hypo, depth=1)) == dog.hyponyms()\n",
    "True\n",
    "&gt;&gt;&gt; list(dog.closure(hyper, depth=1)) == dog.hypernyms()\n",
    "True\n",
    "&gt;&gt;&gt; list(dog.closure(hypo))\n",
    "[Synset('basenji.n.01'), Synset('corgi.n.01'), Synset('cur.n.01'),\n",
    " Synset('dalmatian.n.02'), Synset('great_pyrenees.n.01'),\n",
    " Synset('griffon.n.02'), Synset('hunting_dog.n.01'), Synset('lapdog.n.01'),\n",
    " Synset('leonberg.n.01'), Synset('mexican_hairless.n.01'),\n",
    " Synset('newfoundland.n.01'), Synset('pooch.n.01'), Synset('poodle.n.01'), ...]\n",
    "&gt;&gt;&gt; list(dog.closure(hyper))\n",
    "[Synset('canine.n.02'), Synset('domestic_animal.n.01'), Synset('carnivore.n.01'),\n",
    "Synset('animal.n.01'), Synset('placental.n.01'), Synset('organism.n.01'),\n",
    "Synset('mammal.n.01'), Synset('living_thing.n.01'), Synset('vertebrate.n.01'),\n",
    "Synset('whole.n.02'), Synset('chordate.n.01'), Synset('object.n.01'),\n",
    "Synset('physical_entity.n.01'), Synset('entity.n.01')]\n",
    "</pre>\n",
    "</blockquote>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "</body></html>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
