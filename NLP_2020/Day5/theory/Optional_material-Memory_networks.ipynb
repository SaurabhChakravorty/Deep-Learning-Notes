{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory networks \n",
    "\n",
    "The idea of attention mechanisms over a representation had far wider consequences than one could imagine at first, since some researchers started to generalize this mechanism as a general storage-retrieval method method for differentiable computation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gated RNN memory problems\n",
    "\n",
    "### Comparatively small \"working memory\"\n",
    "\n",
    "The size of the hidden state, that is the \"working memory\" of LSTM-like models is very limited\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1-LbAhO8U_sfr5ipSaPTEm_0niPxS39u8\"><img src=\"https://drive.google.com/uc?export=view&id=1sfFBw-2YoRLQsx58-67lQ-T6B3bp9Hmu\" width=60%></a>\n",
    "\n",
    "If we take a layer width of 2000 and 64 bit floating point numbers, we get approximately: 128kbit = 16kB, which was considered very limited even with the advent of personal computing\n",
    "\n",
    "<a href=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/Commodore_16_002a.png/1920px-Commodore_16_002a.png\"><img src=\"https://drive.google.com/uc?export=view&id=1ivxwUtXg7IPPXDx_7lZ9QzE_sZUoFYCd\" width=40%></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The storage requirement of weights\n",
    "\n",
    "In spite of the limited capacity, the storage needed for the weights is quadratically related to the size of memory, since the \"gates\" are dense layers.\n",
    "\n",
    "So if the size of the hidden layer is $h$, the number of weights for an LSTM model is more than $4 h^2$, that means, for the 2000 width example, we are talking about more than **16 million weights**, for which we again calculate with 64 bit numbers, we have to use at least 128MB of storage for the weights (16kB information, at least 128MB retrieval mechanism!!)\n",
    "\n",
    "\n",
    "#### External memory\n",
    "\n",
    "The question naturally arises: how can we increase the storage capacity without increasing the number of weights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lSJN3Wv9ESZy"
   },
   "source": [
    "### Memory Networks\n",
    "\n",
    "[Weston et al. (Facebook AI Research, 2014): Memory Networks](https://arxiv.org/pdf/1410.3916.pdf)\n",
    "\n",
    "#### Abstract architecture: IGOR\n",
    "\n",
    "- __Input__: Transforms the input into internal feature respresentations\n",
    "- __Generalization__: Refreshes the memory based on the input, typically it compresses, represents\n",
    "- __Output__: Generates new output (in the feature representation space)based on input and memory state\n",
    "- __Response__: Transforms output to the required output format\n",
    "\n",
    "#### Modules more in detail\n",
    "\n",
    "##### Input\n",
    "In NLP cases processing and embedding can happen here\n",
    "\n",
    "##### Generalization\n",
    "The most basic solution is to simply store the inner representation at a memory location depending on the $x$ input:\n",
    "\n",
    "$$m_{H(x)} = I(x) $$\n",
    "\n",
    "where $H(.)$ is definign the appropriate memory location.\n",
    "\n",
    "##### Output and response\n",
    "- Typically the oputput reads and composes data from the memory locations, which means a form of reasoning\n",
    "- Based on output, response layer gives the final response, eg. an RNN decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vRwkjhxZyGuM"
   },
   "source": [
    "### One example architecture: Neural Turing Machine 2.0 - Differentiable Neural Computer\n",
    "\n",
    "[Graves et al (Google DeepMind, 2016): Hybrid computing using a neural\n",
    "network with dynamic external memory](https://www.dropbox.com/s/0a40xi702grx3dq/2016-graves.pdf)\n",
    "\n",
    "#### Architecture\n",
    "\n",
    "The architecture is based on that of the classic Turing machine: there are separate reading and writing network components (\"heads\") to interact with the external memory, which is an array of writable/readable numeric vectors.\n",
    "The main method of addressing the memory is similarity based. Given a key, a similarity based attention mechanism accesses the memory by focusing on the memory cells with content that is most similar to the key. Among uses, this mechanism enables using the memory as a key-value store. \n",
    "\n",
    "The memory related components:\n",
    "- a memory address adjacency matrix that stores which memory addresses were written after each other.\n",
    "- a vector storing the list of already used memory addresses.\n",
    "- a single \"write head\", which uses either a key/content based addressing scheme or writes to newly allocated memory places.\n",
    "- two reading heads, both of which can read the external memory in three ways:\n",
    "  - based on the similarity of content to a given key\n",
    "  - sequentially according to the earlier writing order\n",
    "  - by selecting an unused or long ago used memory cell\n",
    "\n",
    "The above external memory machinery is driven by a recurrent network \"controller\" which reads the input, interacts with the external memory and produces the output.\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1HQMkHgWYUL348DT86ZQe371snij1Ui6X\"><img src=\"https://drive.google.com/uc?export=view&id=1CIhX3xBXNy44l_zPTQDp3Lk0pwG27cOO\"></a>\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dk5zBfhhefg8"
   },
   "source": [
    "### Results\n",
    "\n",
    "- __Large scale QA__ Search in a memory stored database of 14M triplets in (subject, relation, object) form (eg. milne authored winnie-the-pooh) based on natural language query, eg. \"Who is pooh's creator?\"\n",
    "\n",
    "> \"The results show that MemNNs are a viable approach for large scale QA in\n",
    "terms of performance.\"\n",
    "\n",
    "- __Simulated World QA__ \n",
    "\n",
    "Answering questions based on simple stories:\n",
    "\n",
    ">we also built a simple simulation of 4 characters, 3 objects and 5 rooms â€“ with characters moving around, picking up and dropping objects. The actions are transcribed into text using a simple automated grammar, and labeled questions are generated in a similar way.\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1oxe_-Wm4s4K-Ax880NCu4Z_lK-PFnriH\"><img src=\"https://drive.google.com/uc?export=view&id=1R86U4s8e36kq6i2sZnJJ0clAsYAaI5a4\"></a>\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1BtY9jKwtt3xr4NS9huadwCTllP-GQCkp\"><img src=\"https://drive.google.com/uc?export=view&id=1HM2w2BUCTituYseVDjCzw3mnOl1Vk2nD\" width=\"700px\"></a>\n",
    "\n",
    "(Difficulty: In which sentence did the asked object appear in the last time? Actor vs actor + object expariment: in the first only \"go\" was allowed as action, in the later \"get\" and \"drop\" also.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YS1X448R_ehG"
   },
   "source": [
    "### Mature benchmark - The bAbI dataset\n",
    "\n",
    "bAbI tasks: synthetic \"toy\" QA dataset produced by simulation\n",
    "\n",
    "([Weston et al (Facebook AI Research, 2016): Towards ai-complete question answering: A set of prerequisite toy tasks.](https://arxiv.org/pdf/1502.05698.pdf)):\n",
    "\n",
    ">All of the tasks are noiseless and a human able to read that language can potentially achieve 100%\n",
    "accuracy. We tried to choose tasks that are natural to a human: they are based on simple usual situations and no background in areas such as formal semantics, machine learning, logic or knowledge\n",
    "representation is required for an adult to solve them.\n",
    "\n",
    ">The data itself is produced using a simple simulation of characters and objects moving around and\n",
    "interacting in locations, described in Section 4.  The simulation allows us to generate data in many\n",
    "different scenarios where the true labels are known by grounding to the simulation.\n",
    "\n",
    "Components:\n",
    "\n",
    "- \"entities\"\n",
    "  - places\n",
    "  - objects\n",
    "  - persons\n",
    "- states\n",
    "  - absolute/relative place\n",
    "  - mental state\n",
    "- attributes\n",
    "  - size\n",
    "  - colour\n",
    "- actions:\n",
    "  - go _location_, get _object_, get _object1_ from _object2_, put _object1_ in/on _object2_, give _object_ to\n",
    "_actor_, drop _object_, set _entitity_ _state_, look, inventory and examine _object_.\n",
    "\n",
    "\"For each task, we describe it by giving a small sample of the dataset including statements, questions and the true\n",
    "labels (in red) in Tables 1 and 2.\"\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1zwM3eG-QuTkcyWWFzgius2r_xCMyTPOo\"><img src=\"https://drive.google.com/uc?export=view&id=18_X6GfoOLawuDXPhaapdHhN5cR6xIn_i\" width=\"700px\"></a>\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1GpyNrRy9B294D01SpspKX9mpxVFqp0D5\"><img src=\"https://drive.google.com/uc?export=view&id=1LtxXkbkcKTfAxnkv0vn_VdwVwXQQfOz9\" width=\"700px\"></a>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_RYJ78NTXEn6"
   },
   "source": [
    "### Results for DNC\n",
    "\n",
    "#### bAbI\n",
    "\n",
    "Mean test error rate 7.5% $\\rightarrow$ 3.8%\n",
    "\n",
    "#### Randomly generated graph tasks\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1ckenwxkD75EwfRJSED0O0xi20PtCEMJ3\"><img src=\"https://drive.google.com/uc?export=view&id=1-eN4vjXV3D_6HMrbsVSMqlmm8qjkUPOx\" width=\"700px\"></a>\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1wr7CT728KYoVG44P89R5WnVmUVAr5WLC\"><img src=\"https://drive.google.com/uc?export=view&id=1qNTu8nO5uJLBdlmw97c7KQnwm7yq8BWQ\"  width=\"600px\"></a>\n",
    "\n",
    "#### Moving objects (mini SHRDLU)\n",
    "\n",
    "This is the domaion of Reinforcement Learning...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
