{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture models and EM (Expectation Maximisation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixture models\n",
    "\n",
    "__Different types of clustering methods__\n",
    "- hard clustering: clusters do not overlap element either belongs to cluster or it does not\n",
    "- soft clustering: clusters may overlap stength of association between clusters and instances\n",
    "\n",
    "__Mixture models__\n",
    "- probabilistically-grounded way of doing soft clustering\n",
    "- each cluster: a generative model (Gaussian or multinomial)\n",
    "- parameters (e.g. mean/covariance are unknown)\n",
    "\n",
    "\n",
    "__Expectation Maximization (EM) algorithm__\n",
    "- automatically discover all parameters for the $\\mathrm{K}$ \"sources\"\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixture models in 1-d\n",
    "\n",
    "\n",
    "__Observations $x_{1} \\ldots x_{n}$__\n",
    "- $\\mathrm{K}=2$ Gaussians with unknown $\\mu, \\sigma^{2}$\n",
    "- estimation trivial if we know the\n",
    "source of each observation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1HcAIjOtyH9mJMDnwUmlBrKwOg0V_Fhie\"><img src=\"https://drive.google.com/uc?export=view&id=1PFaZw8zS-DxM6g997TseO-4xLoSFN7VT\" width=\"300px\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we know which cluster each point belongs to easy to calculate mean and variance of the Gaussians\n",
    "\n",
    "Mean:\n",
    "$$\n",
    "\\mu_{b}=\\frac{x_{1}+x_{2}+\\ldots+x_{n}}{n_{b}}\n",
    "$$\n",
    "\n",
    "Variance:\n",
    "$$\n",
    "\\sigma_{b}^{2}=\\frac{\\left(x_{1}-\\mu_{b}\\right)^{2}+\\ldots+\\left(x_{n}-\\mu_{b}\\right)^{2}}{n_{b}}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1jlw8y5Z_6lVgGry4LxUWwaX4zFSVt6as\"><img src=\"https://drive.google.com/uc?export=view&id=11kzbjiUVK6z4_v9128BUoO2TQfVqEwUs\" width=\"300px\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What if we don't konw the source__\n",
    "- k different data points, suspect they come from different Gaussians but don't know which data point belongs to which Gaussian\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=19NiPYuu2iOSc6u2O2UMb7jU7YhH2Oirs\" width=\"300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we knew parameters of the Gaussians $\\left(\\mu, \\sigma^{2}\\right)$\n",
    "- can guess whether point is more likely to be a or b (which parameter from which Gaussian)\n",
    "- can calculate for each point what is the probability it is coming from the yellow Gaussian and the probabiltiy it is coming from the blue Gaussian\n",
    "\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1EHE5bIz3gWRGdOTVJKRiX9-2ITJic6aa\"><img src=\"https://drive.google.com/uc?export=view&id=17ZMKQgFdWRraCHMLcev5au4Mezw5m-7o\" width=\"300px\"></a>\n",
    "\n",
    "Use Bayes rule and Gaussian Formula \n",
    "\n",
    "e.g. probability of point $x_1$ being blue use Bayes rule\n",
    "\n",
    "$$\n",
    "P\\left(b \\mid x_{i}\\right)=\\frac{P(x_1 \\mid b) P(b)}{P(x_1 \\mid b) P(b)+P(x_1 \\mid a) P(a)}\n",
    "$$\n",
    "\n",
    "This is essentially a weighing function which ensures that the probability of every point across all Gaussians adds up to 1\n",
    "\n",
    "And for the generative probability use the Gaussian formula\n",
    "\n",
    "$$\n",
    "P\\left(x_{i} \\mid b\\right)=\\frac{1}{\\sqrt{2 \\pi \\sigma_{b}^{2}}} \\exp \\left(-\\frac{\\left(x_{1}-\\mu_{b}\\right)^{2}}{2 \\sigma_{b}^{2}}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1Z4JlvOdBLYzlqa4zPaz0lf4muJGnaExM\"><img src=\"https://drive.google.com/uc?export=view&id=1jNvmc8VMjyGbo78-F3P0rNvNJUdEkrmL\" width=\"300px\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation Maximisation (EM)\n",
    "\n",
    "\n",
    "__Chicken and egg problem__\n",
    "- need $\\left(\\mu_{\\mathrm{a}}, \\sigma_{\\mathrm{a}}^{2}\\right)$ and $\\left(\\mu_{\\mathrm{b}}, \\sigma_{\\mathrm{b}}^{2}\\right)$ to guess source of points\n",
    "- need to know source to estimate $\\left(\\mu_{a}, \\sigma_{a}^{2}\\right)$ and $\\left(\\mu_{b}, \\sigma_{b}^{2}\\right)$\n",
    "\n",
    "__EM algorithm__\n",
    "- start with two randomly placed Gaussians $\\left(\\mu_{a}, \\sigma_{a}^{2}\\right),\\left(\\mu_{b}, \\sigma_{b}^{2}\\right)$\n",
    "- E Step: for each point: $\\mathrm{P}\\left(\\mathrm{b} \\mid \\mathrm{x}_{i}\\right)=$ does it look like it came from $\\mathrm{b}$ ?\n",
    "- M step: just $\\left(\\mu_{a}, \\sigma_{a}^{2}\\right)$ and $\\left(\\mu_{b}, \\sigma_{b}^{2}\\right)$ to fit points assigned to them\n",
    "- iterate until convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EM: 1-d example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task: two Gaussians- want to discover what they are__\n",
    "\n",
    "\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1CprxK0z9aBxvHh5-aSeapvRET0XDwB-J\"><img src=\"https://drive.google.com/uc?export=view&id=1IdBxFid5g37pbvPbO1SeOhKq_2wOkZYg\" width=\"300px\"></a>\n",
    "\n",
    "First step- how likely is each point from the yellow or from the blue:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "For each point- does it look more like the yellow or the blue Gaussian\n",
    "\n",
    "$$\n",
    "P\\left(x_{i} \\mid b\\right)=\\frac{1}{\\sqrt{2 \\pi \\sigma_{b}^{2}}} \\exp \\left(-\\frac{\\left(x_{1}-\\mu_{b}\\right)^{2}}{2 \\sigma_{b}^{2}}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "Then when you compute Bayesian posterior take probabilities from blue an yellow combine them with the priors, $b_i$ for the point just on the right of the blue Gaussian is almost going to be 1. Much more unlike yellow than blue\n",
    "\n",
    "$$\n",
    "P\\left(b \\mid x_{i}\\right)=\\frac{P(x_i \\mid b) P(b)}{P(x_i \\mid b) P(b)+P(x_i \\mid a) P(a)}\n",
    "$$\n",
    "\n",
    "Then $a_i$ is :\n",
    "\n",
    "$$\n",
    "a_{i}=P\\left(a \\mid x_{i}\\right)=1-b_{i}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1JN2MU1hhC_dDdqx4eKhIzrwlaKyMvpCG\"><img src=\"https://drive.google.com/uc?export=view&id=1BXPxTixT6ASLQYZaQQy6vgF9hzopwJnw\" width=\"300px\"></a>\n",
    "\n",
    "Once we have done \"coloring\", estimating with which likelihood each points belongs to a Gaussian we can do the reestimation of the mean and standard deviation of each Gaussian:\n",
    "\n",
    "add up \"x\" es for the points and divide by the sum of the probabilities (basically a mean weighted by the probabilities)\n",
    "\n",
    "\n",
    "$$\n",
    "\\mu_{b}=\\frac{b_{1} x_{1}+b_{2} x_{2}+\\ldots+b_{n} x_{n}}{b_{1}+b_{2}+\\ldots+b_{n}}\n",
    "$$\n",
    "\n",
    "\n",
    "a probability weighted mean (soft assignment in contrast to K-means where the assignment is hard)..\n",
    "\n",
    "and then estimate the standard deviation accordingly \n",
    "\n",
    "\n",
    "$$\n",
    "\\sigma_{i}^{2}=\\frac{b_{1}\\left(x_{1}-\\mu_{1}\\right)^{2}+\\ldots+b_{n}\\left(x_{n}-\\mu_{n}\\right)^{2}}{b_{1}+b_{2}+\\ldots+b_{n}}\n",
    "$$\n",
    "\n",
    "Then we do the same for a, the yellow points\n",
    "\n",
    "\n",
    "$$\n",
    "\\mu_{a}=\\frac{a_{1} x_{1}+a_{2} x_{2}+\\ldots+a_{n} x_{s}}{a_{1}+a_{2}+\\ldots+a_{n}}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\sigma_{a}^{2}=\\frac{a_{1}\\left(x_{1}-\\mu_{a}\\right)^{2}+\\ldots+a_{n}\\left(x_{n}-\\mu_{a}\\right)^{2}}{a_{1}+a_{2}+\\ldots+a_{n}}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After updating (one iteration)\n",
    "\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1zAO6QSnSW0mjvh17TT3Tz5Ik8T7VPINV\"><img src=\"https://drive.google.com/uc?export=view&id=1fG77sJ3R1w7ZHna9dv5FMhPSU8-pyVZN\" width=\"300px\"></a>\n",
    "\n",
    "Another iteration\n",
    "\n",
    "\n",
    "<a href=\"http://drive.google.com/uc?export=view&id=1jsLTSIGwpidzGqfrCeCCw_I_bwFzZZDx\"><img src=\"https://drive.google.com/uc?export=view&id=115EJmz74irKWa-Qhlqp7x0TBXa93cdqn\" width=\"600px\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Models d>1\n",
    "\n",
    "The main difference from the previous part 2, is that instead of a scalar variance we now estimate a covariance matrix, using the same posteriors as before.\n",
    "\n",
    "\n",
    "- Data with d attributes, from $\\mathrm{k}$ sources\n",
    "- Each source c is a Gaussian\n",
    "- Iteratively estimate parameters:\n",
    "\n",
    "\n",
    "(1) prior: what % of instances came from source c?\n",
    "$$\n",
    "P(c)=\\frac{1}{n} \\sum_{i=1}^{n} P\\left(c \\mid \\vec{x}_{i}\\right)\n",
    "$$\n",
    "\n",
    "(2) mean: expected value of attribute j from source c\n",
    "\n",
    "$$\n",
    "\\mu_{c, j}=\\sum_{i=1}^{n}\\left(\\frac{P\\left(c \\mid \\bar{x}_{i}\\right)}{n P(c)}\\right) x_{i, j}\n",
    "$$\n",
    "\n",
    "(3) covariance: how correlated are attributes $\\mathrm{j}$ and $\\mathrm{k}$ in source c? \n",
    "\n",
    "\n",
    "$$\n",
    "\\left(\\Sigma_{c}\\right)_{j, k}=\\sum_{i=1}^{n}\\left(\\frac{P\\left(r \\vec{x}_{i}\\right)}{n P(c)}\\right)\\left(x_{i, j}-\\mu_{c, j}\\right)\\left(x_{i, k}-\\mu_{c, k}\\right)\n",
    "$$\n",
    "\n",
    "(4) base on our guess of the covariance for each instance\n",
    "\n",
    "$$\n",
    "P\\left(c \\mid \\vec{x}_{i}\\right)=\\frac{P\\left(\\vec{x}_{i} \\mid c\\right) P(c)}{\\sum_{c^{\\prime}-1}^{k} P\\left(\\vec{x}_{i} \\mid c^{\\prime}\\right) P\\left(c^{\\prime}\\right)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(\\vec{x}, \\mid c)=\\frac{1}{\\sqrt{2 \\pi} \\Sigma_{c} \\mid} \\exp \\left(-\\frac{1}{2}\\left(\\vec{x}_{i}-\\vec{\\mu}_{c}\\right) \\Sigma_{c}^{-1}\\left(\\vec{x}_{i}-\\vec{\\mu}_{i}\\right)\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(This notebook is based on: [Victor Lavrenko](https://www.youtube.com/user/victorlavrenko))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
