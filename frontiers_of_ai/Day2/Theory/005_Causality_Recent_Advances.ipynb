{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recent Advances in Causal modelling\n",
    "\n",
    "## Main motivation\n",
    "- High dimensional data (curse of dimensionality)\n",
    "- Hidden/latent confounders\n",
    "- More effective representation of non-linear effects\n",
    "\n",
    "Get to know state of the art of causal models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. General Intuition of Machine Learning Models\n",
    "\n",
    "\"Learning Representations for Counterfactual Inference\" (2019) by Johansson et al.  [here](http://proceedings.mlr.press/v48/johansson16.pdf).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main contributions:**\n",
    "-\tShow how to formulate problem of **counterfactual inference** as **domain adaptation problem** (specifically covariate shift)\n",
    "-\tLearning **representations** that **encourage similarity (balance) between the treated and control populations**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the set $\\hat{P}^F ∼ P^F$  the **empirical factual distribution**, and the set $\\hat{P}^{CF} ∼P^{CF}  $ the **empirical counterfactual distribution** respectively. Because **$P^F$ and $P^{CF}$ need not to be equal**, the problem of causal inference by counterfactual prediction might require **inference over a different distribution than** the one from which **samples** are given. \n",
    "\n",
    "In machine learning terms, this means that the **feature distribution** of the **test set differs** from that of the **train set**. This is a case of **covariate shift**, which is a special case of domain adaptation\n",
    "\n",
    "Specifically, we have that $P^F(x; t) = P (x) · P (t|x)$ and\n",
    "$P^{CF} (x; t) = P (x) · P (\\lnot t|x)$. The **difference** between\n",
    "the observed (factual) sample and the sample we must perform inference on, lies **precisely in the treatment assignment\n",
    "mechanism, $P (t|x)$**.\n",
    "\n",
    "In observational studies, which are the focus of\n",
    "this work, the treatment assignment mechanism is not under our control and in general will not be independent of\n",
    "the context x. Therefore, in general, the counterfactual distribution will be different from the factual distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://drive.google.com/uc?export=view&id=1i8O6fqvgErzGYBQ7auIM_qyjAFhHS6qk\" width=75%>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Representation learned to trade-off three objectives:**\n",
    "\n",
    "(1) **Low-error** prediction of the **observed outcomes** over the **factual representation**\n",
    "\n",
    "(2) Enabling **low error** prediction of **unobserved counterfactuals** by taking into account relevant factual outcomes\n",
    "\n",
    "(3) **Distributions** of **treatment populations** are **similar or balanced**\n",
    "\n",
    "(1) Accomplished by means of **usual error minimization** over training set and regularization\n",
    "\n",
    "(2) Accomplished by **penalty** that encourages **counterfactual predictions to be close to nearest observed outcome from the perspective of the treated control set**\n",
    "\n",
    "(3) Accomplished by **minimizing discrepancy distance**, which is a hypothesis class dependent distance measure for **domain adaptation**. This could also be done by MMD (Maximum Mean Discrepancy)\n",
    "\n",
    "\n",
    "**Discrepancy Distance** $disc_h$:\n",
    "\n",
    "Intuitively, representations that **reduce the discrepancy between the treated and control populations** **prevent the learner from using \"unreliable\" aspects of the data** when trying to generalize form the factual to the counterfactual domains\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intuition of dicrepancy**\n",
    "\n",
    "Basically, the idea is to preserver local distances from the original parameters space\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1Y890kiKD_Ai91uOmWzBxJ_WsSVghmWf5\" width=30%>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__Balancing variable selection__\n",
    "\n",
    "A naive way of obtaining a balanced representation is to use only features that are already well balanced, i.e. features which have a similar distribution over both treated and control sets. However, imbalanced features can be highly predictive of the outcome, and should not always be discarded. A middle-ground is to restrict the influence of imbalanced features on the predicted outcome. We build on this idea by learning a sparse re-weighting of the features that minimizes the bound in Theorem $1 .$ The re-weighting determines the influence of a feature by trading off its predictive capabilities and its balance.\n",
    "\n",
    "We implement the re-weighting as a diagonal matrix $W$, forming the representation $\\Phi(x)=W x,$ with $\\operatorname{diag}(W)$ subject to a simplex constraint to achieve sparsity. Let $\\mathcal{N}=$ $\\left\\{x \\mapsto W x: W=\\operatorname{diag}(w), w_{i} \\in[0,1], \\sum_{i} w_{i}=1\\right\\}$ de-\n",
    "note the space of such representations. We can now apply Algorithm 1 with $\\mathcal{H}_{l}$ the space of linear hypotheses. Because the hypotheses are linear, $\\operatorname{disc}(\\Phi)$ is a function of the distance between the weighted population means, see Section $4.1 .$ With $p=\\mathbb{E}[t], c=p-1 / 2, n_{t}=\\sum_{i=1}^{n} t_{i}$\n",
    "$\\mu_{1}=\\frac{1}{n_{t}} \\sum_{i: t_{i}=1}^{n} x_{i},$ and $\\mu_{0}$ analogously defined,\n",
    "$$\n",
    "\\operatorname{disc}_{\\mathcal{H}_{i}}(X W)=c+\\sqrt{\\left.c^{2}+\\| W\\left(p \\mu_{1}-(1-p) \\mu_{0}\\right)\\right] \\|_{2}^{2}}\n",
    "$$\n",
    "To minimize the discrepancy, features $k$ that differ a lot between treatment groups will receive a smaller weight $w_{k}$ Minimizing the overall objective $B,$ involves a trade-off between maximizing balance and predictive accuracy. We minimize (2) using alternating sub-gradient descent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Balancing variable selection**\n",
    "- A **naive way of obtaining a balanced representation** is to use **only features that are already well balanced**, i.e. features which have a similar distribution over both treated and control sets\n",
    "-  However, **imbalanced features can be highly predictive of the outcome**, and should not always be discarded\n",
    "-  A middle-ground is to **restrict the influence of imbalanced features on the predicted outcome**.\n",
    "- We build on this idea by learning a sparse re-weighting of the features . The re-weighting determines the influence of a feature by **trading off its predictive capabilities and its balance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Blessing of multiple causes and latent deconfounders\n",
    "\n",
    "\"The Blessings of Multiple Causes\" (2019) by Wang and Blei  [here](https://www.tandfonline.com/doi/full/10.1080/01621459.2019.1686987).\n",
    "\n",
    "- Paper not so much an **advancement of empirical precision** in inferring causes, but rather  in terms of showing that **multiple causes** of which some have an effect on both the treatment and the outcome (confounders) and are **not observed (latent) can be of advantage**\n",
    "- By using **latent factor / latent variable**  models to **estimate the generative distribution**, we can deal with **latent, unobserved confounders and still correctly infer causality**\n",
    "- It can be seen as the **main motivation** and formal explanation to apply **latent variable models** that are parametrized through machine learning for causal inference\n",
    "- The paper is an excellent theoretical explanation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Observational data often assumes \"strong ignorability\"**, that all confounders are observed\n",
    "- Deconfounder **infers a latent variable as substitute for unobserved confounders** and then uses that substitute to perform causal inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Deconfounder: multiple causal inference without ignorability \n",
    "\n",
    "Three steps for deconfounder (for non-observed confounding latent variables):\n",
    "\n",
    "(1) Find a **good latent variable model of the assignment mechanism $p(z,a_1,....,a_m)$**, where z is a local factor \n",
    "\n",
    "\n",
    "(2) Second, use the model to infer the **latent variable for each individual $p(z|a_{i1},....,a_{im})$**\n",
    "\n",
    "\n",
    "(3) Use the inferred variable as a **substitute for unobserved confounders** and form causal inferences \n",
    "\n",
    "__First Step__\n",
    "\n",
    "In the first step of the deconfoudner, define and fit a \"probabalistic factor model\" to capture the joint distribution of causes $p(a_1,....,a_m)$. A factor model posits per-individual latent variables $Z_i$, which we call local factors, and uses them to model the assigned causes. The model is:\n",
    "\n",
    "$$Z_i \\sim p(.|\\alpha), i=1,...,n$$\n",
    "\n",
    "\n",
    "$$A_{ij}|Z \\sim p(.|z_i, \\theta_j), j=1,...,m$$\n",
    "\n",
    "where $\\alpha$ parametrizes the distribution of $Z_i$ and $\\theta_j$ parametrizes the per-cause distribution of $A_{ij}$. Notice that $Z_i$ can be multi dimensional. Factor models encompass many methods including deep generative models.\n",
    "\n",
    "\n",
    "__Second step__\n",
    "\n",
    "In the next step, use the fitted factor model to calculate the conditional expectation of each individual's local factor weights $\\hat{z}=\\mathbb{E}_M[Z_i|A_i=\\pmb{a_i}]$. We emphasize that this expectation is from the fitted model M(not the population distribution). \n",
    "\n",
    "\n",
    "__Third step__\n",
    "\n",
    "In the final step, condition on $\\hat{z_i}$ as a substitute confounder and proceed with causal inference. \n",
    "\n",
    "For example, we can estimate $\\mathbb{E}[\\mathbb{E}[Y_i(\\pmb{a_i})|\\hat{Z}_i,A_i=\\pmb{a}]$. The main idea is this: if the factor model captures the distribution of assigned causes-  a testable proposition- then we can safely use $\\hat{z}_i$ as a variable that contains the confounders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Why is this strategy sensible strategy?__ Assume the fitted factor model captures the (unconditional) distribution of assigned causes $p(a_{i1},...,a_{im})$. This means that all causes are conditionally independent given the local latent factors. \n",
    "\n",
    "$$p(a_{i1},.....,a_{im}|z_i)=\\prod_{j=1}^m p(a_{ij}|z_i)$$\n",
    "\n",
    "There must not be any unobserved single cause confounders i.e. confounders that do not have any influence on other observed independent variables.\n",
    "\n",
    "-> if we find a factor model that captures the population distribution of assigned causes, then we have essentially discovered a variable that captures all multiple-cause confounders.\n",
    "The reason is that multiple cause confounders induces dependence among the assigned causes, regardless of how the connect to the potential outcome function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://drive.google.com/uc?export=view&id=1iKfdvrSdtPcYsvJs4nGW3ekm8Rildxvu\" width=75%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is the deconfounder a free lunch?**: no, trades confounding bias for estimation variance (due to larger number of parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does the deconfounder relate to the gernalized propensity score?**\n",
    "- Can be interpreted as generalized propensity score approach, except where the propensity score model involves latent variables. If we treat the substitute confounder $Z_i$ as observed covariates, then the factor model $P(A_i|Z_i)$ is precisely the propensity score of the causes $A_i$. Moreover, it is the multiplicity of causes  $A_{i1},....,A_{im}$ that makes a latent variable $Z_i$ feasible: we can construct $Z_i$ by finding a random variable that renders all the causes conditionally independent\n",
    "\n",
    "**What about instrumental variables?**\n",
    "\n",
    "The deconfounder can also be interpreted as a way of constructing instruments, using latent factor models. Think of a factor model of the cause with linearly separable noise $A_{ij}=f(Z_i)+\\epsilon{ij}$. Given the substitute confounder, consider the residual of the cause $\\epsilon_{ij}$. Assuming single ignorability, the variable $\\epsilon{ij}$ is an instrumental variable for the jth cause $A_{ij}$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good recap of Factor Analysis and its commonalities and difference to Principcal Component Analysis can be found  [here](https://stats.idre.ucla.edu/spss/seminars/introduction-to-factor-analysis/a-practical-introduction-to-factor-analysis/).\n",
    "\n",
    "Not that the paper does not talk about factor analysis per se but probabalistic factor analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Local similarity preserved individual treatment effect (SITE) estimation method based on deep representation learning\n",
    "\n",
    "Recent papers in relation to the same idea:\n",
    "\n",
    "\"Representation Learning for Treatment Effect Estimation from Observational Data\" (2019) by Yao et al [here](http://papers.nips.cc/paper/7529-representation-learning-for-treatment-effect-estimation-from-observational-data.pdf).\n",
    "\n",
    "- Use Neural network to generated **balanced representation**\n",
    "- And add measure into cost function to **preserve local similarity**: similar units shall have similar outcomes\n",
    "\n",
    "The key idea of SITE is to map the original __pre-treatment covariate space X into a latent space Z__ learned by deep neural networks. Particularly, SITE attempts to enforce __two special properties on the latent space Z__, including the balanced distribution and preserved\n",
    "similarity:\n",
    "- Position Dependent Deep Metric (__PDDM__)  -> local similarity \n",
    "- Middle Point Distance Minimization (__MPDM__) -> balanced distribb\n",
    "\n",
    "SITE maps mini-batches of units from the\n",
    "covariate space to a latent space using a representation network. In the latent space, SITE preserves\n",
    "the local similarity information using the Position-Dependent Deep Metric (PDDM), and balances\n",
    "the data distributions with a Middle-point Distance Minimization (MPDM) strategy. PDDM and\n",
    "MPDM can be viewed as a regularization, which helps learn a better representation and decrease\n",
    "the generalization error in estimating the potential outcomes. Implementing PDDM and MPDM\n",
    "only involves triplet pairs and quartic pairs of units respectively from each mini-batch, which makes\n",
    "SITE efficient for large-scale data. The proposed method is validated on both synthetic and real world datasets, and the experimental results demonstrate its advantages brought by preserving the\n",
    "local similarity information.\n",
    "\n",
    "\n",
    "The key idea of SITE is to map the original pre-treatment covariate\n",
    "space X into a latent space Z learned by deep neural networks. Particularly, SITE attempts to enforce two special properties on the latent space Z, including the balanced distribution and preserved\n",
    "similarity.\n",
    "\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1S0LOUCK3WuTmaKrES9NNLKU96LYZdPk5\" width=75%>\n",
    "\n",
    "\n",
    "The framework of SITE is shown in Figure 1, which contains five major components: representation\n",
    "network, triplet pairs selection, position-dependent deep metric (PDDM), middle point distance\n",
    "minimization (MPDM), and the outcome prediction network. To improve the model efficiency,\n",
    "SITE takes input units in a mini-batch fashion, and triplet pairs could be selected from every minibatch. The representation network learns latent embeddings for the input units. With the selected\n",
    "triplet pairs, PDDM and MPDM are able to preserve the local similarity information and meanwhile\n",
    "achieve the balanced distributions in the latent space. Finally, the embeddings of mini-batch are fed\n",
    "forward to a dichotomous outcome prediction network to get the potential outcomes.\n",
    "\n",
    "The loss function of SITE is as follows:\n",
    "$$\n",
    "\\mathcal{L}=\\mathcal{L}_{\\mathrm{FL}}+\\beta \\mathcal{L}_{\\mathrm{PDDM}}+\\gamma \\mathcal{L}_{\\mathrm{MPDM}}+\\lambda\\|W\\|_{2}\n",
    "$$\n",
    "\n",
    "where $ \\mathcal{L}_{\\mathrm{FL}} $ is the factual loss between the estimated and observed factual outcomes. $ \\mathcal{L}_{\\mathrm{PDDM}} $ and $ \\mathcal{L}_{\\mathrm{MPDM}} $ are the loss functions for PDDM and MPDM, respectively. The last term is $ L_{2} $ regularization on model parameters $ W $ (except the bias term).\n",
    "\n",
    "\n",
    "**Triplet pair selection**\n",
    "\n",
    "Step 1: Choose data pair $ ( \\mathbf{x}_{i}, \\mathbf{x}_{\\hat{j}} ) $ s.t.\n",
    "$$\n",
    "(\\hat{i}, \\hat{j})=\\underset{i \\in \\mathcal{T}, j \\in \\mathcal{C}}{\\operatorname{argmin}}\\left|s_{i}-0.5\\right|+\\left|s_{j}-0.5\\right|\n",
    "$$\n",
    "\n",
    "\n",
    "where $ \\mathcal{T} $ and $ \\mathcal{C} $ denote the treated group and control group, respectively. $ \\mathbf{x}_{i} $ and $ \\mathbf{x}_{j} $ are the closest units in the intermediate region where both control and treated units are mixed.\n",
    "- Step 2: Choose $ \\left(\\mathbf{x}_{\\hat{k}}, \\mathbf{x}_{i}\\right) $ s.t.\n",
    "$$\n",
    "\\hat{k}=\\underset{k \\in \\mathcal{C}}{\\operatorname{argmax}}\\left|s_{k}-s_{i}\\right|, \\quad \\hat{l}=\\underset{l}{\\operatorname{argmax}}\\left|s_{l}-s_{\\hat{k}}\\right|\n",
    "$$\n",
    "\n",
    "\n",
    "$ \\mathbf{x}_{\\hat{k}} $ is the farthest control unit from $ \\mathbf{x}_{\\hat{i}}, $ and is on the margin of control group with plenty of control units.\n",
    "\n",
    "- Step 3: Choose $ \\left(\\mathbf{x}_{\\text {in }}, \\mathbf{x}_{\\hat{n}}\\right) $ s.t.\n",
    "$$\n",
    "\\hat{m}=\\underset{m \\in \\mathcal{T}}{\\operatorname{argmax}}\\left|s_{m}-s_{\\hat{j}}\\right|, \\quad \\hat{n}=\\underset{n}{\\operatorname{argmax}}\\left|s_{n}-s_{\\hat{m}}\\right|\n",
    "$$\n",
    "$ \\mathbf{x}_{\\hat{k}} $ is the farthest control unit from $ \\mathbf{x}_{i}, $ and is on the margin of control group with plenty of control units.\n",
    "\n",
    "The pair $ (\\hat{i}, \\hat{j}) $ lies in the intermediate region of control and treated groups. Pairs $ (\\hat{k}, l) $ and $ (\\hat{m}, \\hat{n}) $ are located on the margins that are far away from the intermediate region. The selected triplet pairs can be viewed as hard cases. Intuitively, if the desired property of preserved similarity can be achieved for the hard cases, it will hold for other cases as well. Thus, we focus on preserving such a property for the hard cases (e.g., triplet pairs) in the latent space, and employ PDDM to achieve this goal.\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1lGBA0LEvfo9DAjCtk-0jj8OsSoxoYDyu\" width=75%>\n",
    "\n",
    "\n",
    "**Position-Dependent Deep Metric (PDDM)**\n",
    "\n",
    "The PDDM component measures the local similarity of\n",
    "two units based on their relative and absolute positions in the latent space Z.\n",
    "\n",
    "The PDDM learns a metric that makes the local similarity of $ \\left(\\mathbf{z}_{i}, \\mathbf{z}_{j}\\right) $ in the latent space close to their similarity in the original space. The similarity $ \\hat{S}(i, j) $ is defined as:\n",
    "$$\n",
    "\\hat{S}(i, j)=\\mathbf{W}_{s} \\mathbf{h}+b_{s}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "\\text { where } \\mathbf{h}=\\sigma\\left(\\mathbf{W}_{c}\\left[\\frac{\\mathbf{u}_{1}}{\\left\\|\\mathbf{u}_{1}\\right\\|_{2}}, \\frac{\\mathbf{v}_{1}}{\\left\\|\\mathbf{v}_{1}\\right\\|_{2}}\\right]^{T}+\\right. \\\\\n",
    "\\left.b_{c}\\right), \\mathbf{u}=\\left|\\mathbf{z}_{i}-\\mathbf{z}_{j}\\right|, \\mathbf{v}=\\frac{\\left|\\mathbf{z}_{i}+\\mathbf{z}_{j}\\right|}{2}, \\mathbf{u}_{1}=\\sigma\\left(\\left.\\mathbf{W}_{u}\\right|_{\\|\\left.\\mathbf{u}\\right|_{2}} ^{\\mathbf{u}}+b_{u}\\right), \\mathbf{v}_{1}=\\sigma\\left(\\mathbf{W}_{v} | \\mathbf{v}_{\\| 2}+b_{v}\\right) \\cdot \\mathbf{W}_{c}, \\mathbf{W}_{s}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "\n",
    "$ \\mathbf{W}_{v}, \\mathbf{W}_{u}, b_{c}, b_{s}, b_{v} $ and $ b_{u} $ are the model parameters. $ \\sigma(\\cdot) $ is a nonlinear function such as ReLU. As shown in Figure $ 3, $ the PDDM structure first calculates the feature mean vector $ \\mathbf{v} $ and the absolute position vector $ u $ of the input $ \\left(\\mathbf{z}_{i}, \\mathbf{z}_{j}\\right), $ and then feeds $ \\mathbf{v} $ and $ \\mathbf{u} $ to the fully connected layers separately. After normalization, PDDM concatenates the learned vectors $ \\mathbf{u}_{1} $ and $ \\mathbf{v}_{1}, $ and feeds it to another fully connected layer to get the vector $ \\mathbf{h} $. The final similarity score $ \\hat{S}(,) $ is calculated by mapping the score $ h $ to the $ \\mathcal{R}^{1} $ space.\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=18qfyotW1uQ1umREAWbtnrxCLsl7Y1RXJ\" width=75%>\n",
    "\n",
    "\n",
    "The loss function of PDDM is as follows:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{L}_{\\mathrm{PDDM}}=\\frac{1}{5} \\sum_{\\hat{i}, \\hat{\\jmath}, \\hat{k}, \\hat{l}, \\hat{m}, \\hat{n}} &\\left[(\\hat{S}(\\hat{k}, \\hat{l})-S(\\hat{k}, \\hat{l}))^{2}+(\\hat{S}(\\hat{m}, \\hat{n})-S(\\hat{m}, \\hat{n}))^{2}+(\\hat{S}(\\hat{k}, \\hat{m})-S(\\hat{k}, \\hat{m}))^{2}\\right.\\\\\n",
    "&\\left.+(\\hat{S}(\\hat{i}, \\hat{m})-S(\\hat{i}, \\hat{m}))^{2}+(\\hat{S}(\\hat{j}, \\hat{k})-S(\\hat{j}, \\hat{l}))^{2}\\right]\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $ S(i, j)=0.75\\left|\\frac{s_{i}+s_{j}}{2}-0.5\\right|-\\left|\\frac{s_{i}-s_{j}}{2}\\right|+0.5 . $ Similar to the design of the PDDM structure, the true similarity score $ S(i, j) $ is calculated using the mean and the difference of two propensity scores. The loss function $ \\mathcal{L}_{\\mathrm{PDDM}} $ measures the similarity loss on five pairs in each mini batch: the pairs located in the margin area of the mini batch, i.e., $ (\\mathbf{z}_{k}, \\mathbf{z}_{l}) $ and  $\\left(\\mathbf{z}_{m}, \\mathbf{z}_{n}\\right) ; $ the pair that is most dissimilar among the selected points, i.e., $ \\left(\\mathbf{z}_{k}, \\mathbf{z}_{m}\\right) ; $ the pairs located in the margin of the control/treated group,\n",
    "i.e., $ \\left(\\mathbf{z}_{j}, \\mathbf{z}_{k}\\right) $ and $ \\left(\\mathbf{z}_{i}, \\mathbf{z}_{m}\\right) . $ As shown in Figure $ 2, $ minimizing $ \\mathcal{L}_{\\text {PDDM }} $ on the above five pairs helps to preserve the similarity when mapping the original data into the representation space.\n",
    "\n",
    "By using the PDDM structure, the similarity information within and between each of the pairs $ \\left(\\mathbf{z}_{\\hat{k}}, \\mathbf{z}_{\\hat{l}}\\right),\\left(\\mathbf{z}_{\\hat{m}}, \\mathbf{z}_{\\hat{n}}\\right), $ and $ \\left(\\mathbf{z}_{\\hat{k}}, \\mathbf{z}_{\\hat{n}}\\right) $ will be preserved.\n",
    "\n",
    "\n",
    "\n",
    "**Middle Point Distance Minimization (MPDM)**\n",
    "\n",
    "To achieve balanced distributions in the latent space, we design the middle point distance minimization (MPDM) component in SITE. MPDM makes the middle point of $ \\left(\\mathbf{z}_{i}, \\mathbf{z}_{m}\\right)$ close to the middle point of $ \\left(\\mathbf{z}_{j}, \\mathbf{z}_{\\hat{k}}\\right) . $ The units $ \\mathbf{z}_{i} $ and $ \\mathbf{z}_{j} $ are located in a region where the control and treated units are sufficient and mixed. In other words, they are the closest units from treated and control groups\n",
    "\n",
    "separately that lie in the intermediate zone. Meanwhile, $ \\mathbf{z}_{\\hat{k}} $ is the farthest control unit from the margin of the treated group, and $ \\mathbf{z}_{m} $ is the farthest treated unit from the margin of control group. We use the middle points of $ \\left(\\mathbf{z}_{\\hat{i}}, \\mathbf{z}_{\\hat{m}}\\right) $ and $ \\left(\\mathbf{z}_{\\hat{j}}, \\mathbf{z}_{\\hat{k}}\\right) $ to approximate the centers of treated and control groups, respectively. By minimizing the distance of two middle points, the units in the margin area are gradually made close to the intermediate region. As a result, the distributions of two groups will be balanced.\n",
    "The loss function of MPDM is as follows:\n",
    "$$\n",
    "\\mathcal{L}_{\\mathrm{MPDM}}=\\sum_{i, j, \\hat{k}, \\hat{m}}\\left(\\frac{\\mathrm{z}_{i}+\\mathrm{z}_{m}}{2}-\\frac{\\mathrm{z}_{j}+\\mathrm{z}_{k}}{2}\\right)^{2}\n",
    "$$\n",
    "The MPDM balances the distributions of two groups in the latent space, while the PDDM preserves the local similarity. A 2 -D toy example shown in Figure 4 vividly demonstrates the combined effect of MPDM and PDDM. Four units $ \\mathbf{x}_{i}, \\mathbf{x}_{j}, \\mathbf{x}_{k} $ and $ \\mathbf{x}_{\\hat{m}} $ are the same as what we choose in Figure 2 Figure 4 shows that MPDM makes the units that belong to treated group close to the control group, and PDDM restricts the way that the two groups close to each other. PDDM preserves the similarity information between $ \\mathbf{x}_{\\hat{k}} $ and $ \\mathbf{x}_{m} \\cdot \\mathbf{x}_{\\hat{k}} $ and $ \\mathbf{x}_{\\hat{m}} $ are the farthest data points in the treated and control groups. When MPDM makes two groups approaching each other, PDDM ensures that the data points $ \\mathbf{x}_{\\hat{k}} $ and $ \\mathbf{x}_{\\hat{m}} $ are still the farthest, which prevents MPDM squeezing all data points into one point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Variational inference and information Bottle-neck\n",
    "\n",
    "Recent papers in relation to the same idea:\n",
    "\n",
    "\n",
    "\"Reliable estimation of individual treatment effects with causal information bottleneck\" (2019) by Kim et al [here](https://arxiv.org/abs/1906.03118).\n",
    "\n",
    "\n",
    "\"Reliable Estimation of Individual Treatment Effect with Causal Information Bottleneck\" (2019) Parbhoo, Wiser and Roth [here](https://arxiv.org/abs/1807.02326).\n",
    "\n",
    "\n",
    "**Key mechanism:** \n",
    "- Confounder unobserved BUT noisy proxy of confounder available for inference\n",
    "- Confounders may be latent (in principle not observable)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combination of:** \n",
    "-    Deep variational autoencoders (learn the generative distributions)\n",
    "- Encourage independence of potential confounders through information bottle neck (Li et al., 2019) \n",
    "- Thus estimate average treatment effect (ATE) and Individual Treatment Effects (ITE) in the presence of noisy proxies \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General Idea of VAE**\n",
    "\n",
    " <img src=\"https://lilianweng.github.io/lil-log/assets/images/autoencoder-architecture.png\" width=110%>\n",
    "\n",
    "\n",
    "\n",
    "https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic intuition**\n",
    "\n",
    "Aim: Balanced and maximally expressive representation\n",
    "\n",
    "Causal information bottleneck:\n",
    "- Additionally **maximum compressivness** between the **representation** for **ITE prediction** and **observed covariates**\n",
    "- Ideal representation to predict counterfactual outcome\n",
    "- More robust for **overfitting** since it is encouraged to **throw away as much information about X as possible** (essentiall a form of regularization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Information Bottleneck**\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1d__X_oUgF66spF_nFOq8TvRRbTwtVfmX\" width=150%>\n",
    "\n",
    "\n",
    "\n",
    "**Statistics**: soft sufficient statistic\n",
    "**Information theory**: lossy compression, distortion ~ relevance\n",
    "**Machine learning**: maximally informative clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://drive.google.com/uc?export=view&id=1-zV2TylKo32ETQD27ZXCqqbsb_xKlM9I\" width=150%>\n",
    "\n",
    "\n",
    "Given joint distribution P(X,Y) and  seek mapping from X to Z- encoder/ clustering/ compression. Cost function has two terms to encourage compression by minimizing information that Z retains about X. second one- relevance. Maximises information that Z has about Y. ß is the weighing parameter trading the two off. The bigger beta the more the loss function will consider that T has information on Y. Small beta maximum compression, large beta encourages maximum relevance. Keep all the information about y. \n",
    "Markov constraint- after training on the joint distribution of x and y in our test-set we are receiving examples of X and need to predict information about Y without looking.\n",
    "Can be expanded using variational calculus approach taking derivatives and setting them to 0. Get three equations which one iterations to convergence from some initialization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://drive.google.com/uc?export=view&id=1CjRQ_K1n2jIJnVMr0Xn3W553EnIa4Jev\" width=150%>\n",
    "\n",
    "\n",
    "Solution : Second and third equation enforce Bayes rule and Markov constraint. First equation can be understood by thinking about the clustering approach. Conditional probability of z given x asks with which probability will we map data point x to cluster z. \n",
    "To answer this question we compare two conditional distributions of y given  x and y given z. What we essentially do is asking do data point x and cluster Z that we are considering mapping it to say the same thing about the relevant variable y. If they do the similarity measure between the distributions, the KL divergence will be small, the exponential will be large and we are likely to map the data-point to the cluster. Or if they are very different, the KL divergence will be large, the exponential will be small and we are not likely to map them to each other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Specifically, we assume a parametric form of the conditionals pφ(z|x), pθ(y|t, z) and pψ(t|z), as well as the Markov chain z − x − t − y. A graphical illustration of the proposed model is provided in Figure 2. The two terms in Equation 4 have the following forms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://drive.google.com/uc?export=view&id=18rex94rq8BzLo7-nxTyzKHCUArlWlCtT\" width=150%>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$minimize \\; \\mathbb{E} [Var(y_{cf}|x)]$   - this term is a penalty for the variance of the $y_{cf}$ given that particular x have occured. \n",
    "\n",
    "The graphical model of the above figure assumes that representation Z is conditionally independent of the treatment T given covariate X. Without additional constraint, this assumption can not be satisfied with a stochastic encoder $p_φ(z|x)$. \n",
    "\n",
    "Hence, mutual information guided disentangling is introduced.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mutual Information Guided Disentangled Representation (MIGDR)**\n",
    "In oder to encourage $Z\\perp T|X$ according to our graphical structure, we minimize the conditional mutual infomation between them:\n",
    "\n",
    "$$I(Z;T|X)=\\mathbb{E}_{p(x)}[D_{KL}(p(z,t|x)||p_{\\phi}(z|x)p(t|x))]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Counterfactual Predictive Variance Regularization (CPVR)**\n",
    "\n",
    "- Adds variance minimization to the predictive distirbution of unlabled data as a regularization term\n",
    "- In the regularized Baysian framework, this methods includes the intuition that an **unlabled samples is close to the labled sample in the representation space**\n",
    "-  In this paper, we provide an inductive bias so that counterfactual predictions generated by stochastic encoder are consistent to each other.\n",
    "\n",
    "$$L_v(\\phi, \\theta):=-\\mathbb{E}_{p(x)}[Var_{q_\\theta(y|x)}[y^{CF}|x]]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Performance Comparison of Algorithms\n",
    "\n",
    "<img src=\"http://drive.google.com/uc?export=view&id=1EopFED7cEfR_HwSYkTJr1cctJh3OvqsV\" width=50%>\n",
    "\n",
    "\n",
    "[Source: Kim et al. (2019)](https://arxiv.org/pdf/1906.03118.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 \"Alternative\" approaches - not based on potential outcome framework - but closely related to the idea of covariate shift\n",
    "\n",
    "\"A Meta-Transfer Objective for Learning to Disentangle Causal\n",
    "Mechanisms\" (2019) by Bengio et al [here](https://arxiv.org/abs/1901.10912).\n",
    "\n",
    "**Idea: the correct causal distribution generalizes faster: as there are changes the distribution has to be adjusted more slowly**\n",
    "- We propose to meta-learn causal structures based on **how fast a learner adapts to new distributions** arising from **sparse distributional changes**, e.g. due to interventions, actions of agents and other sources of non-stationarities\n",
    "- We show that under this assumption, the **correct causal structural choices lead to faster adaptation** to modified distributions because the changes are concentrated in one or just a few mechanisms when the learned knowledge is modularized appropriately. \n",
    "- The key idea is that if we learn a **\"correct\" causal structure** we will be much **faster to adapt to unseen interventions** (here causation is a tool for generalization)\n",
    "\n",
    "\n",
    "\"LEARNING NEURAL CAUSAL MODELS FROM UNKNOWN INTERVENTIONS\" (2019) by Ke et al. [here](https://arxiv.org/pdf/1910.01075.pdf).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
